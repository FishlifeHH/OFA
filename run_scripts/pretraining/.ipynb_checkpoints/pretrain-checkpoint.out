2023-03-15 13:59:28 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmp7jge8bvr
2023-03-15 13:59:28 - instantiator.py[line:76] - INFO: Writing /tmp/tmp7jge8bvr/_remote_module_non_scriptable.py
2023-03-15 13:59:32 - utils.py[line:255] - INFO: distributed init (rank 0): env://
2023-03-15 13:59:32 - utils.py[line:261] - INFO: Start init
2023-03-15 13:59:32 - distributed_c10d.py[line:228] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2023-03-15 13:59:32 - distributed_c10d.py[line:262] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
2023-03-15 13:59:32 - utils.py[line:271] - INFO: initialized host autodl-container-a33911ac3c-7acd8e14 as rank 0
single-machine distributed training is initialized.
2023-03-15 13:59:34 - train.py[line:77] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 4, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': True, 'max_tokens_valid': None, 'batch_size_valid': 4, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 50, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 5.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints', 'restore_file': '../../checkpoints/ofa_base.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 6000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 15, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=4, batch_size_valid=4, best_checkpoint_metric='loss', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=5.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='../../dataset/pretrain_data/vision_language_simple.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, detection_data=None, detection_selected_cols='0,1,2', device_id=0, disable_entangle=True, disable_validation=True, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=128, fp32_reduce_scatter=False, freeze_decoder_embedding=False, freeze_encoder_embedding=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, image_data=None, image_selected_cols='0,1,2', imagenet_default_mean_and_std=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=15, keep_ratio=0.0, label_smoothing=0.0, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[0.0001], lr_scheduler='polynomial_decay', mask_length='span-poisson', mask_ratio=0.3, max_epoch=50, max_image_size=768, max_source_positions=1024, max_src_length=1200, max_target_positions=1024, max_tgt_length=1200, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, neg_sample_dir='../../dataset/pretrain_data/negative_sample', no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_bins=1000, num_shards=1, num_workers=0, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=384, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', poisson_lambda=3.0, pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, pretrain_seed=7, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, random_ratio=0.0, reg_alpha=1.0, relu_dropout=0.0, replace_length=1, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='../../checkpoints/ofa_base.pt', sample_patch_num=196, save_dir='./checkpoints', save_interval=1, save_interval_updates=6000, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols='0,1,2,3,4,5,6,7', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, sync_bn=False, task='unify_task', tensorboard_logdir=None, text_data=None, text_selected_cols='0,1', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[1], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_ratio=0.01, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'unify_task', 'data': '../../dataset/pretrain_data/vision_language_simple.tsv', 'selected_cols': '0,1,2,3,4,5,6,7', 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 1200, 'max_tgt_length': 1200, 'code_dict_size': 8192, 'patch_image_size': 384, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'max_image_size': 768, 'text_data': None, 'image_data': None, 'detection_data': None, 'text_selected_cols': '0,1', 'image_selected_cols': '0,1,2', 'detection_selected_cols': '0,1,2', 'neg_sample_dir': '../../dataset/pretrain_data/negative_sample', 'code_image_size': 128, 'pretrain_seed': 7, 'mask_ratio': 0.3, 'random_ratio': 0.0, 'keep_ratio': 0.0, 'mask_length': 'span-poisson', 'poisson_lambda': 3.0, 'replace_length': 1}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.0, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0001]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.01, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [0.0001]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-03-15 13:59:34 - ofa_task.py[line:109] - INFO: source dictionary: 59457 types
2023-03-15 13:59:34 - ofa_task.py[line:110] - INFO: target dictionary: 59457 types
/root/miniconda3/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
2023-03-15 13:59:42 - train.py[line:110] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=59457, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2023-03-15 13:59:42 - train.py[line:111] - INFO: task: UnifyTask
2023-03-15 13:59:42 - train.py[line:112] - INFO: model: OFAModel
2023-03-15 13:59:42 - train.py[line:113] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2023-03-15 13:59:42 - train.py[line:114] - INFO: num. shared model params: 182,238,536 (num. trained: 182,238,536)
2023-03-15 13:59:42 - train.py[line:121] - INFO: num. expert model params: 0 (num. trained: 0)
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 row count 8015 total row count 8015
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2023-03-15 13:59:42 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2023-03-15 13:59:42 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 1 workers***********************
2023-03-15 13:59:42 - utils.py[line:761] - INFO: rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-03-15 13:59:42 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 1 workers***********************
2023-03-15 13:59:42 - train.py[line:152] - INFO: training on 1 devices (GPUs/TPUs)
2023-03-15 13:59:42 - train.py[line:157] - INFO: max tokens per device = None and max sentences per device = 4
2023-03-15 13:59:42 - trainer.py[line:458] - INFO: Preparing to load checkpoint ../../checkpoints/ofa_base.pt
2023-03-15 13:59:42 - trainer.py[line:624] - INFO: No existing checkpoint found ../../checkpoints/ofa_base.pt
2023-03-15 13:59:42 - trainer.py[line:639] - INFO: loading train data for epoch 1
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 row count 8015 total row count 8015
/root/miniconda3/lib/python3.8/site-packages/torchvision/transforms/functional.py:417: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
slice_id 0 seek offset 0
Total steps 100200, warmup steps 1002, warmup_factor 0.000998003992015968
2023-03-15 13:59:43 - trainer.py[line:703] - INFO: begin training epoch 1
2023-03-15 13:59:43 - train.py[line:305] - INFO: Start iterating over samples
2023-03-15 13:59:48 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-03-15 13:59:50 - progress_bar.py[line:272] - INFO: epoch 001:     11 / 2004 loss=11.102, loss_v1=0, loss_v2=0, nll_loss=11.102, ntokens=337.5, nsentences=8, sample_size=337.5, sample_size_v1=0, sample_size_v2=0, ppl=2198.45, wps=893, ups=2.67, wpb=337.5, bsz=8, num_updates=10, lr=9.98004e-07, gnorm=21.226, clip=100, loss_scale=64, train_wall=7, gb_free=15.8, wall=8
2023-03-15 13:59:51 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-03-15 13:59:54 - progress_bar.py[line:272] - INFO: epoch 001:     22 / 2004 loss=10.823, loss_v1=0, loss_v2=0, nll_loss=10.823, ntokens=328.8, nsentences=8, sample_size=328.8, sample_size_v1=0, sample_size_v2=0, ppl=1811.81, wps=872.5, ups=2.65, wpb=328.8, bsz=8, num_updates=20, lr=1.99601e-06, gnorm=19.598, clip=100, loss_scale=32, train_wall=4, gb_free=14.8, wall=11
2023-03-15 13:59:57 - progress_bar.py[line:272] - INFO: epoch 001:     32 / 2004 loss=10.377, loss_v1=0, loss_v2=0, nll_loss=10.377, ntokens=353.3, nsentences=8, sample_size=353.3, sample_size_v1=0, sample_size_v2=0, ppl=1329.38, wps=1030.1, ups=2.92, wpb=353.3, bsz=8, num_updates=30, lr=2.99401e-06, gnorm=14.335, clip=100, loss_scale=32, train_wall=3, gb_free=14.7, wall=15
2023-03-15 14:00:01 - progress_bar.py[line:272] - INFO: epoch 001:     42 / 2004 loss=9.93, loss_v1=0, loss_v2=0, nll_loss=9.93, ntokens=364.2, nsentences=8, sample_size=364.2, sample_size_v1=0, sample_size_v2=0, ppl=975.65, wps=1056.2, ups=2.9, wpb=364.2, bsz=8, num_updates=40, lr=3.99202e-06, gnorm=12.672, clip=100, loss_scale=32, train_wall=3, gb_free=13.6, wall=18
2023-03-15 14:00:04 - progress_bar.py[line:272] - INFO: epoch 001:     52 / 2004 loss=9.633, loss_v1=0, loss_v2=0, nll_loss=9.633, ntokens=339.6, nsentences=8, sample_size=339.6, sample_size_v1=0, sample_size_v2=0, ppl=793.73, wps=963.5, ups=2.84, wpb=339.6, bsz=8, num_updates=50, lr=4.99002e-06, gnorm=10.007, clip=100, loss_scale=32, train_wall=3, gb_free=15.2, wall=22
2023-03-15 14:00:07 - progress_bar.py[line:272] - INFO: epoch 001:     62 / 2004 loss=9.372, loss_v1=0, loss_v2=0, nll_loss=9.372, ntokens=330.6, nsentences=8, sample_size=330.6, sample_size_v1=0, sample_size_v2=0, ppl=662.62, wps=988.7, ups=2.99, wpb=330.6, bsz=8, num_updates=60, lr=5.98802e-06, gnorm=8.449, clip=100, loss_scale=32, train_wall=3, gb_free=15, wall=25
2023-03-15 14:00:11 - progress_bar.py[line:272] - INFO: epoch 001:     72 / 2004 loss=9.294, loss_v1=0, loss_v2=0, nll_loss=9.294, ntokens=359, nsentences=8, sample_size=359, sample_size_v1=0, sample_size_v2=0, ppl=627.83, wps=1043.7, ups=2.91, wpb=359, bsz=8, num_updates=70, lr=6.98603e-06, gnorm=8.942, clip=100, loss_scale=32, train_wall=3, gb_free=14.5, wall=28
2023-03-15 14:00:14 - progress_bar.py[line:272] - INFO: epoch 001:     82 / 2004 loss=9.006, loss_v1=0, loss_v2=0, nll_loss=9.006, ntokens=332.4, nsentences=8, sample_size=332.4, sample_size_v1=0, sample_size_v2=0, ppl=514.08, wps=969.8, ups=2.92, wpb=332.4, bsz=8, num_updates=80, lr=7.98403e-06, gnorm=6.513, clip=90, loss_scale=32, train_wall=3, gb_free=14.7, wall=32
2023-03-15 14:00:18 - progress_bar.py[line:272] - INFO: epoch 001:     92 / 2004 loss=8.888, loss_v1=0, loss_v2=0, nll_loss=8.888, ntokens=352.7, nsentences=8, sample_size=352.7, sample_size_v1=0, sample_size_v2=0, ppl=473.63, wps=1011.5, ups=2.87, wpb=352.7, bsz=8, num_updates=90, lr=8.98204e-06, gnorm=5.424, clip=80, loss_scale=32, train_wall=3, gb_free=14.6, wall=35
2023-03-15 14:00:21 - progress_bar.py[line:272] - INFO: epoch 001:    102 / 2004 loss=8.65, loss_v1=0, loss_v2=0, nll_loss=8.65, ntokens=377.7, nsentences=8, sample_size=377.7, sample_size_v1=0, sample_size_v2=0, ppl=401.71, wps=1095.6, ups=2.9, wpb=377.7, bsz=8, num_updates=100, lr=9.98004e-06, gnorm=5.041, clip=30, loss_scale=32, train_wall=3, gb_free=15.1, wall=39
2023-03-15 14:00:25 - progress_bar.py[line:272] - INFO: epoch 001:    112 / 2004 loss=8.433, loss_v1=0, loss_v2=0, nll_loss=8.433, ntokens=334.5, nsentences=8, sample_size=334.5, sample_size_v1=0, sample_size_v2=0, ppl=345.51, wps=985.7, ups=2.95, wpb=334.5, bsz=8, num_updates=110, lr=1.0978e-05, gnorm=4.766, clip=30, loss_scale=32, train_wall=3, gb_free=15, wall=42
2023-03-15 14:00:28 - progress_bar.py[line:272] - INFO: epoch 001:    122 / 2004 loss=8.249, loss_v1=0, loss_v2=0, nll_loss=8.249, ntokens=354.4, nsentences=8, sample_size=354.4, sample_size_v1=0, sample_size_v2=0, ppl=304.18, wps=1023.3, ups=2.89, wpb=354.4, bsz=8, num_updates=120, lr=1.1976e-05, gnorm=5.292, clip=70, loss_scale=32, train_wall=3, gb_free=15.1, wall=46
2023-03-15 14:00:32 - progress_bar.py[line:272] - INFO: epoch 001:    132 / 2004 loss=7.897, loss_v1=0, loss_v2=0, nll_loss=7.897, ntokens=311.6, nsentences=8, sample_size=311.6, sample_size_v1=0, sample_size_v2=0, ppl=238.32, wps=909.1, ups=2.92, wpb=311.6, bsz=8, num_updates=130, lr=1.29741e-05, gnorm=5.572, clip=60, loss_scale=32, train_wall=3, gb_free=15, wall=49
2023-03-15 14:00:35 - progress_bar.py[line:272] - INFO: epoch 001:    142 / 2004 loss=7.771, loss_v1=0, loss_v2=0, nll_loss=7.771, ntokens=357.5, nsentences=8, sample_size=357.5, sample_size_v1=0, sample_size_v2=0, ppl=218.35, wps=1035.4, ups=2.9, wpb=357.5, bsz=8, num_updates=140, lr=1.39721e-05, gnorm=5.712, clip=80, loss_scale=32, train_wall=3, gb_free=15.1, wall=53
2023-03-15 14:00:38 - progress_bar.py[line:272] - INFO: epoch 001:    152 / 2004 loss=7.409, loss_v1=0, loss_v2=0, nll_loss=7.409, ntokens=326.8, nsentences=8, sample_size=326.8, sample_size_v1=0, sample_size_v2=0, ppl=169.95, wps=977.7, ups=2.99, wpb=326.8, bsz=8, num_updates=150, lr=1.49701e-05, gnorm=6.008, clip=90, loss_scale=64, train_wall=3, gb_free=14.6, wall=56
2023-03-15 14:00:42 - progress_bar.py[line:272] - INFO: epoch 001:    162 / 2004 loss=7.134, loss_v1=0, loss_v2=0, nll_loss=7.134, ntokens=365.1, nsentences=8, sample_size=365.1, sample_size_v1=0, sample_size_v2=0, ppl=140.47, wps=1066.6, ups=2.92, wpb=365.1, bsz=8, num_updates=160, lr=1.59681e-05, gnorm=5.219, clip=50, loss_scale=64, train_wall=3, gb_free=14.2, wall=59
2023-03-15 14:00:45 - progress_bar.py[line:272] - INFO: epoch 001:    172 / 2004 loss=6.616, loss_v1=0, loss_v2=0, nll_loss=6.616, ntokens=326.2, nsentences=8, sample_size=326.2, sample_size_v1=0, sample_size_v2=0, ppl=98.08, wps=962.3, ups=2.95, wpb=326.2, bsz=8, num_updates=170, lr=1.69661e-05, gnorm=5.853, clip=70, loss_scale=64, train_wall=3, gb_free=15.2, wall=63
2023-03-15 14:00:49 - progress_bar.py[line:272] - INFO: epoch 001:    182 / 2004 loss=6.548, loss_v1=0, loss_v2=0, nll_loss=6.548, ntokens=331.8, nsentences=8, sample_size=331.8, sample_size_v1=0, sample_size_v2=0, ppl=93.6, wps=963.5, ups=2.9, wpb=331.8, bsz=8, num_updates=180, lr=1.79641e-05, gnorm=6.235, clip=90, loss_scale=64, train_wall=3, gb_free=14.7, wall=66
2023-03-15 14:00:52 - progress_bar.py[line:272] - INFO: epoch 001:    192 / 2004 loss=6.162, loss_v1=0, loss_v2=0, nll_loss=6.162, ntokens=333.8, nsentences=8, sample_size=333.8, sample_size_v1=0, sample_size_v2=0, ppl=71.61, wps=948.4, ups=2.84, wpb=333.8, bsz=8, num_updates=190, lr=1.89621e-05, gnorm=5.691, clip=80, loss_scale=64, train_wall=3, gb_free=14.3, wall=70
2023-03-15 14:00:56 - progress_bar.py[line:272] - INFO: epoch 001:    202 / 2004 loss=5.983, loss_v1=0, loss_v2=0, nll_loss=5.983, ntokens=337.8, nsentences=8, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=63.27, wps=988.6, ups=2.93, wpb=337.8, bsz=8, num_updates=200, lr=1.99601e-05, gnorm=4.731, clip=40, loss_scale=64, train_wall=3, gb_free=15.2, wall=73
2023-03-15 14:00:59 - progress_bar.py[line:272] - INFO: epoch 001:    212 / 2004 loss=5.89, loss_v1=0, loss_v2=0, nll_loss=5.89, ntokens=331.5, nsentences=8, sample_size=331.5, sample_size_v1=0, sample_size_v2=0, ppl=59.29, wps=968.2, ups=2.92, wpb=331.5, bsz=8, num_updates=210, lr=2.09581e-05, gnorm=5.163, clip=70, loss_scale=64, train_wall=3, gb_free=14.1, wall=77
2023-03-15 14:01:02 - progress_bar.py[line:272] - INFO: epoch 001:    222 / 2004 loss=5.294, loss_v1=0, loss_v2=0, nll_loss=5.294, ntokens=324.7, nsentences=8, sample_size=324.7, sample_size_v1=0, sample_size_v2=0, ppl=39.24, wps=966.5, ups=2.98, wpb=324.7, bsz=8, num_updates=220, lr=2.19561e-05, gnorm=4.942, clip=40, loss_scale=64, train_wall=3, gb_free=15, wall=80
2023-03-15 14:01:06 - progress_bar.py[line:272] - INFO: epoch 001:    232 / 2004 loss=5.196, loss_v1=0, loss_v2=0, nll_loss=5.196, ntokens=361.1, nsentences=8, sample_size=361.1, sample_size_v1=0, sample_size_v2=0, ppl=36.65, wps=1025.9, ups=2.84, wpb=361.1, bsz=8, num_updates=230, lr=2.29541e-05, gnorm=5.251, clip=60, loss_scale=64, train_wall=3, gb_free=14.4, wall=83
2023-03-15 14:01:09 - progress_bar.py[line:272] - INFO: epoch 001:    242 / 2004 loss=5.019, loss_v1=0, loss_v2=0, nll_loss=5.019, ntokens=364.1, nsentences=8, sample_size=364.1, sample_size_v1=0, sample_size_v2=0, ppl=32.42, wps=1053.4, ups=2.89, wpb=364.1, bsz=8, num_updates=240, lr=2.39521e-05, gnorm=4.744, clip=30, loss_scale=64, train_wall=3, gb_free=14.7, wall=87
2023-03-15 14:01:13 - progress_bar.py[line:272] - INFO: epoch 001:    252 / 2004 loss=4.665, loss_v1=0, loss_v2=0, nll_loss=4.665, ntokens=352.5, nsentences=8, sample_size=352.5, sample_size_v1=0, sample_size_v2=0, ppl=25.36, wps=1048.9, ups=2.98, wpb=352.5, bsz=8, num_updates=250, lr=2.49501e-05, gnorm=4.456, clip=0, loss_scale=64, train_wall=3, gb_free=14, wall=90
2023-03-15 14:01:16 - progress_bar.py[line:272] - INFO: epoch 001:    262 / 2004 loss=4.475, loss_v1=0, loss_v2=0, nll_loss=4.475, ntokens=332.1, nsentences=8, sample_size=332.1, sample_size_v1=0, sample_size_v2=0, ppl=22.23, wps=950.5, ups=2.86, wpb=332.1, bsz=8, num_updates=260, lr=2.59481e-05, gnorm=4.447, clip=20, loss_scale=64, train_wall=3, gb_free=15.1, wall=94
2023-03-15 14:01:20 - progress_bar.py[line:272] - INFO: epoch 001:    272 / 2004 loss=4.332, loss_v1=0, loss_v2=0, nll_loss=4.332, ntokens=339.5, nsentences=8, sample_size=339.5, sample_size_v1=0, sample_size_v2=0, ppl=20.14, wps=997, ups=2.94, wpb=339.5, bsz=8, num_updates=270, lr=2.69461e-05, gnorm=4.537, clip=20, loss_scale=128, train_wall=3, gb_free=15.3, wall=97
2023-03-15 14:01:23 - progress_bar.py[line:272] - INFO: epoch 001:    282 / 2004 loss=4.299, loss_v1=0, loss_v2=0, nll_loss=4.299, ntokens=361.7, nsentences=8, sample_size=361.7, sample_size_v1=0, sample_size_v2=0, ppl=19.69, wps=1048, ups=2.9, wpb=361.7, bsz=8, num_updates=280, lr=2.79441e-05, gnorm=4.068, clip=0, loss_scale=128, train_wall=3, gb_free=14.1, wall=101
2023-03-15 14:01:26 - progress_bar.py[line:272] - INFO: epoch 001:    292 / 2004 loss=4.107, loss_v1=0, loss_v2=0, nll_loss=4.107, ntokens=367.8, nsentences=8, sample_size=367.8, sample_size_v1=0, sample_size_v2=0, ppl=17.24, wps=1081, ups=2.94, wpb=367.8, bsz=8, num_updates=290, lr=2.89421e-05, gnorm=3.877, clip=0, loss_scale=128, train_wall=3, gb_free=15.1, wall=104
2023-03-15 14:01:30 - progress_bar.py[line:272] - INFO: epoch 001:    302 / 2004 loss=3.821, loss_v1=0, loss_v2=0, nll_loss=3.821, ntokens=349.1, nsentences=8, sample_size=349.1, sample_size_v1=0, sample_size_v2=0, ppl=14.14, wps=1040.4, ups=2.98, wpb=349.1, bsz=8, num_updates=300, lr=2.99401e-05, gnorm=3.779, clip=0, loss_scale=128, train_wall=3, gb_free=14.8, wall=107
2023-03-15 14:01:33 - progress_bar.py[line:272] - INFO: epoch 001:    312 / 2004 loss=3.675, loss_v1=0, loss_v2=0, nll_loss=3.675, ntokens=349.8, nsentences=8, sample_size=349.8, sample_size_v1=0, sample_size_v2=0, ppl=12.77, wps=1030.8, ups=2.95, wpb=349.8, bsz=8, num_updates=310, lr=3.09381e-05, gnorm=3.475, clip=0, loss_scale=128, train_wall=3, gb_free=15.5, wall=111
2023-03-15 14:01:37 - progress_bar.py[line:272] - INFO: epoch 001:    322 / 2004 loss=3.407, loss_v1=0, loss_v2=0, nll_loss=3.407, ntokens=335.1, nsentences=8, sample_size=335.1, sample_size_v1=0, sample_size_v2=0, ppl=10.61, wps=986.8, ups=2.94, wpb=335.1, bsz=8, num_updates=320, lr=3.19361e-05, gnorm=3.279, clip=0, loss_scale=128, train_wall=3, gb_free=14.9, wall=114
2023-03-15 14:01:40 - progress_bar.py[line:272] - INFO: epoch 001:    332 / 2004 loss=3.625, loss_v1=0, loss_v2=0, nll_loss=3.625, ntokens=327.2, nsentences=8, sample_size=327.2, sample_size_v1=0, sample_size_v2=0, ppl=12.34, wps=972.1, ups=2.97, wpb=327.2, bsz=8, num_updates=330, lr=3.29341e-05, gnorm=3.851, clip=10, loss_scale=128, train_wall=3, gb_free=15.4, wall=118
2023-03-15 14:01:43 - progress_bar.py[line:272] - INFO: epoch 001:    342 / 2004 loss=3.618, loss_v1=0, loss_v2=0, nll_loss=3.618, ntokens=370.1, nsentences=8, sample_size=370.1, sample_size_v1=0, sample_size_v2=0, ppl=12.28, wps=1055.1, ups=2.85, wpb=370.1, bsz=8, num_updates=340, lr=3.39321e-05, gnorm=3.432, clip=0, loss_scale=128, train_wall=3, gb_free=14.1, wall=121
2023-03-15 14:01:47 - progress_bar.py[line:272] - INFO: epoch 001:    352 / 2004 loss=3.453, loss_v1=0, loss_v2=0, nll_loss=3.453, ntokens=353.7, nsentences=8, sample_size=353.7, sample_size_v1=0, sample_size_v2=0, ppl=10.95, wps=1050.7, ups=2.97, wpb=353.7, bsz=8, num_updates=350, lr=3.49301e-05, gnorm=3.615, clip=10, loss_scale=128, train_wall=3, gb_free=14.6, wall=124
2023-03-15 14:01:50 - progress_bar.py[line:272] - INFO: epoch 001:    362 / 2004 loss=3.429, loss_v1=0, loss_v2=0, nll_loss=3.429, ntokens=364.1, nsentences=8, sample_size=364.1, sample_size_v1=0, sample_size_v2=0, ppl=10.77, wps=1055.3, ups=2.9, wpb=364.1, bsz=8, num_updates=360, lr=3.59281e-05, gnorm=3.76, clip=0, loss_scale=128, train_wall=3, gb_free=14.7, wall=128
2023-03-15 14:01:54 - progress_bar.py[line:272] - INFO: epoch 001:    372 / 2004 loss=3.137, loss_v1=0, loss_v2=0, nll_loss=3.137, ntokens=316.2, nsentences=8, sample_size=316.2, sample_size_v1=0, sample_size_v2=0, ppl=8.8, wps=921.8, ups=2.92, wpb=316.2, bsz=8, num_updates=370, lr=3.69261e-05, gnorm=3.496, clip=0, loss_scale=128, train_wall=3, gb_free=14.8, wall=131
2023-03-15 14:01:57 - progress_bar.py[line:272] - INFO: epoch 001:    382 / 2004 loss=3.246, loss_v1=0, loss_v2=0, nll_loss=3.246, ntokens=316.6, nsentences=8, sample_size=316.6, sample_size_v1=0, sample_size_v2=0, ppl=9.48, wps=941, ups=2.97, wpb=316.6, bsz=8, num_updates=380, lr=3.79242e-05, gnorm=3.708, clip=0, loss_scale=128, train_wall=3, gb_free=15, wall=135
2023-03-15 14:02:00 - progress_bar.py[line:272] - INFO: epoch 001:    392 / 2004 loss=3.131, loss_v1=0, loss_v2=0, nll_loss=3.131, ntokens=352.6, nsentences=8, sample_size=352.6, sample_size_v1=0, sample_size_v2=0, ppl=8.76, wps=1024.1, ups=2.9, wpb=352.6, bsz=8, num_updates=390, lr=3.89222e-05, gnorm=3.542, clip=0, loss_scale=128, train_wall=3, gb_free=14.9, wall=138
2023-03-15 14:02:04 - progress_bar.py[line:272] - INFO: epoch 001:    402 / 2004 loss=3.024, loss_v1=0, loss_v2=0, nll_loss=3.024, ntokens=376.4, nsentences=8, sample_size=376.4, sample_size_v1=0, sample_size_v2=0, ppl=8.14, wps=1102.1, ups=2.93, wpb=376.4, bsz=8, num_updates=400, lr=3.99202e-05, gnorm=3.155, clip=0, loss_scale=256, train_wall=3, gb_free=14.6, wall=141
2023-03-15 14:02:07 - progress_bar.py[line:272] - INFO: epoch 001:    412 / 2004 loss=2.943, loss_v1=0, loss_v2=0, nll_loss=2.943, ntokens=342.2, nsentences=8, sample_size=342.2, sample_size_v1=0, sample_size_v2=0, ppl=7.69, wps=985.6, ups=2.88, wpb=342.2, bsz=8, num_updates=410, lr=4.09182e-05, gnorm=3.226, clip=0, loss_scale=256, train_wall=3, gb_free=15.1, wall=145
2023-03-15 14:02:11 - progress_bar.py[line:272] - INFO: epoch 001:    422 / 2004 loss=2.88, loss_v1=0, loss_v2=0, nll_loss=2.88, ntokens=338.9, nsentences=8, sample_size=338.9, sample_size_v1=0, sample_size_v2=0, ppl=7.36, wps=993.4, ups=2.93, wpb=338.9, bsz=8, num_updates=420, lr=4.19162e-05, gnorm=3.054, clip=0, loss_scale=256, train_wall=3, gb_free=15.2, wall=148
2023-03-15 14:02:14 - progress_bar.py[line:272] - INFO: epoch 001:    432 / 2004 loss=2.871, loss_v1=0, loss_v2=0, nll_loss=2.871, ntokens=345, nsentences=8, sample_size=345, sample_size_v1=0, sample_size_v2=0, ppl=7.32, wps=1016.1, ups=2.95, wpb=345, bsz=8, num_updates=430, lr=4.29142e-05, gnorm=3.11, clip=0, loss_scale=256, train_wall=3, gb_free=14.4, wall=152
2023-03-15 14:02:18 - progress_bar.py[line:272] - INFO: epoch 001:    442 / 2004 loss=2.797, loss_v1=0, loss_v2=0, nll_loss=2.797, ntokens=372.3, nsentences=8, sample_size=372.3, sample_size_v1=0, sample_size_v2=0, ppl=6.95, wps=1067.2, ups=2.87, wpb=372.3, bsz=8, num_updates=440, lr=4.39122e-05, gnorm=2.895, clip=0, loss_scale=256, train_wall=3, gb_free=14.1, wall=155
2023-03-15 14:02:21 - progress_bar.py[line:272] - INFO: epoch 001:    452 / 2004 loss=2.87, loss_v1=0, loss_v2=0, nll_loss=2.87, ntokens=349, nsentences=8, sample_size=349, sample_size_v1=0, sample_size_v2=0, ppl=7.31, wps=1019.8, ups=2.92, wpb=349, bsz=8, num_updates=450, lr=4.49102e-05, gnorm=3.042, clip=0, loss_scale=256, train_wall=3, gb_free=15.6, wall=159
2023-03-15 14:02:25 - progress_bar.py[line:272] - INFO: epoch 001:    462 / 2004 loss=3.179, loss_v1=0, loss_v2=0, nll_loss=3.179, ntokens=390.3, nsentences=8, sample_size=390.3, sample_size_v1=0, sample_size_v2=0, ppl=9.05, wps=1123.7, ups=2.88, wpb=390.3, bsz=8, num_updates=460, lr=4.59082e-05, gnorm=3.118, clip=0, loss_scale=256, train_wall=3, gb_free=14.2, wall=162
2023-03-15 14:02:28 - progress_bar.py[line:272] - INFO: epoch 001:    472 / 2004 loss=2.803, loss_v1=0, loss_v2=0, nll_loss=2.803, ntokens=348.9, nsentences=8, sample_size=348.9, sample_size_v1=0, sample_size_v2=0, ppl=6.98, wps=1006.5, ups=2.88, wpb=348.9, bsz=8, num_updates=470, lr=4.69062e-05, gnorm=3.226, clip=0, loss_scale=256, train_wall=3, gb_free=15.1, wall=166
2023-03-15 14:02:31 - progress_bar.py[line:272] - INFO: epoch 001:    482 / 2004 loss=2.729, loss_v1=0, loss_v2=0, nll_loss=2.729, ntokens=364.5, nsentences=8, sample_size=364.5, sample_size_v1=0, sample_size_v2=0, ppl=6.63, wps=1054.6, ups=2.89, wpb=364.5, bsz=8, num_updates=480, lr=4.79042e-05, gnorm=3.161, clip=0, loss_scale=256, train_wall=3, gb_free=14.8, wall=169
2023-03-15 14:02:35 - progress_bar.py[line:272] - INFO: epoch 001:    492 / 2004 loss=2.602, loss_v1=0, loss_v2=0, nll_loss=2.602, ntokens=376.1, nsentences=8, sample_size=376.1, sample_size_v1=0, sample_size_v2=0, ppl=6.07, wps=1104.4, ups=2.94, wpb=376.1, bsz=8, num_updates=490, lr=4.89022e-05, gnorm=2.892, clip=0, loss_scale=256, train_wall=3, gb_free=14.7, wall=172
2023-03-15 14:02:38 - progress_bar.py[line:272] - INFO: epoch 001:    502 / 2004 loss=2.627, loss_v1=0, loss_v2=0, nll_loss=2.627, ntokens=362.2, nsentences=8, sample_size=362.2, sample_size_v1=0, sample_size_v2=0, ppl=6.18, wps=1066.9, ups=2.95, wpb=362.2, bsz=8, num_updates=500, lr=4.99002e-05, gnorm=3.26, clip=0, loss_scale=256, train_wall=3, gb_free=15.2, wall=176
2023-03-15 14:02:42 - progress_bar.py[line:272] - INFO: epoch 001:    512 / 2004 loss=2.654, loss_v1=0, loss_v2=0, nll_loss=2.654, ntokens=347.2, nsentences=8, sample_size=347.2, sample_size_v1=0, sample_size_v2=0, ppl=6.29, wps=1011.9, ups=2.91, wpb=347.2, bsz=8, num_updates=510, lr=5.08982e-05, gnorm=2.8, clip=0, loss_scale=256, train_wall=3, gb_free=14.6, wall=179
2023-03-15 14:02:45 - progress_bar.py[line:272] - INFO: epoch 001:    522 / 2004 loss=2.742, loss_v1=0, loss_v2=0, nll_loss=2.742, ntokens=377.6, nsentences=8, sample_size=377.6, sample_size_v1=0, sample_size_v2=0, ppl=6.69, wps=1099.4, ups=2.91, wpb=377.6, bsz=8, num_updates=520, lr=5.18962e-05, gnorm=2.747, clip=0, loss_scale=256, train_wall=3, gb_free=14.4, wall=183
2023-03-15 14:02:49 - progress_bar.py[line:272] - INFO: epoch 001:    532 / 2004 loss=2.656, loss_v1=0, loss_v2=0, nll_loss=2.656, ntokens=385.3, nsentences=8, sample_size=385.3, sample_size_v1=0, sample_size_v2=0, ppl=6.3, wps=1105.7, ups=2.87, wpb=385.3, bsz=8, num_updates=530, lr=5.28942e-05, gnorm=2.822, clip=0, loss_scale=512, train_wall=3, gb_free=15.1, wall=186
2023-03-15 14:02:52 - progress_bar.py[line:272] - INFO: epoch 001:    542 / 2004 loss=2.711, loss_v1=0, loss_v2=0, nll_loss=2.711, ntokens=374.1, nsentences=8, sample_size=374.1, sample_size_v1=0, sample_size_v2=0, ppl=6.55, wps=1097.7, ups=2.93, wpb=374.1, bsz=8, num_updates=540, lr=5.38922e-05, gnorm=2.824, clip=0, loss_scale=512, train_wall=3, gb_free=14.7, wall=190
2023-03-15 14:02:55 - progress_bar.py[line:272] - INFO: epoch 001:    552 / 2004 loss=2.551, loss_v1=0, loss_v2=0, nll_loss=2.551, ntokens=362.2, nsentences=8, sample_size=362.2, sample_size_v1=0, sample_size_v2=0, ppl=5.86, wps=1077.3, ups=2.97, wpb=362.2, bsz=8, num_updates=550, lr=5.48902e-05, gnorm=2.973, clip=0, loss_scale=512, train_wall=3, gb_free=15.2, wall=193
2023-03-15 14:02:59 - progress_bar.py[line:272] - INFO: epoch 001:    562 / 2004 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=2.433, ntokens=370.4, nsentences=8, sample_size=370.4, sample_size_v1=0, sample_size_v2=0, ppl=5.4, wps=1084.7, ups=2.93, wpb=370.4, bsz=8, num_updates=560, lr=5.58882e-05, gnorm=2.815, clip=0, loss_scale=512, train_wall=3, gb_free=14.7, wall=196
2023-03-15 14:03:02 - progress_bar.py[line:272] - INFO: epoch 001:    572 / 2004 loss=2.46, loss_v1=0, loss_v2=0, nll_loss=2.46, ntokens=367.1, nsentences=8, sample_size=367.1, sample_size_v1=0, sample_size_v2=0, ppl=5.5, wps=1068.5, ups=2.91, wpb=367.1, bsz=8, num_updates=570, lr=5.68862e-05, gnorm=2.891, clip=0, loss_scale=512, train_wall=3, gb_free=14.9, wall=200
2023-03-15 14:03:06 - progress_bar.py[line:272] - INFO: epoch 001:    582 / 2004 loss=2.568, loss_v1=0, loss_v2=0, nll_loss=2.568, ntokens=355.9, nsentences=8, sample_size=355.9, sample_size_v1=0, sample_size_v2=0, ppl=5.93, wps=1044.2, ups=2.93, wpb=355.9, bsz=8, num_updates=580, lr=5.78842e-05, gnorm=2.875, clip=0, loss_scale=512, train_wall=3, gb_free=14.8, wall=203
2023-03-15 14:03:09 - progress_bar.py[line:272] - INFO: epoch 001:    592 / 2004 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=2.41, ntokens=338.3, nsentences=8, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=5.31, wps=985, ups=2.91, wpb=338.3, bsz=8, num_updates=590, lr=5.88822e-05, gnorm=2.668, clip=0, loss_scale=512, train_wall=3, gb_free=15.4, wall=207
2023-03-15 14:03:13 - progress_bar.py[line:272] - INFO: epoch 001:    602 / 2004 loss=2.511, loss_v1=0, loss_v2=0, nll_loss=2.511, ntokens=358.5, nsentences=8, sample_size=358.5, sample_size_v1=0, sample_size_v2=0, ppl=5.7, wps=1038.6, ups=2.9, wpb=358.5, bsz=8, num_updates=600, lr=5.98802e-05, gnorm=2.801, clip=0, loss_scale=512, train_wall=3, gb_free=15, wall=210
2023-03-15 14:03:16 - progress_bar.py[line:272] - INFO: epoch 001:    612 / 2004 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=2.395, ntokens=356.4, nsentences=8, sample_size=356.4, sample_size_v1=0, sample_size_v2=0, ppl=5.26, wps=1044.9, ups=2.93, wpb=356.4, bsz=8, num_updates=610, lr=6.08782e-05, gnorm=2.793, clip=0, loss_scale=512, train_wall=3, gb_free=14.3, wall=214
2023-03-15 14:03:19 - progress_bar.py[line:272] - INFO: epoch 001:    622 / 2004 loss=2.222, loss_v1=0, loss_v2=0, nll_loss=2.222, ntokens=357.3, nsentences=8, sample_size=357.3, sample_size_v1=0, sample_size_v2=0, ppl=4.67, wps=1142.8, ups=3.2, wpb=357.3, bsz=8, num_updates=620, lr=6.18762e-05, gnorm=2.685, clip=0, loss_scale=512, train_wall=3, gb_free=15.1, wall=217
2023-03-15 14:03:22 - progress_bar.py[line:272] - INFO: epoch 001:    632 / 2004 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=2.333, ntokens=342.4, nsentences=8, sample_size=342.4, sample_size_v1=0, sample_size_v2=0, ppl=5.04, wps=1117.2, ups=3.26, wpb=342.4, bsz=8, num_updates=630, lr=6.28743e-05, gnorm=2.654, clip=0, loss_scale=512, train_wall=3, gb_free=14.9, wall=220
2023-03-15 14:03:25 - progress_bar.py[line:272] - INFO: epoch 001:    642 / 2004 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=2.337, ntokens=340.3, nsentences=8, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=5.05, wps=1086.2, ups=3.19, wpb=340.3, bsz=8, num_updates=640, lr=6.38723e-05, gnorm=2.619, clip=0, loss_scale=512, train_wall=3, gb_free=15.8, wall=223
2023-03-15 14:03:29 - progress_bar.py[line:272] - INFO: epoch 001:    652 / 2004 loss=2.504, loss_v1=0, loss_v2=0, nll_loss=2.504, ntokens=330.2, nsentences=8, sample_size=330.2, sample_size_v1=0, sample_size_v2=0, ppl=5.67, wps=990, ups=3, wpb=330.2, bsz=8, num_updates=650, lr=6.48703e-05, gnorm=2.748, clip=0, loss_scale=512, train_wall=3, gb_free=14.7, wall=226
2023-03-15 14:03:32 - progress_bar.py[line:272] - INFO: epoch 001:    662 / 2004 loss=2.28, loss_v1=0, loss_v2=0, nll_loss=2.28, ntokens=322.9, nsentences=8, sample_size=322.9, sample_size_v1=0, sample_size_v2=0, ppl=4.86, wps=940.5, ups=2.91, wpb=322.9, bsz=8, num_updates=660, lr=6.58683e-05, gnorm=2.811, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=230
2023-03-15 14:03:35 - progress_bar.py[line:272] - INFO: epoch 001:    672 / 2004 loss=2.292, loss_v1=0, loss_v2=0, nll_loss=2.292, ntokens=335.3, nsentences=8, sample_size=335.3, sample_size_v1=0, sample_size_v2=0, ppl=4.9, wps=994.1, ups=2.96, wpb=335.3, bsz=8, num_updates=670, lr=6.68663e-05, gnorm=2.677, clip=0, loss_scale=1024, train_wall=3, gb_free=13.8, wall=233
2023-03-15 14:03:39 - progress_bar.py[line:272] - INFO: epoch 001:    682 / 2004 loss=2.179, loss_v1=0, loss_v2=0, nll_loss=2.179, ntokens=346.4, nsentences=8, sample_size=346.4, sample_size_v1=0, sample_size_v2=0, ppl=4.53, wps=1036.5, ups=2.99, wpb=346.4, bsz=8, num_updates=680, lr=6.78643e-05, gnorm=2.627, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=236
2023-03-15 14:03:42 - progress_bar.py[line:272] - INFO: epoch 001:    692 / 2004 loss=2.217, loss_v1=0, loss_v2=0, nll_loss=2.217, ntokens=353.3, nsentences=8, sample_size=353.3, sample_size_v1=0, sample_size_v2=0, ppl=4.65, wps=1031.3, ups=2.92, wpb=353.3, bsz=8, num_updates=690, lr=6.88623e-05, gnorm=2.633, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=240
2023-03-15 14:03:46 - progress_bar.py[line:272] - INFO: epoch 001:    702 / 2004 loss=2.286, loss_v1=0, loss_v2=0, nll_loss=2.286, ntokens=335, nsentences=8, sample_size=335, sample_size_v1=0, sample_size_v2=0, ppl=4.88, wps=999.7, ups=2.98, wpb=335, bsz=8, num_updates=700, lr=6.98603e-05, gnorm=2.665, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=243
2023-03-15 14:03:49 - progress_bar.py[line:272] - INFO: epoch 001:    712 / 2004 loss=2.266, loss_v1=0, loss_v2=0, nll_loss=2.266, ntokens=318.9, nsentences=8, sample_size=318.9, sample_size_v1=0, sample_size_v2=0, ppl=4.81, wps=946.4, ups=2.97, wpb=318.9, bsz=8, num_updates=710, lr=7.08583e-05, gnorm=2.622, clip=0, loss_scale=1024, train_wall=3, gb_free=15.7, wall=247
2023-03-15 14:03:52 - progress_bar.py[line:272] - INFO: epoch 001:    722 / 2004 loss=2.323, loss_v1=0, loss_v2=0, nll_loss=2.323, ntokens=368.8, nsentences=8, sample_size=368.8, sample_size_v1=0, sample_size_v2=0, ppl=5, wps=1078.5, ups=2.92, wpb=368.8, bsz=8, num_updates=720, lr=7.18563e-05, gnorm=2.595, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=250
2023-03-15 14:03:56 - progress_bar.py[line:272] - INFO: epoch 001:    732 / 2004 loss=2.277, loss_v1=0, loss_v2=0, nll_loss=2.277, ntokens=350, nsentences=8, sample_size=350, sample_size_v1=0, sample_size_v2=0, ppl=4.85, wps=1020.6, ups=2.92, wpb=350, bsz=8, num_updates=730, lr=7.28543e-05, gnorm=2.642, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=253
2023-03-15 14:03:59 - progress_bar.py[line:272] - INFO: epoch 001:    742 / 2004 loss=2.18, loss_v1=0, loss_v2=0, nll_loss=2.18, ntokens=345.2, nsentences=8, sample_size=345.2, sample_size_v1=0, sample_size_v2=0, ppl=4.53, wps=1009.4, ups=2.92, wpb=345.2, bsz=8, num_updates=740, lr=7.38523e-05, gnorm=2.712, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=257
2023-03-15 14:04:03 - progress_bar.py[line:272] - INFO: epoch 001:    752 / 2004 loss=2.222, loss_v1=0, loss_v2=0, nll_loss=2.222, ntokens=346.3, nsentences=8, sample_size=346.3, sample_size_v1=0, sample_size_v2=0, ppl=4.67, wps=1024.8, ups=2.96, wpb=346.3, bsz=8, num_updates=750, lr=7.48503e-05, gnorm=2.627, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=260
2023-03-15 14:04:06 - progress_bar.py[line:272] - INFO: epoch 001:    762 / 2004 loss=2.283, loss_v1=0, loss_v2=0, nll_loss=2.283, ntokens=343, nsentences=8, sample_size=343, sample_size_v1=0, sample_size_v2=0, ppl=4.87, wps=996.9, ups=2.91, wpb=343, bsz=8, num_updates=760, lr=7.58483e-05, gnorm=2.571, clip=0, loss_scale=1024, train_wall=3, gb_free=13.2, wall=264
2023-03-15 14:04:10 - progress_bar.py[line:272] - INFO: epoch 001:    772 / 2004 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=2.311, ntokens=380.4, nsentences=8, sample_size=380.4, sample_size_v1=0, sample_size_v2=0, ppl=4.96, wps=1082.5, ups=2.85, wpb=380.4, bsz=8, num_updates=770, lr=7.68463e-05, gnorm=2.503, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=267
2023-03-15 14:04:13 - progress_bar.py[line:272] - INFO: epoch 001:    782 / 2004 loss=2.208, loss_v1=0, loss_v2=0, nll_loss=2.208, ntokens=337.1, nsentences=8, sample_size=337.1, sample_size_v1=0, sample_size_v2=0, ppl=4.62, wps=979.8, ups=2.91, wpb=337.1, bsz=8, num_updates=780, lr=7.78443e-05, gnorm=2.673, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=271
2023-03-15 14:04:16 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 14:04:17 - progress_bar.py[line:272] - INFO: epoch 001:    793 / 2004 loss=2.046, loss_v1=0, loss_v2=0, nll_loss=2.046, ntokens=325.8, nsentences=8, sample_size=325.8, sample_size_v1=0, sample_size_v2=0, ppl=4.13, wps=888.2, ups=2.73, wpb=325.8, bsz=8, num_updates=790, lr=7.88423e-05, gnorm=2.666, clip=0, loss_scale=1024, train_wall=4, gb_free=15.6, wall=274
2023-03-15 14:04:20 - progress_bar.py[line:272] - INFO: epoch 001:    803 / 2004 loss=2.171, loss_v1=0, loss_v2=0, nll_loss=2.171, ntokens=336, nsentences=8, sample_size=336, sample_size_v1=0, sample_size_v2=0, ppl=4.5, wps=1000.4, ups=2.98, wpb=336, bsz=8, num_updates=800, lr=7.98403e-05, gnorm=2.659, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=278
2023-03-15 14:04:23 - progress_bar.py[line:272] - INFO: epoch 001:    813 / 2004 loss=2.05, loss_v1=0, loss_v2=0, nll_loss=2.05, ntokens=341.4, nsentences=8, sample_size=341.4, sample_size_v1=0, sample_size_v2=0, ppl=4.14, wps=1011.5, ups=2.96, wpb=341.4, bsz=8, num_updates=810, lr=8.08383e-05, gnorm=2.521, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=281
2023-03-15 14:04:27 - progress_bar.py[line:272] - INFO: epoch 001:    823 / 2004 loss=2.089, loss_v1=0, loss_v2=0, nll_loss=2.089, ntokens=353.6, nsentences=8, sample_size=353.6, sample_size_v1=0, sample_size_v2=0, ppl=4.26, wps=1052, ups=2.98, wpb=353.6, bsz=8, num_updates=820, lr=8.18363e-05, gnorm=2.492, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=284
2023-03-15 14:04:30 - progress_bar.py[line:272] - INFO: epoch 001:    833 / 2004 loss=1.965, loss_v1=0, loss_v2=0, nll_loss=1.965, ntokens=337.4, nsentences=8, sample_size=337.4, sample_size_v1=0, sample_size_v2=0, ppl=3.9, wps=993, ups=2.94, wpb=337.4, bsz=8, num_updates=830, lr=8.28343e-05, gnorm=2.416, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=288
2023-03-15 14:04:34 - progress_bar.py[line:272] - INFO: epoch 001:    843 / 2004 loss=1.947, loss_v1=0, loss_v2=0, nll_loss=1.947, ntokens=362.4, nsentences=8, sample_size=362.4, sample_size_v1=0, sample_size_v2=0, ppl=3.86, wps=1035.9, ups=2.86, wpb=362.4, bsz=8, num_updates=840, lr=8.38323e-05, gnorm=2.441, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=291
2023-03-15 14:04:37 - progress_bar.py[line:272] - INFO: epoch 001:    853 / 2004 loss=2.099, loss_v1=0, loss_v2=0, nll_loss=2.099, ntokens=361.8, nsentences=8, sample_size=361.8, sample_size_v1=0, sample_size_v2=0, ppl=4.28, wps=1063.4, ups=2.94, wpb=361.8, bsz=8, num_updates=850, lr=8.48303e-05, gnorm=2.532, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=295
2023-03-15 14:04:40 - progress_bar.py[line:272] - INFO: epoch 001:    863 / 2004 loss=2.092, loss_v1=0, loss_v2=0, nll_loss=2.092, ntokens=342.3, nsentences=8, sample_size=342.3, sample_size_v1=0, sample_size_v2=0, ppl=4.26, wps=999.7, ups=2.92, wpb=342.3, bsz=8, num_updates=860, lr=8.58283e-05, gnorm=2.438, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=298
2023-03-15 14:04:44 - progress_bar.py[line:272] - INFO: epoch 001:    873 / 2004 loss=2.149, loss_v1=0, loss_v2=0, nll_loss=2.149, ntokens=368.3, nsentences=8, sample_size=368.3, sample_size_v1=0, sample_size_v2=0, ppl=4.43, wps=1075.4, ups=2.92, wpb=368.3, bsz=8, num_updates=870, lr=8.68263e-05, gnorm=2.627, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=301
2023-03-15 14:04:48 - progress_bar.py[line:272] - INFO: epoch 001:    883 / 2004 loss=1.889, loss_v1=0, loss_v2=0, nll_loss=1.889, ntokens=319, nsentences=8, sample_size=319, sample_size_v1=0, sample_size_v2=0, ppl=3.7, wps=711.2, ups=2.23, wpb=319, bsz=8, num_updates=880, lr=8.78244e-05, gnorm=2.541, clip=0, loss_scale=1024, train_wall=4, gb_free=15, wall=306
2023-03-15 14:04:52 - progress_bar.py[line:272] - INFO: epoch 001:    893 / 2004 loss=1.944, loss_v1=0, loss_v2=0, nll_loss=1.944, ntokens=299.1, nsentences=8, sample_size=299.1, sample_size_v1=0, sample_size_v2=0, ppl=3.85, wps=925.4, ups=3.09, wpb=299.1, bsz=8, num_updates=890, lr=8.88224e-05, gnorm=2.697, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=309
2023-03-15 14:04:55 - progress_bar.py[line:272] - INFO: epoch 001:    903 / 2004 loss=1.927, loss_v1=0, loss_v2=0, nll_loss=1.927, ntokens=373.1, nsentences=8, sample_size=373.1, sample_size_v1=0, sample_size_v2=0, ppl=3.8, wps=1080.2, ups=2.9, wpb=373.1, bsz=8, num_updates=900, lr=8.98204e-05, gnorm=2.463, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=313
2023-03-15 14:04:58 - progress_bar.py[line:272] - INFO: epoch 001:    913 / 2004 loss=1.909, loss_v1=0, loss_v2=0, nll_loss=1.909, ntokens=374.1, nsentences=8, sample_size=374.1, sample_size_v1=0, sample_size_v2=0, ppl=3.75, wps=1085.8, ups=2.9, wpb=374.1, bsz=8, num_updates=910, lr=9.08184e-05, gnorm=2.465, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=316
2023-03-15 14:05:02 - progress_bar.py[line:272] - INFO: epoch 001:    923 / 2004 loss=1.961, loss_v1=0, loss_v2=0, nll_loss=1.961, ntokens=324.4, nsentences=8, sample_size=324.4, sample_size_v1=0, sample_size_v2=0, ppl=3.89, wps=983.2, ups=3.03, wpb=324.4, bsz=8, num_updates=920, lr=9.18164e-05, gnorm=2.436, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=319
2023-03-15 14:05:05 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 14:05:06 - progress_bar.py[line:272] - INFO: epoch 001:    934 / 2004 loss=1.811, loss_v1=0, loss_v2=0, nll_loss=1.811, ntokens=341.5, nsentences=8, sample_size=341.5, sample_size_v1=0, sample_size_v2=0, ppl=3.51, wps=915.2, ups=2.68, wpb=341.5, bsz=8, num_updates=930, lr=9.28144e-05, gnorm=2.4, clip=0, loss_scale=1024, train_wall=4, gb_free=14.9, wall=323
2023-03-15 14:05:09 - progress_bar.py[line:272] - INFO: epoch 001:    944 / 2004 loss=1.983, loss_v1=0, loss_v2=0, nll_loss=1.983, ntokens=370, nsentences=8, sample_size=370, sample_size_v1=0, sample_size_v2=0, ppl=3.95, wps=1074.6, ups=2.9, wpb=370, bsz=8, num_updates=940, lr=9.38124e-05, gnorm=2.4, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=327
2023-03-15 14:05:12 - progress_bar.py[line:272] - INFO: epoch 001:    954 / 2004 loss=1.995, loss_v1=0, loss_v2=0, nll_loss=1.995, ntokens=335, nsentences=8, sample_size=335, sample_size_v1=0, sample_size_v2=0, ppl=3.99, wps=996.5, ups=2.97, wpb=335, bsz=8, num_updates=950, lr=9.48104e-05, gnorm=2.564, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=330
2023-03-15 14:05:16 - progress_bar.py[line:272] - INFO: epoch 001:    964 / 2004 loss=2.036, loss_v1=0, loss_v2=0, nll_loss=2.036, ntokens=382.1, nsentences=8, sample_size=382.1, sample_size_v1=0, sample_size_v2=0, ppl=4.1, wps=1126.1, ups=2.95, wpb=382.1, bsz=8, num_updates=960, lr=9.58084e-05, gnorm=2.418, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=333
2023-03-15 14:05:19 - progress_bar.py[line:272] - INFO: epoch 001:    974 / 2004 loss=2.006, loss_v1=0, loss_v2=0, nll_loss=2.006, ntokens=325.6, nsentences=8, sample_size=325.6, sample_size_v1=0, sample_size_v2=0, ppl=4.02, wps=949.9, ups=2.92, wpb=325.6, bsz=8, num_updates=970, lr=9.68064e-05, gnorm=2.61, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=337
2023-03-15 14:05:22 - progress_bar.py[line:272] - INFO: epoch 001:    984 / 2004 loss=1.915, loss_v1=0, loss_v2=0, nll_loss=1.915, ntokens=320.1, nsentences=8, sample_size=320.1, sample_size_v1=0, sample_size_v2=0, ppl=3.77, wps=973, ups=3.04, wpb=320.1, bsz=8, num_updates=980, lr=9.78044e-05, gnorm=2.555, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=340
2023-03-15 14:05:26 - progress_bar.py[line:272] - INFO: epoch 001:    994 / 2004 loss=1.815, loss_v1=0, loss_v2=0, nll_loss=1.815, ntokens=392.2, nsentences=8, sample_size=392.2, sample_size_v1=0, sample_size_v2=0, ppl=3.52, wps=1224.2, ups=3.12, wpb=392.2, bsz=8, num_updates=990, lr=9.88024e-05, gnorm=2.25, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=343
2023-03-15 14:05:29 - progress_bar.py[line:272] - INFO: epoch 001:   1004 / 2004 loss=1.852, loss_v1=0, loss_v2=0, nll_loss=1.852, ntokens=315, nsentences=8, sample_size=315, sample_size_v1=0, sample_size_v2=0, ppl=3.61, wps=1010.5, ups=3.21, wpb=315, bsz=8, num_updates=1000, lr=9.98004e-05, gnorm=2.664, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=346
2023-03-15 14:05:32 - progress_bar.py[line:272] - INFO: epoch 001:   1014 / 2004 loss=1.955, loss_v1=0, loss_v2=0, nll_loss=1.955, ntokens=340.7, nsentences=8, sample_size=340.7, sample_size_v1=0, sample_size_v2=0, ppl=3.88, wps=1116.3, ups=3.28, wpb=340.7, bsz=8, num_updates=1010, lr=9.99919e-05, gnorm=2.538, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=349
2023-03-15 14:05:35 - progress_bar.py[line:272] - INFO: epoch 001:   1024 / 2004 loss=1.979, loss_v1=0, loss_v2=0, nll_loss=1.979, ntokens=323.2, nsentences=8, sample_size=323.2, sample_size_v1=0, sample_size_v2=0, ppl=3.94, wps=1084, ups=3.35, wpb=323.2, bsz=8, num_updates=1020, lr=9.99819e-05, gnorm=2.48, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=352
2023-03-15 14:05:38 - progress_bar.py[line:272] - INFO: epoch 001:   1034 / 2004 loss=1.761, loss_v1=0, loss_v2=0, nll_loss=1.761, ntokens=312, nsentences=8, sample_size=312, sample_size_v1=0, sample_size_v2=0, ppl=3.39, wps=1016.5, ups=3.26, wpb=312, bsz=8, num_updates=1030, lr=9.99718e-05, gnorm=2.486, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=355
2023-03-15 14:05:41 - progress_bar.py[line:272] - INFO: epoch 001:   1044 / 2004 loss=1.979, loss_v1=0, loss_v2=0, nll_loss=1.979, ntokens=358.5, nsentences=8, sample_size=358.5, sample_size_v1=0, sample_size_v2=0, ppl=3.94, wps=1155.3, ups=3.22, wpb=358.5, bsz=8, num_updates=1040, lr=9.99617e-05, gnorm=2.46, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=359
2023-03-15 14:05:44 - progress_bar.py[line:272] - INFO: epoch 001:   1054 / 2004 loss=1.828, loss_v1=0, loss_v2=0, nll_loss=1.828, ntokens=381.1, nsentences=8, sample_size=381.1, sample_size_v1=0, sample_size_v2=0, ppl=3.55, wps=1235.8, ups=3.24, wpb=381.1, bsz=8, num_updates=1050, lr=9.99516e-05, gnorm=2.414, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=362
2023-03-15 14:05:47 - progress_bar.py[line:272] - INFO: epoch 001:   1064 / 2004 loss=1.951, loss_v1=0, loss_v2=0, nll_loss=1.951, ntokens=326.4, nsentences=8, sample_size=326.4, sample_size_v1=0, sample_size_v2=0, ppl=3.87, wps=1053.8, ups=3.23, wpb=326.4, bsz=8, num_updates=1060, lr=9.99415e-05, gnorm=2.553, clip=0, loss_scale=2048, train_wall=3, gb_free=13.9, wall=365
2023-03-15 14:05:49 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 14:05:51 - progress_bar.py[line:272] - INFO: epoch 001:   1075 / 2004 loss=1.913, loss_v1=0, loss_v2=0, nll_loss=1.913, ntokens=357.5, nsentences=8, sample_size=357.5, sample_size_v1=0, sample_size_v2=0, ppl=3.77, wps=1049.1, ups=2.93, wpb=357.5, bsz=8, num_updates=1070, lr=9.99315e-05, gnorm=2.333, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=368
2023-03-15 14:05:54 - progress_bar.py[line:272] - INFO: epoch 001:   1085 / 2004 loss=1.795, loss_v1=0, loss_v2=0, nll_loss=1.795, ntokens=369.9, nsentences=8, sample_size=369.9, sample_size_v1=0, sample_size_v2=0, ppl=3.47, wps=1174.7, ups=3.18, wpb=369.9, bsz=8, num_updates=1080, lr=9.99214e-05, gnorm=2.293, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=371
2023-03-15 14:05:57 - progress_bar.py[line:272] - INFO: epoch 001:   1095 / 2004 loss=2.028, loss_v1=0, loss_v2=0, nll_loss=2.028, ntokens=323.2, nsentences=8, sample_size=323.2, sample_size_v1=0, sample_size_v2=0, ppl=4.08, wps=1047.9, ups=3.24, wpb=323.2, bsz=8, num_updates=1090, lr=9.99113e-05, gnorm=2.617, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=374
2023-03-15 14:06:00 - progress_bar.py[line:272] - INFO: epoch 001:   1105 / 2004 loss=1.933, loss_v1=0, loss_v2=0, nll_loss=1.933, ntokens=377.2, nsentences=8, sample_size=377.2, sample_size_v1=0, sample_size_v2=0, ppl=3.82, wps=1193.4, ups=3.16, wpb=377.2, bsz=8, num_updates=1100, lr=9.99012e-05, gnorm=2.372, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=378
2023-03-15 14:06:03 - progress_bar.py[line:272] - INFO: epoch 001:   1115 / 2004 loss=1.814, loss_v1=0, loss_v2=0, nll_loss=1.814, ntokens=344.4, nsentences=8, sample_size=344.4, sample_size_v1=0, sample_size_v2=0, ppl=3.52, wps=1115.1, ups=3.24, wpb=344.4, bsz=8, num_updates=1110, lr=9.98911e-05, gnorm=2.419, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=381
2023-03-15 14:06:06 - progress_bar.py[line:272] - INFO: epoch 001:   1125 / 2004 loss=1.731, loss_v1=0, loss_v2=0, nll_loss=1.731, ntokens=319.6, nsentences=8, sample_size=319.6, sample_size_v1=0, sample_size_v2=0, ppl=3.32, wps=1024.7, ups=3.21, wpb=319.6, bsz=8, num_updates=1120, lr=9.9881e-05, gnorm=2.404, clip=0, loss_scale=1024, train_wall=3, gb_free=13.8, wall=384
2023-03-15 14:06:10 - progress_bar.py[line:272] - INFO: epoch 001:   1135 / 2004 loss=1.777, loss_v1=0, loss_v2=0, nll_loss=1.777, ntokens=383, nsentences=8, sample_size=383, sample_size_v1=0, sample_size_v2=0, ppl=3.43, wps=1108.9, ups=2.9, wpb=383, bsz=8, num_updates=1130, lr=9.9871e-05, gnorm=2.222, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=387
2023-03-15 14:06:13 - progress_bar.py[line:272] - INFO: epoch 001:   1145 / 2004 loss=1.915, loss_v1=0, loss_v2=0, nll_loss=1.915, ntokens=340.1, nsentences=8, sample_size=340.1, sample_size_v1=0, sample_size_v2=0, ppl=3.77, wps=1005.6, ups=2.96, wpb=340.1, bsz=8, num_updates=1140, lr=9.98609e-05, gnorm=2.433, clip=0, loss_scale=1024, train_wall=3, gb_free=13.9, wall=391
2023-03-15 14:06:16 - progress_bar.py[line:272] - INFO: epoch 001:   1155 / 2004 loss=1.732, loss_v1=0, loss_v2=0, nll_loss=1.732, ntokens=394.9, nsentences=8, sample_size=394.9, sample_size_v1=0, sample_size_v2=0, ppl=3.32, wps=1158.5, ups=2.93, wpb=394.9, bsz=8, num_updates=1150, lr=9.98508e-05, gnorm=2.19, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=394
2023-03-15 14:06:19 - progress_bar.py[line:272] - INFO: epoch 001:   1165 / 2004 loss=1.802, loss_v1=0, loss_v2=0, nll_loss=1.802, ntokens=362, nsentences=8, sample_size=362, sample_size_v1=0, sample_size_v2=0, ppl=3.49, wps=1168.8, ups=3.23, wpb=362, bsz=8, num_updates=1160, lr=9.98407e-05, gnorm=2.288, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=397
2023-03-15 14:06:23 - progress_bar.py[line:272] - INFO: epoch 001:   1175 / 2004 loss=1.687, loss_v1=0, loss_v2=0, nll_loss=1.687, ntokens=357.5, nsentences=8, sample_size=357.5, sample_size_v1=0, sample_size_v2=0, ppl=3.22, wps=1078.9, ups=3.02, wpb=357.5, bsz=8, num_updates=1170, lr=9.98306e-05, gnorm=2.354, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=400
2023-03-15 14:06:26 - progress_bar.py[line:272] - INFO: epoch 001:   1185 / 2004 loss=1.675, loss_v1=0, loss_v2=0, nll_loss=1.675, ntokens=341.2, nsentences=8, sample_size=341.2, sample_size_v1=0, sample_size_v2=0, ppl=3.19, wps=974.5, ups=2.86, wpb=341.2, bsz=8, num_updates=1180, lr=9.98206e-05, gnorm=2.257, clip=0, loss_scale=1024, train_wall=3, gb_free=13.6, wall=404
2023-03-15 14:06:30 - progress_bar.py[line:272] - INFO: epoch 001:   1195 / 2004 loss=1.645, loss_v1=0, loss_v2=0, nll_loss=1.645, ntokens=344.1, nsentences=8, sample_size=344.1, sample_size_v1=0, sample_size_v2=0, ppl=3.13, wps=1019.5, ups=2.96, wpb=344.1, bsz=8, num_updates=1190, lr=9.98105e-05, gnorm=2.399, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=407
2023-03-15 14:06:33 - progress_bar.py[line:272] - INFO: epoch 001:   1205 / 2004 loss=1.812, loss_v1=0, loss_v2=0, nll_loss=1.812, ntokens=304.5, nsentences=8, sample_size=304.5, sample_size_v1=0, sample_size_v2=0, ppl=3.51, wps=896.6, ups=2.94, wpb=304.5, bsz=8, num_updates=1200, lr=9.98004e-05, gnorm=2.552, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=411
2023-03-15 14:06:36 - progress_bar.py[line:272] - INFO: epoch 001:   1215 / 2004 loss=1.81, loss_v1=0, loss_v2=0, nll_loss=1.81, ntokens=311.4, nsentences=7.8, sample_size=311.4, sample_size_v1=0, sample_size_v2=0, ppl=3.51, wps=929.5, ups=2.99, wpb=311.4, bsz=7.8, num_updates=1210, lr=9.97903e-05, gnorm=2.48, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=414
2023-03-15 14:06:37 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 14:06:40 - progress_bar.py[line:272] - INFO: epoch 001:   1226 / 2004 loss=1.644, loss_v1=0, loss_v2=0, nll_loss=1.644, ntokens=306.6, nsentences=8, sample_size=306.6, sample_size_v1=0, sample_size_v2=0, ppl=3.13, wps=835.1, ups=2.72, wpb=306.6, bsz=8, num_updates=1220, lr=9.97802e-05, gnorm=2.485, clip=0, loss_scale=1024, train_wall=4, gb_free=15.8, wall=418
2023-03-15 14:06:43 - progress_bar.py[line:272] - INFO: epoch 001:   1236 / 2004 loss=1.695, loss_v1=0, loss_v2=0, nll_loss=1.695, ntokens=357.7, nsentences=8, sample_size=357.7, sample_size_v1=0, sample_size_v2=0, ppl=3.24, wps=1056.7, ups=2.95, wpb=357.7, bsz=8, num_updates=1230, lr=9.97702e-05, gnorm=2.284, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=421
2023-03-15 14:06:47 - progress_bar.py[line:272] - INFO: epoch 001:   1246 / 2004 loss=1.848, loss_v1=0, loss_v2=0, nll_loss=1.848, ntokens=355.5, nsentences=8, sample_size=355.5, sample_size_v1=0, sample_size_v2=0, ppl=3.6, wps=1111.8, ups=3.13, wpb=355.5, bsz=8, num_updates=1240, lr=9.97601e-05, gnorm=2.37, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=424
2023-03-15 14:06:50 - progress_bar.py[line:272] - INFO: epoch 001:   1256 / 2004 loss=1.716, loss_v1=0, loss_v2=0, nll_loss=1.716, ntokens=353.5, nsentences=8, sample_size=353.5, sample_size_v1=0, sample_size_v2=0, ppl=3.29, wps=1083, ups=3.06, wpb=353.5, bsz=8, num_updates=1250, lr=9.975e-05, gnorm=2.249, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=428
2023-03-15 14:06:53 - progress_bar.py[line:272] - INFO: epoch 001:   1266 / 2004 loss=1.707, loss_v1=0, loss_v2=0, nll_loss=1.707, ntokens=337.8, nsentences=8, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=3.26, wps=997, ups=2.95, wpb=337.8, bsz=8, num_updates=1260, lr=9.97399e-05, gnorm=2.309, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=431
2023-03-15 14:06:57 - progress_bar.py[line:272] - INFO: epoch 001:   1276 / 2004 loss=1.733, loss_v1=0, loss_v2=0, nll_loss=1.733, ntokens=348.6, nsentences=8, sample_size=348.6, sample_size_v1=0, sample_size_v2=0, ppl=3.32, wps=1014.4, ups=2.91, wpb=348.6, bsz=8, num_updates=1270, lr=9.97298e-05, gnorm=2.329, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=434
2023-03-15 14:07:00 - progress_bar.py[line:272] - INFO: epoch 001:   1286 / 2004 loss=1.472, loss_v1=0, loss_v2=0, nll_loss=1.472, ntokens=320.2, nsentences=8, sample_size=320.2, sample_size_v1=0, sample_size_v2=0, ppl=2.77, wps=957.9, ups=2.99, wpb=320.2, bsz=8, num_updates=1280, lr=9.97198e-05, gnorm=2.364, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=438
2023-03-15 14:07:03 - progress_bar.py[line:272] - INFO: epoch 001:   1296 / 2004 loss=1.643, loss_v1=0, loss_v2=0, nll_loss=1.643, ntokens=317.6, nsentences=8, sample_size=317.6, sample_size_v1=0, sample_size_v2=0, ppl=3.12, wps=960.3, ups=3.02, wpb=317.6, bsz=8, num_updates=1290, lr=9.97097e-05, gnorm=2.3, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=441
2023-03-15 14:07:06 - progress_bar.py[line:272] - INFO: epoch 001:   1306 / 2004 loss=1.695, loss_v1=0, loss_v2=0, nll_loss=1.695, ntokens=306.1, nsentences=8, sample_size=306.1, sample_size_v1=0, sample_size_v2=0, ppl=3.24, wps=997.8, ups=3.26, wpb=306.1, bsz=8, num_updates=1300, lr=9.96996e-05, gnorm=2.445, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=444
2023-03-15 14:07:10 - progress_bar.py[line:272] - INFO: epoch 001:   1316 / 2004 loss=1.754, loss_v1=0, loss_v2=0, nll_loss=1.754, ntokens=349.7, nsentences=8, sample_size=349.7, sample_size_v1=0, sample_size_v2=0, ppl=3.37, wps=1136, ups=3.25, wpb=349.7, bsz=8, num_updates=1310, lr=9.96895e-05, gnorm=2.326, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=447
2023-03-15 14:07:13 - progress_bar.py[line:272] - INFO: epoch 001:   1326 / 2004 loss=1.724, loss_v1=0, loss_v2=0, nll_loss=1.724, ntokens=296, nsentences=8, sample_size=296, sample_size_v1=0, sample_size_v2=0, ppl=3.3, wps=969.6, ups=3.28, wpb=296, bsz=8, num_updates=1320, lr=9.96794e-05, gnorm=2.548, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=450
2023-03-15 14:07:16 - progress_bar.py[line:272] - INFO: epoch 001:   1336 / 2004 loss=1.86, loss_v1=0, loss_v2=0, nll_loss=1.86, ntokens=361.4, nsentences=8, sample_size=361.4, sample_size_v1=0, sample_size_v2=0, ppl=3.63, wps=1172.1, ups=3.24, wpb=361.4, bsz=8, num_updates=1330, lr=9.96693e-05, gnorm=2.287, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=453
2023-03-15 14:07:19 - progress_bar.py[line:272] - INFO: epoch 001:   1346 / 2004 loss=1.618, loss_v1=0, loss_v2=0, nll_loss=1.618, ntokens=297.5, nsentences=8, sample_size=297.5, sample_size_v1=0, sample_size_v2=0, ppl=3.07, wps=972.8, ups=3.27, wpb=297.5, bsz=8, num_updates=1340, lr=9.96593e-05, gnorm=2.394, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=456
2023-03-15 14:07:22 - progress_bar.py[line:272] - INFO: epoch 001:   1356 / 2004 loss=1.715, loss_v1=0, loss_v2=0, nll_loss=1.715, ntokens=327.6, nsentences=8, sample_size=327.6, sample_size_v1=0, sample_size_v2=0, ppl=3.28, wps=1060.5, ups=3.24, wpb=327.6, bsz=8, num_updates=1350, lr=9.96492e-05, gnorm=2.357, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=459
2023-03-15 14:07:25 - progress_bar.py[line:272] - INFO: epoch 001:   1366 / 2004 loss=1.737, loss_v1=0, loss_v2=0, nll_loss=1.737, ntokens=310.3, nsentences=8, sample_size=310.3, sample_size_v1=0, sample_size_v2=0, ppl=3.33, wps=999.5, ups=3.22, wpb=310.3, bsz=8, num_updates=1360, lr=9.96391e-05, gnorm=2.485, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=463
2023-03-15 14:07:28 - progress_bar.py[line:272] - INFO: epoch 001:   1376 / 2004 loss=1.639, loss_v1=0, loss_v2=0, nll_loss=1.639, ntokens=329.6, nsentences=8, sample_size=329.6, sample_size_v1=0, sample_size_v2=0, ppl=3.12, wps=1034.5, ups=3.14, wpb=329.6, bsz=8, num_updates=1370, lr=9.9629e-05, gnorm=2.339, clip=0, loss_scale=2048, train_wall=3, gb_free=12.7, wall=466
2023-03-15 14:07:30 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 14:07:32 - progress_bar.py[line:272] - INFO: epoch 001:   1387 / 2004 loss=1.558, loss_v1=0, loss_v2=0, nll_loss=1.558, ntokens=390.9, nsentences=8, sample_size=390.9, sample_size_v1=0, sample_size_v2=0, ppl=2.94, wps=1138.8, ups=2.91, wpb=390.9, bsz=8, num_updates=1380, lr=9.96189e-05, gnorm=2.147, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=469
2023-03-15 14:07:35 - progress_bar.py[line:272] - INFO: epoch 001:   1397 / 2004 loss=1.525, loss_v1=0, loss_v2=0, nll_loss=1.525, ntokens=339.6, nsentences=8, sample_size=339.6, sample_size_v1=0, sample_size_v2=0, ppl=2.88, wps=1094.5, ups=3.22, wpb=339.6, bsz=8, num_updates=1390, lr=9.96089e-05, gnorm=2.225, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=472
2023-03-15 14:07:38 - progress_bar.py[line:272] - INFO: epoch 001:   1407 / 2004 loss=1.587, loss_v1=0, loss_v2=0, nll_loss=1.587, ntokens=348.2, nsentences=8, sample_size=348.2, sample_size_v1=0, sample_size_v2=0, ppl=3, wps=1127.8, ups=3.24, wpb=348.2, bsz=8, num_updates=1400, lr=9.95988e-05, gnorm=2.165, clip=0, loss_scale=1024, train_wall=3, gb_free=13.7, wall=475
2023-03-15 14:07:41 - progress_bar.py[line:272] - INFO: epoch 001:   1417 / 2004 loss=1.744, loss_v1=0, loss_v2=0, nll_loss=1.744, ntokens=382.3, nsentences=8, sample_size=382.3, sample_size_v1=0, sample_size_v2=0, ppl=3.35, wps=1225.6, ups=3.21, wpb=382.3, bsz=8, num_updates=1410, lr=9.95887e-05, gnorm=2.134, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=479
2023-03-15 14:07:44 - progress_bar.py[line:272] - INFO: epoch 001:   1427 / 2004 loss=1.508, loss_v1=0, loss_v2=0, nll_loss=1.508, ntokens=289.4, nsentences=8, sample_size=289.4, sample_size_v1=0, sample_size_v2=0, ppl=2.84, wps=943.2, ups=3.26, wpb=289.4, bsz=8, num_updates=1420, lr=9.95786e-05, gnorm=2.26, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=482
2023-03-15 14:07:47 - progress_bar.py[line:272] - INFO: epoch 001:   1437 / 2004 loss=1.693, loss_v1=0, loss_v2=0, nll_loss=1.693, ntokens=366.3, nsentences=8, sample_size=366.3, sample_size_v1=0, sample_size_v2=0, ppl=3.23, wps=1066.6, ups=2.91, wpb=366.3, bsz=8, num_updates=1430, lr=9.95685e-05, gnorm=2.311, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=485
2023-03-15 14:07:51 - progress_bar.py[line:272] - INFO: epoch 001:   1447 / 2004 loss=1.592, loss_v1=0, loss_v2=0, nll_loss=1.592, ntokens=329.8, nsentences=8, sample_size=329.8, sample_size_v1=0, sample_size_v2=0, ppl=3.01, wps=973.8, ups=2.95, wpb=329.8, bsz=8, num_updates=1440, lr=9.95585e-05, gnorm=2.297, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=488
2023-03-15 14:07:54 - progress_bar.py[line:272] - INFO: epoch 001:   1457 / 2004 loss=1.803, loss_v1=0, loss_v2=0, nll_loss=1.803, ntokens=358.2, nsentences=8, sample_size=358.2, sample_size_v1=0, sample_size_v2=0, ppl=3.49, wps=1031.8, ups=2.88, wpb=358.2, bsz=8, num_updates=1450, lr=9.95484e-05, gnorm=2.215, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=492
2023-03-15 14:07:58 - progress_bar.py[line:272] - INFO: epoch 001:   1467 / 2004 loss=1.638, loss_v1=0, loss_v2=0, nll_loss=1.638, ntokens=409.2, nsentences=8, sample_size=409.2, sample_size_v1=0, sample_size_v2=0, ppl=3.11, wps=1170.9, ups=2.86, wpb=409.2, bsz=8, num_updates=1460, lr=9.95383e-05, gnorm=2.117, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=495
2023-03-15 14:08:01 - progress_bar.py[line:272] - INFO: epoch 001:   1477 / 2004 loss=1.65, loss_v1=0, loss_v2=0, nll_loss=1.65, ntokens=400.9, nsentences=8, sample_size=400.9, sample_size_v1=0, sample_size_v2=0, ppl=3.14, wps=1178.6, ups=2.94, wpb=400.9, bsz=8, num_updates=1470, lr=9.95282e-05, gnorm=2.222, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=499
2023-03-15 14:08:05 - progress_bar.py[line:272] - INFO: epoch 001:   1487 / 2004 loss=1.599, loss_v1=0, loss_v2=0, nll_loss=1.599, ntokens=332, nsentences=8, sample_size=332, sample_size_v1=0, sample_size_v2=0, ppl=3.03, wps=961.7, ups=2.9, wpb=332, bsz=8, num_updates=1480, lr=9.95181e-05, gnorm=2.278, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=502
2023-03-15 14:08:08 - progress_bar.py[line:272] - INFO: epoch 001:   1497 / 2004 loss=1.696, loss_v1=0, loss_v2=0, nll_loss=1.696, ntokens=342.2, nsentences=8, sample_size=342.2, sample_size_v1=0, sample_size_v2=0, ppl=3.24, wps=1013.3, ups=2.96, wpb=342.2, bsz=8, num_updates=1490, lr=9.95081e-05, gnorm=2.304, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=506
2023-03-15 14:08:11 - progress_bar.py[line:272] - INFO: epoch 001:   1507 / 2004 loss=1.656, loss_v1=0, loss_v2=0, nll_loss=1.656, ntokens=323.1, nsentences=8, sample_size=323.1, sample_size_v1=0, sample_size_v2=0, ppl=3.15, wps=976.7, ups=3.02, wpb=323.1, bsz=8, num_updates=1500, lr=9.9498e-05, gnorm=2.313, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=509
2023-03-15 14:08:15 - progress_bar.py[line:272] - INFO: epoch 001:   1517 / 2004 loss=1.496, loss_v1=0, loss_v2=0, nll_loss=1.496, ntokens=330.4, nsentences=8, sample_size=330.4, sample_size_v1=0, sample_size_v2=0, ppl=2.82, wps=974.6, ups=2.95, wpb=330.4, bsz=8, num_updates=1510, lr=9.94879e-05, gnorm=2.211, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=512
2023-03-15 14:08:18 - progress_bar.py[line:272] - INFO: epoch 001:   1527 / 2004 loss=1.641, loss_v1=0, loss_v2=0, nll_loss=1.641, ntokens=321, nsentences=8, sample_size=321, sample_size_v1=0, sample_size_v2=0, ppl=3.12, wps=952.8, ups=2.97, wpb=321, bsz=8, num_updates=1520, lr=9.94778e-05, gnorm=2.407, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=516
2023-03-15 14:08:21 - progress_bar.py[line:272] - INFO: epoch 001:   1537 / 2004 loss=1.459, loss_v1=0, loss_v2=0, nll_loss=1.459, ntokens=353.2, nsentences=8, sample_size=353.2, sample_size_v1=0, sample_size_v2=0, ppl=2.75, wps=1049.1, ups=2.97, wpb=353.2, bsz=8, num_updates=1530, lr=9.94677e-05, gnorm=2.046, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=519
2023-03-15 14:08:24 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 14:08:25 - progress_bar.py[line:272] - INFO: epoch 001:   1548 / 2004 loss=1.485, loss_v1=0, loss_v2=0, nll_loss=1.485, ntokens=304.4, nsentences=8, sample_size=304.4, sample_size_v1=0, sample_size_v2=0, ppl=2.8, wps=822.5, ups=2.7, wpb=304.4, bsz=8, num_updates=1540, lr=9.94577e-05, gnorm=2.334, clip=0, loss_scale=1024, train_wall=4, gb_free=15, wall=523
2023-03-15 14:08:29 - progress_bar.py[line:272] - INFO: epoch 001:   1558 / 2004 loss=1.626, loss_v1=0, loss_v2=0, nll_loss=1.626, ntokens=354.8, nsentences=8, sample_size=354.8, sample_size_v1=0, sample_size_v2=0, ppl=3.09, wps=1026.1, ups=2.89, wpb=354.8, bsz=8, num_updates=1550, lr=9.94476e-05, gnorm=2.194, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=526
2023-03-15 14:08:32 - progress_bar.py[line:272] - INFO: epoch 001:   1568 / 2004 loss=1.447, loss_v1=0, loss_v2=0, nll_loss=1.447, ntokens=328.6, nsentences=8, sample_size=328.6, sample_size_v1=0, sample_size_v2=0, ppl=2.73, wps=959.7, ups=2.92, wpb=328.6, bsz=8, num_updates=1560, lr=9.94375e-05, gnorm=2.289, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=530
2023-03-15 14:08:35 - progress_bar.py[line:272] - INFO: epoch 001:   1578 / 2004 loss=1.622, loss_v1=0, loss_v2=0, nll_loss=1.622, ntokens=359.8, nsentences=8, sample_size=359.8, sample_size_v1=0, sample_size_v2=0, ppl=3.08, wps=1053.5, ups=2.93, wpb=359.8, bsz=8, num_updates=1570, lr=9.94274e-05, gnorm=2.15, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=533
2023-03-15 14:08:39 - progress_bar.py[line:272] - INFO: epoch 001:   1588 / 2004 loss=1.463, loss_v1=0, loss_v2=0, nll_loss=1.463, ntokens=314.3, nsentences=8, sample_size=314.3, sample_size_v1=0, sample_size_v2=0, ppl=2.76, wps=924.1, ups=2.94, wpb=314.3, bsz=8, num_updates=1580, lr=9.94173e-05, gnorm=2.23, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=536
2023-03-15 14:08:42 - progress_bar.py[line:272] - INFO: epoch 001:   1598 / 2004 loss=1.573, loss_v1=0, loss_v2=0, nll_loss=1.573, ntokens=352.1, nsentences=8, sample_size=352.1, sample_size_v1=0, sample_size_v2=0, ppl=2.97, wps=1028.9, ups=2.92, wpb=352.1, bsz=8, num_updates=1590, lr=9.94072e-05, gnorm=2.209, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=540
2023-03-15 14:08:46 - progress_bar.py[line:272] - INFO: epoch 001:   1608 / 2004 loss=1.595, loss_v1=0, loss_v2=0, nll_loss=1.595, ntokens=336.3, nsentences=8, sample_size=336.3, sample_size_v1=0, sample_size_v2=0, ppl=3.02, wps=986.9, ups=2.93, wpb=336.3, bsz=8, num_updates=1600, lr=9.93972e-05, gnorm=2.243, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=543
2023-03-15 14:08:49 - progress_bar.py[line:272] - INFO: epoch 001:   1618 / 2004 loss=1.664, loss_v1=0, loss_v2=0, nll_loss=1.664, ntokens=345.6, nsentences=8, sample_size=345.6, sample_size_v1=0, sample_size_v2=0, ppl=3.17, wps=1018.3, ups=2.95, wpb=345.6, bsz=8, num_updates=1610, lr=9.93871e-05, gnorm=2.284, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=547
2023-03-15 14:08:52 - progress_bar.py[line:272] - INFO: epoch 001:   1628 / 2004 loss=1.637, loss_v1=0, loss_v2=0, nll_loss=1.637, ntokens=369.5, nsentences=8, sample_size=369.5, sample_size_v1=0, sample_size_v2=0, ppl=3.11, wps=1077.4, ups=2.92, wpb=369.5, bsz=8, num_updates=1620, lr=9.9377e-05, gnorm=2.25, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=550
2023-03-15 14:08:56 - progress_bar.py[line:272] - INFO: epoch 001:   1638 / 2004 loss=1.608, loss_v1=0, loss_v2=0, nll_loss=1.608, ntokens=319, nsentences=8, sample_size=319, sample_size_v1=0, sample_size_v2=0, ppl=3.05, wps=930.5, ups=2.92, wpb=319, bsz=8, num_updates=1630, lr=9.93669e-05, gnorm=2.333, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=554
2023-03-15 14:08:59 - progress_bar.py[line:272] - INFO: epoch 001:   1648 / 2004 loss=1.595, loss_v1=0, loss_v2=0, nll_loss=1.595, ntokens=315.7, nsentences=8, sample_size=315.7, sample_size_v1=0, sample_size_v2=0, ppl=3.02, wps=911.7, ups=2.89, wpb=315.7, bsz=8, num_updates=1640, lr=9.93568e-05, gnorm=2.29, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=557
2023-03-15 14:09:03 - progress_bar.py[line:272] - INFO: epoch 001:   1658 / 2004 loss=1.55, loss_v1=0, loss_v2=0, nll_loss=1.55, ntokens=343.7, nsentences=8, sample_size=343.7, sample_size_v1=0, sample_size_v2=0, ppl=2.93, wps=1071, ups=3.12, wpb=343.7, bsz=8, num_updates=1650, lr=9.93468e-05, gnorm=2.178, clip=0, loss_scale=1024, train_wall=3, gb_free=15.8, wall=560
2023-03-15 14:09:06 - progress_bar.py[line:272] - INFO: epoch 001:   1668 / 2004 loss=1.691, loss_v1=0, loss_v2=0, nll_loss=1.691, ntokens=355, nsentences=8, sample_size=355, sample_size_v1=0, sample_size_v2=0, ppl=3.23, wps=1117.8, ups=3.15, wpb=355, bsz=8, num_updates=1660, lr=9.93367e-05, gnorm=2.315, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=563
2023-03-15 14:09:09 - progress_bar.py[line:272] - INFO: epoch 001:   1678 / 2004 loss=1.55, loss_v1=0, loss_v2=0, nll_loss=1.55, ntokens=321.1, nsentences=8, sample_size=321.1, sample_size_v1=0, sample_size_v2=0, ppl=2.93, wps=986.1, ups=3.07, wpb=321.1, bsz=8, num_updates=1670, lr=9.93266e-05, gnorm=2.284, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=567
2023-03-15 14:09:12 - progress_bar.py[line:272] - INFO: epoch 001:   1688 / 2004 loss=1.589, loss_v1=0, loss_v2=0, nll_loss=1.589, ntokens=341.6, nsentences=8, sample_size=341.6, sample_size_v1=0, sample_size_v2=0, ppl=3.01, wps=1039.8, ups=3.04, wpb=341.6, bsz=8, num_updates=1680, lr=9.93165e-05, gnorm=2.217, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=570
2023-03-15 14:09:16 - progress_bar.py[line:272] - INFO: epoch 001:   1698 / 2004 loss=1.509, loss_v1=0, loss_v2=0, nll_loss=1.509, ntokens=336.2, nsentences=8, sample_size=336.2, sample_size_v1=0, sample_size_v2=0, ppl=2.85, wps=1019.3, ups=3.03, wpb=336.2, bsz=8, num_updates=1690, lr=9.93064e-05, gnorm=2.153, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=573
2023-03-15 14:09:19 - progress_bar.py[line:272] - INFO: epoch 001:   1708 / 2004 loss=1.537, loss_v1=0, loss_v2=0, nll_loss=1.537, ntokens=343.8, nsentences=8, sample_size=343.8, sample_size_v1=0, sample_size_v2=0, ppl=2.9, wps=1078.9, ups=3.14, wpb=343.8, bsz=8, num_updates=1700, lr=9.92964e-05, gnorm=2.262, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=576
2023-03-15 14:09:22 - progress_bar.py[line:272] - INFO: epoch 001:   1718 / 2004 loss=1.666, loss_v1=0, loss_v2=0, nll_loss=1.666, ntokens=379.9, nsentences=8, sample_size=379.9, sample_size_v1=0, sample_size_v2=0, ppl=3.17, wps=1103.9, ups=2.91, wpb=379.9, bsz=8, num_updates=1710, lr=9.92863e-05, gnorm=2.13, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=580
2023-03-15 14:09:26 - progress_bar.py[line:272] - INFO: epoch 001:   1728 / 2004 loss=1.531, loss_v1=0, loss_v2=0, nll_loss=1.531, ntokens=390.8, nsentences=8, sample_size=390.8, sample_size_v1=0, sample_size_v2=0, ppl=2.89, wps=1156.5, ups=2.96, wpb=390.8, bsz=8, num_updates=1720, lr=9.92762e-05, gnorm=2.054, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=583
2023-03-15 14:09:29 - progress_bar.py[line:272] - INFO: epoch 001:   1738 / 2004 loss=1.605, loss_v1=0, loss_v2=0, nll_loss=1.605, ntokens=326.8, nsentences=8, sample_size=326.8, sample_size_v1=0, sample_size_v2=0, ppl=3.04, wps=950.7, ups=2.91, wpb=326.8, bsz=8, num_updates=1730, lr=9.92661e-05, gnorm=2.293, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=587
2023-03-15 14:09:31 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 14:09:33 - progress_bar.py[line:272] - INFO: epoch 001:   1749 / 2004 loss=1.51, loss_v1=0, loss_v2=0, nll_loss=1.51, ntokens=340.5, nsentences=8, sample_size=340.5, sample_size_v1=0, sample_size_v2=0, ppl=2.85, wps=899.3, ups=2.64, wpb=340.5, bsz=8, num_updates=1740, lr=9.9256e-05, gnorm=2.237, clip=0, loss_scale=1024, train_wall=4, gb_free=14.5, wall=590
2023-03-15 14:09:36 - progress_bar.py[line:272] - INFO: epoch 001:   1759 / 2004 loss=1.612, loss_v1=0, loss_v2=0, nll_loss=1.612, ntokens=313.7, nsentences=8, sample_size=313.7, sample_size_v1=0, sample_size_v2=0, ppl=3.06, wps=896.1, ups=2.86, wpb=313.7, bsz=8, num_updates=1750, lr=9.9246e-05, gnorm=2.269, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=594
2023-03-15 14:09:40 - progress_bar.py[line:272] - INFO: epoch 001:   1769 / 2004 loss=1.623, loss_v1=0, loss_v2=0, nll_loss=1.623, ntokens=338.7, nsentences=8, sample_size=338.7, sample_size_v1=0, sample_size_v2=0, ppl=3.08, wps=995.5, ups=2.94, wpb=338.7, bsz=8, num_updates=1760, lr=9.92359e-05, gnorm=2.306, clip=0, loss_scale=1024, train_wall=3, gb_free=14.2, wall=597
2023-03-15 14:09:43 - progress_bar.py[line:272] - INFO: epoch 001:   1779 / 2004 loss=1.572, loss_v1=0, loss_v2=0, nll_loss=1.572, ntokens=339.3, nsentences=8, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=2.97, wps=992.7, ups=2.93, wpb=339.3, bsz=8, num_updates=1770, lr=9.92258e-05, gnorm=2.316, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=601
2023-03-15 14:09:47 - progress_bar.py[line:272] - INFO: epoch 001:   1789 / 2004 loss=1.476, loss_v1=0, loss_v2=0, nll_loss=1.476, ntokens=301.3, nsentences=8, sample_size=301.3, sample_size_v1=0, sample_size_v2=0, ppl=2.78, wps=878.8, ups=2.92, wpb=301.3, bsz=8, num_updates=1780, lr=9.92157e-05, gnorm=2.2, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=604
2023-03-15 14:09:50 - progress_bar.py[line:272] - INFO: epoch 001:   1799 / 2004 loss=1.634, loss_v1=0, loss_v2=0, nll_loss=1.634, ntokens=347.4, nsentences=8, sample_size=347.4, sample_size_v1=0, sample_size_v2=0, ppl=3.1, wps=1025.5, ups=2.95, wpb=347.4, bsz=8, num_updates=1790, lr=9.92056e-05, gnorm=2.268, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=608
2023-03-15 14:09:53 - progress_bar.py[line:272] - INFO: epoch 001:   1809 / 2004 loss=1.636, loss_v1=0, loss_v2=0, nll_loss=1.636, ntokens=347.7, nsentences=8, sample_size=347.7, sample_size_v1=0, sample_size_v2=0, ppl=3.11, wps=994.9, ups=2.86, wpb=347.7, bsz=8, num_updates=1800, lr=9.91955e-05, gnorm=2.272, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=611
2023-03-15 14:09:57 - progress_bar.py[line:272] - INFO: epoch 001:   1819 / 2004 loss=1.4, loss_v1=0, loss_v2=0, nll_loss=1.4, ntokens=357.9, nsentences=8, sample_size=357.9, sample_size_v1=0, sample_size_v2=0, ppl=2.64, wps=1063.1, ups=2.97, wpb=357.9, bsz=8, num_updates=1810, lr=9.91855e-05, gnorm=2.115, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=614
2023-03-15 14:10:00 - progress_bar.py[line:272] - INFO: epoch 001:   1829 / 2004 loss=1.558, loss_v1=0, loss_v2=0, nll_loss=1.558, ntokens=339.4, nsentences=8, sample_size=339.4, sample_size_v1=0, sample_size_v2=0, ppl=2.94, wps=993.9, ups=2.93, wpb=339.4, bsz=8, num_updates=1820, lr=9.91754e-05, gnorm=2.246, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=618
2023-03-15 14:10:04 - progress_bar.py[line:272] - INFO: epoch 001:   1839 / 2004 loss=1.493, loss_v1=0, loss_v2=0, nll_loss=1.493, ntokens=341.2, nsentences=8, sample_size=341.2, sample_size_v1=0, sample_size_v2=0, ppl=2.82, wps=1021, ups=2.99, wpb=341.2, bsz=8, num_updates=1830, lr=9.91653e-05, gnorm=2.193, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=621
2023-03-15 14:10:07 - progress_bar.py[line:272] - INFO: epoch 001:   1849 / 2004 loss=1.418, loss_v1=0, loss_v2=0, nll_loss=1.418, ntokens=351.7, nsentences=8, sample_size=351.7, sample_size_v1=0, sample_size_v2=0, ppl=2.67, wps=1053, ups=2.99, wpb=351.7, bsz=8, num_updates=1840, lr=9.91552e-05, gnorm=2.134, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=625
2023-03-15 14:10:10 - progress_bar.py[line:272] - INFO: epoch 001:   1859 / 2004 loss=1.574, loss_v1=0, loss_v2=0, nll_loss=1.574, ntokens=330.7, nsentences=8, sample_size=330.7, sample_size_v1=0, sample_size_v2=0, ppl=2.98, wps=974.8, ups=2.95, wpb=330.7, bsz=8, num_updates=1850, lr=9.91451e-05, gnorm=2.257, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=628
2023-03-15 14:10:14 - progress_bar.py[line:272] - INFO: epoch 001:   1869 / 2004 loss=1.38, loss_v1=0, loss_v2=0, nll_loss=1.38, ntokens=335.2, nsentences=8, sample_size=335.2, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=983, ups=2.93, wpb=335.2, bsz=8, num_updates=1860, lr=9.91351e-05, gnorm=2.123, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=631
2023-03-15 14:10:17 - progress_bar.py[line:272] - INFO: epoch 001:   1879 / 2004 loss=1.522, loss_v1=0, loss_v2=0, nll_loss=1.522, ntokens=333.8, nsentences=8, sample_size=333.8, sample_size_v1=0, sample_size_v2=0, ppl=2.87, wps=999.6, ups=2.99, wpb=333.8, bsz=8, num_updates=1870, lr=9.9125e-05, gnorm=2.338, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=635
2023-03-15 14:10:20 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 14:10:20 - progress_bar.py[line:272] - INFO: epoch 001:   1890 / 2004 loss=1.457, loss_v1=0, loss_v2=0, nll_loss=1.457, ntokens=321.7, nsentences=8, sample_size=321.7, sample_size_v1=0, sample_size_v2=0, ppl=2.75, wps=972, ups=3.02, wpb=321.7, bsz=8, num_updates=1880, lr=9.91149e-05, gnorm=2.232, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=638
2023-03-15 14:10:24 - progress_bar.py[line:272] - INFO: epoch 001:   1900 / 2004 loss=1.416, loss_v1=0, loss_v2=0, nll_loss=1.416, ntokens=352.6, nsentences=8, sample_size=352.6, sample_size_v1=0, sample_size_v2=0, ppl=2.67, wps=1075.7, ups=3.05, wpb=352.6, bsz=8, num_updates=1890, lr=9.91048e-05, gnorm=2.133, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=641
2023-03-15 14:10:27 - progress_bar.py[line:272] - INFO: epoch 001:   1910 / 2004 loss=1.454, loss_v1=0, loss_v2=0, nll_loss=1.454, ntokens=339.3, nsentences=8, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=2.74, wps=1023.1, ups=3.02, wpb=339.3, bsz=8, num_updates=1900, lr=9.90947e-05, gnorm=2.177, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=645
2023-03-15 14:10:30 - progress_bar.py[line:272] - INFO: epoch 001:   1920 / 2004 loss=1.389, loss_v1=0, loss_v2=0, nll_loss=1.389, ntokens=330.2, nsentences=8, sample_size=330.2, sample_size_v1=0, sample_size_v2=0, ppl=2.62, wps=979.4, ups=2.97, wpb=330.2, bsz=8, num_updates=1910, lr=9.90847e-05, gnorm=2.224, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=648
2023-03-15 14:10:34 - progress_bar.py[line:272] - INFO: epoch 001:   1930 / 2004 loss=1.397, loss_v1=0, loss_v2=0, nll_loss=1.397, ntokens=316.2, nsentences=8, sample_size=316.2, sample_size_v1=0, sample_size_v2=0, ppl=2.63, wps=946.7, ups=2.99, wpb=316.2, bsz=8, num_updates=1920, lr=9.90746e-05, gnorm=2.247, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=651
2023-03-15 14:10:37 - progress_bar.py[line:272] - INFO: epoch 001:   1940 / 2004 loss=1.41, loss_v1=0, loss_v2=0, nll_loss=1.41, ntokens=349.9, nsentences=8, sample_size=349.9, sample_size_v1=0, sample_size_v2=0, ppl=2.66, wps=1013.3, ups=2.9, wpb=349.9, bsz=8, num_updates=1930, lr=9.90645e-05, gnorm=2.213, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=655
2023-03-15 14:10:41 - progress_bar.py[line:272] - INFO: epoch 001:   1950 / 2004 loss=1.509, loss_v1=0, loss_v2=0, nll_loss=1.509, ntokens=337.9, nsentences=8, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=2.85, wps=988.7, ups=2.93, wpb=337.9, bsz=8, num_updates=1940, lr=9.90544e-05, gnorm=2.226, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=658
2023-03-15 14:10:44 - progress_bar.py[line:272] - INFO: epoch 001:   1960 / 2004 loss=1.341, loss_v1=0, loss_v2=0, nll_loss=1.341, ntokens=365.6, nsentences=8, sample_size=365.6, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=1076.8, ups=2.95, wpb=365.6, bsz=8, num_updates=1950, lr=9.90443e-05, gnorm=2.121, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=662
2023-03-15 14:10:47 - progress_bar.py[line:272] - INFO: epoch 001:   1970 / 2004 loss=1.472, loss_v1=0, loss_v2=0, nll_loss=1.472, ntokens=336.8, nsentences=8, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=2.77, wps=984.2, ups=2.92, wpb=336.8, bsz=8, num_updates=1960, lr=9.90343e-05, gnorm=2.182, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=665
2023-03-15 14:10:51 - progress_bar.py[line:272] - INFO: epoch 001:   1980 / 2004 loss=1.384, loss_v1=0, loss_v2=0, nll_loss=1.384, ntokens=343.1, nsentences=8, sample_size=343.1, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=999.5, ups=2.91, wpb=343.1, bsz=8, num_updates=1970, lr=9.90242e-05, gnorm=2.245, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=668
2023-03-15 14:10:54 - progress_bar.py[line:272] - INFO: epoch 001:   1990 / 2004 loss=1.468, loss_v1=0, loss_v2=0, nll_loss=1.468, ntokens=355.1, nsentences=8, sample_size=355.1, sample_size_v1=0, sample_size_v2=0, ppl=2.77, wps=1045.2, ups=2.94, wpb=355.1, bsz=8, num_updates=1980, lr=9.90141e-05, gnorm=2.144, clip=0, loss_scale=1024, train_wall=3, gb_free=14.2, wall=672
2023-03-15 14:10:57 - progress_bar.py[line:272] - INFO: epoch 001:   2000 / 2004 loss=1.492, loss_v1=0, loss_v2=0, nll_loss=1.492, ntokens=377.8, nsentences=8, sample_size=377.8, sample_size_v1=0, sample_size_v2=0, ppl=2.81, wps=1164.9, ups=3.08, wpb=377.8, bsz=8, num_updates=1990, lr=9.9004e-05, gnorm=1.995, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=675
2023-03-15 14:10:59 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 1994 updates
2023-03-15 14:10:59 - trainer.py[line:431] - INFO: Saving checkpoint to ./checkpoints/checkpoint1.pt
2023-03-15 14:11:04 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./checkpoints/checkpoint1.pt
2023-03-15 14:11:05 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./checkpoints/checkpoint1.pt (epoch 1 @ 1994 updates, score None) (writing took 6.304305968806148 seconds)
2023-03-15 14:11:05 - train.py[line:332] - INFO: end of epoch 1 (average epoch stats below)
2023-03-15 14:11:05 - progress_bar.py[line:282] - INFO: epoch 001 | loss 2.767 | loss_v1 0 | loss_v2 0 | nll_loss 2.767 | ntokens 345.248 | nsentences 7.999 | sample_size 345.248 | sample_size_v1 0 | sample_size_v2 0 | ppl 6.81 | wps 1014.1 | ups 2.94 | wpb 345.2 | bsz 8 | num_updates 1994 | lr 9.9e-05 | gnorm 3.195 | clip 9.1 | loss_scale 1024 | train_wall 664 | gb_free 14.4 | wall 683
2023-03-15 14:11:05 - trainer.py[line:639] - INFO: loading train data for epoch 2
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 row count 8015 total row count 8015
slice_id 0 seek offset 0
2023-03-15 14:11:06 - trainer.py[line:703] - INFO: begin training epoch 2
2023-03-15 14:11:06 - train.py[line:305] - INFO: Start iterating over samples
2023-03-15 14:11:08 - progress_bar.py[line:272] - INFO: epoch 002:      6 / 2004 loss=1.557, loss_v1=0, loss_v2=0, nll_loss=1.557, ntokens=382.1, nsentences=8, sample_size=382.1, sample_size_v1=0, sample_size_v2=0, ppl=2.94, wps=367, ups=0.96, wpb=382.1, bsz=8, num_updates=2000, lr=9.89939e-05, gnorm=2.057, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=685
2023-03-15 14:11:11 - progress_bar.py[line:272] - INFO: epoch 002:     16 / 2004 loss=1.442, loss_v1=0, loss_v2=0, nll_loss=1.442, ntokens=311.6, nsentences=8, sample_size=311.6, sample_size_v1=0, sample_size_v2=0, ppl=2.72, wps=946.8, ups=3.04, wpb=311.6, bsz=8, num_updates=2010, lr=9.89839e-05, gnorm=2.217, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=689
2023-03-15 14:11:15 - progress_bar.py[line:272] - INFO: epoch 002:     26 / 2004 loss=1.502, loss_v1=0, loss_v2=0, nll_loss=1.502, ntokens=366.9, nsentences=8, sample_size=366.9, sample_size_v1=0, sample_size_v2=0, ppl=2.83, wps=1097.9, ups=2.99, wpb=366.9, bsz=8, num_updates=2020, lr=9.89738e-05, gnorm=2.114, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=692
2023-03-15 14:11:18 - progress_bar.py[line:272] - INFO: epoch 002:     36 / 2004 loss=1.551, loss_v1=0, loss_v2=0, nll_loss=1.551, ntokens=337.9, nsentences=8, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=2.93, wps=996.3, ups=2.95, wpb=337.9, bsz=8, num_updates=2030, lr=9.89637e-05, gnorm=2.171, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=696
2023-03-15 14:11:21 - progress_bar.py[line:272] - INFO: epoch 002:     46 / 2004 loss=1.413, loss_v1=0, loss_v2=0, nll_loss=1.413, ntokens=362.6, nsentences=8, sample_size=362.6, sample_size_v1=0, sample_size_v2=0, ppl=2.66, wps=1073.8, ups=2.96, wpb=362.6, bsz=8, num_updates=2040, lr=9.89536e-05, gnorm=2.123, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=699
2023-03-15 14:11:25 - progress_bar.py[line:272] - INFO: epoch 002:     56 / 2004 loss=1.497, loss_v1=0, loss_v2=0, nll_loss=1.497, ntokens=343, nsentences=8, sample_size=343, sample_size_v1=0, sample_size_v2=0, ppl=2.82, wps=1031.2, ups=3.01, wpb=343, bsz=8, num_updates=2050, lr=9.89435e-05, gnorm=2.153, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=702
2023-03-15 14:11:28 - progress_bar.py[line:272] - INFO: epoch 002:     66 / 2004 loss=1.487, loss_v1=0, loss_v2=0, nll_loss=1.487, ntokens=337.6, nsentences=8, sample_size=337.6, sample_size_v1=0, sample_size_v2=0, ppl=2.8, wps=1006.6, ups=2.98, wpb=337.6, bsz=8, num_updates=2060, lr=9.89334e-05, gnorm=2.181, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=706
2023-03-15 14:11:31 - progress_bar.py[line:272] - INFO: epoch 002:     76 / 2004 loss=1.445, loss_v1=0, loss_v2=0, nll_loss=1.445, ntokens=347, nsentences=8, sample_size=347, sample_size_v1=0, sample_size_v2=0, ppl=2.72, wps=1005.8, ups=2.9, wpb=347, bsz=8, num_updates=2070, lr=9.89234e-05, gnorm=2.094, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=709
2023-03-15 14:11:35 - progress_bar.py[line:272] - INFO: epoch 002:     86 / 2004 loss=1.337, loss_v1=0, loss_v2=0, nll_loss=1.337, ntokens=345.7, nsentences=8, sample_size=345.7, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=999.3, ups=2.89, wpb=345.7, bsz=8, num_updates=2080, lr=9.89133e-05, gnorm=2.044, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=712
2023-03-15 14:11:37 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 14:11:39 - progress_bar.py[line:272] - INFO: epoch 002:     97 / 2004 loss=1.531, loss_v1=0, loss_v2=0, nll_loss=1.531, ntokens=359.7, nsentences=8, sample_size=359.7, sample_size_v1=0, sample_size_v2=0, ppl=2.89, wps=966, ups=2.69, wpb=359.7, bsz=8, num_updates=2090, lr=9.89032e-05, gnorm=2.143, clip=0, loss_scale=1024, train_wall=4, gb_free=14.8, wall=716
2023-03-15 14:11:42 - progress_bar.py[line:272] - INFO: epoch 002:    107 / 2004 loss=1.343, loss_v1=0, loss_v2=0, nll_loss=1.343, ntokens=363.5, nsentences=8, sample_size=363.5, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=1076.3, ups=2.96, wpb=363.5, bsz=8, num_updates=2100, lr=9.88931e-05, gnorm=2.043, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=720
2023-03-15 14:11:45 - progress_bar.py[line:272] - INFO: epoch 002:    117 / 2004 loss=1.484, loss_v1=0, loss_v2=0, nll_loss=1.484, ntokens=328.6, nsentences=8, sample_size=328.6, sample_size_v1=0, sample_size_v2=0, ppl=2.8, wps=997.6, ups=3.04, wpb=328.6, bsz=8, num_updates=2110, lr=9.8883e-05, gnorm=2.201, clip=0, loss_scale=1024, train_wall=3, gb_free=15.9, wall=723
2023-03-15 14:11:49 - progress_bar.py[line:272] - INFO: epoch 002:    127 / 2004 loss=1.499, loss_v1=0, loss_v2=0, nll_loss=1.499, ntokens=344.5, nsentences=8, sample_size=344.5, sample_size_v1=0, sample_size_v2=0, ppl=2.83, wps=1030.1, ups=2.99, wpb=344.5, bsz=8, num_updates=2120, lr=9.8873e-05, gnorm=2.1, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=726
2023-03-15 14:11:52 - progress_bar.py[line:272] - INFO: epoch 002:    137 / 2004 loss=1.345, loss_v1=0, loss_v2=0, nll_loss=1.345, ntokens=325.1, nsentences=8, sample_size=325.1, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=957.3, ups=2.94, wpb=325.1, bsz=8, num_updates=2130, lr=9.88629e-05, gnorm=2.123, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=730
2023-03-15 14:11:55 - progress_bar.py[line:272] - INFO: epoch 002:    147 / 2004 loss=1.419, loss_v1=0, loss_v2=0, nll_loss=1.419, ntokens=336.8, nsentences=8, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=2.67, wps=991.2, ups=2.94, wpb=336.8, bsz=8, num_updates=2140, lr=9.88528e-05, gnorm=2.14, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=733
2023-03-15 14:11:59 - progress_bar.py[line:272] - INFO: epoch 002:    157 / 2004 loss=1.488, loss_v1=0, loss_v2=0, nll_loss=1.488, ntokens=342.5, nsentences=8, sample_size=342.5, sample_size_v1=0, sample_size_v2=0, ppl=2.81, wps=1022, ups=2.98, wpb=342.5, bsz=8, num_updates=2150, lr=9.88427e-05, gnorm=2.168, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=736
2023-03-15 14:12:02 - progress_bar.py[line:272] - INFO: epoch 002:    167 / 2004 loss=1.346, loss_v1=0, loss_v2=0, nll_loss=1.346, ntokens=351.3, nsentences=8, sample_size=351.3, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=1046, ups=2.98, wpb=351.3, bsz=8, num_updates=2160, lr=9.88326e-05, gnorm=2.082, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=740
2023-03-15 14:12:05 - progress_bar.py[line:272] - INFO: epoch 002:    177 / 2004 loss=1.368, loss_v1=0, loss_v2=0, nll_loss=1.368, ntokens=336.2, nsentences=8, sample_size=336.2, sample_size_v1=0, sample_size_v2=0, ppl=2.58, wps=1087.5, ups=3.23, wpb=336.2, bsz=8, num_updates=2170, lr=9.88226e-05, gnorm=2.113, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=743
2023-03-15 14:12:08 - progress_bar.py[line:272] - INFO: epoch 002:    187 / 2004 loss=1.275, loss_v1=0, loss_v2=0, nll_loss=1.275, ntokens=330.2, nsentences=8, sample_size=330.2, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=1082.1, ups=3.28, wpb=330.2, bsz=8, num_updates=2180, lr=9.88125e-05, gnorm=2.105, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=746
2023-03-15 14:12:11 - progress_bar.py[line:272] - INFO: epoch 002:    197 / 2004 loss=1.346, loss_v1=0, loss_v2=0, nll_loss=1.346, ntokens=319.2, nsentences=8, sample_size=319.2, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=1068.3, ups=3.35, wpb=319.2, bsz=8, num_updates=2190, lr=9.88024e-05, gnorm=2.19, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=749
2023-03-15 14:12:14 - progress_bar.py[line:272] - INFO: epoch 002:    207 / 2004 loss=1.434, loss_v1=0, loss_v2=0, nll_loss=1.434, ntokens=346.4, nsentences=8, sample_size=346.4, sample_size_v1=0, sample_size_v2=0, ppl=2.7, wps=1133.9, ups=3.27, wpb=346.4, bsz=8, num_updates=2200, lr=9.87923e-05, gnorm=2.166, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=752
2023-03-15 14:12:17 - progress_bar.py[line:272] - INFO: epoch 002:    217 / 2004 loss=1.31, loss_v1=0, loss_v2=0, nll_loss=1.31, ntokens=321.6, nsentences=8, sample_size=321.6, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=1067.9, ups=3.32, wpb=321.6, bsz=8, num_updates=2210, lr=9.87822e-05, gnorm=2.145, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=755
2023-03-15 14:12:20 - progress_bar.py[line:272] - INFO: epoch 002:    227 / 2004 loss=1.38, loss_v1=0, loss_v2=0, nll_loss=1.38, ntokens=347.8, nsentences=8, sample_size=347.8, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=1128.9, ups=3.25, wpb=347.8, bsz=8, num_updates=2220, lr=9.87722e-05, gnorm=2.159, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=758
2023-03-15 14:12:24 - progress_bar.py[line:272] - INFO: epoch 002:    237 / 2004 loss=1.332, loss_v1=0, loss_v2=0, nll_loss=1.332, ntokens=375.8, nsentences=8, sample_size=375.8, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=1204.4, ups=3.2, wpb=375.8, bsz=8, num_updates=2230, lr=9.87621e-05, gnorm=2.141, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=761
2023-03-15 14:12:27 - progress_bar.py[line:272] - INFO: epoch 002:    247 / 2004 loss=1.465, loss_v1=0, loss_v2=0, nll_loss=1.465, ntokens=347.4, nsentences=8, sample_size=347.4, sample_size_v1=0, sample_size_v2=0, ppl=2.76, wps=1090.2, ups=3.14, wpb=347.4, bsz=8, num_updates=2240, lr=9.8752e-05, gnorm=2.164, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=764
2023-03-15 14:12:30 - progress_bar.py[line:272] - INFO: epoch 002:    257 / 2004 loss=1.269, loss_v1=0, loss_v2=0, nll_loss=1.269, ntokens=336.8, nsentences=8, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=974.7, ups=2.89, wpb=336.8, bsz=8, num_updates=2250, lr=9.87419e-05, gnorm=2.118, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=768
2023-03-15 14:12:34 - progress_bar.py[line:272] - INFO: epoch 002:    267 / 2004 loss=1.433, loss_v1=0, loss_v2=0, nll_loss=1.433, ntokens=352.4, nsentences=8, sample_size=352.4, sample_size_v1=0, sample_size_v2=0, ppl=2.7, wps=1049.4, ups=2.98, wpb=352.4, bsz=8, num_updates=2260, lr=9.87318e-05, gnorm=2.079, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=771
2023-03-15 14:12:37 - progress_bar.py[line:272] - INFO: epoch 002:    277 / 2004 loss=1.399, loss_v1=0, loss_v2=0, nll_loss=1.399, ntokens=345.8, nsentences=8, sample_size=345.8, sample_size_v1=0, sample_size_v2=0, ppl=2.64, wps=1024, ups=2.96, wpb=345.8, bsz=8, num_updates=2270, lr=9.87217e-05, gnorm=2.137, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=775
2023-03-15 14:12:40 - progress_bar.py[line:272] - INFO: epoch 002:    287 / 2004 loss=1.322, loss_v1=0, loss_v2=0, nll_loss=1.322, ntokens=357.4, nsentences=8, sample_size=357.4, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=1055.8, ups=2.95, wpb=357.4, bsz=8, num_updates=2280, lr=9.87117e-05, gnorm=2.027, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=778
2023-03-15 14:12:44 - progress_bar.py[line:272] - INFO: epoch 002:    297 / 2004 loss=1.409, loss_v1=0, loss_v2=0, nll_loss=1.409, ntokens=374.1, nsentences=8, sample_size=374.1, sample_size_v1=0, sample_size_v2=0, ppl=2.66, wps=1092.7, ups=2.92, wpb=374.1, bsz=8, num_updates=2290, lr=9.87016e-05, gnorm=2.053, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=781
2023-03-15 14:12:47 - progress_bar.py[line:272] - INFO: epoch 002:    307 / 2004 loss=1.394, loss_v1=0, loss_v2=0, nll_loss=1.394, ntokens=336, nsentences=8, sample_size=336, sample_size_v1=0, sample_size_v2=0, ppl=2.63, wps=1013.1, ups=3.02, wpb=336, bsz=8, num_updates=2300, lr=9.86915e-05, gnorm=2.166, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=785
2023-03-15 14:12:47 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 14:12:51 - progress_bar.py[line:272] - INFO: epoch 002:    318 / 2004 loss=1.38, loss_v1=0, loss_v2=0, nll_loss=1.38, ntokens=341.1, nsentences=8, sample_size=341.1, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=900.8, ups=2.64, wpb=341.1, bsz=8, num_updates=2310, lr=9.86814e-05, gnorm=2.152, clip=0, loss_scale=1024, train_wall=4, gb_free=14.7, wall=788
2023-03-15 14:12:54 - progress_bar.py[line:272] - INFO: epoch 002:    328 / 2004 loss=1.337, loss_v1=0, loss_v2=0, nll_loss=1.337, ntokens=331.4, nsentences=8, sample_size=331.4, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=987, ups=2.98, wpb=331.4, bsz=8, num_updates=2320, lr=9.86713e-05, gnorm=2.054, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=792
2023-03-15 14:12:58 - progress_bar.py[line:272] - INFO: epoch 002:    338 / 2004 loss=1.457, loss_v1=0, loss_v2=0, nll_loss=1.457, ntokens=344.4, nsentences=8, sample_size=344.4, sample_size_v1=0, sample_size_v2=0, ppl=2.75, wps=1028.1, ups=2.99, wpb=344.4, bsz=8, num_updates=2330, lr=9.86613e-05, gnorm=2.24, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=795
2023-03-15 14:13:01 - progress_bar.py[line:272] - INFO: epoch 002:    348 / 2004 loss=1.47, loss_v1=0, loss_v2=0, nll_loss=1.47, ntokens=367.8, nsentences=8, sample_size=367.8, sample_size_v1=0, sample_size_v2=0, ppl=2.77, wps=1087.9, ups=2.96, wpb=367.8, bsz=8, num_updates=2340, lr=9.86512e-05, gnorm=2.218, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=799
2023-03-15 14:13:04 - progress_bar.py[line:272] - INFO: epoch 002:    358 / 2004 loss=1.462, loss_v1=0, loss_v2=0, nll_loss=1.462, ntokens=330.8, nsentences=7.8, sample_size=330.8, sample_size_v1=0, sample_size_v2=0, ppl=2.76, wps=968.7, ups=2.93, wpb=330.8, bsz=7.8, num_updates=2350, lr=9.86411e-05, gnorm=2.187, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=802
2023-03-15 14:13:08 - progress_bar.py[line:272] - INFO: epoch 002:    368 / 2004 loss=1.427, loss_v1=0, loss_v2=0, nll_loss=1.427, ntokens=363, nsentences=8, sample_size=363, sample_size_v1=0, sample_size_v2=0, ppl=2.69, wps=1077, ups=2.97, wpb=363, bsz=8, num_updates=2360, lr=9.8631e-05, gnorm=2.158, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=805
2023-03-15 14:13:11 - progress_bar.py[line:272] - INFO: epoch 002:    378 / 2004 loss=1.328, loss_v1=0, loss_v2=0, nll_loss=1.328, ntokens=295.3, nsentences=8, sample_size=295.3, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=882, ups=2.99, wpb=295.3, bsz=8, num_updates=2370, lr=9.86209e-05, gnorm=2.246, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=809
2023-03-15 14:13:14 - progress_bar.py[line:272] - INFO: epoch 002:    388 / 2004 loss=1.365, loss_v1=0, loss_v2=0, nll_loss=1.365, ntokens=348.3, nsentences=8, sample_size=348.3, sample_size_v1=0, sample_size_v2=0, ppl=2.58, wps=1034.9, ups=2.97, wpb=348.3, bsz=8, num_updates=2380, lr=9.86109e-05, gnorm=2.148, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=812
2023-03-15 14:13:18 - progress_bar.py[line:272] - INFO: epoch 002:    398 / 2004 loss=1.395, loss_v1=0, loss_v2=0, nll_loss=1.395, ntokens=341.8, nsentences=8, sample_size=341.8, sample_size_v1=0, sample_size_v2=0, ppl=2.63, wps=1022.1, ups=2.99, wpb=341.8, bsz=8, num_updates=2390, lr=9.86008e-05, gnorm=2.103, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=815
2023-03-15 14:13:21 - progress_bar.py[line:272] - INFO: epoch 002:    408 / 2004 loss=1.348, loss_v1=0, loss_v2=0, nll_loss=1.348, ntokens=376.2, nsentences=8, sample_size=376.2, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=1107.4, ups=2.94, wpb=376.2, bsz=8, num_updates=2400, lr=9.85907e-05, gnorm=2.033, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=819
2023-03-15 14:13:25 - progress_bar.py[line:272] - INFO: epoch 002:    418 / 2004 loss=1.318, loss_v1=0, loss_v2=0, nll_loss=1.318, ntokens=343.4, nsentences=8, sample_size=343.4, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=1007.6, ups=2.93, wpb=343.4, bsz=8, num_updates=2410, lr=9.85806e-05, gnorm=2.079, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=822
2023-03-15 14:13:28 - progress_bar.py[line:272] - INFO: epoch 002:    428 / 2004 loss=1.317, loss_v1=0, loss_v2=0, nll_loss=1.317, ntokens=332.9, nsentences=8, sample_size=332.9, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=984.6, ups=2.96, wpb=332.9, bsz=8, num_updates=2420, lr=9.85705e-05, gnorm=2.118, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=826
2023-03-15 14:13:31 - progress_bar.py[line:272] - INFO: epoch 002:    438 / 2004 loss=1.297, loss_v1=0, loss_v2=0, nll_loss=1.297, ntokens=355.4, nsentences=8, sample_size=355.4, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=1034, ups=2.91, wpb=355.4, bsz=8, num_updates=2430, lr=9.85605e-05, gnorm=2.072, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=829
2023-03-15 14:13:35 - progress_bar.py[line:272] - INFO: epoch 002:    448 / 2004 loss=1.526, loss_v1=0, loss_v2=0, nll_loss=1.526, ntokens=373.4, nsentences=8, sample_size=373.4, sample_size_v1=0, sample_size_v2=0, ppl=2.88, wps=1085.3, ups=2.91, wpb=373.4, bsz=8, num_updates=2440, lr=9.85504e-05, gnorm=2.198, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=832
2023-03-15 14:13:38 - progress_bar.py[line:272] - INFO: epoch 002:    458 / 2004 loss=1.533, loss_v1=0, loss_v2=0, nll_loss=1.533, ntokens=393.3, nsentences=8, sample_size=393.3, sample_size_v1=0, sample_size_v2=0, ppl=2.89, wps=1132.2, ups=2.88, wpb=393.3, bsz=8, num_updates=2450, lr=9.85403e-05, gnorm=2.066, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=836
2023-03-15 14:13:42 - progress_bar.py[line:272] - INFO: epoch 002:    468 / 2004 loss=1.569, loss_v1=0, loss_v2=0, nll_loss=1.569, ntokens=362.7, nsentences=8, sample_size=362.7, sample_size_v1=0, sample_size_v2=0, ppl=2.97, wps=1053.4, ups=2.9, wpb=362.7, bsz=8, num_updates=2460, lr=9.85302e-05, gnorm=2.229, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=839
2023-03-15 14:13:45 - progress_bar.py[line:272] - INFO: epoch 002:    478 / 2004 loss=1.26, loss_v1=0, loss_v2=0, nll_loss=1.26, ntokens=332.6, nsentences=8, sample_size=332.6, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=989.3, ups=2.97, wpb=332.6, bsz=8, num_updates=2470, lr=9.85201e-05, gnorm=2.042, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=843
2023-03-15 14:13:48 - progress_bar.py[line:272] - INFO: epoch 002:    488 / 2004 loss=1.307, loss_v1=0, loss_v2=0, nll_loss=1.307, ntokens=385, nsentences=8, sample_size=385, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=1229.1, ups=3.19, wpb=385, bsz=8, num_updates=2480, lr=9.85101e-05, gnorm=1.99, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=846
2023-03-15 14:13:51 - progress_bar.py[line:272] - INFO: epoch 002:    498 / 2004 loss=1.305, loss_v1=0, loss_v2=0, nll_loss=1.305, ntokens=366.3, nsentences=8, sample_size=366.3, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=1124.1, ups=3.07, wpb=366.3, bsz=8, num_updates=2490, lr=9.85e-05, gnorm=1.987, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=849
2023-03-15 14:13:55 - progress_bar.py[line:272] - INFO: epoch 002:    508 / 2004 loss=1.376, loss_v1=0, loss_v2=0, nll_loss=1.376, ntokens=343.5, nsentences=8, sample_size=343.5, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=1025.3, ups=2.98, wpb=343.5, bsz=8, num_updates=2500, lr=9.84899e-05, gnorm=2.106, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=852
2023-03-15 14:13:58 - progress_bar.py[line:272] - INFO: epoch 002:    518 / 2004 loss=1.446, loss_v1=0, loss_v2=0, nll_loss=1.446, ntokens=357.9, nsentences=8, sample_size=357.9, sample_size_v1=0, sample_size_v2=0, ppl=2.72, wps=1026.2, ups=2.87, wpb=357.9, bsz=8, num_updates=2510, lr=9.84798e-05, gnorm=2.146, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=856
2023-03-15 14:14:02 - progress_bar.py[line:272] - INFO: epoch 002:    528 / 2004 loss=1.417, loss_v1=0, loss_v2=0, nll_loss=1.417, ntokens=403.5, nsentences=8, sample_size=403.5, sample_size_v1=0, sample_size_v2=0, ppl=2.67, wps=1184.1, ups=2.93, wpb=403.5, bsz=8, num_updates=2520, lr=9.84697e-05, gnorm=1.993, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=859
2023-03-15 14:14:05 - progress_bar.py[line:272] - INFO: epoch 002:    538 / 2004 loss=1.403, loss_v1=0, loss_v2=0, nll_loss=1.403, ntokens=380.9, nsentences=8, sample_size=380.9, sample_size_v1=0, sample_size_v2=0, ppl=2.64, wps=1156.1, ups=3.04, wpb=380.9, bsz=8, num_updates=2530, lr=9.84596e-05, gnorm=2.012, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=863
2023-03-15 14:14:08 - progress_bar.py[line:272] - INFO: epoch 002:    548 / 2004 loss=1.377, loss_v1=0, loss_v2=0, nll_loss=1.377, ntokens=353.2, nsentences=8, sample_size=353.2, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=1086.4, ups=3.08, wpb=353.2, bsz=8, num_updates=2540, lr=9.84496e-05, gnorm=2.149, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=866
2023-03-15 14:14:11 - progress_bar.py[line:272] - INFO: epoch 002:    558 / 2004 loss=1.283, loss_v1=0, loss_v2=0, nll_loss=1.283, ntokens=374.9, nsentences=8, sample_size=374.9, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=1224.7, ups=3.27, wpb=374.9, bsz=8, num_updates=2550, lr=9.84395e-05, gnorm=1.929, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=869
2023-03-15 14:14:13 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 14:14:15 - progress_bar.py[line:272] - INFO: epoch 002:    569 / 2004 loss=1.234, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=367.6, nsentences=8, sample_size=367.6, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=1059.3, ups=2.88, wpb=367.6, bsz=8, num_updates=2560, lr=9.84294e-05, gnorm=1.962, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=872
2023-03-15 14:14:18 - progress_bar.py[line:272] - INFO: epoch 002:    579 / 2004 loss=1.431, loss_v1=0, loss_v2=0, nll_loss=1.431, ntokens=326.9, nsentences=8, sample_size=326.9, sample_size_v1=0, sample_size_v2=0, ppl=2.7, wps=984.7, ups=3.01, wpb=326.9, bsz=8, num_updates=2570, lr=9.84193e-05, gnorm=2.209, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=876
2023-03-15 14:14:21 - progress_bar.py[line:272] - INFO: epoch 002:    589 / 2004 loss=1.253, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=374.6, nsentences=8, sample_size=374.6, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=1116.4, ups=2.98, wpb=374.6, bsz=8, num_updates=2580, lr=9.84092e-05, gnorm=1.97, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=879
2023-03-15 14:14:25 - progress_bar.py[line:272] - INFO: epoch 002:    599 / 2004 loss=1.378, loss_v1=0, loss_v2=0, nll_loss=1.378, ntokens=341.7, nsentences=8, sample_size=341.7, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=1020, ups=2.99, wpb=341.7, bsz=8, num_updates=2590, lr=9.83992e-05, gnorm=2.07, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=882
2023-03-15 14:14:28 - progress_bar.py[line:272] - INFO: epoch 002:    609 / 2004 loss=1.424, loss_v1=0, loss_v2=0, nll_loss=1.424, ntokens=346.5, nsentences=8, sample_size=346.5, sample_size_v1=0, sample_size_v2=0, ppl=2.68, wps=1018.5, ups=2.94, wpb=346.5, bsz=8, num_updates=2600, lr=9.83891e-05, gnorm=2.121, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=886
2023-03-15 14:14:32 - progress_bar.py[line:272] - INFO: epoch 002:    619 / 2004 loss=1.181, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=362, nsentences=8, sample_size=362, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1064.4, ups=2.94, wpb=362, bsz=8, num_updates=2610, lr=9.8379e-05, gnorm=1.911, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=889
2023-03-15 14:14:35 - progress_bar.py[line:272] - INFO: epoch 002:    629 / 2004 loss=1.253, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=357.6, nsentences=8, sample_size=357.6, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=1067.5, ups=2.99, wpb=357.6, bsz=8, num_updates=2620, lr=9.83689e-05, gnorm=2.04, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=893
2023-03-15 14:14:38 - progress_bar.py[line:272] - INFO: epoch 002:    639 / 2004 loss=1.317, loss_v1=0, loss_v2=0, nll_loss=1.317, ntokens=330.1, nsentences=8, sample_size=330.1, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=989.9, ups=3, wpb=330.1, bsz=8, num_updates=2630, lr=9.83588e-05, gnorm=2.132, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=896
2023-03-15 14:14:42 - progress_bar.py[line:272] - INFO: epoch 002:    649 / 2004 loss=1.436, loss_v1=0, loss_v2=0, nll_loss=1.436, ntokens=335.3, nsentences=8, sample_size=335.3, sample_size_v1=0, sample_size_v2=0, ppl=2.7, wps=1005.8, ups=3, wpb=335.3, bsz=8, num_updates=2640, lr=9.83488e-05, gnorm=2.184, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=899
2023-03-15 14:14:45 - progress_bar.py[line:272] - INFO: epoch 002:    659 / 2004 loss=1.427, loss_v1=0, loss_v2=0, nll_loss=1.427, ntokens=349.3, nsentences=8, sample_size=349.3, sample_size_v1=0, sample_size_v2=0, ppl=2.69, wps=1036.7, ups=2.97, wpb=349.3, bsz=8, num_updates=2650, lr=9.83387e-05, gnorm=2.134, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=903
2023-03-15 14:14:48 - progress_bar.py[line:272] - INFO: epoch 002:    669 / 2004 loss=1.331, loss_v1=0, loss_v2=0, nll_loss=1.331, ntokens=302.7, nsentences=8, sample_size=302.7, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=894.4, ups=2.95, wpb=302.7, bsz=8, num_updates=2660, lr=9.83286e-05, gnorm=2.2, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=906
2023-03-15 14:14:52 - progress_bar.py[line:272] - INFO: epoch 002:    679 / 2004 loss=1.263, loss_v1=0, loss_v2=0, nll_loss=1.263, ntokens=347, nsentences=8, sample_size=347, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=1033.9, ups=2.98, wpb=347, bsz=8, num_updates=2670, lr=9.83185e-05, gnorm=2.072, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=909
2023-03-15 14:14:55 - progress_bar.py[line:272] - INFO: epoch 002:    689 / 2004 loss=1.288, loss_v1=0, loss_v2=0, nll_loss=1.288, ntokens=348.2, nsentences=8, sample_size=348.2, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=1028.6, ups=2.95, wpb=348.2, bsz=8, num_updates=2680, lr=9.83084e-05, gnorm=2.026, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=913
2023-03-15 14:14:57 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 14:14:59 - progress_bar.py[line:272] - INFO: epoch 002:    700 / 2004 loss=1.388, loss_v1=0, loss_v2=0, nll_loss=1.388, ntokens=347.8, nsentences=8, sample_size=347.8, sample_size_v1=0, sample_size_v2=0, ppl=2.62, wps=939.7, ups=2.7, wpb=347.8, bsz=8, num_updates=2690, lr=9.82984e-05, gnorm=2.125, clip=0, loss_scale=2048, train_wall=4, gb_free=15.1, wall=916
2023-03-15 14:15:02 - progress_bar.py[line:272] - INFO: epoch 002:    710 / 2004 loss=1.417, loss_v1=0, loss_v2=0, nll_loss=1.417, ntokens=334.8, nsentences=8, sample_size=334.8, sample_size_v1=0, sample_size_v2=0, ppl=2.67, wps=989.5, ups=2.96, wpb=334.8, bsz=8, num_updates=2700, lr=9.82883e-05, gnorm=2.332, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=920
2023-03-15 14:15:06 - progress_bar.py[line:272] - INFO: epoch 002:    720 / 2004 loss=1.376, loss_v1=0, loss_v2=0, nll_loss=1.376, ntokens=353, nsentences=8, sample_size=353, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=1052.4, ups=2.98, wpb=353, bsz=8, num_updates=2710, lr=9.82782e-05, gnorm=2.156, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=923
2023-03-15 14:15:09 - progress_bar.py[line:272] - INFO: epoch 002:    730 / 2004 loss=1.418, loss_v1=0, loss_v2=0, nll_loss=1.418, ntokens=351.9, nsentences=8, sample_size=351.9, sample_size_v1=0, sample_size_v2=0, ppl=2.67, wps=1035.2, ups=2.94, wpb=351.9, bsz=8, num_updates=2720, lr=9.82681e-05, gnorm=2.177, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=927
2023-03-15 14:15:11 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 14:15:13 - progress_bar.py[line:272] - INFO: epoch 002:    741 / 2004 loss=1.26, loss_v1=0, loss_v2=0, nll_loss=1.26, ntokens=314.7, nsentences=8, sample_size=314.7, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=860.6, ups=2.73, wpb=314.7, bsz=8, num_updates=2730, lr=9.8258e-05, gnorm=2.187, clip=0, loss_scale=1024, train_wall=4, gb_free=15.2, wall=930
2023-03-15 14:15:16 - progress_bar.py[line:272] - INFO: epoch 002:    751 / 2004 loss=1.385, loss_v1=0, loss_v2=0, nll_loss=1.385, ntokens=361.5, nsentences=8, sample_size=361.5, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=1064.5, ups=2.94, wpb=361.5, bsz=8, num_updates=2740, lr=9.82479e-05, gnorm=2.138, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=934
2023-03-15 14:15:19 - progress_bar.py[line:272] - INFO: epoch 002:    761 / 2004 loss=1.385, loss_v1=0, loss_v2=0, nll_loss=1.385, ntokens=324.2, nsentences=8, sample_size=324.2, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=991.7, ups=3.06, wpb=324.2, bsz=8, num_updates=2750, lr=9.82379e-05, gnorm=2.241, clip=0, loss_scale=1024, train_wall=3, gb_free=14.1, wall=937
2023-03-15 14:15:22 - progress_bar.py[line:272] - INFO: epoch 002:    771 / 2004 loss=1.458, loss_v1=0, loss_v2=0, nll_loss=1.458, ntokens=396, nsentences=8, sample_size=396, sample_size_v1=0, sample_size_v2=0, ppl=2.75, wps=1274.1, ups=3.22, wpb=396, bsz=8, num_updates=2760, lr=9.82278e-05, gnorm=2.071, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=940
2023-03-15 14:15:25 - progress_bar.py[line:272] - INFO: epoch 002:    781 / 2004 loss=1.378, loss_v1=0, loss_v2=0, nll_loss=1.378, ntokens=338.7, nsentences=8, sample_size=338.7, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=1111.8, ups=3.28, wpb=338.7, bsz=8, num_updates=2770, lr=9.82177e-05, gnorm=2.174, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=943
2023-03-15 14:15:29 - progress_bar.py[line:272] - INFO: epoch 002:    791 / 2004 loss=1.215, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=342.2, nsentences=8, sample_size=342.2, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=1120.7, ups=3.27, wpb=342.2, bsz=8, num_updates=2780, lr=9.82076e-05, gnorm=2.049, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=946
2023-03-15 14:15:32 - progress_bar.py[line:272] - INFO: epoch 002:    801 / 2004 loss=1.323, loss_v1=0, loss_v2=0, nll_loss=1.323, ntokens=329, nsentences=8, sample_size=329, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=1071.2, ups=3.26, wpb=329, bsz=8, num_updates=2790, lr=9.81975e-05, gnorm=2.228, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=949
2023-03-15 14:15:35 - progress_bar.py[line:272] - INFO: epoch 002:    811 / 2004 loss=1.261, loss_v1=0, loss_v2=0, nll_loss=1.261, ntokens=352.5, nsentences=8, sample_size=352.5, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=1055.6, ups=2.99, wpb=352.5, bsz=8, num_updates=2800, lr=9.81875e-05, gnorm=2.02, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=953
2023-03-15 14:15:38 - progress_bar.py[line:272] - INFO: epoch 002:    821 / 2004 loss=1.181, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=321, nsentences=8, sample_size=321, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=946.4, ups=2.95, wpb=321, bsz=8, num_updates=2810, lr=9.81774e-05, gnorm=2.069, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=956
2023-03-15 14:15:42 - progress_bar.py[line:272] - INFO: epoch 002:    831 / 2004 loss=1.377, loss_v1=0, loss_v2=0, nll_loss=1.377, ntokens=355.1, nsentences=8, sample_size=355.1, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=1047.4, ups=2.95, wpb=355.1, bsz=8, num_updates=2820, lr=9.81673e-05, gnorm=2.138, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=959
2023-03-15 14:15:45 - progress_bar.py[line:272] - INFO: epoch 002:    841 / 2004 loss=1.201, loss_v1=0, loss_v2=0, nll_loss=1.201, ntokens=353.7, nsentences=8, sample_size=353.7, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=1035.7, ups=2.93, wpb=353.7, bsz=8, num_updates=2830, lr=9.81572e-05, gnorm=2.013, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=963
2023-03-15 14:15:49 - progress_bar.py[line:272] - INFO: epoch 002:    851 / 2004 loss=1.259, loss_v1=0, loss_v2=0, nll_loss=1.259, ntokens=358, nsentences=8, sample_size=358, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=1047.1, ups=2.92, wpb=358, bsz=8, num_updates=2840, lr=9.81471e-05, gnorm=2.032, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=966
2023-03-15 14:15:52 - progress_bar.py[line:272] - INFO: epoch 002:    861 / 2004 loss=1.413, loss_v1=0, loss_v2=0, nll_loss=1.413, ntokens=345.4, nsentences=8, sample_size=345.4, sample_size_v1=0, sample_size_v2=0, ppl=2.66, wps=1031.9, ups=2.99, wpb=345.4, bsz=8, num_updates=2850, lr=9.81371e-05, gnorm=2.134, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=970
2023-03-15 14:15:54 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 14:15:56 - progress_bar.py[line:272] - INFO: epoch 002:    872 / 2004 loss=1.345, loss_v1=0, loss_v2=0, nll_loss=1.345, ntokens=364.5, nsentences=8, sample_size=364.5, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=987, ups=2.71, wpb=364.5, bsz=8, num_updates=2860, lr=9.8127e-05, gnorm=1.998, clip=0, loss_scale=1024, train_wall=4, gb_free=15.4, wall=973
2023-03-15 14:15:59 - progress_bar.py[line:272] - INFO: epoch 002:    882 / 2004 loss=1.218, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=321.6, nsentences=8, sample_size=321.6, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=951.7, ups=2.96, wpb=321.6, bsz=8, num_updates=2870, lr=9.81169e-05, gnorm=2.053, clip=0, loss_scale=1024, train_wall=3, gb_free=13.7, wall=977
2023-03-15 14:16:02 - progress_bar.py[line:272] - INFO: epoch 002:    892 / 2004 loss=1.264, loss_v1=0, loss_v2=0, nll_loss=1.264, ntokens=308.5, nsentences=8, sample_size=308.5, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=920.8, ups=2.98, wpb=308.5, bsz=8, num_updates=2880, lr=9.81068e-05, gnorm=2.162, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=980
2023-03-15 14:16:06 - progress_bar.py[line:272] - INFO: epoch 002:    902 / 2004 loss=1.259, loss_v1=0, loss_v2=0, nll_loss=1.259, ntokens=364.3, nsentences=8, sample_size=364.3, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=1072.8, ups=2.94, wpb=364.3, bsz=8, num_updates=2890, lr=9.80967e-05, gnorm=2.059, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=983
2023-03-15 14:16:09 - progress_bar.py[line:272] - INFO: epoch 002:    912 / 2004 loss=1.212, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=373.3, nsentences=8, sample_size=373.3, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=1158.6, ups=3.1, wpb=373.3, bsz=8, num_updates=2900, lr=9.80867e-05, gnorm=1.963, clip=0, loss_scale=1024, train_wall=3, gb_free=14, wall=987
2023-03-15 14:16:12 - progress_bar.py[line:272] - INFO: epoch 002:    922 / 2004 loss=1.296, loss_v1=0, loss_v2=0, nll_loss=1.296, ntokens=330.8, nsentences=8, sample_size=330.8, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=1082.6, ups=3.27, wpb=330.8, bsz=8, num_updates=2910, lr=9.80766e-05, gnorm=2.076, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=990
2023-03-15 14:16:15 - progress_bar.py[line:272] - INFO: epoch 002:    932 / 2004 loss=1.189, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=335.4, nsentences=8, sample_size=335.4, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=1077.9, ups=3.21, wpb=335.4, bsz=8, num_updates=2920, lr=9.80665e-05, gnorm=2.049, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=993
2023-03-15 14:16:18 - progress_bar.py[line:272] - INFO: epoch 002:    942 / 2004 loss=1.343, loss_v1=0, loss_v2=0, nll_loss=1.343, ntokens=376.6, nsentences=8, sample_size=376.6, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=1187.3, ups=3.15, wpb=376.6, bsz=8, num_updates=2930, lr=9.80564e-05, gnorm=2.032, clip=0, loss_scale=1024, train_wall=3, gb_free=13.9, wall=996
2023-03-15 14:16:21 - progress_bar.py[line:272] - INFO: epoch 002:    952 / 2004 loss=1.242, loss_v1=0, loss_v2=0, nll_loss=1.242, ntokens=343.4, nsentences=8, sample_size=343.4, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=1111.6, ups=3.24, wpb=343.4, bsz=8, num_updates=2940, lr=9.80463e-05, gnorm=2.031, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=999
2023-03-15 14:16:25 - progress_bar.py[line:272] - INFO: epoch 002:    962 / 2004 loss=1.396, loss_v1=0, loss_v2=0, nll_loss=1.396, ntokens=381.7, nsentences=8, sample_size=381.7, sample_size_v1=0, sample_size_v2=0, ppl=2.63, wps=1139.6, ups=2.99, wpb=381.7, bsz=8, num_updates=2950, lr=9.80363e-05, gnorm=2.135, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=1002
2023-03-15 14:16:28 - progress_bar.py[line:272] - INFO: epoch 002:    972 / 2004 loss=1.306, loss_v1=0, loss_v2=0, nll_loss=1.306, ntokens=332.1, nsentences=8, sample_size=332.1, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=996.1, ups=3, wpb=332.1, bsz=8, num_updates=2960, lr=9.80262e-05, gnorm=2.159, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=1006
2023-03-15 14:16:31 - progress_bar.py[line:272] - INFO: epoch 002:    982 / 2004 loss=1.246, loss_v1=0, loss_v2=0, nll_loss=1.246, ntokens=315.8, nsentences=8, sample_size=315.8, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=1031.3, ups=3.27, wpb=315.8, bsz=8, num_updates=2970, lr=9.80161e-05, gnorm=2.222, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=1009
2023-03-15 14:16:34 - progress_bar.py[line:272] - INFO: epoch 002:    992 / 2004 loss=1.262, loss_v1=0, loss_v2=0, nll_loss=1.262, ntokens=382.3, nsentences=8, sample_size=382.3, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=1234.7, ups=3.23, wpb=382.3, bsz=8, num_updates=2980, lr=9.8006e-05, gnorm=1.921, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=1012
2023-03-15 14:16:37 - progress_bar.py[line:272] - INFO: epoch 002:   1002 / 2004 loss=1.216, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=329.7, nsentences=8, sample_size=329.7, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=1063.6, ups=3.23, wpb=329.7, bsz=8, num_updates=2990, lr=9.79959e-05, gnorm=2.071, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=1015
2023-03-15 14:16:38 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 14:16:41 - progress_bar.py[line:272] - INFO: epoch 002:   1013 / 2004 loss=1.307, loss_v1=0, loss_v2=0, nll_loss=1.307, ntokens=340.9, nsentences=8, sample_size=340.9, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=1049.8, ups=3.08, wpb=340.9, bsz=8, num_updates=3000, lr=9.79858e-05, gnorm=2.155, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=1018
2023-03-15 14:16:44 - progress_bar.py[line:272] - INFO: epoch 002:   1023 / 2004 loss=1.265, loss_v1=0, loss_v2=0, nll_loss=1.265, ntokens=325.9, nsentences=8, sample_size=325.9, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=1070.4, ups=3.28, wpb=325.9, bsz=8, num_updates=3010, lr=9.79758e-05, gnorm=2.147, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=1021
2023-03-15 14:16:47 - progress_bar.py[line:272] - INFO: epoch 002:   1033 / 2004 loss=1.238, loss_v1=0, loss_v2=0, nll_loss=1.238, ntokens=317.2, nsentences=8, sample_size=317.2, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=1002.5, ups=3.16, wpb=317.2, bsz=8, num_updates=3020, lr=9.79657e-05, gnorm=2.116, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=1024
2023-03-15 14:16:50 - progress_bar.py[line:272] - INFO: epoch 002:   1043 / 2004 loss=1.345, loss_v1=0, loss_v2=0, nll_loss=1.345, ntokens=349.3, nsentences=8, sample_size=349.3, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=1011.2, ups=2.89, wpb=349.3, bsz=8, num_updates=3030, lr=9.79556e-05, gnorm=2.095, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=1028
2023-03-15 14:16:53 - progress_bar.py[line:272] - INFO: epoch 002:   1053 / 2004 loss=1.205, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=374.2, nsentences=8, sample_size=374.2, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=1175.2, ups=3.14, wpb=374.2, bsz=8, num_updates=3040, lr=9.79455e-05, gnorm=1.95, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=1031
2023-03-15 14:16:56 - progress_bar.py[line:272] - INFO: epoch 002:   1063 / 2004 loss=1.333, loss_v1=0, loss_v2=0, nll_loss=1.333, ntokens=333.1, nsentences=8, sample_size=333.1, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=1108.9, ups=3.33, wpb=333.1, bsz=8, num_updates=3050, lr=9.79354e-05, gnorm=2.217, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=1034
2023-03-15 14:16:59 - progress_bar.py[line:272] - INFO: epoch 002:   1073 / 2004 loss=1.36, loss_v1=0, loss_v2=0, nll_loss=1.36, ntokens=353.3, nsentences=8, sample_size=353.3, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=1147.1, ups=3.25, wpb=353.3, bsz=8, num_updates=3060, lr=9.79254e-05, gnorm=2.114, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=1037
2023-03-15 14:17:03 - progress_bar.py[line:272] - INFO: epoch 002:   1083 / 2004 loss=1.253, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=365.6, nsentences=8, sample_size=365.6, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=1184.7, ups=3.24, wpb=365.6, bsz=8, num_updates=3070, lr=9.79153e-05, gnorm=2.016, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=1040
2023-03-15 14:17:06 - progress_bar.py[line:272] - INFO: epoch 002:   1093 / 2004 loss=1.363, loss_v1=0, loss_v2=0, nll_loss=1.363, ntokens=336.9, nsentences=8, sample_size=336.9, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=1089.8, ups=3.23, wpb=336.9, bsz=8, num_updates=3080, lr=9.79052e-05, gnorm=2.118, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=1043
2023-03-15 14:17:09 - progress_bar.py[line:272] - INFO: epoch 002:   1103 / 2004 loss=1.423, loss_v1=0, loss_v2=0, nll_loss=1.423, ntokens=369, nsentences=8, sample_size=369, sample_size_v1=0, sample_size_v2=0, ppl=2.68, wps=1150.1, ups=3.12, wpb=369, bsz=8, num_updates=3090, lr=9.78951e-05, gnorm=2.158, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=1046
2023-03-15 14:17:12 - progress_bar.py[line:272] - INFO: epoch 002:   1113 / 2004 loss=1.258, loss_v1=0, loss_v2=0, nll_loss=1.258, ntokens=345.6, nsentences=8, sample_size=345.6, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=1105.7, ups=3.2, wpb=345.6, bsz=8, num_updates=3100, lr=9.7885e-05, gnorm=1.984, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=1050
2023-03-15 14:17:15 - progress_bar.py[line:272] - INFO: epoch 002:   1123 / 2004 loss=1.139, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=309.4, nsentences=8, sample_size=309.4, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1021.3, ups=3.3, wpb=309.4, bsz=8, num_updates=3110, lr=9.7875e-05, gnorm=1.999, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=1053
2023-03-15 14:17:18 - progress_bar.py[line:272] - INFO: epoch 002:   1133 / 2004 loss=1.25, loss_v1=0, loss_v2=0, nll_loss=1.25, ntokens=379.2, nsentences=8, sample_size=379.2, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=1217.5, ups=3.21, wpb=379.2, bsz=8, num_updates=3120, lr=9.78649e-05, gnorm=1.959, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=1056
2023-03-15 14:17:21 - progress_bar.py[line:272] - INFO: epoch 002:   1143 / 2004 loss=1.329, loss_v1=0, loss_v2=0, nll_loss=1.329, ntokens=365, nsentences=8, sample_size=365, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=1221.4, ups=3.35, wpb=365, bsz=8, num_updates=3130, lr=9.78548e-05, gnorm=2.084, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=1059
2023-03-15 14:17:24 - progress_bar.py[line:272] - INFO: epoch 002:   1153 / 2004 loss=1.216, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=370.9, nsentences=8, sample_size=370.9, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=1122.7, ups=3.03, wpb=370.9, bsz=8, num_updates=3140, lr=9.78447e-05, gnorm=1.997, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=1062
2023-03-15 14:17:27 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 14:17:28 - progress_bar.py[line:272] - INFO: epoch 002:   1164 / 2004 loss=1.239, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=376.4, nsentences=8, sample_size=376.4, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=992, ups=2.64, wpb=376.4, bsz=8, num_updates=3150, lr=9.78346e-05, gnorm=1.962, clip=0, loss_scale=1024, train_wall=4, gb_free=13.9, wall=1066
2023-03-15 14:17:31 - progress_bar.py[line:272] - INFO: epoch 002:   1174 / 2004 loss=1.202, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=356.9, nsentences=8, sample_size=356.9, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=1098.2, ups=3.08, wpb=356.9, bsz=8, num_updates=3160, lr=9.78246e-05, gnorm=2.045, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=1069
2023-03-15 14:17:35 - progress_bar.py[line:272] - INFO: epoch 002:   1184 / 2004 loss=1.157, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=328.1, nsentences=8, sample_size=328.1, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1073.6, ups=3.27, wpb=328.1, bsz=8, num_updates=3170, lr=9.78145e-05, gnorm=2.112, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=1072
2023-03-15 14:17:38 - progress_bar.py[line:272] - INFO: epoch 002:   1194 / 2004 loss=1.185, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=360.4, nsentences=8, sample_size=360.4, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1154, ups=3.2, wpb=360.4, bsz=8, num_updates=3180, lr=9.78044e-05, gnorm=2.076, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=1075
2023-03-15 14:17:41 - progress_bar.py[line:272] - INFO: epoch 002:   1204 / 2004 loss=1.211, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=313.8, nsentences=8, sample_size=313.8, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=1039.4, ups=3.31, wpb=313.8, bsz=8, num_updates=3190, lr=9.77943e-05, gnorm=2.154, clip=0, loss_scale=1024, train_wall=3, gb_free=15.7, wall=1078
2023-03-15 14:17:44 - progress_bar.py[line:272] - INFO: epoch 002:   1214 / 2004 loss=1.325, loss_v1=0, loss_v2=0, nll_loss=1.325, ntokens=308.1, nsentences=8, sample_size=308.1, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=1043.5, ups=3.39, wpb=308.1, bsz=8, num_updates=3200, lr=9.77842e-05, gnorm=2.257, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=1081
2023-03-15 14:17:47 - progress_bar.py[line:272] - INFO: epoch 002:   1224 / 2004 loss=1.188, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=323.6, nsentences=8, sample_size=323.6, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=1071.5, ups=3.31, wpb=323.6, bsz=8, num_updates=3210, lr=9.77741e-05, gnorm=2.202, clip=0, loss_scale=1024, train_wall=3, gb_free=15.7, wall=1084
2023-03-15 14:17:50 - progress_bar.py[line:272] - INFO: epoch 002:   1234 / 2004 loss=1.172, loss_v1=0, loss_v2=0, nll_loss=1.172, ntokens=326, nsentences=8, sample_size=326, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1066, ups=3.27, wpb=326, bsz=8, num_updates=3220, lr=9.77641e-05, gnorm=2.177, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=1087
2023-03-15 14:17:53 - progress_bar.py[line:272] - INFO: epoch 002:   1244 / 2004 loss=1.378, loss_v1=0, loss_v2=0, nll_loss=1.378, ntokens=385.1, nsentences=8, sample_size=385.1, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=1227.9, ups=3.19, wpb=385.1, bsz=8, num_updates=3230, lr=9.7754e-05, gnorm=2.05, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=1090
2023-03-15 14:17:56 - progress_bar.py[line:272] - INFO: epoch 002:   1254 / 2004 loss=1.242, loss_v1=0, loss_v2=0, nll_loss=1.242, ntokens=339.2, nsentences=8, sample_size=339.2, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=1113, ups=3.28, wpb=339.2, bsz=8, num_updates=3240, lr=9.77439e-05, gnorm=2.154, clip=0, loss_scale=1024, train_wall=3, gb_free=15.8, wall=1094
2023-03-15 14:17:59 - progress_bar.py[line:272] - INFO: epoch 002:   1264 / 2004 loss=1.276, loss_v1=0, loss_v2=0, nll_loss=1.276, ntokens=337.7, nsentences=8, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=1056.7, ups=3.13, wpb=337.7, bsz=8, num_updates=3250, lr=9.77338e-05, gnorm=2.126, clip=0, loss_scale=1024, train_wall=3, gb_free=14, wall=1097
2023-03-15 14:18:02 - progress_bar.py[line:272] - INFO: epoch 002:   1274 / 2004 loss=1.221, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=346.2, nsentences=8, sample_size=346.2, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=1022, ups=2.95, wpb=346.2, bsz=8, num_updates=3260, lr=9.77237e-05, gnorm=2.023, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=1100
2023-03-15 14:18:06 - progress_bar.py[line:272] - INFO: epoch 002:   1284 / 2004 loss=1.148, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=334.4, nsentences=8, sample_size=334.4, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=975.5, ups=2.92, wpb=334.4, bsz=8, num_updates=3270, lr=9.77137e-05, gnorm=2.11, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=1104
2023-03-15 14:18:09 - progress_bar.py[line:272] - INFO: epoch 002:   1294 / 2004 loss=1.114, loss_v1=0, loss_v2=0, nll_loss=1.114, ntokens=310.1, nsentences=8, sample_size=310.1, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=928.1, ups=2.99, wpb=310.1, bsz=8, num_updates=3280, lr=9.77036e-05, gnorm=2.084, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=1107
2023-03-15 14:18:12 - progress_bar.py[line:272] - INFO: epoch 002:   1304 / 2004 loss=1.292, loss_v1=0, loss_v2=0, nll_loss=1.292, ntokens=327.6, nsentences=8, sample_size=327.6, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=1041.7, ups=3.18, wpb=327.6, bsz=8, num_updates=3290, lr=9.76935e-05, gnorm=2.104, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=1110
2023-03-15 14:18:16 - progress_bar.py[line:272] - INFO: epoch 002:   1314 / 2004 loss=1.203, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=326.5, nsentences=8, sample_size=326.5, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=1006.1, ups=3.08, wpb=326.5, bsz=8, num_updates=3300, lr=9.76834e-05, gnorm=2.024, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=1113
2023-03-15 14:18:18 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 14:18:19 - progress_bar.py[line:272] - INFO: epoch 002:   1325 / 2004 loss=1.337, loss_v1=0, loss_v2=0, nll_loss=1.337, ntokens=313, nsentences=8, sample_size=313, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=908.2, ups=2.9, wpb=313, bsz=8, num_updates=3310, lr=9.76733e-05, gnorm=2.237, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=1117
2023-03-15 14:18:22 - progress_bar.py[line:272] - INFO: epoch 002:   1335 / 2004 loss=1.404, loss_v1=0, loss_v2=0, nll_loss=1.404, ntokens=350.2, nsentences=8, sample_size=350.2, sample_size_v1=0, sample_size_v2=0, ppl=2.65, wps=1148.5, ups=3.28, wpb=350.2, bsz=8, num_updates=3320, lr=9.76633e-05, gnorm=2.208, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=1120
2023-03-15 14:18:25 - progress_bar.py[line:272] - INFO: epoch 002:   1345 / 2004 loss=1.249, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=299.1, nsentences=8, sample_size=299.1, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=1004.3, ups=3.36, wpb=299.1, bsz=8, num_updates=3330, lr=9.76532e-05, gnorm=2.272, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=1123
2023-03-15 14:18:28 - progress_bar.py[line:272] - INFO: epoch 002:   1355 / 2004 loss=1.295, loss_v1=0, loss_v2=0, nll_loss=1.295, ntokens=322.6, nsentences=8, sample_size=322.6, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=1084.6, ups=3.36, wpb=322.6, bsz=8, num_updates=3340, lr=9.76431e-05, gnorm=2.163, clip=0, loss_scale=1024, train_wall=3, gb_free=15.9, wall=1126
2023-03-15 14:18:31 - progress_bar.py[line:272] - INFO: epoch 002:   1365 / 2004 loss=1.298, loss_v1=0, loss_v2=0, nll_loss=1.298, ntokens=315.7, nsentences=8, sample_size=315.7, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=1048, ups=3.32, wpb=315.7, bsz=8, num_updates=3350, lr=9.7633e-05, gnorm=2.199, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=1129
2023-03-15 14:18:34 - progress_bar.py[line:272] - INFO: epoch 002:   1375 / 2004 loss=1.188, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=319, nsentences=8, sample_size=319, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=1044.2, ups=3.27, wpb=319, bsz=8, num_updates=3360, lr=9.76229e-05, gnorm=2.063, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=1132
2023-03-15 14:18:37 - progress_bar.py[line:272] - INFO: epoch 002:   1385 / 2004 loss=1.28, loss_v1=0, loss_v2=0, nll_loss=1.28, ntokens=399.1, nsentences=8, sample_size=399.1, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=1264.3, ups=3.17, wpb=399.1, bsz=8, num_updates=3370, lr=9.76129e-05, gnorm=1.926, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=1135
2023-03-15 14:18:40 - progress_bar.py[line:272] - INFO: epoch 002:   1395 / 2004 loss=1.146, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=348.3, nsentences=8, sample_size=348.3, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1127.5, ups=3.24, wpb=348.3, bsz=8, num_updates=3380, lr=9.76028e-05, gnorm=1.946, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=1138
2023-03-15 14:18:44 - progress_bar.py[line:272] - INFO: epoch 002:   1405 / 2004 loss=1.152, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=342.2, nsentences=8, sample_size=342.2, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1102, ups=3.22, wpb=342.2, bsz=8, num_updates=3390, lr=9.75927e-05, gnorm=2, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=1141
2023-03-15 14:18:47 - progress_bar.py[line:272] - INFO: epoch 002:   1415 / 2004 loss=1.356, loss_v1=0, loss_v2=0, nll_loss=1.356, ntokens=395.9, nsentences=8, sample_size=395.9, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=1245.1, ups=3.15, wpb=395.9, bsz=8, num_updates=3400, lr=9.75826e-05, gnorm=1.993, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=1144
2023-03-15 14:18:50 - progress_bar.py[line:272] - INFO: epoch 002:   1425 / 2004 loss=1.102, loss_v1=0, loss_v2=0, nll_loss=1.102, ntokens=287.7, nsentences=8, sample_size=287.7, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=920.8, ups=3.2, wpb=287.7, bsz=8, num_updates=3410, lr=9.75725e-05, gnorm=2.055, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=1147
2023-03-15 14:18:53 - progress_bar.py[line:272] - INFO: epoch 002:   1435 / 2004 loss=1.286, loss_v1=0, loss_v2=0, nll_loss=1.286, ntokens=360.9, nsentences=8, sample_size=360.9, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=1098.7, ups=3.04, wpb=360.9, bsz=8, num_updates=3420, lr=9.75625e-05, gnorm=2.068, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=1151
2023-03-15 14:18:56 - progress_bar.py[line:272] - INFO: epoch 002:   1445 / 2004 loss=1.217, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=325.8, nsentences=8, sample_size=325.8, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=1051.7, ups=3.23, wpb=325.8, bsz=8, num_updates=3430, lr=9.75524e-05, gnorm=2.088, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=1154
2023-03-15 14:18:59 - progress_bar.py[line:272] - INFO: epoch 002:   1455 / 2004 loss=1.351, loss_v1=0, loss_v2=0, nll_loss=1.351, ntokens=370.5, nsentences=8, sample_size=370.5, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=1179.5, ups=3.18, wpb=370.5, bsz=8, num_updates=3440, lr=9.75423e-05, gnorm=2.053, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=1157
2023-03-15 14:19:02 - progress_bar.py[line:272] - INFO: epoch 002:   1465 / 2004 loss=1.269, loss_v1=0, loss_v2=0, nll_loss=1.269, ntokens=388.9, nsentences=8, sample_size=388.9, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=1272.1, ups=3.27, wpb=388.9, bsz=8, num_updates=3450, lr=9.75322e-05, gnorm=1.972, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=1160
2023-03-15 14:19:06 - progress_bar.py[line:272] - INFO: epoch 002:   1475 / 2004 loss=1.244, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=411.5, nsentences=8, sample_size=411.5, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=1308.5, ups=3.18, wpb=411.5, bsz=8, num_updates=3460, lr=9.75221e-05, gnorm=1.977, clip=0, loss_scale=2048, train_wall=3, gb_free=13.8, wall=1163
2023-03-15 14:19:09 - progress_bar.py[line:272] - INFO: epoch 002:   1485 / 2004 loss=1.239, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=355.3, nsentences=8, sample_size=355.3, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=1169.8, ups=3.29, wpb=355.3, bsz=8, num_updates=3470, lr=9.7512e-05, gnorm=1.999, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=1166
2023-03-15 14:19:12 - progress_bar.py[line:272] - INFO: epoch 002:   1495 / 2004 loss=1.28, loss_v1=0, loss_v2=0, nll_loss=1.28, ntokens=323.5, nsentences=8, sample_size=323.5, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=1050.6, ups=3.25, wpb=323.5, bsz=8, num_updates=3480, lr=9.7502e-05, gnorm=2.167, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=1169
2023-03-15 14:19:15 - progress_bar.py[line:272] - INFO: epoch 002:   1505 / 2004 loss=1.222, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=329.6, nsentences=8, sample_size=329.6, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=1086.4, ups=3.3, wpb=329.6, bsz=8, num_updates=3490, lr=9.74919e-05, gnorm=2.095, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=1172
2023-03-15 14:19:18 - progress_bar.py[line:272] - INFO: epoch 002:   1515 / 2004 loss=1.139, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=322.3, nsentences=8, sample_size=322.3, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1063.5, ups=3.3, wpb=322.3, bsz=8, num_updates=3500, lr=9.74818e-05, gnorm=2.045, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=1175
2023-03-15 14:19:21 - progress_bar.py[line:272] - INFO: epoch 002:   1525 / 2004 loss=1.251, loss_v1=0, loss_v2=0, nll_loss=1.251, ntokens=327.9, nsentences=8, sample_size=327.9, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=1096.8, ups=3.34, wpb=327.9, bsz=8, num_updates=3510, lr=9.74717e-05, gnorm=2.155, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=1178
2023-03-15 14:19:24 - progress_bar.py[line:272] - INFO: epoch 002:   1535 / 2004 loss=1.199, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=356.9, nsentences=8, sample_size=356.9, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=1145.7, ups=3.21, wpb=356.9, bsz=8, num_updates=3520, lr=9.74616e-05, gnorm=1.987, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=1181
2023-03-15 14:19:27 - progress_bar.py[line:272] - INFO: epoch 002:   1545 / 2004 loss=1.16, loss_v1=0, loss_v2=0, nll_loss=1.16, ntokens=309.5, nsentences=8, sample_size=309.5, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1025.8, ups=3.31, wpb=309.5, bsz=8, num_updates=3530, lr=9.74516e-05, gnorm=2.149, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=1184
2023-03-15 14:19:30 - progress_bar.py[line:272] - INFO: epoch 002:   1555 / 2004 loss=1.315, loss_v1=0, loss_v2=0, nll_loss=1.315, ntokens=355.3, nsentences=8, sample_size=355.3, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=1134.4, ups=3.19, wpb=355.3, bsz=8, num_updates=3540, lr=9.74415e-05, gnorm=2.056, clip=0, loss_scale=2048, train_wall=3, gb_free=13.5, wall=1188
2023-03-15 14:19:33 - progress_bar.py[line:272] - INFO: epoch 002:   1565 / 2004 loss=1.1, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=347, nsentences=8, sample_size=347, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1095.4, ups=3.16, wpb=347, bsz=8, num_updates=3550, lr=9.74314e-05, gnorm=2.024, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=1191
2023-03-15 14:19:37 - progress_bar.py[line:272] - INFO: epoch 002:   1575 / 2004 loss=1.236, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=336.5, nsentences=8, sample_size=336.5, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=1005.7, ups=2.99, wpb=336.5, bsz=8, num_updates=3560, lr=9.74213e-05, gnorm=2.106, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=1194
2023-03-15 14:19:38 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 14:19:40 - progress_bar.py[line:272] - INFO: epoch 002:   1586 / 2004 loss=1.238, loss_v1=0, loss_v2=0, nll_loss=1.238, ntokens=329.1, nsentences=8, sample_size=329.1, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=901.4, ups=2.74, wpb=329.1, bsz=8, num_updates=3570, lr=9.74112e-05, gnorm=2.113, clip=0, loss_scale=2048, train_wall=4, gb_free=14.8, wall=1198
2023-03-15 14:19:44 - progress_bar.py[line:272] - INFO: epoch 002:   1596 / 2004 loss=1.267, loss_v1=0, loss_v2=0, nll_loss=1.267, ntokens=353.3, nsentences=8, sample_size=353.3, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=1021.1, ups=2.89, wpb=353.3, bsz=8, num_updates=3580, lr=9.74012e-05, gnorm=2.106, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=1201
2023-03-15 14:19:47 - progress_bar.py[line:272] - INFO: epoch 002:   1606 / 2004 loss=1.186, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=337.1, nsentences=8, sample_size=337.1, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=985.2, ups=2.92, wpb=337.1, bsz=8, num_updates=3590, lr=9.73911e-05, gnorm=2.022, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=1205
2023-03-15 14:19:50 - progress_bar.py[line:272] - INFO: epoch 002:   1616 / 2004 loss=1.237, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=332.6, nsentences=8, sample_size=332.6, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=976.3, ups=2.94, wpb=332.6, bsz=8, num_updates=3600, lr=9.7381e-05, gnorm=2.06, clip=0, loss_scale=2048, train_wall=3, gb_free=15.8, wall=1208
2023-03-15 14:19:54 - progress_bar.py[line:272] - INFO: epoch 002:   1626 / 2004 loss=1.309, loss_v1=0, loss_v2=0, nll_loss=1.309, ntokens=364.7, nsentences=8, sample_size=364.7, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=1063.9, ups=2.92, wpb=364.7, bsz=8, num_updates=3610, lr=9.73709e-05, gnorm=2.062, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=1211
2023-03-15 14:19:57 - progress_bar.py[line:272] - INFO: epoch 002:   1636 / 2004 loss=1.233, loss_v1=0, loss_v2=0, nll_loss=1.233, ntokens=324, nsentences=8, sample_size=324, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=980.5, ups=3.03, wpb=324, bsz=8, num_updates=3620, lr=9.73608e-05, gnorm=2.164, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=1215
2023-03-15 14:20:00 - progress_bar.py[line:272] - INFO: epoch 002:   1646 / 2004 loss=1.277, loss_v1=0, loss_v2=0, nll_loss=1.277, ntokens=318.5, nsentences=8, sample_size=318.5, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=992.5, ups=3.12, wpb=318.5, bsz=8, num_updates=3630, lr=9.73508e-05, gnorm=2.169, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=1218
2023-03-15 14:20:03 - progress_bar.py[line:272] - INFO: epoch 002:   1656 / 2004 loss=1.232, loss_v1=0, loss_v2=0, nll_loss=1.232, ntokens=358.1, nsentences=8, sample_size=358.1, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=1154.3, ups=3.22, wpb=358.1, bsz=8, num_updates=3640, lr=9.73407e-05, gnorm=2.072, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=1221
2023-03-15 14:20:07 - progress_bar.py[line:272] - INFO: epoch 002:   1666 / 2004 loss=1.338, loss_v1=0, loss_v2=0, nll_loss=1.338, ntokens=345.7, nsentences=8, sample_size=345.7, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=1119.3, ups=3.24, wpb=345.7, bsz=8, num_updates=3650, lr=9.73306e-05, gnorm=2.167, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=1224
2023-03-15 14:20:11 - progress_bar.py[line:272] - INFO: epoch 002:   1676 / 2004 loss=1.212, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=320.2, nsentences=8, sample_size=320.2, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=804.7, ups=2.51, wpb=320.2, bsz=8, num_updates=3660, lr=9.73205e-05, gnorm=2.147, clip=0, loss_scale=2048, train_wall=4, gb_free=14.9, wall=1228
2023-03-15 14:20:14 - progress_bar.py[line:272] - INFO: epoch 002:   1686 / 2004 loss=1.279, loss_v1=0, loss_v2=0, nll_loss=1.279, ntokens=334, nsentences=8, sample_size=334, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=1074.6, ups=3.22, wpb=334, bsz=8, num_updates=3670, lr=9.73104e-05, gnorm=2.116, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=1231
2023-03-15 14:20:17 - progress_bar.py[line:272] - INFO: epoch 002:   1696 / 2004 loss=1.14, loss_v1=0, loss_v2=0, nll_loss=1.14, ntokens=337.7, nsentences=8, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1085.2, ups=3.21, wpb=337.7, bsz=8, num_updates=3680, lr=9.73003e-05, gnorm=1.99, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=1234
2023-03-15 14:20:20 - progress_bar.py[line:272] - INFO: epoch 002:   1706 / 2004 loss=1.228, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=348.9, nsentences=8, sample_size=348.9, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=1073.7, ups=3.08, wpb=348.9, bsz=8, num_updates=3690, lr=9.72903e-05, gnorm=2.065, clip=0, loss_scale=2048, train_wall=3, gb_free=13.9, wall=1238
2023-03-15 14:20:21 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 14:20:24 - progress_bar.py[line:272] - INFO: epoch 002:   1717 / 2004 loss=1.294, loss_v1=0, loss_v2=0, nll_loss=1.294, ntokens=366, nsentences=8, sample_size=366, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=978.7, ups=2.67, wpb=366, bsz=8, num_updates=3700, lr=9.72802e-05, gnorm=2.061, clip=0, loss_scale=2048, train_wall=4, gb_free=14, wall=1241
2023-03-15 14:20:24 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 14:20:27 - progress_bar.py[line:272] - INFO: epoch 002:   1728 / 2004 loss=1.207, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=390.8, nsentences=8, sample_size=390.8, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=1048.6, ups=2.68, wpb=390.8, bsz=8, num_updates=3710, lr=9.72701e-05, gnorm=1.951, clip=0, loss_scale=1024, train_wall=4, gb_free=14.9, wall=1245
2023-03-15 14:20:31 - progress_bar.py[line:272] - INFO: epoch 002:   1738 / 2004 loss=1.257, loss_v1=0, loss_v2=0, nll_loss=1.257, ntokens=326.8, nsentences=8, sample_size=326.8, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=961.4, ups=2.94, wpb=326.8, bsz=8, num_updates=3720, lr=9.726e-05, gnorm=2.143, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=1249
2023-03-15 14:20:34 - progress_bar.py[line:272] - INFO: epoch 002:   1748 / 2004 loss=1.193, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=348.9, nsentences=8, sample_size=348.9, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=1037.3, ups=2.97, wpb=348.9, bsz=8, num_updates=3730, lr=9.72499e-05, gnorm=2.062, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=1252
2023-03-15 14:20:38 - progress_bar.py[line:272] - INFO: epoch 002:   1758 / 2004 loss=1.315, loss_v1=0, loss_v2=0, nll_loss=1.315, ntokens=328, nsentences=8, sample_size=328, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=961.2, ups=2.93, wpb=328, bsz=8, num_updates=3740, lr=9.72399e-05, gnorm=2.143, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=1255
2023-03-15 14:20:41 - progress_bar.py[line:272] - INFO: epoch 002:   1768 / 2004 loss=1.234, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=323.1, nsentences=8, sample_size=323.1, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=951.6, ups=2.95, wpb=323.1, bsz=8, num_updates=3750, lr=9.72298e-05, gnorm=2.188, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=1259
2023-03-15 14:20:45 - progress_bar.py[line:272] - INFO: epoch 002:   1778 / 2004 loss=1.277, loss_v1=0, loss_v2=0, nll_loss=1.277, ntokens=347.6, nsentences=8, sample_size=347.6, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=1012.5, ups=2.91, wpb=347.6, bsz=8, num_updates=3760, lr=9.72197e-05, gnorm=2.092, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=1262
2023-03-15 14:20:48 - progress_bar.py[line:272] - INFO: epoch 002:   1788 / 2004 loss=1.179, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=297.6, nsentences=8, sample_size=297.6, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=879, ups=2.95, wpb=297.6, bsz=8, num_updates=3770, lr=9.72096e-05, gnorm=2.162, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=1266
2023-03-15 14:20:51 - progress_bar.py[line:272] - INFO: epoch 002:   1798 / 2004 loss=1.296, loss_v1=0, loss_v2=0, nll_loss=1.296, ntokens=346.2, nsentences=8, sample_size=346.2, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=1022.1, ups=2.95, wpb=346.2, bsz=8, num_updates=3780, lr=9.71995e-05, gnorm=2.196, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=1269
2023-03-15 14:20:55 - progress_bar.py[line:272] - INFO: epoch 002:   1808 / 2004 loss=1.336, loss_v1=0, loss_v2=0, nll_loss=1.336, ntokens=353.9, nsentences=8, sample_size=353.9, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=1044.4, ups=2.95, wpb=353.9, bsz=8, num_updates=3790, lr=9.71895e-05, gnorm=2.159, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=1272
2023-03-15 14:20:58 - progress_bar.py[line:272] - INFO: epoch 002:   1818 / 2004 loss=1.115, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=349.7, nsentences=8, sample_size=349.7, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1027.8, ups=2.94, wpb=349.7, bsz=8, num_updates=3800, lr=9.71794e-05, gnorm=1.977, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=1276
2023-03-15 14:21:01 - progress_bar.py[line:272] - INFO: epoch 002:   1828 / 2004 loss=1.177, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=349.5, nsentences=8, sample_size=349.5, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1028.1, ups=2.94, wpb=349.5, bsz=8, num_updates=3810, lr=9.71693e-05, gnorm=2.008, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=1279
2023-03-15 14:21:05 - progress_bar.py[line:272] - INFO: epoch 002:   1838 / 2004 loss=1.198, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=332.8, nsentences=8, sample_size=332.8, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=1010.7, ups=3.04, wpb=332.8, bsz=8, num_updates=3820, lr=9.71592e-05, gnorm=2.066, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=1282
2023-03-15 14:21:08 - progress_bar.py[line:272] - INFO: epoch 002:   1848 / 2004 loss=1.166, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=359.3, nsentences=8, sample_size=359.3, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1046.1, ups=2.91, wpb=359.3, bsz=8, num_updates=3830, lr=9.71491e-05, gnorm=1.989, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=1286
2023-03-15 14:21:09 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 14:21:11 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-03-15 14:21:12 - progress_bar.py[line:272] - INFO: epoch 002:   1860 / 2004 loss=1.219, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=320.9, nsentences=8, sample_size=320.9, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=844.4, ups=2.63, wpb=320.9, bsz=8, num_updates=3840, lr=9.71391e-05, gnorm=2.126, clip=0, loss_scale=512, train_wall=4, gb_free=15, wall=1290
2023-03-15 14:21:15 - progress_bar.py[line:272] - INFO: epoch 002:   1870 / 2004 loss=1.086, loss_v1=0, loss_v2=0, nll_loss=1.086, ntokens=343.6, nsentences=8, sample_size=343.6, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1011.3, ups=2.94, wpb=343.6, bsz=8, num_updates=3850, lr=9.7129e-05, gnorm=1.943, clip=0, loss_scale=512, train_wall=3, gb_free=13.9, wall=1293
2023-03-15 14:21:19 - progress_bar.py[line:272] - INFO: epoch 002:   1880 / 2004 loss=1.207, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=332, nsentences=8, sample_size=332, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=971.2, ups=2.93, wpb=332, bsz=8, num_updates=3860, lr=9.71189e-05, gnorm=2.084, clip=0, loss_scale=512, train_wall=3, gb_free=15.1, wall=1296
2023-03-15 14:21:22 - progress_bar.py[line:272] - INFO: epoch 002:   1890 / 2004 loss=1.205, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=323, nsentences=8, sample_size=323, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=949.8, ups=2.94, wpb=323, bsz=8, num_updates=3870, lr=9.71088e-05, gnorm=2.124, clip=0, loss_scale=512, train_wall=3, gb_free=14.6, wall=1300
2023-03-15 14:21:26 - progress_bar.py[line:272] - INFO: epoch 002:   1900 / 2004 loss=1.127, loss_v1=0, loss_v2=0, nll_loss=1.127, ntokens=352.6, nsentences=8, sample_size=352.6, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1015.7, ups=2.88, wpb=352.6, bsz=8, num_updates=3880, lr=9.70987e-05, gnorm=2.002, clip=0, loss_scale=512, train_wall=3, gb_free=15.3, wall=1303
2023-03-15 14:21:29 - progress_bar.py[line:272] - INFO: epoch 002:   1910 / 2004 loss=1.174, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=339.3, nsentences=8, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1002.6, ups=2.96, wpb=339.3, bsz=8, num_updates=3890, lr=9.70887e-05, gnorm=2.082, clip=0, loss_scale=512, train_wall=3, gb_free=14.7, wall=1307
2023-03-15 14:21:32 - progress_bar.py[line:272] - INFO: epoch 002:   1920 / 2004 loss=1.123, loss_v1=0, loss_v2=0, nll_loss=1.123, ntokens=330.2, nsentences=8, sample_size=330.2, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=978.2, ups=2.96, wpb=330.2, bsz=8, num_updates=3900, lr=9.70786e-05, gnorm=2.058, clip=0, loss_scale=512, train_wall=3, gb_free=15.4, wall=1310
2023-03-15 14:21:36 - progress_bar.py[line:272] - INFO: epoch 002:   1930 / 2004 loss=1.113, loss_v1=0, loss_v2=0, nll_loss=1.113, ntokens=316.2, nsentences=8, sample_size=316.2, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=934.8, ups=2.96, wpb=316.2, bsz=8, num_updates=3910, lr=9.70685e-05, gnorm=2.072, clip=0, loss_scale=512, train_wall=3, gb_free=14.6, wall=1313
2023-03-15 14:21:39 - progress_bar.py[line:272] - INFO: epoch 002:   1940 / 2004 loss=1.13, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=349.9, nsentences=8, sample_size=349.9, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1017.6, ups=2.91, wpb=349.9, bsz=8, num_updates=3920, lr=9.70584e-05, gnorm=2.088, clip=0, loss_scale=512, train_wall=3, gb_free=15.1, wall=1317
2023-03-15 14:21:43 - progress_bar.py[line:272] - INFO: epoch 002:   1950 / 2004 loss=1.253, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=337.9, nsentences=8, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=954, ups=2.82, wpb=337.9, bsz=8, num_updates=3930, lr=9.70483e-05, gnorm=2.078, clip=0, loss_scale=512, train_wall=3, gb_free=15.7, wall=1320
2023-03-15 14:21:46 - progress_bar.py[line:272] - INFO: epoch 002:   1960 / 2004 loss=1.051, loss_v1=0, loss_v2=0, nll_loss=1.051, ntokens=365.6, nsentences=8, sample_size=365.6, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=1070.9, ups=2.93, wpb=365.6, bsz=8, num_updates=3940, lr=9.70382e-05, gnorm=1.949, clip=0, loss_scale=512, train_wall=3, gb_free=15, wall=1324
2023-03-15 14:21:50 - progress_bar.py[line:272] - INFO: epoch 002:   1970 / 2004 loss=1.177, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=336.8, nsentences=8, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1012.6, ups=3.01, wpb=336.8, bsz=8, num_updates=3950, lr=9.70282e-05, gnorm=2.075, clip=0, loss_scale=512, train_wall=3, gb_free=15, wall=1327
2023-03-15 14:21:53 - progress_bar.py[line:272] - INFO: epoch 002:   1980 / 2004 loss=1.123, loss_v1=0, loss_v2=0, nll_loss=1.123, ntokens=343.1, nsentences=8, sample_size=343.1, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1004.4, ups=2.93, wpb=343.1, bsz=8, num_updates=3960, lr=9.70181e-05, gnorm=2.036, clip=0, loss_scale=512, train_wall=3, gb_free=14.9, wall=1331
2023-03-15 14:21:56 - progress_bar.py[line:272] - INFO: epoch 002:   1990 / 2004 loss=1.18, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=355.1, nsentences=8, sample_size=355.1, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1034.6, ups=2.91, wpb=355.1, bsz=8, num_updates=3970, lr=9.7008e-05, gnorm=2.009, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=1334
2023-03-15 14:22:00 - progress_bar.py[line:272] - INFO: epoch 002:   2000 / 2004 loss=1.199, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=377.8, nsentences=8, sample_size=377.8, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=1143.7, ups=3.03, wpb=377.8, bsz=8, num_updates=3980, lr=9.69979e-05, gnorm=1.898, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=1337
2023-03-15 14:22:01 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 3984 updates
2023-03-15 14:22:01 - trainer.py[line:431] - INFO: Saving checkpoint to ./checkpoints/checkpoint2.pt
2023-03-15 14:22:06 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./checkpoints/checkpoint2.pt
2023-03-15 14:22:09 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./checkpoints/checkpoint2.pt (epoch 2 @ 3984 updates, score None) (writing took 7.706503139808774 seconds)
2023-03-15 14:22:09 - train.py[line:332] - INFO: end of epoch 2 (average epoch stats below)
2023-03-15 14:22:09 - progress_bar.py[line:282] - INFO: epoch 002 | loss 1.298 | loss_v1 0 | loss_v2 0 | nll_loss 1.298 | ntokens 345.424 | nsentences 7.999 | sample_size 345.424 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.46 | wps 1035.7 | ups 3 | wpb 345.4 | bsz 8 | num_updates 3984 | lr 9.69939e-05 | gnorm 2.094 | clip 0 | loss_scale 1024 | train_wall 644 | gb_free 14.4 | wall 1346
2023-03-15 14:22:09 - trainer.py[line:639] - INFO: loading train data for epoch 3
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 row count 8015 total row count 8015
slice_id 0 seek offset 0
2023-03-15 14:22:09 - trainer.py[line:703] - INFO: begin training epoch 3
2023-03-15 14:22:09 - train.py[line:305] - INFO: Start iterating over samples
2023-03-15 14:22:12 - progress_bar.py[line:272] - INFO: epoch 003:      6 / 2004 loss=1.282, loss_v1=0, loss_v2=0, nll_loss=1.282, ntokens=382.1, nsentences=8, sample_size=382.1, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=323.3, ups=0.85, wpb=382.1, bsz=8, num_updates=3990, lr=9.69878e-05, gnorm=1.976, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=1349
2023-03-15 14:22:15 - progress_bar.py[line:272] - INFO: epoch 003:     16 / 2004 loss=1.193, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=311.6, nsentences=8, sample_size=311.6, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=1037.4, ups=3.33, wpb=311.6, bsz=8, num_updates=4000, lr=9.69778e-05, gnorm=2.126, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=1352
2023-03-15 14:22:18 - progress_bar.py[line:272] - INFO: epoch 003:     26 / 2004 loss=1.211, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=366.9, nsentences=8, sample_size=366.9, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=1148.7, ups=3.13, wpb=366.9, bsz=8, num_updates=4010, lr=9.69677e-05, gnorm=1.999, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=1355
2023-03-15 14:22:21 - progress_bar.py[line:272] - INFO: epoch 003:     36 / 2004 loss=1.248, loss_v1=0, loss_v2=0, nll_loss=1.248, ntokens=337.9, nsentences=8, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=1032.8, ups=3.06, wpb=337.9, bsz=8, num_updates=4020, lr=9.69576e-05, gnorm=2.095, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=1359
2023-03-15 14:22:24 - progress_bar.py[line:272] - INFO: epoch 003:     46 / 2004 loss=1.143, loss_v1=0, loss_v2=0, nll_loss=1.143, ntokens=362.6, nsentences=8, sample_size=362.6, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1101, ups=3.04, wpb=362.6, bsz=8, num_updates=4030, lr=9.69475e-05, gnorm=1.99, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=1362
2023-03-15 14:22:28 - progress_bar.py[line:272] - INFO: epoch 003:     56 / 2004 loss=1.241, loss_v1=0, loss_v2=0, nll_loss=1.241, ntokens=343, nsentences=8, sample_size=343, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=995, ups=2.9, wpb=343, bsz=8, num_updates=4040, lr=9.69374e-05, gnorm=2.049, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=1365
2023-03-15 14:22:31 - progress_bar.py[line:272] - INFO: epoch 003:     66 / 2004 loss=1.225, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=337.6, nsentences=8, sample_size=337.6, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=1008.1, ups=2.99, wpb=337.6, bsz=8, num_updates=4050, lr=9.69274e-05, gnorm=2.129, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=1369
2023-03-15 14:22:34 - progress_bar.py[line:272] - INFO: epoch 003:     76 / 2004 loss=1.161, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=347, nsentences=8, sample_size=347, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1027.9, ups=2.96, wpb=347, bsz=8, num_updates=4060, lr=9.69173e-05, gnorm=1.961, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=1372
2023-03-15 14:22:38 - progress_bar.py[line:272] - INFO: epoch 003:     86 / 2004 loss=1.119, loss_v1=0, loss_v2=0, nll_loss=1.119, ntokens=345.7, nsentences=8, sample_size=345.7, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1007.3, ups=2.91, wpb=345.7, bsz=8, num_updates=4070, lr=9.69072e-05, gnorm=1.921, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=1376
2023-03-15 14:22:41 - progress_bar.py[line:272] - INFO: epoch 003:     96 / 2004 loss=1.312, loss_v1=0, loss_v2=0, nll_loss=1.312, ntokens=368, nsentences=8, sample_size=368, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=1047.8, ups=2.85, wpb=368, bsz=8, num_updates=4080, lr=9.68971e-05, gnorm=2.051, clip=0, loss_scale=1024, train_wall=3, gb_free=14, wall=1379
2023-03-15 14:22:45 - progress_bar.py[line:272] - INFO: epoch 003:    106 / 2004 loss=1.056, loss_v1=0, loss_v2=0, nll_loss=1.056, ntokens=367.2, nsentences=8, sample_size=367.2, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=1091.9, ups=2.97, wpb=367.2, bsz=8, num_updates=4090, lr=9.6887e-05, gnorm=1.919, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=1382
2023-03-15 14:22:48 - progress_bar.py[line:272] - INFO: epoch 003:    116 / 2004 loss=1.259, loss_v1=0, loss_v2=0, nll_loss=1.259, ntokens=336, nsentences=8, sample_size=336, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=975.3, ups=2.9, wpb=336, bsz=8, num_updates=4100, lr=9.6877e-05, gnorm=2.089, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=1386
2023-03-15 14:22:52 - progress_bar.py[line:272] - INFO: epoch 003:    126 / 2004 loss=1.232, loss_v1=0, loss_v2=0, nll_loss=1.232, ntokens=332.7, nsentences=8, sample_size=332.7, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=953.2, ups=2.87, wpb=332.7, bsz=8, num_updates=4110, lr=9.68669e-05, gnorm=2.066, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=1389
2023-03-15 14:22:55 - progress_bar.py[line:272] - INFO: epoch 003:    136 / 2004 loss=1.127, loss_v1=0, loss_v2=0, nll_loss=1.127, ntokens=333.1, nsentences=8, sample_size=333.1, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=963.7, ups=2.89, wpb=333.1, bsz=8, num_updates=4120, lr=9.68568e-05, gnorm=1.976, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=1393
2023-03-15 14:22:57 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 14:22:59 - progress_bar.py[line:272] - INFO: epoch 003:    147 / 2004 loss=1.147, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=333.1, nsentences=8, sample_size=333.1, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=911.3, ups=2.74, wpb=333.1, bsz=8, num_updates=4130, lr=9.68467e-05, gnorm=2.042, clip=0, loss_scale=1024, train_wall=4, gb_free=15.4, wall=1396
2023-03-15 14:23:02 - progress_bar.py[line:272] - INFO: epoch 003:    157 / 2004 loss=1.232, loss_v1=0, loss_v2=0, nll_loss=1.232, ntokens=342.5, nsentences=8, sample_size=342.5, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=1010.6, ups=2.95, wpb=342.5, bsz=8, num_updates=4140, lr=9.68366e-05, gnorm=2.053, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=1400
2023-03-15 14:23:06 - progress_bar.py[line:272] - INFO: epoch 003:    167 / 2004 loss=1.099, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=351.3, nsentences=8, sample_size=351.3, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1047.7, ups=2.98, wpb=351.3, bsz=8, num_updates=4150, lr=9.68265e-05, gnorm=1.97, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=1403
2023-03-15 14:23:09 - progress_bar.py[line:272] - INFO: epoch 003:    177 / 2004 loss=1.13, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=336.2, nsentences=8, sample_size=336.2, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=987.2, ups=2.94, wpb=336.2, bsz=8, num_updates=4160, lr=9.68165e-05, gnorm=2.042, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=1407
2023-03-15 14:23:12 - progress_bar.py[line:272] - INFO: epoch 003:    187 / 2004 loss=1.027, loss_v1=0, loss_v2=0, nll_loss=1.027, ntokens=330.2, nsentences=8, sample_size=330.2, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=991.2, ups=3, wpb=330.2, bsz=8, num_updates=4170, lr=9.68064e-05, gnorm=1.979, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=1410
2023-03-15 14:23:16 - progress_bar.py[line:272] - INFO: epoch 003:    197 / 2004 loss=1.109, loss_v1=0, loss_v2=0, nll_loss=1.109, ntokens=319.2, nsentences=8, sample_size=319.2, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=934.6, ups=2.93, wpb=319.2, bsz=8, num_updates=4180, lr=9.67963e-05, gnorm=2.095, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=1413
2023-03-15 14:23:19 - progress_bar.py[line:272] - INFO: epoch 003:    207 / 2004 loss=1.197, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=346.4, nsentences=8, sample_size=346.4, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=1017, ups=2.94, wpb=346.4, bsz=8, num_updates=4190, lr=9.67862e-05, gnorm=2.039, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=1417
2023-03-15 14:23:22 - progress_bar.py[line:272] - INFO: epoch 003:    217 / 2004 loss=1.062, loss_v1=0, loss_v2=0, nll_loss=1.062, ntokens=321.6, nsentences=8, sample_size=321.6, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=964.5, ups=3, wpb=321.6, bsz=8, num_updates=4200, lr=9.67761e-05, gnorm=2.025, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=1420
2023-03-15 14:23:26 - progress_bar.py[line:272] - INFO: epoch 003:    227 / 2004 loss=1.151, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=347.8, nsentences=8, sample_size=347.8, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1035.7, ups=2.98, wpb=347.8, bsz=8, num_updates=4210, lr=9.67661e-05, gnorm=2.121, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=1423
2023-03-15 14:23:29 - progress_bar.py[line:272] - INFO: epoch 003:    237 / 2004 loss=1.104, loss_v1=0, loss_v2=0, nll_loss=1.104, ntokens=375.8, nsentences=8, sample_size=375.8, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1189.4, ups=3.16, wpb=375.8, bsz=8, num_updates=4220, lr=9.6756e-05, gnorm=1.966, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=1427
2023-03-15 14:23:32 - progress_bar.py[line:272] - INFO: epoch 003:    247 / 2004 loss=1.216, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=347.4, nsentences=8, sample_size=347.4, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=1135.2, ups=3.27, wpb=347.4, bsz=8, num_updates=4230, lr=9.67459e-05, gnorm=2.071, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=1430
2023-03-15 14:23:35 - progress_bar.py[line:272] - INFO: epoch 003:    257 / 2004 loss=1.026, loss_v1=0, loss_v2=0, nll_loss=1.026, ntokens=336.8, nsentences=8, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=1079.6, ups=3.21, wpb=336.8, bsz=8, num_updates=4240, lr=9.67358e-05, gnorm=1.951, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=1433
2023-03-15 14:23:39 - progress_bar.py[line:272] - INFO: epoch 003:    267 / 2004 loss=1.231, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=352.4, nsentences=8, sample_size=352.4, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=1023.4, ups=2.9, wpb=352.4, bsz=8, num_updates=4250, lr=9.67257e-05, gnorm=2.039, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=1436
2023-03-15 14:23:42 - progress_bar.py[line:272] - INFO: epoch 003:    277 / 2004 loss=1.154, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=345.8, nsentences=8, sample_size=345.8, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1031.6, ups=2.98, wpb=345.8, bsz=8, num_updates=4260, lr=9.67157e-05, gnorm=2.005, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=1440
2023-03-15 14:23:45 - progress_bar.py[line:272] - INFO: epoch 003:    287 / 2004 loss=1.075, loss_v1=0, loss_v2=0, nll_loss=1.075, ntokens=357.4, nsentences=8, sample_size=357.4, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1032.7, ups=2.89, wpb=357.4, bsz=8, num_updates=4270, lr=9.67056e-05, gnorm=1.884, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=1443
2023-03-15 14:23:49 - progress_bar.py[line:272] - INFO: epoch 003:    297 / 2004 loss=1.178, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=374.1, nsentences=8, sample_size=374.1, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1099.6, ups=2.94, wpb=374.1, bsz=8, num_updates=4280, lr=9.66955e-05, gnorm=1.939, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=1446
2023-03-15 14:23:52 - progress_bar.py[line:272] - INFO: epoch 003:    307 / 2004 loss=1.152, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=336, nsentences=8, sample_size=336, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1010.2, ups=3.01, wpb=336, bsz=8, num_updates=4290, lr=9.66854e-05, gnorm=2.024, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=1450
2023-03-15 14:23:56 - progress_bar.py[line:272] - INFO: epoch 003:    317 / 2004 loss=1.159, loss_v1=0, loss_v2=0, nll_loss=1.159, ntokens=348, nsentences=8, sample_size=348, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1000.6, ups=2.88, wpb=348, bsz=8, num_updates=4300, lr=9.66753e-05, gnorm=2.06, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=1453
2023-03-15 14:23:59 - progress_bar.py[line:272] - INFO: epoch 003:    327 / 2004 loss=1.086, loss_v1=0, loss_v2=0, nll_loss=1.086, ntokens=323.6, nsentences=8, sample_size=323.6, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=968.9, ups=2.99, wpb=323.6, bsz=8, num_updates=4310, lr=9.66653e-05, gnorm=1.989, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=1457
2023-03-15 14:24:02 - progress_bar.py[line:272] - INFO: epoch 003:    337 / 2004 loss=1.234, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=342.5, nsentences=8, sample_size=342.5, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=1000.5, ups=2.92, wpb=342.5, bsz=8, num_updates=4320, lr=9.66552e-05, gnorm=2.154, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=1460
2023-03-15 14:24:06 - progress_bar.py[line:272] - INFO: epoch 003:    347 / 2004 loss=1.204, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=374.8, nsentences=8, sample_size=374.8, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=1092, ups=2.91, wpb=374.8, bsz=8, num_updates=4330, lr=9.66451e-05, gnorm=2.061, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=1463
2023-03-15 14:24:09 - progress_bar.py[line:272] - INFO: epoch 003:    357 / 2004 loss=1.258, loss_v1=0, loss_v2=0, nll_loss=1.258, ntokens=353.3, nsentences=8, sample_size=353.3, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=1059.5, ups=3, wpb=353.3, bsz=8, num_updates=4340, lr=9.6635e-05, gnorm=2.13, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=1467
2023-03-15 14:24:13 - progress_bar.py[line:272] - INFO: epoch 003:    367 / 2004 loss=1.169, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=351.7, nsentences=8, sample_size=351.7, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1040, ups=2.96, wpb=351.7, bsz=8, num_updates=4350, lr=9.66249e-05, gnorm=2.05, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=1470
2023-03-15 14:24:16 - progress_bar.py[line:272] - INFO: epoch 003:    377 / 2004 loss=1.081, loss_v1=0, loss_v2=0, nll_loss=1.081, ntokens=302.3, nsentences=8, sample_size=302.3, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=876.8, ups=2.9, wpb=302.3, bsz=8, num_updates=4360, lr=9.66149e-05, gnorm=2.081, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=1474
2023-03-15 14:24:19 - progress_bar.py[line:272] - INFO: epoch 003:    387 / 2004 loss=1.152, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=336.1, nsentences=8, sample_size=336.1, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1000.1, ups=2.98, wpb=336.1, bsz=8, num_updates=4370, lr=9.66048e-05, gnorm=2.082, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=1477
2023-03-15 14:24:23 - progress_bar.py[line:272] - INFO: epoch 003:    397 / 2004 loss=1.169, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=347, nsentences=8, sample_size=347, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1014.1, ups=2.92, wpb=347, bsz=8, num_updates=4380, lr=9.65947e-05, gnorm=2.071, clip=0, loss_scale=4096, train_wall=3, gb_free=15.1, wall=1480
2023-03-15 14:24:24 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 14:24:27 - progress_bar.py[line:272] - INFO: epoch 003:    408 / 2004 loss=1.072, loss_v1=0, loss_v2=0, nll_loss=1.072, ntokens=366.9, nsentences=8, sample_size=366.9, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=964.9, ups=2.63, wpb=366.9, bsz=8, num_updates=4390, lr=9.65846e-05, gnorm=1.924, clip=0, loss_scale=2048, train_wall=4, gb_free=15.4, wall=1484
2023-03-15 14:24:30 - progress_bar.py[line:272] - INFO: epoch 003:    418 / 2004 loss=1.091, loss_v1=0, loss_v2=0, nll_loss=1.091, ntokens=340.8, nsentences=8, sample_size=340.8, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=994.1, ups=2.92, wpb=340.8, bsz=8, num_updates=4400, lr=9.65745e-05, gnorm=2.025, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=1488
2023-03-15 14:24:33 - progress_bar.py[line:272] - INFO: epoch 003:    428 / 2004 loss=1.095, loss_v1=0, loss_v2=0, nll_loss=1.095, ntokens=336, nsentences=8, sample_size=336, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1012.5, ups=3.01, wpb=336, bsz=8, num_updates=4410, lr=9.65644e-05, gnorm=1.981, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=1491
2023-03-15 14:24:35 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 14:24:37 - progress_bar.py[line:272] - INFO: epoch 003:    439 / 2004 loss=1.067, loss_v1=0, loss_v2=0, nll_loss=1.067, ntokens=351, nsentences=8, sample_size=351, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=939, ups=2.68, wpb=351, bsz=8, num_updates=4420, lr=9.65544e-05, gnorm=1.911, clip=0, loss_scale=1024, train_wall=4, gb_free=14.4, wall=1495
2023-03-15 14:24:41 - progress_bar.py[line:272] - INFO: epoch 003:    449 / 2004 loss=1.254, loss_v1=0, loss_v2=0, nll_loss=1.254, ntokens=377.3, nsentences=8, sample_size=377.3, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=1075.4, ups=2.85, wpb=377.3, bsz=8, num_updates=4430, lr=9.65443e-05, gnorm=2.043, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=1498
2023-03-15 14:24:44 - progress_bar.py[line:272] - INFO: epoch 003:    459 / 2004 loss=1.309, loss_v1=0, loss_v2=0, nll_loss=1.309, ntokens=389.4, nsentences=8, sample_size=389.4, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=1142.2, ups=2.93, wpb=389.4, bsz=8, num_updates=4440, lr=9.65342e-05, gnorm=2.039, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=1502
2023-03-15 14:24:47 - progress_bar.py[line:272] - INFO: epoch 003:    469 / 2004 loss=1.313, loss_v1=0, loss_v2=0, nll_loss=1.313, ntokens=356, nsentences=8, sample_size=356, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=1063.1, ups=2.99, wpb=356, bsz=8, num_updates=4450, lr=9.65241e-05, gnorm=2.174, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=1505
2023-03-15 14:24:50 - progress_bar.py[line:272] - INFO: epoch 003:    479 / 2004 loss=1.122, loss_v1=0, loss_v2=0, nll_loss=1.122, ntokens=345.5, nsentences=8, sample_size=345.5, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1116.9, ups=3.23, wpb=345.5, bsz=8, num_updates=4460, lr=9.6514e-05, gnorm=1.987, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=1508
2023-03-15 14:24:54 - progress_bar.py[line:272] - INFO: epoch 003:    489 / 2004 loss=1.019, loss_v1=0, loss_v2=0, nll_loss=1.019, ntokens=373.4, nsentences=8, sample_size=373.4, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=1198.4, ups=3.21, wpb=373.4, bsz=8, num_updates=4470, lr=9.6504e-05, gnorm=1.919, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=1511
2023-03-15 14:24:57 - progress_bar.py[line:272] - INFO: epoch 003:    499 / 2004 loss=1.105, loss_v1=0, loss_v2=0, nll_loss=1.105, ntokens=354.9, nsentences=8, sample_size=354.9, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1135.7, ups=3.2, wpb=354.9, bsz=8, num_updates=4480, lr=9.64939e-05, gnorm=1.946, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=1514
2023-03-15 14:25:00 - progress_bar.py[line:272] - INFO: epoch 003:    509 / 2004 loss=1.174, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=358.8, nsentences=8, sample_size=358.8, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1200.3, ups=3.35, wpb=358.8, bsz=8, num_updates=4490, lr=9.64838e-05, gnorm=1.973, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=1517
2023-03-15 14:25:03 - progress_bar.py[line:272] - INFO: epoch 003:    519 / 2004 loss=1.187, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=354, nsentences=8, sample_size=354, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=1109.7, ups=3.13, wpb=354, bsz=8, num_updates=4500, lr=9.64737e-05, gnorm=2.031, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=1520
2023-03-15 14:25:06 - progress_bar.py[line:272] - INFO: epoch 003:    529 / 2004 loss=1.211, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=398.8, nsentences=8, sample_size=398.8, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=1198.9, ups=3.01, wpb=398.8, bsz=8, num_updates=4510, lr=9.64636e-05, gnorm=1.942, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=1524
2023-03-15 14:25:09 - progress_bar.py[line:272] - INFO: epoch 003:    539 / 2004 loss=1.231, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=390.9, nsentences=8, sample_size=390.9, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=1194.2, ups=3.06, wpb=390.9, bsz=8, num_updates=4520, lr=9.64536e-05, gnorm=2.002, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=1527
2023-03-15 14:25:13 - progress_bar.py[line:272] - INFO: epoch 003:    549 / 2004 loss=1.173, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=355.2, nsentences=8, sample_size=355.2, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1098.7, ups=3.09, wpb=355.2, bsz=8, num_updates=4530, lr=9.64435e-05, gnorm=2.042, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=1530
2023-03-15 14:25:16 - progress_bar.py[line:272] - INFO: epoch 003:    559 / 2004 loss=1.057, loss_v1=0, loss_v2=0, nll_loss=1.057, ntokens=367.9, nsentences=8, sample_size=367.9, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=1082, ups=2.94, wpb=367.9, bsz=8, num_updates=4540, lr=9.64334e-05, gnorm=1.878, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=1534
2023-03-15 14:25:20 - progress_bar.py[line:272] - INFO: epoch 003:    569 / 2004 loss=1.092, loss_v1=0, loss_v2=0, nll_loss=1.092, ntokens=378.1, nsentences=8, sample_size=378.1, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1091.3, ups=2.89, wpb=378.1, bsz=8, num_updates=4550, lr=9.64233e-05, gnorm=1.946, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=1537
2023-03-15 14:25:23 - progress_bar.py[line:272] - INFO: epoch 003:    579 / 2004 loss=1.184, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=322.4, nsentences=8, sample_size=322.4, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=963.1, ups=2.99, wpb=322.4, bsz=8, num_updates=4560, lr=9.64132e-05, gnorm=2.137, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=1541
2023-03-15 14:25:26 - progress_bar.py[line:272] - INFO: epoch 003:    589 / 2004 loss=1.064, loss_v1=0, loss_v2=0, nll_loss=1.064, ntokens=378.2, nsentences=8, sample_size=378.2, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=1079.4, ups=2.85, wpb=378.2, bsz=8, num_updates=4570, lr=9.64032e-05, gnorm=1.902, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=1544
2023-03-15 14:25:30 - progress_bar.py[line:272] - INFO: epoch 003:    599 / 2004 loss=1.202, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=352.5, nsentences=8, sample_size=352.5, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=1035.2, ups=2.94, wpb=352.5, bsz=8, num_updates=4580, lr=9.63931e-05, gnorm=2.001, clip=0, loss_scale=2048, train_wall=3, gb_free=13.8, wall=1547
2023-03-15 14:25:33 - progress_bar.py[line:272] - INFO: epoch 003:    609 / 2004 loss=1.163, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=333.9, nsentences=8, sample_size=333.9, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=987.4, ups=2.96, wpb=333.9, bsz=8, num_updates=4590, lr=9.6383e-05, gnorm=2.024, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=1551
2023-03-15 14:25:37 - progress_bar.py[line:272] - INFO: epoch 003:    619 / 2004 loss=1.017, loss_v1=0, loss_v2=0, nll_loss=1.017, ntokens=367.6, nsentences=8, sample_size=367.6, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=1062, ups=2.89, wpb=367.6, bsz=8, num_updates=4600, lr=9.63729e-05, gnorm=1.852, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=1554
2023-03-15 14:25:40 - progress_bar.py[line:272] - INFO: epoch 003:    629 / 2004 loss=1.037, loss_v1=0, loss_v2=0, nll_loss=1.037, ntokens=356.6, nsentences=8, sample_size=356.6, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=1071.4, ups=3, wpb=356.6, bsz=8, num_updates=4610, lr=9.63628e-05, gnorm=1.933, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=1558
2023-03-15 14:25:43 - progress_bar.py[line:272] - INFO: epoch 003:    639 / 2004 loss=1.113, loss_v1=0, loss_v2=0, nll_loss=1.113, ntokens=330.3, nsentences=8, sample_size=330.3, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=981.3, ups=2.97, wpb=330.3, bsz=8, num_updates=4620, lr=9.63527e-05, gnorm=2.088, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=1561
2023-03-15 14:25:47 - progress_bar.py[line:272] - INFO: epoch 003:    649 / 2004 loss=1.211, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=335.9, nsentences=8, sample_size=335.9, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=1063, ups=3.16, wpb=335.9, bsz=8, num_updates=4630, lr=9.63427e-05, gnorm=2.124, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=1564
2023-03-15 14:25:50 - progress_bar.py[line:272] - INFO: epoch 003:    659 / 2004 loss=1.229, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=342, nsentences=8, sample_size=342, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=1069.1, ups=3.13, wpb=342, bsz=8, num_updates=4640, lr=9.63326e-05, gnorm=2.123, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=1567
2023-03-15 14:25:53 - progress_bar.py[line:272] - INFO: epoch 003:    669 / 2004 loss=1.11, loss_v1=0, loss_v2=0, nll_loss=1.11, ntokens=304.6, nsentences=8, sample_size=304.6, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=930.3, ups=3.05, wpb=304.6, bsz=8, num_updates=4650, lr=9.63225e-05, gnorm=2.087, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=1571
2023-03-15 14:25:56 - progress_bar.py[line:272] - INFO: epoch 003:    679 / 2004 loss=1.083, loss_v1=0, loss_v2=0, nll_loss=1.083, ntokens=353.2, nsentences=8, sample_size=353.2, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1039.1, ups=2.94, wpb=353.2, bsz=8, num_updates=4660, lr=9.63124e-05, gnorm=2.001, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=1574
2023-03-15 14:26:00 - progress_bar.py[line:272] - INFO: epoch 003:    689 / 2004 loss=1.1, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=343.1, nsentences=8, sample_size=343.1, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1004.6, ups=2.93, wpb=343.1, bsz=8, num_updates=4670, lr=9.63023e-05, gnorm=1.991, clip=0, loss_scale=4096, train_wall=3, gb_free=15.1, wall=1577
2023-03-15 14:26:00 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 14:26:04 - progress_bar.py[line:272] - INFO: epoch 003:    700 / 2004 loss=1.129, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=341, nsentences=8, sample_size=341, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=907.6, ups=2.66, wpb=341, bsz=8, num_updates=4680, lr=9.62923e-05, gnorm=2.047, clip=0, loss_scale=2048, train_wall=4, gb_free=15.1, wall=1581
2023-03-15 14:26:07 - progress_bar.py[line:272] - INFO: epoch 003:    710 / 2004 loss=1.169, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=334.2, nsentences=8, sample_size=334.2, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=968.4, ups=2.9, wpb=334.2, bsz=8, num_updates=4690, lr=9.62822e-05, gnorm=2.095, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=1585
2023-03-15 14:26:10 - progress_bar.py[line:272] - INFO: epoch 003:    720 / 2004 loss=1.167, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=351.7, nsentences=8, sample_size=351.7, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1039.4, ups=2.96, wpb=351.7, bsz=8, num_updates=4700, lr=9.62721e-05, gnorm=2.088, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=1588
2023-03-15 14:26:14 - progress_bar.py[line:272] - INFO: epoch 003:    730 / 2004 loss=1.223, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=355.5, nsentences=8, sample_size=355.5, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=1014.6, ups=2.85, wpb=355.5, bsz=8, num_updates=4710, lr=9.6262e-05, gnorm=2.128, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=1592
2023-03-15 14:26:17 - progress_bar.py[line:272] - INFO: epoch 003:    740 / 2004 loss=1.101, loss_v1=0, loss_v2=0, nll_loss=1.101, ntokens=330.9, nsentences=8, sample_size=330.9, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=964.9, ups=2.92, wpb=330.9, bsz=8, num_updates=4720, lr=9.62519e-05, gnorm=2.097, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=1595
2023-03-15 14:26:21 - progress_bar.py[line:272] - INFO: epoch 003:    750 / 2004 loss=1.154, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=367.4, nsentences=8, sample_size=367.4, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1064.4, ups=2.9, wpb=367.4, bsz=8, num_updates=4730, lr=9.62419e-05, gnorm=1.993, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=1598
2023-03-15 14:26:24 - progress_bar.py[line:272] - INFO: epoch 003:    760 / 2004 loss=1.191, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=305.9, nsentences=8, sample_size=305.9, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=911.4, ups=2.98, wpb=305.9, bsz=8, num_updates=4740, lr=9.62318e-05, gnorm=2.177, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=1602
2023-03-15 14:26:28 - progress_bar.py[line:272] - INFO: epoch 003:    770 / 2004 loss=1.266, loss_v1=0, loss_v2=0, nll_loss=1.266, ntokens=412.1, nsentences=8, sample_size=412.1, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=1200.4, ups=2.91, wpb=412.1, bsz=8, num_updates=4750, lr=9.62217e-05, gnorm=2.008, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=1605
2023-03-15 14:26:31 - progress_bar.py[line:272] - INFO: epoch 003:    780 / 2004 loss=1.158, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=326.4, nsentences=8, sample_size=326.4, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=962.3, ups=2.95, wpb=326.4, bsz=8, num_updates=4760, lr=9.62116e-05, gnorm=2.087, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=1609
2023-03-15 14:26:34 - progress_bar.py[line:272] - INFO: epoch 003:    790 / 2004 loss=1.075, loss_v1=0, loss_v2=0, nll_loss=1.075, ntokens=352, nsentences=8, sample_size=352, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1035.9, ups=2.94, wpb=352, bsz=8, num_updates=4770, lr=9.62015e-05, gnorm=1.93, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=1612
2023-03-15 14:26:38 - progress_bar.py[line:272] - INFO: epoch 003:    800 / 2004 loss=1.072, loss_v1=0, loss_v2=0, nll_loss=1.072, ntokens=324.6, nsentences=8, sample_size=324.6, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=961.7, ups=2.96, wpb=324.6, bsz=8, num_updates=4780, lr=9.61915e-05, gnorm=2.125, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=1615
2023-03-15 14:26:41 - progress_bar.py[line:272] - INFO: epoch 003:    810 / 2004 loss=1.11, loss_v1=0, loss_v2=0, nll_loss=1.11, ntokens=352.2, nsentences=8, sample_size=352.2, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1028, ups=2.92, wpb=352.2, bsz=8, num_updates=4790, lr=9.61814e-05, gnorm=1.999, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=1619
2023-03-15 14:26:45 - progress_bar.py[line:272] - INFO: epoch 003:    820 / 2004 loss=0.988, loss_v1=0, loss_v2=0, nll_loss=0.988, ntokens=315.2, nsentences=8, sample_size=315.2, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=932.4, ups=2.96, wpb=315.2, bsz=8, num_updates=4800, lr=9.61713e-05, gnorm=2.008, clip=0, loss_scale=4096, train_wall=3, gb_free=15.4, wall=1622
2023-03-15 14:26:45 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 14:26:48 - progress_bar.py[line:272] - INFO: epoch 003:    831 / 2004 loss=1.162, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=353.1, nsentences=8, sample_size=353.1, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=938.8, ups=2.66, wpb=353.1, bsz=8, num_updates=4810, lr=9.61612e-05, gnorm=2.051, clip=0, loss_scale=2048, train_wall=4, gb_free=15, wall=1626
2023-03-15 14:26:52 - progress_bar.py[line:272] - INFO: epoch 003:    841 / 2004 loss=1.049, loss_v1=0, loss_v2=0, nll_loss=1.049, ntokens=352.8, nsentences=8, sample_size=352.8, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=1038.4, ups=2.94, wpb=352.8, bsz=8, num_updates=4820, lr=9.61511e-05, gnorm=2.023, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=1629
2023-03-15 14:26:55 - progress_bar.py[line:272] - INFO: epoch 003:    851 / 2004 loss=1.101, loss_v1=0, loss_v2=0, nll_loss=1.101, ntokens=361.9, nsentences=8, sample_size=361.9, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1084, ups=3, wpb=361.9, bsz=8, num_updates=4830, lr=9.61411e-05, gnorm=1.98, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=1633
2023-03-15 14:26:58 - progress_bar.py[line:272] - INFO: epoch 003:    861 / 2004 loss=1.198, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=345, nsentences=8, sample_size=345, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=1004.4, ups=2.91, wpb=345, bsz=8, num_updates=4840, lr=9.6131e-05, gnorm=2.041, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=1636
2023-03-15 14:27:02 - progress_bar.py[line:272] - INFO: epoch 003:    871 / 2004 loss=1.161, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=373.7, nsentences=8, sample_size=373.7, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1074.4, ups=2.88, wpb=373.7, bsz=8, num_updates=4850, lr=9.61209e-05, gnorm=1.968, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=1640
2023-03-15 14:27:05 - progress_bar.py[line:272] - INFO: epoch 003:    881 / 2004 loss=0.976, loss_v1=0, loss_v2=0, nll_loss=0.976, ntokens=313.5, nsentences=8, sample_size=313.5, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=928.2, ups=2.96, wpb=313.5, bsz=8, num_updates=4860, lr=9.61108e-05, gnorm=2.018, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=1643
2023-03-15 14:27:09 - progress_bar.py[line:272] - INFO: epoch 003:    891 / 2004 loss=1.125, loss_v1=0, loss_v2=0, nll_loss=1.125, ntokens=320.9, nsentences=8, sample_size=320.9, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=960.8, ups=2.99, wpb=320.9, bsz=8, num_updates=4870, lr=9.61007e-05, gnorm=2.079, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=1646
2023-03-15 14:27:11 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 14:27:12 - progress_bar.py[line:272] - INFO: epoch 003:    902 / 2004 loss=1.097, loss_v1=0, loss_v2=0, nll_loss=1.097, ntokens=353.3, nsentences=8, sample_size=353.3, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=948.6, ups=2.68, wpb=353.3, bsz=8, num_updates=4880, lr=9.60906e-05, gnorm=2.038, clip=0, loss_scale=1024, train_wall=4, gb_free=15, wall=1650
2023-03-15 14:27:16 - progress_bar.py[line:272] - INFO: epoch 003:    912 / 2004 loss=1.052, loss_v1=0, loss_v2=0, nll_loss=1.052, ntokens=379.3, nsentences=8, sample_size=379.3, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=1103.4, ups=2.91, wpb=379.3, bsz=8, num_updates=4890, lr=9.60806e-05, gnorm=1.915, clip=0, loss_scale=1024, train_wall=3, gb_free=14, wall=1653
2023-03-15 14:27:19 - progress_bar.py[line:272] - INFO: epoch 003:    922 / 2004 loss=1.117, loss_v1=0, loss_v2=0, nll_loss=1.117, ntokens=323.5, nsentences=8, sample_size=323.5, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=969.6, ups=3, wpb=323.5, bsz=8, num_updates=4900, lr=9.60705e-05, gnorm=2.063, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=1657
2023-03-15 14:27:23 - progress_bar.py[line:272] - INFO: epoch 003:    932 / 2004 loss=1.057, loss_v1=0, loss_v2=0, nll_loss=1.057, ntokens=341.5, nsentences=8, sample_size=341.5, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=1012.8, ups=2.97, wpb=341.5, bsz=8, num_updates=4910, lr=9.60604e-05, gnorm=1.944, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=1660
2023-03-15 14:27:26 - progress_bar.py[line:272] - INFO: epoch 003:    942 / 2004 loss=1.164, loss_v1=0, loss_v2=0, nll_loss=1.164, ntokens=374, nsentences=8, sample_size=374, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1083.4, ups=2.9, wpb=374, bsz=8, num_updates=4920, lr=9.60503e-05, gnorm=2.016, clip=0, loss_scale=1024, train_wall=3, gb_free=13.9, wall=1664
2023-03-15 14:27:29 - progress_bar.py[line:272] - INFO: epoch 003:    952 / 2004 loss=1.07, loss_v1=0, loss_v2=0, nll_loss=1.07, ntokens=335.9, nsentences=8, sample_size=335.9, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=985.1, ups=2.93, wpb=335.9, bsz=8, num_updates=4930, lr=9.60402e-05, gnorm=2.05, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=1667
2023-03-15 14:27:33 - progress_bar.py[line:272] - INFO: epoch 003:    962 / 2004 loss=1.207, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=378.4, nsentences=7.8, sample_size=378.4, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=1108.2, ups=2.93, wpb=378.4, bsz=7.8, num_updates=4940, lr=9.60302e-05, gnorm=2.017, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=1670
2023-03-15 14:27:36 - progress_bar.py[line:272] - INFO: epoch 003:    972 / 2004 loss=1.12, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=332.1, nsentences=8, sample_size=332.1, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=991, ups=2.98, wpb=332.1, bsz=8, num_updates=4950, lr=9.60201e-05, gnorm=2.043, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=1674
2023-03-15 14:27:39 - progress_bar.py[line:272] - INFO: epoch 003:    982 / 2004 loss=1.072, loss_v1=0, loss_v2=0, nll_loss=1.072, ntokens=315.8, nsentences=8, sample_size=315.8, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=954.2, ups=3.02, wpb=315.8, bsz=8, num_updates=4960, lr=9.601e-05, gnorm=2.087, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=1677
2023-03-15 14:27:43 - progress_bar.py[line:272] - INFO: epoch 003:    992 / 2004 loss=1.069, loss_v1=0, loss_v2=0, nll_loss=1.069, ntokens=382.3, nsentences=8, sample_size=382.3, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=1113.2, ups=2.91, wpb=382.3, bsz=8, num_updates=4970, lr=9.59999e-05, gnorm=1.843, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=1681
2023-03-15 14:27:46 - progress_bar.py[line:272] - INFO: epoch 003:   1002 / 2004 loss=1.061, loss_v1=0, loss_v2=0, nll_loss=1.061, ntokens=329.7, nsentences=8, sample_size=329.7, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=969.2, ups=2.94, wpb=329.7, bsz=8, num_updates=4980, lr=9.59898e-05, gnorm=2.017, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=1684
2023-03-15 14:27:50 - progress_bar.py[line:272] - INFO: epoch 003:   1012 / 2004 loss=1.133, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=334.7, nsentences=8, sample_size=334.7, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=995.5, ups=2.97, wpb=334.7, bsz=8, num_updates=4990, lr=9.59798e-05, gnorm=2.109, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=1687
2023-03-15 14:27:53 - progress_bar.py[line:272] - INFO: epoch 003:   1022 / 2004 loss=1.087, loss_v1=0, loss_v2=0, nll_loss=1.087, ntokens=325.3, nsentences=8, sample_size=325.3, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=975.1, ups=3, wpb=325.3, bsz=8, num_updates=5000, lr=9.59697e-05, gnorm=2.035, clip=0, loss_scale=1024, train_wall=3, gb_free=15.8, wall=1691
2023-03-15 14:27:56 - progress_bar.py[line:272] - INFO: epoch 003:   1032 / 2004 loss=1.089, loss_v1=0, loss_v2=0, nll_loss=1.089, ntokens=324.1, nsentences=8, sample_size=324.1, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=967.4, ups=2.99, wpb=324.1, bsz=8, num_updates=5010, lr=9.59596e-05, gnorm=2.049, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=1694
2023-03-15 14:28:00 - progress_bar.py[line:272] - INFO: epoch 003:   1042 / 2004 loss=1.154, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=342, nsentences=8, sample_size=342, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1022, ups=2.99, wpb=342, bsz=8, num_updates=5020, lr=9.59495e-05, gnorm=2.036, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=1697
2023-03-15 14:28:03 - progress_bar.py[line:272] - INFO: epoch 003:   1052 / 2004 loss=1.081, loss_v1=0, loss_v2=0, nll_loss=1.081, ntokens=368.4, nsentences=8, sample_size=368.4, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1075.1, ups=2.92, wpb=368.4, bsz=8, num_updates=5030, lr=9.59394e-05, gnorm=1.993, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=1701
2023-03-15 14:28:06 - progress_bar.py[line:272] - INFO: epoch 003:   1062 / 2004 loss=1.111, loss_v1=0, loss_v2=0, nll_loss=1.111, ntokens=339.1, nsentences=8, sample_size=339.1, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1014.6, ups=2.99, wpb=339.1, bsz=8, num_updates=5040, lr=9.59294e-05, gnorm=2.03, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=1704
2023-03-15 14:28:10 - progress_bar.py[line:272] - INFO: epoch 003:   1072 / 2004 loss=1.182, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=355.3, nsentences=8, sample_size=355.3, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1037.7, ups=2.92, wpb=355.3, bsz=8, num_updates=5050, lr=9.59193e-05, gnorm=2.072, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=1708
2023-03-15 14:28:13 - progress_bar.py[line:272] - INFO: epoch 003:   1082 / 2004 loss=1.044, loss_v1=0, loss_v2=0, nll_loss=1.044, ntokens=365.5, nsentences=8, sample_size=365.5, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=1070.2, ups=2.93, wpb=365.5, bsz=8, num_updates=5060, lr=9.59092e-05, gnorm=1.963, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=1711
2023-03-15 14:28:17 - progress_bar.py[line:272] - INFO: epoch 003:   1092 / 2004 loss=1.183, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=332.2, nsentences=8, sample_size=332.2, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1005.1, ups=3.03, wpb=332.2, bsz=8, num_updates=5070, lr=9.58991e-05, gnorm=2.107, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=1714
2023-03-15 14:28:20 - progress_bar.py[line:272] - INFO: epoch 003:   1102 / 2004 loss=1.222, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=364.8, nsentences=8, sample_size=364.8, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=1054.8, ups=2.89, wpb=364.8, bsz=8, num_updates=5080, lr=9.5889e-05, gnorm=2.147, clip=0, loss_scale=2048, train_wall=3, gb_free=13.9, wall=1718
2023-03-15 14:28:23 - progress_bar.py[line:272] - INFO: epoch 003:   1112 / 2004 loss=1.095, loss_v1=0, loss_v2=0, nll_loss=1.095, ntokens=351.9, nsentences=8, sample_size=351.9, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1048.9, ups=2.98, wpb=351.9, bsz=8, num_updates=5090, lr=9.58789e-05, gnorm=1.997, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=1721
2023-03-15 14:28:27 - progress_bar.py[line:272] - INFO: epoch 003:   1122 / 2004 loss=0.987, loss_v1=0, loss_v2=0, nll_loss=0.987, ntokens=315.6, nsentences=8, sample_size=315.6, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=932, ups=2.95, wpb=315.6, bsz=8, num_updates=5100, lr=9.58689e-05, gnorm=1.939, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=1724
2023-03-15 14:28:30 - progress_bar.py[line:272] - INFO: epoch 003:   1132 / 2004 loss=1.128, loss_v1=0, loss_v2=0, nll_loss=1.128, ntokens=376.8, nsentences=8, sample_size=376.8, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1104.2, ups=2.93, wpb=376.8, bsz=8, num_updates=5110, lr=9.58588e-05, gnorm=1.978, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=1728
2023-03-15 14:28:34 - progress_bar.py[line:272] - INFO: epoch 003:   1142 / 2004 loss=1.109, loss_v1=0, loss_v2=0, nll_loss=1.109, ntokens=360.1, nsentences=8, sample_size=360.1, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1063.2, ups=2.95, wpb=360.1, bsz=8, num_updates=5120, lr=9.58487e-05, gnorm=2.045, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=1731
2023-03-15 14:28:37 - progress_bar.py[line:272] - INFO: epoch 003:   1152 / 2004 loss=1.024, loss_v1=0, loss_v2=0, nll_loss=1.024, ntokens=375.7, nsentences=8, sample_size=375.7, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=1094.1, ups=2.91, wpb=375.7, bsz=8, num_updates=5130, lr=9.58386e-05, gnorm=1.897, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=1735
2023-03-15 14:28:39 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 14:28:41 - progress_bar.py[line:272] - INFO: epoch 003:   1163 / 2004 loss=1.153, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=357.4, nsentences=8, sample_size=357.4, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=970.7, ups=2.72, wpb=357.4, bsz=8, num_updates=5140, lr=9.58285e-05, gnorm=2.036, clip=0, loss_scale=2048, train_wall=4, gb_free=15.4, wall=1738
2023-03-15 14:28:44 - progress_bar.py[line:272] - INFO: epoch 003:   1173 / 2004 loss=1.062, loss_v1=0, loss_v2=0, nll_loss=1.062, ntokens=356.8, nsentences=8, sample_size=356.8, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=1145.7, ups=3.21, wpb=356.8, bsz=8, num_updates=5150, lr=9.58185e-05, gnorm=1.962, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=1741
2023-03-15 14:28:47 - progress_bar.py[line:272] - INFO: epoch 003:   1183 / 2004 loss=1.018, loss_v1=0, loss_v2=0, nll_loss=1.018, ntokens=334.4, nsentences=8, sample_size=334.4, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=1100, ups=3.29, wpb=334.4, bsz=8, num_updates=5160, lr=9.58084e-05, gnorm=2.046, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=1745
2023-03-15 14:28:50 - progress_bar.py[line:272] - INFO: epoch 003:   1193 / 2004 loss=0.973, loss_v1=0, loss_v2=0, nll_loss=0.973, ntokens=359.7, nsentences=8, sample_size=359.7, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=1153.5, ups=3.21, wpb=359.7, bsz=8, num_updates=5170, lr=9.57983e-05, gnorm=1.926, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=1748
2023-03-15 14:28:53 - progress_bar.py[line:272] - INFO: epoch 003:   1203 / 2004 loss=1.078, loss_v1=0, loss_v2=0, nll_loss=1.078, ntokens=325.9, nsentences=8, sample_size=325.9, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1084.5, ups=3.33, wpb=325.9, bsz=8, num_updates=5180, lr=9.57882e-05, gnorm=2.063, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=1751
2023-03-15 14:28:56 - progress_bar.py[line:272] - INFO: epoch 003:   1213 / 2004 loss=1.12, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=288.4, nsentences=8, sample_size=288.4, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=959.4, ups=3.33, wpb=288.4, bsz=8, num_updates=5190, lr=9.57781e-05, gnorm=2.229, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=1754
2023-03-15 14:28:59 - progress_bar.py[line:272] - INFO: epoch 003:   1223 / 2004 loss=1.033, loss_v1=0, loss_v2=0, nll_loss=1.033, ntokens=339.3, nsentences=8, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=1060, ups=3.12, wpb=339.3, bsz=8, num_updates=5200, lr=9.57681e-05, gnorm=2.039, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=1757
2023-03-15 14:29:02 - progress_bar.py[line:272] - INFO: epoch 003:   1233 / 2004 loss=0.957, loss_v1=0, loss_v2=0, nll_loss=0.957, ntokens=306.4, nsentences=8, sample_size=306.4, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=965.4, ups=3.15, wpb=306.4, bsz=8, num_updates=5210, lr=9.5758e-05, gnorm=2.036, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=1760
2023-03-15 14:29:06 - progress_bar.py[line:272] - INFO: epoch 003:   1243 / 2004 loss=1.184, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=392.9, nsentences=8, sample_size=392.9, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1207.4, ups=3.07, wpb=392.9, bsz=8, num_updates=5220, lr=9.57479e-05, gnorm=1.992, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=1763
2023-03-15 14:29:09 - progress_bar.py[line:272] - INFO: epoch 003:   1253 / 2004 loss=1.115, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=350.1, nsentences=8, sample_size=350.1, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1025.6, ups=2.93, wpb=350.1, bsz=8, num_updates=5230, lr=9.57378e-05, gnorm=2.089, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=1767
2023-03-15 14:29:13 - progress_bar.py[line:272] - INFO: epoch 003:   1263 / 2004 loss=1.064, loss_v1=0, loss_v2=0, nll_loss=1.064, ntokens=326.6, nsentences=8, sample_size=326.6, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=949.3, ups=2.91, wpb=326.6, bsz=8, num_updates=5240, lr=9.57277e-05, gnorm=2.075, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=1770
2023-03-15 14:29:16 - progress_bar.py[line:272] - INFO: epoch 003:   1273 / 2004 loss=1.089, loss_v1=0, loss_v2=0, nll_loss=1.089, ntokens=346.4, nsentences=8, sample_size=346.4, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1025.1, ups=2.96, wpb=346.4, bsz=8, num_updates=5250, lr=9.57177e-05, gnorm=2.021, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=1774
2023-03-15 14:29:19 - progress_bar.py[line:272] - INFO: epoch 003:   1283 / 2004 loss=1.04, loss_v1=0, loss_v2=0, nll_loss=1.04, ntokens=343.9, nsentences=8, sample_size=343.9, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=1016.5, ups=2.96, wpb=343.9, bsz=8, num_updates=5260, lr=9.57076e-05, gnorm=2.127, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=1777
2023-03-15 14:29:22 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 14:29:23 - progress_bar.py[line:272] - INFO: epoch 003:   1294 / 2004 loss=0.898, loss_v1=0, loss_v2=0, nll_loss=0.898, ntokens=296.8, nsentences=8, sample_size=296.8, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=814.1, ups=2.74, wpb=296.8, bsz=8, num_updates=5270, lr=9.56975e-05, gnorm=2.029, clip=0, loss_scale=2048, train_wall=4, gb_free=15.4, wall=1781
2023-03-15 14:29:26 - progress_bar.py[line:272] - INFO: epoch 003:   1304 / 2004 loss=1.121, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=327.6, nsentences=8, sample_size=327.6, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=960, ups=2.93, wpb=327.6, bsz=8, num_updates=5280, lr=9.56874e-05, gnorm=2.062, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=1784
2023-03-15 14:29:30 - progress_bar.py[line:272] - INFO: epoch 003:   1314 / 2004 loss=1.049, loss_v1=0, loss_v2=0, nll_loss=1.049, ntokens=326.5, nsentences=8, sample_size=326.5, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=964.2, ups=2.95, wpb=326.5, bsz=8, num_updates=5290, lr=9.56773e-05, gnorm=2, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=1787
2023-03-15 14:29:32 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 14:29:33 - progress_bar.py[line:272] - INFO: epoch 003:   1325 / 2004 loss=1.15, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=313, nsentences=8, sample_size=313, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=844.6, ups=2.7, wpb=313, bsz=8, num_updates=5300, lr=9.56673e-05, gnorm=2.233, clip=0, loss_scale=1024, train_wall=4, gb_free=15.6, wall=1791
2023-03-15 14:29:37 - progress_bar.py[line:272] - INFO: epoch 003:   1335 / 2004 loss=1.23, loss_v1=0, loss_v2=0, nll_loss=1.23, ntokens=350.2, nsentences=8, sample_size=350.2, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=1026.8, ups=2.93, wpb=350.2, bsz=8, num_updates=5310, lr=9.56572e-05, gnorm=2.184, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=1794
2023-03-15 14:29:40 - progress_bar.py[line:272] - INFO: epoch 003:   1345 / 2004 loss=1.078, loss_v1=0, loss_v2=0, nll_loss=1.078, ntokens=299.1, nsentences=8, sample_size=299.1, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=892, ups=2.98, wpb=299.1, bsz=8, num_updates=5320, lr=9.56471e-05, gnorm=2.179, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=1798
2023-03-15 14:29:44 - progress_bar.py[line:272] - INFO: epoch 003:   1355 / 2004 loss=1.126, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=322.6, nsentences=8, sample_size=322.6, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=969.8, ups=3.01, wpb=322.6, bsz=8, num_updates=5330, lr=9.5637e-05, gnorm=2.117, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=1801
2023-03-15 14:29:47 - progress_bar.py[line:272] - INFO: epoch 003:   1365 / 2004 loss=1.126, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=315.7, nsentences=8, sample_size=315.7, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=952.8, ups=3.02, wpb=315.7, bsz=8, num_updates=5340, lr=9.56269e-05, gnorm=2.138, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=1804
2023-03-15 14:29:50 - progress_bar.py[line:272] - INFO: epoch 003:   1375 / 2004 loss=1.04, loss_v1=0, loss_v2=0, nll_loss=1.04, ntokens=319, nsentences=8, sample_size=319, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=957.7, ups=3, wpb=319, bsz=8, num_updates=5350, lr=9.56168e-05, gnorm=2.107, clip=0, loss_scale=1024, train_wall=3, gb_free=15.8, wall=1808
2023-03-15 14:29:54 - progress_bar.py[line:272] - INFO: epoch 003:   1385 / 2004 loss=1.119, loss_v1=0, loss_v2=0, nll_loss=1.119, ntokens=399.1, nsentences=8, sample_size=399.1, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1145.7, ups=2.87, wpb=399.1, bsz=8, num_updates=5360, lr=9.56068e-05, gnorm=1.952, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=1811
2023-03-15 14:29:57 - progress_bar.py[line:272] - INFO: epoch 003:   1395 / 2004 loss=0.989, loss_v1=0, loss_v2=0, nll_loss=0.989, ntokens=348.3, nsentences=8, sample_size=348.3, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=1023.7, ups=2.94, wpb=348.3, bsz=8, num_updates=5370, lr=9.55967e-05, gnorm=1.892, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=1815
2023-03-15 14:30:00 - progress_bar.py[line:272] - INFO: epoch 003:   1405 / 2004 loss=1.008, loss_v1=0, loss_v2=0, nll_loss=1.008, ntokens=342.2, nsentences=8, sample_size=342.2, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=1009.3, ups=2.95, wpb=342.2, bsz=8, num_updates=5380, lr=9.55866e-05, gnorm=2.003, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=1818
2023-03-15 14:30:04 - progress_bar.py[line:272] - INFO: epoch 003:   1415 / 2004 loss=1.188, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=395.9, nsentences=8, sample_size=395.9, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=1161.8, ups=2.93, wpb=395.9, bsz=8, num_updates=5390, lr=9.55765e-05, gnorm=1.982, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=1821
2023-03-15 14:30:07 - progress_bar.py[line:272] - INFO: epoch 003:   1425 / 2004 loss=0.955, loss_v1=0, loss_v2=0, nll_loss=0.955, ntokens=287.7, nsentences=8, sample_size=287.7, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=834.7, ups=2.9, wpb=287.7, bsz=8, num_updates=5400, lr=9.55664e-05, gnorm=2.028, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=1825
2023-03-15 14:30:11 - progress_bar.py[line:272] - INFO: epoch 003:   1435 / 2004 loss=1.129, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=360.9, nsentences=8, sample_size=360.9, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1067.3, ups=2.96, wpb=360.9, bsz=8, num_updates=5410, lr=9.55564e-05, gnorm=2.067, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=1828
2023-03-15 14:30:14 - progress_bar.py[line:272] - INFO: epoch 003:   1445 / 2004 loss=1.08, loss_v1=0, loss_v2=0, nll_loss=1.08, ntokens=325.8, nsentences=8, sample_size=325.8, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1072.6, ups=3.29, wpb=325.8, bsz=8, num_updates=5420, lr=9.55463e-05, gnorm=2.115, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=1831
2023-03-15 14:30:17 - progress_bar.py[line:272] - INFO: epoch 003:   1455 / 2004 loss=1.187, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=370.5, nsentences=8, sample_size=370.5, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=1210.1, ups=3.27, wpb=370.5, bsz=8, num_updates=5430, lr=9.55362e-05, gnorm=2.06, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=1834
2023-03-15 14:30:20 - progress_bar.py[line:272] - INFO: epoch 003:   1465 / 2004 loss=1.11, loss_v1=0, loss_v2=0, nll_loss=1.11, ntokens=388.9, nsentences=8, sample_size=388.9, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1256.6, ups=3.23, wpb=388.9, bsz=8, num_updates=5440, lr=9.55261e-05, gnorm=1.948, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=1837
2023-03-15 14:30:23 - progress_bar.py[line:272] - INFO: epoch 003:   1475 / 2004 loss=1.103, loss_v1=0, loss_v2=0, nll_loss=1.103, ntokens=411.5, nsentences=8, sample_size=411.5, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1297.5, ups=3.15, wpb=411.5, bsz=8, num_updates=5450, lr=9.5516e-05, gnorm=1.96, clip=0, loss_scale=2048, train_wall=3, gb_free=13.8, wall=1841
2023-03-15 14:30:26 - progress_bar.py[line:272] - INFO: epoch 003:   1485 / 2004 loss=1.087, loss_v1=0, loss_v2=0, nll_loss=1.087, ntokens=355.3, nsentences=8, sample_size=355.3, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1140.9, ups=3.21, wpb=355.3, bsz=8, num_updates=5460, lr=9.5506e-05, gnorm=2.029, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=1844
2023-03-15 14:30:29 - progress_bar.py[line:272] - INFO: epoch 003:   1495 / 2004 loss=1.119, loss_v1=0, loss_v2=0, nll_loss=1.119, ntokens=323.5, nsentences=8, sample_size=323.5, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1054.3, ups=3.26, wpb=323.5, bsz=8, num_updates=5470, lr=9.54959e-05, gnorm=2.192, clip=0, loss_scale=2048, train_wall=3, gb_free=13.9, wall=1847
2023-03-15 14:30:33 - progress_bar.py[line:272] - INFO: epoch 003:   1505 / 2004 loss=1.056, loss_v1=0, loss_v2=0, nll_loss=1.056, ntokens=329.6, nsentences=8, sample_size=329.6, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=985.8, ups=2.99, wpb=329.6, bsz=8, num_updates=5480, lr=9.54858e-05, gnorm=2.072, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=1850
2023-03-15 14:30:36 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 14:30:36 - progress_bar.py[line:272] - INFO: epoch 003:   1516 / 2004 loss=1.015, loss_v1=0, loss_v2=0, nll_loss=1.015, ntokens=321.8, nsentences=8, sample_size=321.8, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=954.1, ups=2.96, wpb=321.8, bsz=8, num_updates=5490, lr=9.54757e-05, gnorm=2.091, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=1854
2023-03-15 14:30:39 - progress_bar.py[line:272] - INFO: epoch 003:   1526 / 2004 loss=1.124, loss_v1=0, loss_v2=0, nll_loss=1.124, ntokens=330.1, nsentences=8, sample_size=330.1, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1077, ups=3.26, wpb=330.1, bsz=8, num_updates=5500, lr=9.54656e-05, gnorm=2.154, clip=0, loss_scale=1024, train_wall=3, gb_free=14, wall=1857
2023-03-15 14:30:42 - progress_bar.py[line:272] - INFO: epoch 003:   1536 / 2004 loss=0.995, loss_v1=0, loss_v2=0, nll_loss=0.995, ntokens=354.8, nsentences=8, sample_size=354.8, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=1171.2, ups=3.3, wpb=354.8, bsz=8, num_updates=5510, lr=9.54556e-05, gnorm=1.906, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=1860
2023-03-15 14:30:45 - progress_bar.py[line:272] - INFO: epoch 003:   1546 / 2004 loss=1.042, loss_v1=0, loss_v2=0, nll_loss=1.042, ntokens=324.7, nsentences=8, sample_size=324.7, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=1052.8, ups=3.24, wpb=324.7, bsz=8, num_updates=5520, lr=9.54455e-05, gnorm=2.097, clip=0, loss_scale=1024, train_wall=3, gb_free=13.8, wall=1863
2023-03-15 14:30:48 - progress_bar.py[line:272] - INFO: epoch 003:   1556 / 2004 loss=1.141, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=339.6, nsentences=8, sample_size=339.6, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1048.1, ups=3.09, wpb=339.6, bsz=8, num_updates=5530, lr=9.54354e-05, gnorm=2.057, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=1866
2023-03-15 14:30:52 - progress_bar.py[line:272] - INFO: epoch 003:   1566 / 2004 loss=0.911, loss_v1=0, loss_v2=0, nll_loss=0.911, ntokens=342.6, nsentences=8, sample_size=342.6, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=1043.3, ups=3.05, wpb=342.6, bsz=8, num_updates=5540, lr=9.54253e-05, gnorm=1.969, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=1869
2023-03-15 14:30:55 - progress_bar.py[line:272] - INFO: epoch 003:   1576 / 2004 loss=1.106, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=351.2, nsentences=8, sample_size=351.2, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1078.2, ups=3.07, wpb=351.2, bsz=8, num_updates=5550, lr=9.54152e-05, gnorm=2.085, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=1873
2023-03-15 14:30:58 - progress_bar.py[line:272] - INFO: epoch 003:   1586 / 2004 loss=1.046, loss_v1=0, loss_v2=0, nll_loss=1.046, ntokens=322, nsentences=8, sample_size=322, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=970, ups=3.01, wpb=322, bsz=8, num_updates=5560, lr=9.54051e-05, gnorm=2.11, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=1876
2023-03-15 14:31:02 - progress_bar.py[line:272] - INFO: epoch 003:   1596 / 2004 loss=1.092, loss_v1=0, loss_v2=0, nll_loss=1.092, ntokens=353.3, nsentences=8, sample_size=353.3, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1054.5, ups=2.98, wpb=353.3, bsz=8, num_updates=5570, lr=9.53951e-05, gnorm=2.036, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=1879
2023-03-15 14:31:05 - progress_bar.py[line:272] - INFO: epoch 003:   1606 / 2004 loss=1.031, loss_v1=0, loss_v2=0, nll_loss=1.031, ntokens=337.1, nsentences=8, sample_size=337.1, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=999.5, ups=2.97, wpb=337.1, bsz=8, num_updates=5580, lr=9.5385e-05, gnorm=2.024, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=1883
2023-03-15 14:31:08 - progress_bar.py[line:272] - INFO: epoch 003:   1616 / 2004 loss=1.082, loss_v1=0, loss_v2=0, nll_loss=1.082, ntokens=332.6, nsentences=8, sample_size=332.6, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=983.6, ups=2.96, wpb=332.6, bsz=8, num_updates=5590, lr=9.53749e-05, gnorm=2.056, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=1886
2023-03-15 14:31:12 - progress_bar.py[line:272] - INFO: epoch 003:   1626 / 2004 loss=1.148, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=364.7, nsentences=8, sample_size=364.7, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1094.6, ups=3, wpb=364.7, bsz=8, num_updates=5600, lr=9.53648e-05, gnorm=2.129, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=1889
2023-03-15 14:31:15 - progress_bar.py[line:272] - INFO: epoch 003:   1636 / 2004 loss=1.075, loss_v1=0, loss_v2=0, nll_loss=1.075, ntokens=324, nsentences=8, sample_size=324, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=987.2, ups=3.05, wpb=324, bsz=8, num_updates=5610, lr=9.53547e-05, gnorm=2.145, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=1893
2023-03-15 14:31:18 - progress_bar.py[line:272] - INFO: epoch 003:   1646 / 2004 loss=1.085, loss_v1=0, loss_v2=0, nll_loss=1.085, ntokens=318.5, nsentences=8, sample_size=318.5, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=949.2, ups=2.98, wpb=318.5, bsz=8, num_updates=5620, lr=9.53447e-05, gnorm=2.172, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=1896
2023-03-15 14:31:22 - progress_bar.py[line:272] - INFO: epoch 003:   1656 / 2004 loss=1.075, loss_v1=0, loss_v2=0, nll_loss=1.075, ntokens=358.1, nsentences=8, sample_size=358.1, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1028.4, ups=2.87, wpb=358.1, bsz=8, num_updates=5630, lr=9.53346e-05, gnorm=2.081, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=1899
2023-03-15 14:31:25 - progress_bar.py[line:272] - INFO: epoch 003:   1666 / 2004 loss=1.187, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=345.7, nsentences=8, sample_size=345.7, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=996.3, ups=2.88, wpb=345.7, bsz=8, num_updates=5640, lr=9.53245e-05, gnorm=2.161, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=1903
2023-03-15 14:31:29 - progress_bar.py[line:272] - INFO: epoch 003:   1676 / 2004 loss=1.066, loss_v1=0, loss_v2=0, nll_loss=1.066, ntokens=320.2, nsentences=8, sample_size=320.2, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=948.6, ups=2.96, wpb=320.2, bsz=8, num_updates=5650, lr=9.53144e-05, gnorm=2.16, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=1906
2023-03-15 14:31:32 - progress_bar.py[line:272] - INFO: epoch 003:   1686 / 2004 loss=1.117, loss_v1=0, loss_v2=0, nll_loss=1.117, ntokens=334, nsentences=8, sample_size=334, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=985.4, ups=2.95, wpb=334, bsz=8, num_updates=5660, lr=9.53043e-05, gnorm=2.12, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=1910
2023-03-15 14:31:35 - progress_bar.py[line:272] - INFO: epoch 003:   1696 / 2004 loss=1.007, loss_v1=0, loss_v2=0, nll_loss=1.007, ntokens=337.7, nsentences=8, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=1000.9, ups=2.96, wpb=337.7, bsz=8, num_updates=5670, lr=9.52943e-05, gnorm=2.022, clip=0, loss_scale=2048, train_wall=3, gb_free=15.9, wall=1913
2023-03-15 14:31:39 - progress_bar.py[line:272] - INFO: epoch 003:   1706 / 2004 loss=1.074, loss_v1=0, loss_v2=0, nll_loss=1.074, ntokens=348.9, nsentences=8, sample_size=348.9, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1019.7, ups=2.92, wpb=348.9, bsz=8, num_updates=5680, lr=9.52842e-05, gnorm=2.088, clip=0, loss_scale=2048, train_wall=3, gb_free=13.9, wall=1916
2023-03-15 14:31:42 - progress_bar.py[line:272] - INFO: epoch 003:   1716 / 2004 loss=1.19, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=356.2, nsentences=8, sample_size=356.2, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=1046.9, ups=2.94, wpb=356.2, bsz=8, num_updates=5690, lr=9.52741e-05, gnorm=2.095, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=1920
2023-03-15 14:31:46 - progress_bar.py[line:272] - INFO: epoch 003:   1726 / 2004 loss=1.111, loss_v1=0, loss_v2=0, nll_loss=1.111, ntokens=396.6, nsentences=8, sample_size=396.6, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1162.3, ups=2.93, wpb=396.6, bsz=8, num_updates=5700, lr=9.5264e-05, gnorm=1.916, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=1923
2023-03-15 14:31:48 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 14:31:49 - progress_bar.py[line:272] - INFO: epoch 003:   1737 / 2004 loss=1.015, loss_v1=0, loss_v2=0, nll_loss=1.015, ntokens=342.8, nsentences=8, sample_size=342.8, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=939.6, ups=2.74, wpb=342.8, bsz=8, num_updates=5710, lr=9.52539e-05, gnorm=2.005, clip=0, loss_scale=1024, train_wall=4, gb_free=15.2, wall=1927
2023-03-15 14:31:53 - progress_bar.py[line:272] - INFO: epoch 003:   1747 / 2004 loss=1.067, loss_v1=0, loss_v2=0, nll_loss=1.067, ntokens=349.9, nsentences=8, sample_size=349.9, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=1033.1, ups=2.95, wpb=349.9, bsz=8, num_updates=5720, lr=9.52439e-05, gnorm=2.088, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=1930
2023-03-15 14:31:56 - progress_bar.py[line:272] - INFO: epoch 003:   1757 / 2004 loss=1.106, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=328.9, nsentences=8, sample_size=328.9, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=989.5, ups=3.01, wpb=328.9, bsz=8, num_updates=5730, lr=9.52338e-05, gnorm=2.091, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=1934
2023-03-15 14:31:59 - progress_bar.py[line:272] - INFO: epoch 003:   1767 / 2004 loss=1.114, loss_v1=0, loss_v2=0, nll_loss=1.114, ntokens=314.3, nsentences=8, sample_size=314.3, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=938.6, ups=2.99, wpb=314.3, bsz=8, num_updates=5740, lr=9.52237e-05, gnorm=2.18, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=1937
2023-03-15 14:32:03 - progress_bar.py[line:272] - INFO: epoch 003:   1777 / 2004 loss=1.141, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=350.3, nsentences=8, sample_size=350.3, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1068, ups=3.05, wpb=350.3, bsz=8, num_updates=5750, lr=9.52136e-05, gnorm=2.093, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=1940
2023-03-15 14:32:06 - progress_bar.py[line:272] - INFO: epoch 003:   1787 / 2004 loss=1.034, loss_v1=0, loss_v2=0, nll_loss=1.034, ntokens=306.3, nsentences=8, sample_size=306.3, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=900.1, ups=2.94, wpb=306.3, bsz=8, num_updates=5760, lr=9.52035e-05, gnorm=2.146, clip=0, loss_scale=1024, train_wall=3, gb_free=15.8, wall=1944
2023-03-15 14:32:10 - progress_bar.py[line:272] - INFO: epoch 003:   1797 / 2004 loss=1.09, loss_v1=0, loss_v2=0, nll_loss=1.09, ntokens=349.8, nsentences=8, sample_size=349.8, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=995.5, ups=2.85, wpb=349.8, bsz=8, num_updates=5770, lr=9.51935e-05, gnorm=2.069, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=1947
2023-03-15 14:32:13 - progress_bar.py[line:272] - INFO: epoch 003:   1807 / 2004 loss=1.2, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=345.7, nsentences=8, sample_size=345.7, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=1027.6, ups=2.97, wpb=345.7, bsz=8, num_updates=5780, lr=9.51834e-05, gnorm=2.212, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=1951
2023-03-15 14:32:16 - progress_bar.py[line:272] - INFO: epoch 003:   1817 / 2004 loss=1.006, loss_v1=0, loss_v2=0, nll_loss=1.006, ntokens=339.3, nsentences=8, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=1005, ups=2.96, wpb=339.3, bsz=8, num_updates=5790, lr=9.51733e-05, gnorm=2.075, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=1954
2023-03-15 14:32:20 - progress_bar.py[line:272] - INFO: epoch 003:   1827 / 2004 loss=1.017, loss_v1=0, loss_v2=0, nll_loss=1.017, ntokens=357.3, nsentences=8, sample_size=357.3, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=1050.3, ups=2.94, wpb=357.3, bsz=8, num_updates=5800, lr=9.51632e-05, gnorm=2.014, clip=0, loss_scale=1024, train_wall=3, gb_free=15.7, wall=1957
2023-03-15 14:32:23 - progress_bar.py[line:272] - INFO: epoch 003:   1837 / 2004 loss=1.059, loss_v1=0, loss_v2=0, nll_loss=1.059, ntokens=341.2, nsentences=8, sample_size=341.2, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=995.8, ups=2.92, wpb=341.2, bsz=8, num_updates=5810, lr=9.51531e-05, gnorm=2.029, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=1961
2023-03-15 14:32:27 - progress_bar.py[line:272] - INFO: epoch 003:   1847 / 2004 loss=1.04, loss_v1=0, loss_v2=0, nll_loss=1.04, ntokens=355.5, nsentences=8, sample_size=355.5, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=1048.1, ups=2.95, wpb=355.5, bsz=8, num_updates=5820, lr=9.5143e-05, gnorm=1.99, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=1964
2023-03-15 14:32:30 - progress_bar.py[line:272] - INFO: epoch 003:   1857 / 2004 loss=1.126, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=312.4, nsentences=8, sample_size=312.4, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=941.5, ups=3.01, wpb=312.4, bsz=8, num_updates=5830, lr=9.5133e-05, gnorm=2.166, clip=0, loss_scale=1024, train_wall=3, gb_free=14.1, wall=1967
2023-03-15 14:32:33 - progress_bar.py[line:272] - INFO: epoch 003:   1867 / 2004 loss=1.005, loss_v1=0, loss_v2=0, nll_loss=1.005, ntokens=352.6, nsentences=8, sample_size=352.6, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=1037.3, ups=2.94, wpb=352.6, bsz=8, num_updates=5840, lr=9.51229e-05, gnorm=1.937, clip=0, loss_scale=2048, train_wall=3, gb_free=14, wall=1971
2023-03-15 14:32:37 - progress_bar.py[line:272] - INFO: epoch 003:   1877 / 2004 loss=1.046, loss_v1=0, loss_v2=0, nll_loss=1.046, ntokens=331.6, nsentences=8, sample_size=331.6, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=972.6, ups=2.93, wpb=331.6, bsz=8, num_updates=5850, lr=9.51128e-05, gnorm=2.1, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=1974
2023-03-15 14:32:40 - progress_bar.py[line:272] - INFO: epoch 003:   1887 / 2004 loss=0.987, loss_v1=0, loss_v2=0, nll_loss=0.987, ntokens=314.3, nsentences=8, sample_size=314.3, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=1013, ups=3.22, wpb=314.3, bsz=8, num_updates=5860, lr=9.51027e-05, gnorm=2.06, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=1977
2023-03-15 14:32:43 - progress_bar.py[line:272] - INFO: epoch 003:   1897 / 2004 loss=1.059, loss_v1=0, loss_v2=0, nll_loss=1.059, ntokens=352.5, nsentences=8, sample_size=352.5, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=1143, ups=3.24, wpb=352.5, bsz=8, num_updates=5870, lr=9.50926e-05, gnorm=2.048, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=1980
2023-03-15 14:32:46 - progress_bar.py[line:272] - INFO: epoch 003:   1907 / 2004 loss=0.97, loss_v1=0, loss_v2=0, nll_loss=0.97, ntokens=333.2, nsentences=8, sample_size=333.2, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=1068.7, ups=3.21, wpb=333.2, bsz=8, num_updates=5880, lr=9.50826e-05, gnorm=2.007, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=1984
2023-03-15 14:32:49 - progress_bar.py[line:272] - INFO: epoch 003:   1917 / 2004 loss=1.045, loss_v1=0, loss_v2=0, nll_loss=1.045, ntokens=332, nsentences=8, sample_size=332, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=991, ups=2.98, wpb=332, bsz=8, num_updates=5890, lr=9.50725e-05, gnorm=2.109, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=1987
2023-03-15 14:32:52 - progress_bar.py[line:272] - INFO: epoch 003:   1927 / 2004 loss=0.961, loss_v1=0, loss_v2=0, nll_loss=0.961, ntokens=330.9, nsentences=8, sample_size=330.9, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=1061.2, ups=3.21, wpb=330.9, bsz=8, num_updates=5900, lr=9.50624e-05, gnorm=1.981, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=1990
2023-03-15 14:32:56 - progress_bar.py[line:272] - INFO: epoch 003:   1937 / 2004 loss=0.946, loss_v1=0, loss_v2=0, nll_loss=0.946, ntokens=337.9, nsentences=8, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=1083, ups=3.21, wpb=337.9, bsz=8, num_updates=5910, lr=9.50523e-05, gnorm=2.04, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=1993
2023-03-15 14:32:59 - progress_bar.py[line:272] - INFO: epoch 003:   1947 / 2004 loss=1.126, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=344.1, nsentences=8, sample_size=344.1, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1101, ups=3.2, wpb=344.1, bsz=8, num_updates=5920, lr=9.50422e-05, gnorm=2.134, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=1996
2023-03-15 14:33:02 - progress_bar.py[line:272] - INFO: epoch 003:   1957 / 2004 loss=0.943, loss_v1=0, loss_v2=0, nll_loss=0.943, ntokens=354.9, nsentences=8, sample_size=354.9, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=1156.6, ups=3.26, wpb=354.9, bsz=8, num_updates=5930, lr=9.50322e-05, gnorm=1.984, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=1999
2023-03-15 14:33:05 - progress_bar.py[line:272] - INFO: epoch 003:   1967 / 2004 loss=1.011, loss_v1=0, loss_v2=0, nll_loss=1.011, ntokens=352.3, nsentences=8, sample_size=352.3, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=1105, ups=3.14, wpb=352.3, bsz=8, num_updates=5940, lr=9.50221e-05, gnorm=1.997, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=2003
2023-03-15 14:33:08 - progress_bar.py[line:272] - INFO: epoch 003:   1977 / 2004 loss=0.989, loss_v1=0, loss_v2=0, nll_loss=0.989, ntokens=346.4, nsentences=8, sample_size=346.4, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=1025.5, ups=2.96, wpb=346.4, bsz=8, num_updates=5950, lr=9.5012e-05, gnorm=1.988, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=2006
2023-03-15 14:33:12 - progress_bar.py[line:272] - INFO: epoch 003:   1987 / 2004 loss=1.009, loss_v1=0, loss_v2=0, nll_loss=1.009, ntokens=323.2, nsentences=8, sample_size=323.2, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=964.8, ups=2.99, wpb=323.2, bsz=8, num_updates=5960, lr=9.50019e-05, gnorm=2.085, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=2009
2023-03-15 14:33:15 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 14:33:15 - progress_bar.py[line:272] - INFO: epoch 003:   1998 / 2004 loss=1.074, loss_v1=0, loss_v2=0, nll_loss=1.074, ntokens=385.6, nsentences=8, sample_size=385.6, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1031, ups=2.67, wpb=385.6, bsz=8, num_updates=5970, lr=9.49918e-05, gnorm=1.96, clip=0, loss_scale=2048, train_wall=4, gb_free=14.9, wall=2013
2023-03-15 14:33:17 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 3 @ 5976 updates
2023-03-15 14:33:17 - trainer.py[line:431] - INFO: Saving checkpoint to ./checkpoints/checkpoint3.pt
2023-03-15 14:33:23 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./checkpoints/checkpoint3.pt
2023-03-15 14:33:25 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./checkpoints/checkpoint3.pt (epoch 3 @ 5976 updates, score None) (writing took 7.541217561811209 seconds)
2023-03-15 14:33:25 - train.py[line:332] - INFO: end of epoch 3 (average epoch stats below)
2023-03-15 14:33:25 - progress_bar.py[line:282] - INFO: epoch 003 | loss 1.11 | loss_v1 0 | loss_v2 0 | nll_loss 1.11 | ntokens 345.347 | nsentences 7.999 | sample_size 345.347 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.16 | wps 1017.3 | ups 2.95 | wpb 345.3 | bsz 8 | num_updates 5976 | lr 9.49858e-05 | gnorm 2.04 | clip 0 | loss_scale 2048 | train_wall 656 | gb_free 13.9 | wall 2023
2023-03-15 14:33:25 - trainer.py[line:639] - INFO: loading train data for epoch 4
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 row count 8015 total row count 8015
slice_id 0 seek offset 0
2023-03-15 14:33:26 - trainer.py[line:703] - INFO: begin training epoch 4
2023-03-15 14:33:26 - train.py[line:305] - INFO: Start iterating over samples
2023-03-15 14:33:27 - progress_bar.py[line:272] - INFO: epoch 004:      4 / 2004 loss=1.149, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=374.3, nsentences=8, sample_size=374.3, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=316.6, ups=0.85, wpb=374.3, bsz=8, num_updates=5980, lr=9.49818e-05, gnorm=2.048, clip=0, loss_scale=2048, train_wall=3, gb_free=12.9, wall=2025
2023-03-15 14:33:30 - progress_bar.py[line:272] - INFO: epoch 004:     14 / 2004 loss=1.031, loss_v1=0, loss_v2=0, nll_loss=1.031, ntokens=320.6, nsentences=8, sample_size=320.6, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=978.8, ups=3.05, wpb=320.6, bsz=8, num_updates=5990, lr=9.49717e-05, gnorm=2.069, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=2028
2023-03-15 14:33:34 - progress_bar.py[line:272] - INFO: epoch 004:     24 / 2004 loss=1.043, loss_v1=0, loss_v2=0, nll_loss=1.043, ntokens=362.6, nsentences=8, sample_size=362.6, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=1066.2, ups=2.94, wpb=362.6, bsz=8, num_updates=6000, lr=9.49616e-05, gnorm=1.981, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=2031
2023-03-15 14:33:34 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 4 @ 6000 updates
2023-03-15 14:33:34 - trainer.py[line:431] - INFO: Saving checkpoint to ./checkpoints/checkpoint_4_6000.pt
2023-03-15 14:33:39 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./checkpoints/checkpoint_4_6000.pt
2023-03-15 14:33:41 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./checkpoints/checkpoint_4_6000.pt (epoch 4 @ 6000 updates, score None) (writing took 7.56663915514946 seconds)
2023-03-15 14:33:45 - progress_bar.py[line:272] - INFO: epoch 004:     34 / 2004 loss=1.132, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=347.1, nsentences=8, sample_size=347.1, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=318.2, ups=0.92, wpb=347.1, bsz=8, num_updates=6010, lr=9.49515e-05, gnorm=2.178, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=2042
2023-03-15 14:33:48 - progress_bar.py[line:272] - INFO: epoch 004:     44 / 2004 loss=1.056, loss_v1=0, loss_v2=0, nll_loss=1.056, ntokens=354.6, nsentences=8, sample_size=354.6, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=1066.4, ups=3.01, wpb=354.6, bsz=8, num_updates=6020, lr=9.49414e-05, gnorm=2.038, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=2046
2023-03-15 14:33:52 - progress_bar.py[line:272] - INFO: epoch 004:     54 / 2004 loss=1.038, loss_v1=0, loss_v2=0, nll_loss=1.038, ntokens=351.6, nsentences=8, sample_size=351.6, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=1021.6, ups=2.91, wpb=351.6, bsz=8, num_updates=6030, lr=9.49313e-05, gnorm=1.997, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=2049
2023-03-15 14:33:55 - progress_bar.py[line:272] - INFO: epoch 004:     64 / 2004 loss=1.055, loss_v1=0, loss_v2=0, nll_loss=1.055, ntokens=320.8, nsentences=8, sample_size=320.8, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=940.8, ups=2.93, wpb=320.8, bsz=8, num_updates=6040, lr=9.49213e-05, gnorm=2.195, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=2053
2023-03-15 14:33:58 - progress_bar.py[line:272] - INFO: epoch 004:     74 / 2004 loss=1.071, loss_v1=0, loss_v2=0, nll_loss=1.071, ntokens=359.2, nsentences=8, sample_size=359.2, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=1109.2, ups=3.09, wpb=359.2, bsz=8, num_updates=6050, lr=9.49112e-05, gnorm=2.036, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=2056
2023-03-15 14:34:02 - progress_bar.py[line:272] - INFO: epoch 004:     84 / 2004 loss=1.016, loss_v1=0, loss_v2=0, nll_loss=1.016, ntokens=335.3, nsentences=8, sample_size=335.3, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=989.4, ups=2.95, wpb=335.3, bsz=8, num_updates=6060, lr=9.49011e-05, gnorm=2.003, clip=0, loss_scale=2048, train_wall=3, gb_free=13.5, wall=2059
2023-03-15 14:34:05 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 14:34:05 - progress_bar.py[line:272] - INFO: epoch 004:     95 / 2004 loss=1.122, loss_v1=0, loss_v2=0, nll_loss=1.122, ntokens=353.2, nsentences=8, sample_size=353.2, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=947.4, ups=2.68, wpb=353.2, bsz=8, num_updates=6070, lr=9.4891e-05, gnorm=2.056, clip=0, loss_scale=1024, train_wall=4, gb_free=15.2, wall=2063
2023-03-15 14:34:09 - progress_bar.py[line:272] - INFO: epoch 004:    105 / 2004 loss=0.98, loss_v1=0, loss_v2=0, nll_loss=0.98, ntokens=376.9, nsentences=8, sample_size=376.9, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=1108.9, ups=2.94, wpb=376.9, bsz=8, num_updates=6080, lr=9.48809e-05, gnorm=1.972, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=2066
2023-03-15 14:34:12 - progress_bar.py[line:272] - INFO: epoch 004:    115 / 2004 loss=1.104, loss_v1=0, loss_v2=0, nll_loss=1.104, ntokens=340.5, nsentences=8, sample_size=340.5, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1023.2, ups=3.01, wpb=340.5, bsz=8, num_updates=6090, lr=9.48709e-05, gnorm=2.093, clip=0, loss_scale=1024, train_wall=3, gb_free=14.2, wall=2070
2023-03-15 14:34:15 - progress_bar.py[line:272] - INFO: epoch 004:    125 / 2004 loss=1.1, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=326.2, nsentences=8, sample_size=326.2, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=970.4, ups=2.97, wpb=326.2, bsz=8, num_updates=6100, lr=9.48608e-05, gnorm=2.135, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=2073
2023-03-15 14:34:19 - progress_bar.py[line:272] - INFO: epoch 004:    135 / 2004 loss=0.978, loss_v1=0, loss_v2=0, nll_loss=0.978, ntokens=341.7, nsentences=8, sample_size=341.7, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=997.7, ups=2.92, wpb=341.7, bsz=8, num_updates=6110, lr=9.48507e-05, gnorm=1.979, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=2076
2023-03-15 14:34:22 - progress_bar.py[line:272] - INFO: epoch 004:    145 / 2004 loss=1.07, loss_v1=0, loss_v2=0, nll_loss=1.07, ntokens=332.7, nsentences=8, sample_size=332.7, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=969, ups=2.91, wpb=332.7, bsz=8, num_updates=6120, lr=9.48406e-05, gnorm=2.108, clip=0, loss_scale=1024, train_wall=3, gb_free=15.7, wall=2080
2023-03-15 14:34:26 - progress_bar.py[line:272] - INFO: epoch 004:    155 / 2004 loss=1.08, loss_v1=0, loss_v2=0, nll_loss=1.08, ntokens=339.4, nsentences=8, sample_size=339.4, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=996.7, ups=2.94, wpb=339.4, bsz=8, num_updates=6130, lr=9.48305e-05, gnorm=2.109, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=2083
2023-03-15 14:34:29 - progress_bar.py[line:272] - INFO: epoch 004:    165 / 2004 loss=0.995, loss_v1=0, loss_v2=0, nll_loss=0.995, ntokens=353.9, nsentences=8, sample_size=353.9, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=1044, ups=2.95, wpb=353.9, bsz=8, num_updates=6140, lr=9.48205e-05, gnorm=2.021, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=2087
2023-03-15 14:34:32 - progress_bar.py[line:272] - INFO: epoch 004:    175 / 2004 loss=1.002, loss_v1=0, loss_v2=0, nll_loss=1.002, ntokens=331.9, nsentences=8, sample_size=331.9, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=980.2, ups=2.95, wpb=331.9, bsz=8, num_updates=6150, lr=9.48104e-05, gnorm=2.031, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=2090
2023-03-15 14:34:36 - progress_bar.py[line:272] - INFO: epoch 004:    185 / 2004 loss=0.927, loss_v1=0, loss_v2=0, nll_loss=0.927, ntokens=336.3, nsentences=8, sample_size=336.3, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=1005.4, ups=2.99, wpb=336.3, bsz=8, num_updates=6160, lr=9.48003e-05, gnorm=1.996, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=2093
2023-03-15 14:34:39 - progress_bar.py[line:272] - INFO: epoch 004:    195 / 2004 loss=0.966, loss_v1=0, loss_v2=0, nll_loss=0.966, ntokens=321.6, nsentences=8, sample_size=321.6, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=949.9, ups=2.95, wpb=321.6, bsz=8, num_updates=6170, lr=9.47902e-05, gnorm=2.07, clip=0, loss_scale=1024, train_wall=3, gb_free=15.9, wall=2097
2023-03-15 14:34:43 - progress_bar.py[line:272] - INFO: epoch 004:    205 / 2004 loss=1.076, loss_v1=0, loss_v2=0, nll_loss=1.076, ntokens=336.6, nsentences=8, sample_size=336.6, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1003.4, ups=2.98, wpb=336.6, bsz=8, num_updates=6180, lr=9.47801e-05, gnorm=2.151, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=2100
2023-03-15 14:34:46 - progress_bar.py[line:272] - INFO: epoch 004:    215 / 2004 loss=1.023, loss_v1=0, loss_v2=0, nll_loss=1.023, ntokens=334.6, nsentences=8, sample_size=334.6, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=973, ups=2.91, wpb=334.6, bsz=8, num_updates=6190, lr=9.47701e-05, gnorm=2.081, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=2104
2023-03-15 14:34:49 - progress_bar.py[line:272] - INFO: epoch 004:    225 / 2004 loss=0.909, loss_v1=0, loss_v2=0, nll_loss=0.909, ntokens=333.2, nsentences=8, sample_size=333.2, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=972.3, ups=2.92, wpb=333.2, bsz=8, num_updates=6200, lr=9.476e-05, gnorm=1.984, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=2107
2023-03-15 14:34:53 - progress_bar.py[line:272] - INFO: epoch 004:    235 / 2004 loss=1.056, loss_v1=0, loss_v2=0, nll_loss=1.056, ntokens=371.3, nsentences=8, sample_size=371.3, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=1071.6, ups=2.89, wpb=371.3, bsz=8, num_updates=6210, lr=9.47499e-05, gnorm=2.065, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=2110
2023-03-15 14:34:56 - progress_bar.py[line:272] - INFO: epoch 004:    245 / 2004 loss=1.068, loss_v1=0, loss_v2=0, nll_loss=1.068, ntokens=353.4, nsentences=8, sample_size=353.4, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=1028, ups=2.91, wpb=353.4, bsz=8, num_updates=6220, lr=9.47398e-05, gnorm=2.065, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=2114
2023-03-15 14:35:00 - progress_bar.py[line:272] - INFO: epoch 004:    255 / 2004 loss=0.907, loss_v1=0, loss_v2=0, nll_loss=0.907, ntokens=338.4, nsentences=8, sample_size=338.4, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=996.2, ups=2.94, wpb=338.4, bsz=8, num_updates=6230, lr=9.47297e-05, gnorm=1.943, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=2117
2023-03-15 14:35:03 - progress_bar.py[line:272] - INFO: epoch 004:    265 / 2004 loss=1.082, loss_v1=0, loss_v2=0, nll_loss=1.082, ntokens=357, nsentences=8, sample_size=357, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1046.1, ups=2.93, wpb=357, bsz=8, num_updates=6240, lr=9.47197e-05, gnorm=2.068, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=2121
2023-03-15 14:35:07 - progress_bar.py[line:272] - INFO: epoch 004:    275 / 2004 loss=0.986, loss_v1=0, loss_v2=0, nll_loss=0.986, ntokens=330.2, nsentences=8, sample_size=330.2, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=975.2, ups=2.95, wpb=330.2, bsz=8, num_updates=6250, lr=9.47096e-05, gnorm=2.057, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=2124
2023-03-15 14:35:10 - progress_bar.py[line:272] - INFO: epoch 004:    285 / 2004 loss=1.042, loss_v1=0, loss_v2=0, nll_loss=1.042, ntokens=376.6, nsentences=8, sample_size=376.6, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=1091.6, ups=2.9, wpb=376.6, bsz=8, num_updates=6260, lr=9.46995e-05, gnorm=1.976, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=2128
2023-03-15 14:35:13 - progress_bar.py[line:272] - INFO: epoch 004:    295 / 2004 loss=1.016, loss_v1=0, loss_v2=0, nll_loss=1.016, ntokens=351.5, nsentences=8, sample_size=351.5, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=1041, ups=2.96, wpb=351.5, bsz=8, num_updates=6270, lr=9.46894e-05, gnorm=1.938, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=2131
2023-03-15 14:35:17 - progress_bar.py[line:272] - INFO: epoch 004:    305 / 2004 loss=1.017, loss_v1=0, loss_v2=0, nll_loss=1.017, ntokens=352.2, nsentences=8, sample_size=352.2, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=1027.8, ups=2.92, wpb=352.2, bsz=8, num_updates=6280, lr=9.46793e-05, gnorm=2.007, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=2134
2023-03-15 14:35:20 - progress_bar.py[line:272] - INFO: epoch 004:    315 / 2004 loss=1.041, loss_v1=0, loss_v2=0, nll_loss=1.041, ntokens=356.3, nsentences=8, sample_size=356.3, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=1050.2, ups=2.95, wpb=356.3, bsz=8, num_updates=6290, lr=9.46692e-05, gnorm=2.073, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=2138
2023-03-15 14:35:24 - progress_bar.py[line:272] - INFO: epoch 004:    325 / 2004 loss=0.966, loss_v1=0, loss_v2=0, nll_loss=0.966, ntokens=325.9, nsentences=8, sample_size=325.9, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=969, ups=2.97, wpb=325.9, bsz=8, num_updates=6300, lr=9.46592e-05, gnorm=2.03, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=2141
2023-03-15 14:35:27 - progress_bar.py[line:272] - INFO: epoch 004:    335 / 2004 loss=1.052, loss_v1=0, loss_v2=0, nll_loss=1.052, ntokens=320.6, nsentences=8, sample_size=320.6, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=957.3, ups=2.99, wpb=320.6, bsz=8, num_updates=6310, lr=9.46491e-05, gnorm=2.158, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=2144
2023-03-15 14:35:30 - progress_bar.py[line:272] - INFO: epoch 004:    345 / 2004 loss=1.13, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=388.7, nsentences=8, sample_size=388.7, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1141.5, ups=2.94, wpb=388.7, bsz=8, num_updates=6320, lr=9.4639e-05, gnorm=2.068, clip=0, loss_scale=2048, train_wall=3, gb_free=13.9, wall=2148
2023-03-15 14:35:34 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 14:35:34 - progress_bar.py[line:272] - INFO: epoch 004:    356 / 2004 loss=1.043, loss_v1=0, loss_v2=0, nll_loss=1.043, ntokens=334.7, nsentences=8, sample_size=334.7, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=887.5, ups=2.65, wpb=334.7, bsz=8, num_updates=6330, lr=9.46289e-05, gnorm=2.151, clip=0, loss_scale=2048, train_wall=4, gb_free=14, wall=2152
2023-03-15 14:35:38 - progress_bar.py[line:272] - INFO: epoch 004:    366 / 2004 loss=1.068, loss_v1=0, loss_v2=0, nll_loss=1.068, ntokens=366.6, nsentences=8, sample_size=366.6, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=1045.6, ups=2.85, wpb=366.6, bsz=8, num_updates=6340, lr=9.46188e-05, gnorm=2.072, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=2155
2023-03-15 14:35:41 - progress_bar.py[line:272] - INFO: epoch 004:    376 / 2004 loss=0.929, loss_v1=0, loss_v2=0, nll_loss=0.929, ntokens=307.5, nsentences=8, sample_size=307.5, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=907.1, ups=2.95, wpb=307.5, bsz=8, num_updates=6350, lr=9.46088e-05, gnorm=2.137, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=2159
2023-03-15 14:35:44 - progress_bar.py[line:272] - INFO: epoch 004:    386 / 2004 loss=1.029, loss_v1=0, loss_v2=0, nll_loss=1.029, ntokens=325.8, nsentences=8, sample_size=325.8, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=967.8, ups=2.97, wpb=325.8, bsz=8, num_updates=6360, lr=9.45987e-05, gnorm=2.094, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=2162
2023-03-15 14:35:48 - progress_bar.py[line:272] - INFO: epoch 004:    396 / 2004 loss=1.049, loss_v1=0, loss_v2=0, nll_loss=1.049, ntokens=352.3, nsentences=8, sample_size=352.3, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=1021.1, ups=2.9, wpb=352.3, bsz=8, num_updates=6370, lr=9.45886e-05, gnorm=2.143, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=2165
2023-03-15 14:35:52 - progress_bar.py[line:272] - INFO: epoch 004:    406 / 2004 loss=0.991, loss_v1=0, loss_v2=0, nll_loss=0.991, ntokens=381.7, nsentences=8, sample_size=381.7, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=852.6, ups=2.23, wpb=381.7, bsz=8, num_updates=6380, lr=9.45785e-05, gnorm=1.991, clip=0, loss_scale=2048, train_wall=4, gb_free=14, wall=2170
2023-03-15 14:35:56 - progress_bar.py[line:272] - INFO: epoch 004:    416 / 2004 loss=0.974, loss_v1=0, loss_v2=0, nll_loss=0.974, ntokens=339.3, nsentences=8, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=1023.4, ups=3.02, wpb=339.3, bsz=8, num_updates=6390, lr=9.45684e-05, gnorm=2.049, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=2173
2023-03-15 14:35:59 - progress_bar.py[line:272] - INFO: epoch 004:    426 / 2004 loss=0.946, loss_v1=0, loss_v2=0, nll_loss=0.946, ntokens=330.6, nsentences=8, sample_size=330.6, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=974.1, ups=2.95, wpb=330.6, bsz=8, num_updates=6400, lr=9.45584e-05, gnorm=1.99, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=2177
2023-03-15 14:36:01 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 14:36:03 - progress_bar.py[line:272] - INFO: epoch 004:    437 / 2004 loss=0.937, loss_v1=0, loss_v2=0, nll_loss=0.937, ntokens=345.6, nsentences=8, sample_size=345.6, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=908.2, ups=2.63, wpb=345.6, bsz=8, num_updates=6410, lr=9.45483e-05, gnorm=1.96, clip=0, loss_scale=1024, train_wall=4, gb_free=15.7, wall=2180
2023-03-15 14:36:06 - progress_bar.py[line:272] - INFO: epoch 004:    447 / 2004 loss=1.112, loss_v1=0, loss_v2=0, nll_loss=1.112, ntokens=374.5, nsentences=8, sample_size=374.5, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1057.1, ups=2.82, wpb=374.5, bsz=8, num_updates=6420, lr=9.45382e-05, gnorm=2.079, clip=0, loss_scale=1024, train_wall=3, gb_free=13.9, wall=2184
2023-03-15 14:36:10 - progress_bar.py[line:272] - INFO: epoch 004:    457 / 2004 loss=1.158, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=390, nsentences=8, sample_size=390, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1130.6, ups=2.9, wpb=390, bsz=8, num_updates=6430, lr=9.45281e-05, gnorm=2.049, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=2187
2023-03-15 14:36:13 - progress_bar.py[line:272] - INFO: epoch 004:    467 / 2004 loss=1.202, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=359.1, nsentences=8, sample_size=359.1, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=1041.6, ups=2.9, wpb=359.1, bsz=8, num_updates=6440, lr=9.4518e-05, gnorm=2.22, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=2191
2023-03-15 14:36:17 - progress_bar.py[line:272] - INFO: epoch 004:    477 / 2004 loss=0.94, loss_v1=0, loss_v2=0, nll_loss=0.94, ntokens=334.5, nsentences=8, sample_size=334.5, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=979.3, ups=2.93, wpb=334.5, bsz=8, num_updates=6450, lr=9.4508e-05, gnorm=2.025, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=2194
2023-03-15 14:36:20 - progress_bar.py[line:272] - INFO: epoch 004:    487 / 2004 loss=0.99, loss_v1=0, loss_v2=0, nll_loss=0.99, ntokens=391.9, nsentences=8, sample_size=391.9, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=1125, ups=2.87, wpb=391.9, bsz=8, num_updates=6460, lr=9.44979e-05, gnorm=1.951, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=2198
2023-03-15 14:36:24 - progress_bar.py[line:272] - INFO: epoch 004:    497 / 2004 loss=0.985, loss_v1=0, loss_v2=0, nll_loss=0.985, ntokens=371, nsentences=8, sample_size=371, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=1075.5, ups=2.9, wpb=371, bsz=8, num_updates=6470, lr=9.44878e-05, gnorm=1.939, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=2201
2023-03-15 14:36:27 - progress_bar.py[line:272] - INFO: epoch 004:    507 / 2004 loss=1.04, loss_v1=0, loss_v2=0, nll_loss=1.04, ntokens=341.1, nsentences=8, sample_size=341.1, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=1006.5, ups=2.95, wpb=341.1, bsz=8, num_updates=6480, lr=9.44777e-05, gnorm=2.096, clip=0, loss_scale=1024, train_wall=3, gb_free=13.5, wall=2205
2023-03-15 14:36:30 - progress_bar.py[line:272] - INFO: epoch 004:    517 / 2004 loss=1.079, loss_v1=0, loss_v2=0, nll_loss=1.079, ntokens=353.3, nsentences=8, sample_size=353.3, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1010.6, ups=2.86, wpb=353.3, bsz=8, num_updates=6490, lr=9.44676e-05, gnorm=2.126, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=2208
2023-03-15 14:36:34 - progress_bar.py[line:272] - INFO: epoch 004:    527 / 2004 loss=1.043, loss_v1=0, loss_v2=0, nll_loss=1.043, ntokens=401.8, nsentences=8, sample_size=401.8, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=1168.1, ups=2.91, wpb=401.8, bsz=8, num_updates=6500, lr=9.44575e-05, gnorm=1.934, clip=0, loss_scale=1024, train_wall=3, gb_free=14.2, wall=2211
2023-03-15 14:36:37 - progress_bar.py[line:272] - INFO: epoch 004:    537 / 2004 loss=1.083, loss_v1=0, loss_v2=0, nll_loss=1.083, ntokens=381.1, nsentences=8, sample_size=381.1, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1115.7, ups=2.93, wpb=381.1, bsz=8, num_updates=6510, lr=9.44475e-05, gnorm=2.001, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=2215
2023-03-15 14:36:41 - progress_bar.py[line:272] - INFO: epoch 004:    547 / 2004 loss=1.047, loss_v1=0, loss_v2=0, nll_loss=1.047, ntokens=352.4, nsentences=8, sample_size=352.4, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=1023.4, ups=2.9, wpb=352.4, bsz=8, num_updates=6520, lr=9.44374e-05, gnorm=2.12, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=2218
2023-03-15 14:36:44 - progress_bar.py[line:272] - INFO: epoch 004:    557 / 2004 loss=0.995, loss_v1=0, loss_v2=0, nll_loss=0.995, ntokens=382, nsentences=8, sample_size=382, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=1113.9, ups=2.92, wpb=382, bsz=8, num_updates=6530, lr=9.44273e-05, gnorm=1.946, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=2222
2023-03-15 14:36:48 - progress_bar.py[line:272] - INFO: epoch 004:    567 / 2004 loss=0.964, loss_v1=0, loss_v2=0, nll_loss=0.964, ntokens=372.3, nsentences=8, sample_size=372.3, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=1093.5, ups=2.94, wpb=372.3, bsz=8, num_updates=6540, lr=9.44172e-05, gnorm=1.961, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=2225
2023-03-15 14:36:51 - progress_bar.py[line:272] - INFO: epoch 004:    577 / 2004 loss=1.011, loss_v1=0, loss_v2=0, nll_loss=1.011, ntokens=336.7, nsentences=8, sample_size=336.7, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=1006.9, ups=2.99, wpb=336.7, bsz=8, num_updates=6550, lr=9.44071e-05, gnorm=2.114, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=2229
2023-03-15 14:36:52 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 14:36:55 - progress_bar.py[line:272] - INFO: epoch 004:    588 / 2004 loss=0.922, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=336.9, nsentences=8, sample_size=336.9, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=894.8, ups=2.66, wpb=336.9, bsz=8, num_updates=6560, lr=9.43971e-05, gnorm=2.043, clip=0, loss_scale=1024, train_wall=4, gb_free=14.4, wall=2232
2023-03-15 14:36:58 - progress_bar.py[line:272] - INFO: epoch 004:    598 / 2004 loss=1.008, loss_v1=0, loss_v2=0, nll_loss=1.008, ntokens=334.5, nsentences=8, sample_size=334.5, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=972, ups=2.91, wpb=334.5, bsz=8, num_updates=6570, lr=9.4387e-05, gnorm=2.078, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=2236
2023-03-15 14:37:02 - progress_bar.py[line:272] - INFO: epoch 004:    608 / 2004 loss=1.077, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=351.9, nsentences=8, sample_size=351.9, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=982.7, ups=2.79, wpb=351.9, bsz=8, num_updates=6580, lr=9.43769e-05, gnorm=2.041, clip=0, loss_scale=1024, train_wall=4, gb_free=14.7, wall=2239
2023-03-15 14:37:05 - progress_bar.py[line:272] - INFO: epoch 004:    618 / 2004 loss=0.918, loss_v1=0, loss_v2=0, nll_loss=0.918, ntokens=354, nsentences=8, sample_size=354, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=1020.6, ups=2.88, wpb=354, bsz=8, num_updates=6590, lr=9.43668e-05, gnorm=1.95, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=2243
2023-03-15 14:37:09 - progress_bar.py[line:272] - INFO: epoch 004:    628 / 2004 loss=0.954, loss_v1=0, loss_v2=0, nll_loss=0.954, ntokens=368.7, nsentences=8, sample_size=368.7, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=1087.9, ups=2.95, wpb=368.7, bsz=8, num_updates=6600, lr=9.43567e-05, gnorm=1.951, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=2246
2023-03-15 14:37:12 - progress_bar.py[line:272] - INFO: epoch 004:    638 / 2004 loss=0.969, loss_v1=0, loss_v2=0, nll_loss=0.969, ntokens=331.9, nsentences=8, sample_size=331.9, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=982, ups=2.96, wpb=331.9, bsz=8, num_updates=6610, lr=9.43467e-05, gnorm=2.102, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=2250
2023-03-15 14:37:15 - progress_bar.py[line:272] - INFO: epoch 004:    648 / 2004 loss=1.089, loss_v1=0, loss_v2=0, nll_loss=1.089, ntokens=330.7, nsentences=8, sample_size=330.7, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=984.9, ups=2.98, wpb=330.7, bsz=8, num_updates=6620, lr=9.43366e-05, gnorm=2.212, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=2253
2023-03-15 14:37:19 - progress_bar.py[line:272] - INFO: epoch 004:    658 / 2004 loss=1.098, loss_v1=0, loss_v2=0, nll_loss=1.098, ntokens=352.5, nsentences=8, sample_size=352.5, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1038.6, ups=2.95, wpb=352.5, bsz=8, num_updates=6630, lr=9.43265e-05, gnorm=2.16, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=2256
2023-03-15 14:37:22 - progress_bar.py[line:272] - INFO: epoch 004:    668 / 2004 loss=0.999, loss_v1=0, loss_v2=0, nll_loss=0.999, ntokens=299.1, nsentences=8, sample_size=299.1, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=883.8, ups=2.95, wpb=299.1, bsz=8, num_updates=6640, lr=9.43164e-05, gnorm=2.231, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=2260
2023-03-15 14:37:25 - progress_bar.py[line:272] - INFO: epoch 004:    678 / 2004 loss=0.957, loss_v1=0, loss_v2=0, nll_loss=0.957, ntokens=343.8, nsentences=8, sample_size=343.8, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=1011.9, ups=2.94, wpb=343.8, bsz=8, num_updates=6650, lr=9.43063e-05, gnorm=2.04, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=2263
2023-03-15 14:37:29 - progress_bar.py[line:272] - INFO: epoch 004:    688 / 2004 loss=0.979, loss_v1=0, loss_v2=0, nll_loss=0.979, ntokens=355.9, nsentences=8, sample_size=355.9, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=1046.7, ups=2.94, wpb=355.9, bsz=8, num_updates=6660, lr=9.42963e-05, gnorm=2.083, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=2266
2023-03-15 14:37:32 - progress_bar.py[line:272] - INFO: epoch 004:    698 / 2004 loss=1.073, loss_v1=0, loss_v2=0, nll_loss=1.073, ntokens=354.1, nsentences=8, sample_size=354.1, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=1041, ups=2.94, wpb=354.1, bsz=8, num_updates=6670, lr=9.42862e-05, gnorm=2.124, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=2270
2023-03-15 14:37:36 - progress_bar.py[line:272] - INFO: epoch 004:    708 / 2004 loss=1.016, loss_v1=0, loss_v2=0, nll_loss=1.016, ntokens=324.6, nsentences=8, sample_size=324.6, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=972.9, ups=3, wpb=324.6, bsz=8, num_updates=6680, lr=9.42761e-05, gnorm=2.143, clip=0, loss_scale=1024, train_wall=3, gb_free=15.9, wall=2273
2023-03-15 14:37:39 - progress_bar.py[line:272] - INFO: epoch 004:    718 / 2004 loss=1.019, loss_v1=0, loss_v2=0, nll_loss=1.019, ntokens=336.8, nsentences=8, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=1005.7, ups=2.99, wpb=336.8, bsz=8, num_updates=6690, lr=9.4266e-05, gnorm=2.117, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=2277
2023-03-15 14:37:42 - progress_bar.py[line:272] - INFO: epoch 004:    728 / 2004 loss=1.085, loss_v1=0, loss_v2=0, nll_loss=1.085, ntokens=365.3, nsentences=8, sample_size=365.3, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1055.9, ups=2.89, wpb=365.3, bsz=8, num_updates=6700, lr=9.42559e-05, gnorm=2.171, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=2280
2023-03-15 14:37:46 - progress_bar.py[line:272] - INFO: epoch 004:    738 / 2004 loss=1.016, loss_v1=0, loss_v2=0, nll_loss=1.016, ntokens=325, nsentences=7.8, sample_size=325, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=963.4, ups=2.96, wpb=325, bsz=7.8, num_updates=6710, lr=9.42459e-05, gnorm=2.194, clip=0, loss_scale=2048, train_wall=3, gb_free=15.8, wall=2283
2023-03-15 14:37:49 - progress_bar.py[line:272] - INFO: epoch 004:    748 / 2004 loss=1.015, loss_v1=0, loss_v2=0, nll_loss=1.015, ntokens=363.7, nsentences=8, sample_size=363.7, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=1066.3, ups=2.93, wpb=363.7, bsz=8, num_updates=6720, lr=9.42358e-05, gnorm=2.042, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=2287
2023-03-15 14:37:53 - progress_bar.py[line:272] - INFO: epoch 004:    758 / 2004 loss=1.045, loss_v1=0, loss_v2=0, nll_loss=1.045, ntokens=305.1, nsentences=8, sample_size=305.1, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=894.8, ups=2.93, wpb=305.1, bsz=8, num_updates=6730, lr=9.42257e-05, gnorm=2.256, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=2290
2023-03-15 14:37:56 - progress_bar.py[line:272] - INFO: epoch 004:    768 / 2004 loss=1.131, loss_v1=0, loss_v2=0, nll_loss=1.131, ntokens=404.3, nsentences=8, sample_size=404.3, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1169.1, ups=2.89, wpb=404.3, bsz=8, num_updates=6740, lr=9.42156e-05, gnorm=2.07, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=2294
2023-03-15 14:37:59 - progress_bar.py[line:272] - INFO: epoch 004:    778 / 2004 loss=1.113, loss_v1=0, loss_v2=0, nll_loss=1.113, ntokens=355, nsentences=8, sample_size=355, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1051.8, ups=2.96, wpb=355, bsz=8, num_updates=6750, lr=9.42055e-05, gnorm=2.138, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=2297
2023-03-15 14:38:03 - progress_bar.py[line:272] - INFO: epoch 004:    788 / 2004 loss=0.966, loss_v1=0, loss_v2=0, nll_loss=0.966, ntokens=342.4, nsentences=8, sample_size=342.4, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=1007.2, ups=2.94, wpb=342.4, bsz=8, num_updates=6760, lr=9.41954e-05, gnorm=2.048, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=2300
2023-03-15 14:38:06 - progress_bar.py[line:272] - INFO: epoch 004:    798 / 2004 loss=0.896, loss_v1=0, loss_v2=0, nll_loss=0.896, ntokens=320.1, nsentences=8, sample_size=320.1, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=944.7, ups=2.95, wpb=320.1, bsz=8, num_updates=6770, lr=9.41854e-05, gnorm=2.107, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=2304
2023-03-15 14:38:10 - progress_bar.py[line:272] - INFO: epoch 004:    808 / 2004 loss=0.98, loss_v1=0, loss_v2=0, nll_loss=0.98, ntokens=340, nsentences=8, sample_size=340, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=1010.4, ups=2.97, wpb=340, bsz=8, num_updates=6780, lr=9.41753e-05, gnorm=2.095, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=2307
2023-03-15 14:38:13 - progress_bar.py[line:272] - INFO: epoch 004:    818 / 2004 loss=0.885, loss_v1=0, loss_v2=0, nll_loss=0.885, ntokens=322.2, nsentences=8, sample_size=322.2, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=937.3, ups=2.91, wpb=322.2, bsz=8, num_updates=6790, lr=9.41652e-05, gnorm=2.111, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=2311
2023-03-15 14:38:17 - progress_bar.py[line:272] - INFO: epoch 004:    828 / 2004 loss=1.047, loss_v1=0, loss_v2=0, nll_loss=1.047, ntokens=383.7, nsentences=8, sample_size=383.7, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=1111.3, ups=2.9, wpb=383.7, bsz=8, num_updates=6800, lr=9.41551e-05, gnorm=2.052, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=2314
2023-03-15 14:38:20 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 14:38:20 - progress_bar.py[line:272] - INFO: epoch 004:    839 / 2004 loss=0.901, loss_v1=0, loss_v2=0, nll_loss=0.901, ntokens=310.9, nsentences=8, sample_size=310.9, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=847, ups=2.72, wpb=310.9, bsz=8, num_updates=6810, lr=9.4145e-05, gnorm=2.074, clip=0, loss_scale=2048, train_wall=4, gb_free=14.4, wall=2318
2023-03-15 14:38:24 - progress_bar.py[line:272] - INFO: epoch 004:    849 / 2004 loss=0.997, loss_v1=0, loss_v2=0, nll_loss=0.997, ntokens=374.6, nsentences=8, sample_size=374.6, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=1080.5, ups=2.88, wpb=374.6, bsz=8, num_updates=6820, lr=9.4135e-05, gnorm=1.975, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=2321
2023-03-15 14:38:27 - progress_bar.py[line:272] - INFO: epoch 004:    859 / 2004 loss=0.998, loss_v1=0, loss_v2=0, nll_loss=0.998, ntokens=343.3, nsentences=8, sample_size=343.3, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=1014.1, ups=2.95, wpb=343.3, bsz=8, num_updates=6830, lr=9.41249e-05, gnorm=2.084, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=2325
2023-03-15 14:38:30 - progress_bar.py[line:272] - INFO: epoch 004:    869 / 2004 loss=1.031, loss_v1=0, loss_v2=0, nll_loss=1.031, ntokens=368.4, nsentences=8, sample_size=368.4, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=1107.2, ups=3.01, wpb=368.4, bsz=8, num_updates=6840, lr=9.41148e-05, gnorm=2.049, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=2328
2023-03-15 14:38:34 - progress_bar.py[line:272] - INFO: epoch 004:    879 / 2004 loss=0.885, loss_v1=0, loss_v2=0, nll_loss=0.885, ntokens=317.3, nsentences=8, sample_size=317.3, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=944.1, ups=2.98, wpb=317.3, bsz=8, num_updates=6850, lr=9.41047e-05, gnorm=2.032, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=2331
2023-03-15 14:38:37 - progress_bar.py[line:272] - INFO: epoch 004:    889 / 2004 loss=1.009, loss_v1=0, loss_v2=0, nll_loss=1.009, ntokens=316.5, nsentences=8, sample_size=316.5, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=998.7, ups=3.16, wpb=316.5, bsz=8, num_updates=6860, lr=9.40946e-05, gnorm=2.275, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=2335
2023-03-15 14:38:40 - progress_bar.py[line:272] - INFO: epoch 004:    899 / 2004 loss=1.052, loss_v1=0, loss_v2=0, nll_loss=1.052, ntokens=362.5, nsentences=8, sample_size=362.5, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=1163.6, ups=3.21, wpb=362.5, bsz=8, num_updates=6870, lr=9.40846e-05, gnorm=2.186, clip=0, loss_scale=2048, train_wall=3, gb_free=13.5, wall=2338
2023-03-15 14:38:43 - progress_bar.py[line:272] - INFO: epoch 004:    909 / 2004 loss=0.899, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=359.1, nsentences=8, sample_size=359.1, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=1107, ups=3.08, wpb=359.1, bsz=8, num_updates=6880, lr=9.40745e-05, gnorm=1.958, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=2341
2023-03-15 14:38:47 - progress_bar.py[line:272] - INFO: epoch 004:    919 / 2004 loss=0.993, loss_v1=0, loss_v2=0, nll_loss=0.993, ntokens=355.3, nsentences=8, sample_size=355.3, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=1046.9, ups=2.95, wpb=355.3, bsz=8, num_updates=6890, lr=9.40644e-05, gnorm=2.12, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=2344
2023-03-15 14:38:50 - progress_bar.py[line:272] - INFO: epoch 004:    929 / 2004 loss=0.96, loss_v1=0, loss_v2=0, nll_loss=0.96, ntokens=326.3, nsentences=8, sample_size=326.3, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=992.6, ups=3.04, wpb=326.3, bsz=8, num_updates=6900, lr=9.40543e-05, gnorm=2.057, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=2348
2023-03-15 14:38:53 - progress_bar.py[line:272] - INFO: epoch 004:    939 / 2004 loss=1.027, loss_v1=0, loss_v2=0, nll_loss=1.027, ntokens=373, nsentences=8, sample_size=373, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=1092.2, ups=2.93, wpb=373, bsz=8, num_updates=6910, lr=9.40442e-05, gnorm=2.121, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=2351
2023-03-15 14:38:57 - progress_bar.py[line:272] - INFO: epoch 004:    949 / 2004 loss=0.964, loss_v1=0, loss_v2=0, nll_loss=0.964, ntokens=346.1, nsentences=8, sample_size=346.1, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=1024.7, ups=2.96, wpb=346.1, bsz=8, num_updates=6920, lr=9.40342e-05, gnorm=2.061, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=2354
2023-03-15 14:39:00 - progress_bar.py[line:272] - INFO: epoch 004:    959 / 2004 loss=1.05, loss_v1=0, loss_v2=0, nll_loss=1.05, ntokens=354, nsentences=8, sample_size=354, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=1032.9, ups=2.92, wpb=354, bsz=8, num_updates=6930, lr=9.40241e-05, gnorm=2.136, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=2358
2023-03-15 14:39:04 - progress_bar.py[line:272] - INFO: epoch 004:    969 / 2004 loss=0.991, loss_v1=0, loss_v2=0, nll_loss=0.991, ntokens=351.2, nsentences=8, sample_size=351.2, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=1032.3, ups=2.94, wpb=351.2, bsz=8, num_updates=6940, lr=9.4014e-05, gnorm=2.081, clip=0, loss_scale=4096, train_wall=3, gb_free=14.8, wall=2361
2023-03-15 14:39:04 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 14:39:07 - progress_bar.py[line:272] - INFO: epoch 004:    980 / 2004 loss=0.997, loss_v1=0, loss_v2=0, nll_loss=0.997, ntokens=333.8, nsentences=8, sample_size=333.8, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=920, ups=2.76, wpb=333.8, bsz=8, num_updates=6950, lr=9.40039e-05, gnorm=2.12, clip=0, loss_scale=2048, train_wall=4, gb_free=15.3, wall=2365
2023-03-15 14:39:11 - progress_bar.py[line:272] - INFO: epoch 004:    990 / 2004 loss=0.999, loss_v1=0, loss_v2=0, nll_loss=0.999, ntokens=374.7, nsentences=8, sample_size=374.7, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=1093.9, ups=2.92, wpb=374.7, bsz=8, num_updates=6960, lr=9.39938e-05, gnorm=2.053, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=2368
2023-03-15 14:39:14 - progress_bar.py[line:272] - INFO: epoch 004:   1000 / 2004 loss=0.968, loss_v1=0, loss_v2=0, nll_loss=0.968, ntokens=345.5, nsentences=8, sample_size=345.5, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=1022.8, ups=2.96, wpb=345.5, bsz=8, num_updates=6970, lr=9.39837e-05, gnorm=2.024, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=2372
2023-03-15 14:39:17 - progress_bar.py[line:272] - INFO: epoch 004:   1010 / 2004 loss=0.989, loss_v1=0, loss_v2=0, nll_loss=0.989, ntokens=313.2, nsentences=8, sample_size=313.2, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=912.2, ups=2.91, wpb=313.2, bsz=8, num_updates=6980, lr=9.39737e-05, gnorm=2.209, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=2375
2023-03-15 14:39:21 - progress_bar.py[line:272] - INFO: epoch 004:   1020 / 2004 loss=0.962, loss_v1=0, loss_v2=0, nll_loss=0.962, ntokens=333.6, nsentences=8, sample_size=333.6, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=985.8, ups=2.95, wpb=333.6, bsz=8, num_updates=6990, lr=9.39636e-05, gnorm=2.142, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=2378
2023-03-15 14:39:24 - progress_bar.py[line:272] - INFO: epoch 004:   1030 / 2004 loss=0.974, loss_v1=0, loss_v2=0, nll_loss=0.974, ntokens=323, nsentences=8, sample_size=323, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=954, ups=2.95, wpb=323, bsz=8, num_updates=7000, lr=9.39535e-05, gnorm=2.127, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=2382
2023-03-15 14:39:28 - progress_bar.py[line:272] - INFO: epoch 004:   1040 / 2004 loss=1.032, loss_v1=0, loss_v2=0, nll_loss=1.032, ntokens=331.2, nsentences=8, sample_size=331.2, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=956.8, ups=2.89, wpb=331.2, bsz=8, num_updates=7010, lr=9.39434e-05, gnorm=2.09, clip=0, loss_scale=2048, train_wall=3, gb_free=13, wall=2385
2023-03-15 14:39:31 - progress_bar.py[line:272] - INFO: epoch 004:   1050 / 2004 loss=0.985, loss_v1=0, loss_v2=0, nll_loss=0.985, ntokens=373.4, nsentences=8, sample_size=373.4, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=1086.2, ups=2.91, wpb=373.4, bsz=8, num_updates=7020, lr=9.39333e-05, gnorm=2.033, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=2389
2023-03-15 14:39:34 - progress_bar.py[line:272] - INFO: epoch 004:   1060 / 2004 loss=0.979, loss_v1=0, loss_v2=0, nll_loss=0.979, ntokens=347.8, nsentences=8, sample_size=347.8, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=1022, ups=2.94, wpb=347.8, bsz=8, num_updates=7030, lr=9.39233e-05, gnorm=2.063, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=2392
2023-03-15 14:39:38 - progress_bar.py[line:272] - INFO: epoch 004:   1070 / 2004 loss=1.079, loss_v1=0, loss_v2=0, nll_loss=1.079, ntokens=342.8, nsentences=8, sample_size=342.8, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1000.3, ups=2.92, wpb=342.8, bsz=8, num_updates=7040, lr=9.39132e-05, gnorm=2.18, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=2396
2023-03-15 14:39:41 - progress_bar.py[line:272] - INFO: epoch 004:   1080 / 2004 loss=0.931, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=359.4, nsentences=8, sample_size=359.4, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=1055.8, ups=2.94, wpb=359.4, bsz=8, num_updates=7050, lr=9.39031e-05, gnorm=2.109, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=2399
2023-03-15 14:39:45 - progress_bar.py[line:272] - INFO: epoch 004:   1090 / 2004 loss=1.092, loss_v1=0, loss_v2=0, nll_loss=1.092, ntokens=359.7, nsentences=8, sample_size=359.7, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1038, ups=2.89, wpb=359.7, bsz=8, num_updates=7060, lr=9.3893e-05, gnorm=2.176, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=2402
2023-03-15 14:39:48 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 14:39:49 - progress_bar.py[line:272] - INFO: epoch 004:   1101 / 2004 loss=1.026, loss_v1=0, loss_v2=0, nll_loss=1.026, ntokens=337.8, nsentences=8, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=903.3, ups=2.67, wpb=337.8, bsz=8, num_updates=7070, lr=9.38829e-05, gnorm=2.176, clip=0, loss_scale=2048, train_wall=4, gb_free=15.1, wall=2406
2023-03-15 14:39:52 - progress_bar.py[line:272] - INFO: epoch 004:   1111 / 2004 loss=1.032, loss_v1=0, loss_v2=0, nll_loss=1.032, ntokens=373, nsentences=8, sample_size=373, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=1101.8, ups=2.95, wpb=373, bsz=8, num_updates=7080, lr=9.38729e-05, gnorm=2.058, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=2410
2023-03-15 14:39:55 - progress_bar.py[line:272] - INFO: epoch 004:   1121 / 2004 loss=0.842, loss_v1=0, loss_v2=0, nll_loss=0.842, ntokens=314, nsentences=8, sample_size=314, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=937.1, ups=2.98, wpb=314, bsz=8, num_updates=7090, lr=9.38628e-05, gnorm=1.981, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=2413
2023-03-15 14:39:59 - progress_bar.py[line:272] - INFO: epoch 004:   1131 / 2004 loss=1.002, loss_v1=0, loss_v2=0, nll_loss=1.002, ntokens=370.8, nsentences=8, sample_size=370.8, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=1110.6, ups=3, wpb=370.8, bsz=8, num_updates=7100, lr=9.38527e-05, gnorm=2.051, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=2416
2023-03-15 14:40:02 - progress_bar.py[line:272] - INFO: epoch 004:   1141 / 2004 loss=0.99, loss_v1=0, loss_v2=0, nll_loss=0.99, ntokens=362.1, nsentences=8, sample_size=362.1, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=1035, ups=2.86, wpb=362.1, bsz=8, num_updates=7110, lr=9.38426e-05, gnorm=2.107, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=2420
2023-03-15 14:40:05 - progress_bar.py[line:272] - INFO: epoch 004:   1151 / 2004 loss=0.929, loss_v1=0, loss_v2=0, nll_loss=0.929, ntokens=365.2, nsentences=8, sample_size=365.2, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=1096.6, ups=3, wpb=365.2, bsz=8, num_updates=7120, lr=9.38325e-05, gnorm=1.975, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=2423
2023-03-15 14:40:09 - progress_bar.py[line:272] - INFO: epoch 004:   1161 / 2004 loss=0.995, loss_v1=0, loss_v2=0, nll_loss=0.995, ntokens=385.8, nsentences=8, sample_size=385.8, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=1114, ups=2.89, wpb=385.8, bsz=8, num_updates=7130, lr=9.38225e-05, gnorm=2.04, clip=0, loss_scale=2048, train_wall=3, gb_free=15.8, wall=2427
2023-03-15 14:40:12 - progress_bar.py[line:272] - INFO: epoch 004:   1171 / 2004 loss=0.977, loss_v1=0, loss_v2=0, nll_loss=0.977, ntokens=346.1, nsentences=8, sample_size=346.1, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=997.2, ups=2.88, wpb=346.1, bsz=8, num_updates=7140, lr=9.38124e-05, gnorm=2.09, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=2430
2023-03-15 14:40:16 - progress_bar.py[line:272] - INFO: epoch 004:   1181 / 2004 loss=0.903, loss_v1=0, loss_v2=0, nll_loss=0.903, ntokens=347.7, nsentences=8, sample_size=347.7, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=1024.1, ups=2.95, wpb=347.7, bsz=8, num_updates=7150, lr=9.38023e-05, gnorm=2.032, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=2433
2023-03-15 14:40:19 - progress_bar.py[line:272] - INFO: epoch 004:   1191 / 2004 loss=0.84, loss_v1=0, loss_v2=0, nll_loss=0.84, ntokens=339.3, nsentences=8, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=985.2, ups=2.9, wpb=339.3, bsz=8, num_updates=7160, lr=9.37922e-05, gnorm=1.981, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=2437
2023-03-15 14:40:23 - progress_bar.py[line:272] - INFO: epoch 004:   1201 / 2004 loss=0.994, loss_v1=0, loss_v2=0, nll_loss=0.994, ntokens=349.8, nsentences=8, sample_size=349.8, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=1031.4, ups=2.95, wpb=349.8, bsz=8, num_updates=7170, lr=9.37821e-05, gnorm=2.152, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=2440
2023-03-15 14:40:26 - progress_bar.py[line:272] - INFO: epoch 004:   1211 / 2004 loss=0.964, loss_v1=0, loss_v2=0, nll_loss=0.964, ntokens=282.4, nsentences=8, sample_size=282.4, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=839.9, ups=2.97, wpb=282.4, bsz=8, num_updates=7180, lr=9.37721e-05, gnorm=2.236, clip=0, loss_scale=2048, train_wall=3, gb_free=15.8, wall=2444
2023-03-15 14:40:29 - progress_bar.py[line:272] - INFO: epoch 004:   1221 / 2004 loss=0.932, loss_v1=0, loss_v2=0, nll_loss=0.932, ntokens=331.6, nsentences=8, sample_size=331.6, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=979.9, ups=2.96, wpb=331.6, bsz=8, num_updates=7190, lr=9.3762e-05, gnorm=2.125, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=2447
2023-03-15 14:40:32 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 14:40:33 - progress_bar.py[line:272] - INFO: epoch 004:   1232 / 2004 loss=0.827, loss_v1=0, loss_v2=0, nll_loss=0.827, ntokens=300.7, nsentences=8, sample_size=300.7, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=799.2, ups=2.66, wpb=300.7, bsz=8, num_updates=7200, lr=9.37519e-05, gnorm=2.164, clip=0, loss_scale=2048, train_wall=4, gb_free=13.6, wall=2451
2023-03-15 14:40:37 - progress_bar.py[line:272] - INFO: epoch 004:   1242 / 2004 loss=1.067, loss_v1=0, loss_v2=0, nll_loss=1.067, ntokens=390.3, nsentences=8, sample_size=390.3, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=1111, ups=2.85, wpb=390.3, bsz=8, num_updates=7210, lr=9.37418e-05, gnorm=2.108, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=2454
2023-03-15 14:40:40 - progress_bar.py[line:272] - INFO: epoch 004:   1252 / 2004 loss=0.961, loss_v1=0, loss_v2=0, nll_loss=0.961, ntokens=345, nsentences=8, sample_size=345, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=1021.5, ups=2.96, wpb=345, bsz=8, num_updates=7220, lr=9.37317e-05, gnorm=2.169, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=2458
2023-03-15 14:40:43 - progress_bar.py[line:272] - INFO: epoch 004:   1262 / 2004 loss=0.993, loss_v1=0, loss_v2=0, nll_loss=0.993, ntokens=343.6, nsentences=8, sample_size=343.6, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=1028.7, ups=2.99, wpb=343.6, bsz=8, num_updates=7230, lr=9.37216e-05, gnorm=2.165, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=2461
2023-03-15 14:40:47 - progress_bar.py[line:272] - INFO: epoch 004:   1272 / 2004 loss=0.987, loss_v1=0, loss_v2=0, nll_loss=0.987, ntokens=348.7, nsentences=8, sample_size=348.7, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=1022.9, ups=2.93, wpb=348.7, bsz=8, num_updates=7240, lr=9.37116e-05, gnorm=2.079, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=2464
2023-03-15 14:40:50 - progress_bar.py[line:272] - INFO: epoch 004:   1282 / 2004 loss=0.928, loss_v1=0, loss_v2=0, nll_loss=0.928, ntokens=327.8, nsentences=8, sample_size=327.8, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=975.1, ups=2.97, wpb=327.8, bsz=8, num_updates=7250, lr=9.37015e-05, gnorm=2.167, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=2468
2023-03-15 14:40:53 - progress_bar.py[line:272] - INFO: epoch 004:   1292 / 2004 loss=0.774, loss_v1=0, loss_v2=0, nll_loss=0.774, ntokens=312.9, nsentences=8, sample_size=312.9, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=978.2, ups=3.13, wpb=312.9, bsz=8, num_updates=7260, lr=9.36914e-05, gnorm=1.975, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=2471
2023-03-15 14:40:57 - progress_bar.py[line:272] - INFO: epoch 004:   1302 / 2004 loss=1.023, loss_v1=0, loss_v2=0, nll_loss=1.023, ntokens=314.8, nsentences=8, sample_size=314.8, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=963.3, ups=3.06, wpb=314.8, bsz=8, num_updates=7270, lr=9.36813e-05, gnorm=2.229, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=2474
2023-03-15 14:41:00 - progress_bar.py[line:272] - INFO: epoch 004:   1312 / 2004 loss=0.968, loss_v1=0, loss_v2=0, nll_loss=0.968, ntokens=337.2, nsentences=8, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=1030.8, ups=3.06, wpb=337.2, bsz=8, num_updates=7280, lr=9.36712e-05, gnorm=2.071, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=2477
2023-03-15 14:41:03 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 14:41:04 - progress_bar.py[line:272] - INFO: epoch 004:   1323 / 2004 loss=1.016, loss_v1=0, loss_v2=0, nll_loss=1.016, ntokens=326.9, nsentences=8, sample_size=326.9, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=895.9, ups=2.74, wpb=326.9, bsz=8, num_updates=7290, lr=9.36612e-05, gnorm=2.199, clip=0, loss_scale=1024, train_wall=4, gb_free=15.3, wall=2481
2023-03-15 14:41:07 - progress_bar.py[line:272] - INFO: epoch 004:   1333 / 2004 loss=1.08, loss_v1=0, loss_v2=0, nll_loss=1.08, ntokens=333.2, nsentences=8, sample_size=333.2, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=993.4, ups=2.98, wpb=333.2, bsz=8, num_updates=7300, lr=9.36511e-05, gnorm=2.256, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=2484
2023-03-15 14:41:10 - progress_bar.py[line:272] - INFO: epoch 004:   1343 / 2004 loss=0.957, loss_v1=0, loss_v2=0, nll_loss=0.957, ntokens=321, nsentences=8, sample_size=321, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=947.8, ups=2.95, wpb=321, bsz=8, num_updates=7310, lr=9.3641e-05, gnorm=2.184, clip=0, loss_scale=1024, train_wall=3, gb_free=14.2, wall=2488
2023-03-15 14:41:14 - progress_bar.py[line:272] - INFO: epoch 004:   1353 / 2004 loss=1.036, loss_v1=0, loss_v2=0, nll_loss=1.036, ntokens=313, nsentences=8, sample_size=313, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=947.8, ups=3.03, wpb=313, bsz=8, num_updates=7320, lr=9.36309e-05, gnorm=2.305, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=2491
2023-03-15 14:41:17 - progress_bar.py[line:272] - INFO: epoch 004:   1363 / 2004 loss=0.992, loss_v1=0, loss_v2=0, nll_loss=0.992, ntokens=326.8, nsentences=8, sample_size=326.8, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=1001.2, ups=3.06, wpb=326.8, bsz=8, num_updates=7330, lr=9.36208e-05, gnorm=2.183, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=2494
2023-03-15 14:41:20 - progress_bar.py[line:272] - INFO: epoch 004:   1373 / 2004 loss=0.921, loss_v1=0, loss_v2=0, nll_loss=0.921, ntokens=299.6, nsentences=8, sample_size=299.6, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=901.8, ups=3.01, wpb=299.6, bsz=8, num_updates=7340, lr=9.36108e-05, gnorm=2.218, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=2498
2023-03-15 14:41:24 - progress_bar.py[line:272] - INFO: epoch 004:   1383 / 2004 loss=1.043, loss_v1=0, loss_v2=0, nll_loss=1.043, ntokens=384.6, nsentences=8, sample_size=384.6, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=1076.5, ups=2.8, wpb=384.6, bsz=8, num_updates=7350, lr=9.36007e-05, gnorm=2.127, clip=0, loss_scale=1024, train_wall=4, gb_free=14.9, wall=2501
2023-03-15 14:41:27 - progress_bar.py[line:272] - INFO: epoch 004:   1393 / 2004 loss=0.879, loss_v1=0, loss_v2=0, nll_loss=0.879, ntokens=362.5, nsentences=8, sample_size=362.5, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=1079.8, ups=2.98, wpb=362.5, bsz=8, num_updates=7360, lr=9.35906e-05, gnorm=1.969, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=2505
2023-03-15 14:41:31 - progress_bar.py[line:272] - INFO: epoch 004:   1403 / 2004 loss=0.872, loss_v1=0, loss_v2=0, nll_loss=0.872, ntokens=337.1, nsentences=8, sample_size=337.1, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=981.7, ups=2.91, wpb=337.1, bsz=8, num_updates=7370, lr=9.35805e-05, gnorm=2.05, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=2508
2023-03-15 14:41:34 - progress_bar.py[line:272] - INFO: epoch 004:   1413 / 2004 loss=1.072, loss_v1=0, loss_v2=0, nll_loss=1.072, ntokens=378.6, nsentences=8, sample_size=378.6, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=1124.8, ups=2.97, wpb=378.6, bsz=8, num_updates=7380, lr=9.35704e-05, gnorm=2.127, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=2511
2023-03-15 14:41:37 - progress_bar.py[line:272] - INFO: epoch 004:   1423 / 2004 loss=0.914, loss_v1=0, loss_v2=0, nll_loss=0.914, ntokens=317.9, nsentences=8, sample_size=317.9, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=984.3, ups=3.1, wpb=317.9, bsz=8, num_updates=7390, lr=9.35604e-05, gnorm=2.082, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=2515
2023-03-15 14:41:40 - progress_bar.py[line:272] - INFO: epoch 004:   1433 / 2004 loss=1.001, loss_v1=0, loss_v2=0, nll_loss=1.001, ntokens=347.9, nsentences=8, sample_size=347.9, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=1035.6, ups=2.98, wpb=347.9, bsz=8, num_updates=7400, lr=9.35503e-05, gnorm=2.135, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=2518
2023-03-15 14:41:44 - progress_bar.py[line:272] - INFO: epoch 004:   1443 / 2004 loss=1.021, loss_v1=0, loss_v2=0, nll_loss=1.021, ntokens=340.6, nsentences=8, sample_size=340.6, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=1003.2, ups=2.95, wpb=340.6, bsz=8, num_updates=7410, lr=9.35402e-05, gnorm=2.207, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=2521
2023-03-15 14:41:47 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 14:41:48 - progress_bar.py[line:272] - INFO: epoch 004:   1454 / 2004 loss=0.981, loss_v1=0, loss_v2=0, nll_loss=0.981, ntokens=339.6, nsentences=8, sample_size=339.6, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=917.4, ups=2.7, wpb=339.6, bsz=8, num_updates=7420, lr=9.35301e-05, gnorm=2.162, clip=0, loss_scale=1024, train_wall=4, gb_free=13.6, wall=2525
2023-03-15 14:41:51 - progress_bar.py[line:272] - INFO: epoch 004:   1464 / 2004 loss=1.037, loss_v1=0, loss_v2=0, nll_loss=1.037, ntokens=386, nsentences=8, sample_size=386, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=1120.5, ups=2.9, wpb=386, bsz=8, num_updates=7430, lr=9.352e-05, gnorm=2.082, clip=0, loss_scale=1024, train_wall=3, gb_free=14, wall=2529
2023-03-15 14:41:54 - progress_bar.py[line:272] - INFO: epoch 004:   1474 / 2004 loss=1.008, loss_v1=0, loss_v2=0, nll_loss=1.008, ntokens=398.2, nsentences=8, sample_size=398.2, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=1185.3, ups=2.98, wpb=398.2, bsz=8, num_updates=7440, lr=9.35099e-05, gnorm=2.057, clip=0, loss_scale=1024, train_wall=3, gb_free=13.5, wall=2532
2023-03-15 14:41:58 - progress_bar.py[line:272] - INFO: epoch 004:   1484 / 2004 loss=0.95, loss_v1=0, loss_v2=0, nll_loss=0.95, ntokens=372.5, nsentences=8, sample_size=372.5, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=1089.2, ups=2.92, wpb=372.5, bsz=8, num_updates=7450, lr=9.34999e-05, gnorm=2.074, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=2535
2023-03-15 14:42:01 - progress_bar.py[line:272] - INFO: epoch 004:   1494 / 2004 loss=0.98, loss_v1=0, loss_v2=0, nll_loss=0.98, ntokens=317.1, nsentences=8, sample_size=317.1, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=933.2, ups=2.94, wpb=317.1, bsz=8, num_updates=7460, lr=9.34898e-05, gnorm=2.26, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=2539
2023-03-15 14:42:05 - progress_bar.py[line:272] - INFO: epoch 004:   1504 / 2004 loss=0.989, loss_v1=0, loss_v2=0, nll_loss=0.989, ntokens=336.8, nsentences=8, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=1003.2, ups=2.98, wpb=336.8, bsz=8, num_updates=7470, lr=9.34797e-05, gnorm=2.179, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=2542
2023-03-15 14:42:08 - progress_bar.py[line:272] - INFO: epoch 004:   1514 / 2004 loss=0.892, loss_v1=0, loss_v2=0, nll_loss=0.892, ntokens=323.5, nsentences=8, sample_size=323.5, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=959.5, ups=2.97, wpb=323.5, bsz=8, num_updates=7480, lr=9.34696e-05, gnorm=2.104, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=2546
2023-03-15 14:42:11 - progress_bar.py[line:272] - INFO: epoch 004:   1524 / 2004 loss=0.918, loss_v1=0, loss_v2=0, nll_loss=0.918, ntokens=321.5, nsentences=8, sample_size=321.5, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=967.1, ups=3.01, wpb=321.5, bsz=8, num_updates=7490, lr=9.34595e-05, gnorm=2.213, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=2549
2023-03-15 14:42:15 - progress_bar.py[line:272] - INFO: epoch 004:   1534 / 2004 loss=0.982, loss_v1=0, loss_v2=0, nll_loss=0.982, ntokens=354.4, nsentences=8, sample_size=354.4, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=1036.6, ups=2.92, wpb=354.4, bsz=8, num_updates=7500, lr=9.34495e-05, gnorm=2.107, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=2552
2023-03-15 14:42:18 - progress_bar.py[line:272] - INFO: epoch 004:   1544 / 2004 loss=0.918, loss_v1=0, loss_v2=0, nll_loss=0.918, ntokens=325.5, nsentences=8, sample_size=325.5, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=956.7, ups=2.94, wpb=325.5, bsz=8, num_updates=7510, lr=9.34394e-05, gnorm=2.171, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=2556
2023-03-15 14:42:21 - progress_bar.py[line:272] - INFO: epoch 004:   1554 / 2004 loss=0.983, loss_v1=0, loss_v2=0, nll_loss=0.983, ntokens=330.8, nsentences=8, sample_size=330.8, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=963.5, ups=2.91, wpb=330.8, bsz=8, num_updates=7520, lr=9.34293e-05, gnorm=2.081, clip=0, loss_scale=1024, train_wall=3, gb_free=14.2, wall=2559
2023-03-15 14:42:25 - progress_bar.py[line:272] - INFO: epoch 004:   1564 / 2004 loss=0.87, loss_v1=0, loss_v2=0, nll_loss=0.87, ntokens=361.7, nsentences=8, sample_size=361.7, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=1054.9, ups=2.92, wpb=361.7, bsz=8, num_updates=7530, lr=9.34192e-05, gnorm=2.07, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=2563
2023-03-15 14:42:28 - progress_bar.py[line:272] - INFO: epoch 004:   1574 / 2004 loss=0.968, loss_v1=0, loss_v2=0, nll_loss=0.968, ntokens=332.8, nsentences=8, sample_size=332.8, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=970.2, ups=2.92, wpb=332.8, bsz=8, num_updates=7540, lr=9.34091e-05, gnorm=2.191, clip=0, loss_scale=1024, train_wall=3, gb_free=14.1, wall=2566
2023-03-15 14:42:32 - progress_bar.py[line:272] - INFO: epoch 004:   1584 / 2004 loss=0.935, loss_v1=0, loss_v2=0, nll_loss=0.935, ntokens=324.1, nsentences=8, sample_size=324.1, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=951.8, ups=2.94, wpb=324.1, bsz=8, num_updates=7550, lr=9.33991e-05, gnorm=2.152, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=2569
2023-03-15 14:42:35 - progress_bar.py[line:272] - INFO: epoch 004:   1594 / 2004 loss=0.983, loss_v1=0, loss_v2=0, nll_loss=0.983, ntokens=360, nsentences=8, sample_size=360, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=1059.3, ups=2.94, wpb=360, bsz=8, num_updates=7560, lr=9.3389e-05, gnorm=2.097, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=2573
2023-03-15 14:42:39 - progress_bar.py[line:272] - INFO: epoch 004:   1604 / 2004 loss=0.929, loss_v1=0, loss_v2=0, nll_loss=0.929, ntokens=337, nsentences=8, sample_size=337, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=1000.3, ups=2.97, wpb=337, bsz=8, num_updates=7570, lr=9.33789e-05, gnorm=2.106, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=2576
2023-03-15 14:42:42 - progress_bar.py[line:272] - INFO: epoch 004:   1614 / 2004 loss=0.94, loss_v1=0, loss_v2=0, nll_loss=0.94, ntokens=352.8, nsentences=8, sample_size=352.8, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=1034.8, ups=2.93, wpb=352.8, bsz=8, num_updates=7580, lr=9.33688e-05, gnorm=2.084, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=2580
2023-03-15 14:42:45 - progress_bar.py[line:272] - INFO: epoch 004:   1624 / 2004 loss=1.046, loss_v1=0, loss_v2=0, nll_loss=1.046, ntokens=345.8, nsentences=8, sample_size=345.8, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=1037.2, ups=3, wpb=345.8, bsz=8, num_updates=7590, lr=9.33587e-05, gnorm=2.19, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=2583
2023-03-15 14:42:49 - progress_bar.py[line:272] - INFO: epoch 004:   1634 / 2004 loss=0.975, loss_v1=0, loss_v2=0, nll_loss=0.975, ntokens=338.9, nsentences=8, sample_size=338.9, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=1013.1, ups=2.99, wpb=338.9, bsz=8, num_updates=7600, lr=9.33487e-05, gnorm=2.214, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=2586
2023-03-15 14:42:52 - progress_bar.py[line:272] - INFO: epoch 004:   1644 / 2004 loss=0.946, loss_v1=0, loss_v2=0, nll_loss=0.946, ntokens=309.4, nsentences=8, sample_size=309.4, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=912.8, ups=2.95, wpb=309.4, bsz=8, num_updates=7610, lr=9.33386e-05, gnorm=2.295, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=2590
2023-03-15 14:42:55 - progress_bar.py[line:272] - INFO: epoch 004:   1654 / 2004 loss=0.981, loss_v1=0, loss_v2=0, nll_loss=0.981, ntokens=338.6, nsentences=8, sample_size=338.6, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=982.8, ups=2.9, wpb=338.6, bsz=8, num_updates=7620, lr=9.33285e-05, gnorm=2.223, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=2593
2023-03-15 14:42:59 - progress_bar.py[line:272] - INFO: epoch 004:   1664 / 2004 loss=0.956, loss_v1=0, loss_v2=0, nll_loss=0.956, ntokens=358.4, nsentences=8, sample_size=358.4, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=1051.8, ups=2.93, wpb=358.4, bsz=8, num_updates=7630, lr=9.33184e-05, gnorm=2.189, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=2596
2023-03-15 14:43:02 - progress_bar.py[line:272] - INFO: epoch 004:   1674 / 2004 loss=1.038, loss_v1=0, loss_v2=0, nll_loss=1.038, ntokens=316.3, nsentences=8, sample_size=316.3, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=963.6, ups=3.05, wpb=316.3, bsz=8, num_updates=7640, lr=9.33083e-05, gnorm=2.33, clip=0, loss_scale=2048, train_wall=3, gb_free=15.9, wall=2600
2023-03-15 14:43:06 - progress_bar.py[line:272] - INFO: epoch 004:   1684 / 2004 loss=0.967, loss_v1=0, loss_v2=0, nll_loss=0.967, ntokens=349.4, nsentences=8, sample_size=349.4, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=1032.6, ups=2.96, wpb=349.4, bsz=8, num_updates=7650, lr=9.32983e-05, gnorm=2.153, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=2603
2023-03-15 14:43:09 - progress_bar.py[line:272] - INFO: epoch 004:   1694 / 2004 loss=0.979, loss_v1=0, loss_v2=0, nll_loss=0.979, ntokens=338.3, nsentences=8, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=990.8, ups=2.93, wpb=338.3, bsz=8, num_updates=7660, lr=9.32882e-05, gnorm=2.225, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=2607
2023-03-15 14:43:12 - progress_bar.py[line:272] - INFO: epoch 004:   1704 / 2004 loss=0.846, loss_v1=0, loss_v2=0, nll_loss=0.846, ntokens=334.7, nsentences=8, sample_size=334.7, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=992.6, ups=2.97, wpb=334.7, bsz=8, num_updates=7670, lr=9.32781e-05, gnorm=2.054, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=2610
2023-03-15 14:43:14 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 14:43:16 - progress_bar.py[line:272] - INFO: epoch 004:   1715 / 2004 loss=1.085, loss_v1=0, loss_v2=0, nll_loss=1.085, ntokens=357.5, nsentences=8, sample_size=357.5, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=960.2, ups=2.69, wpb=357.5, bsz=8, num_updates=7680, lr=9.3268e-05, gnorm=2.256, clip=0, loss_scale=2048, train_wall=4, gb_free=14.7, wall=2614
2023-03-15 14:43:19 - progress_bar.py[line:272] - INFO: epoch 004:   1725 / 2004 loss=0.974, loss_v1=0, loss_v2=0, nll_loss=0.974, ntokens=389.9, nsentences=8, sample_size=389.9, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=1146.3, ups=2.94, wpb=389.9, bsz=8, num_updates=7690, lr=9.32579e-05, gnorm=2.057, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=2617
2023-03-15 14:43:22 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 14:43:23 - progress_bar.py[line:272] - INFO: epoch 004:   1736 / 2004 loss=0.977, loss_v1=0, loss_v2=0, nll_loss=0.977, ntokens=361, nsentences=8, sample_size=361, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=962.8, ups=2.67, wpb=361, bsz=8, num_updates=7700, lr=9.32478e-05, gnorm=2.118, clip=0, loss_scale=1024, train_wall=4, gb_free=15.1, wall=2621
2023-03-15 14:43:27 - progress_bar.py[line:272] - INFO: epoch 004:   1746 / 2004 loss=0.915, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=341.3, nsentences=8, sample_size=341.3, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=994.3, ups=2.91, wpb=341.3, bsz=8, num_updates=7710, lr=9.32378e-05, gnorm=2.158, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=2624
2023-03-15 14:43:30 - progress_bar.py[line:272] - INFO: epoch 004:   1756 / 2004 loss=0.959, loss_v1=0, loss_v2=0, nll_loss=0.959, ntokens=328.1, nsentences=8, sample_size=328.1, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=966.9, ups=2.95, wpb=328.1, bsz=8, num_updates=7720, lr=9.32277e-05, gnorm=2.132, clip=0, loss_scale=1024, train_wall=3, gb_free=15.9, wall=2628
2023-03-15 14:43:33 - progress_bar.py[line:272] - INFO: epoch 004:   1766 / 2004 loss=1.031, loss_v1=0, loss_v2=0, nll_loss=1.031, ntokens=318.3, nsentences=8, sample_size=318.3, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=954.6, ups=3, wpb=318.3, bsz=8, num_updates=7730, lr=9.32176e-05, gnorm=2.302, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=2631
2023-03-15 14:43:37 - progress_bar.py[line:272] - INFO: epoch 004:   1776 / 2004 loss=1.008, loss_v1=0, loss_v2=0, nll_loss=1.008, ntokens=347.4, nsentences=8, sample_size=347.4, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=1026.4, ups=2.95, wpb=347.4, bsz=8, num_updates=7740, lr=9.32075e-05, gnorm=2.169, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=2634
2023-03-15 14:43:40 - progress_bar.py[line:272] - INFO: epoch 004:   1786 / 2004 loss=0.95, loss_v1=0, loss_v2=0, nll_loss=0.95, ntokens=317, nsentences=8, sample_size=317, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=932.8, ups=2.94, wpb=317, bsz=8, num_updates=7750, lr=9.31974e-05, gnorm=2.166, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=2638
2023-03-15 14:43:44 - progress_bar.py[line:272] - INFO: epoch 004:   1796 / 2004 loss=0.957, loss_v1=0, loss_v2=0, nll_loss=0.957, ntokens=337.2, nsentences=8, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=987.9, ups=2.93, wpb=337.2, bsz=8, num_updates=7760, lr=9.31874e-05, gnorm=2.136, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=2641
2023-03-15 14:43:47 - progress_bar.py[line:272] - INFO: epoch 004:   1806 / 2004 loss=1.09, loss_v1=0, loss_v2=0, nll_loss=1.09, ntokens=345.6, nsentences=8, sample_size=345.6, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=995.3, ups=2.88, wpb=345.6, bsz=8, num_updates=7770, lr=9.31773e-05, gnorm=2.345, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=2645
2023-03-15 14:43:50 - progress_bar.py[line:272] - INFO: epoch 004:   1816 / 2004 loss=0.938, loss_v1=0, loss_v2=0, nll_loss=0.938, ntokens=347.7, nsentences=8, sample_size=347.7, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=1021.1, ups=2.94, wpb=347.7, bsz=8, num_updates=7780, lr=9.31672e-05, gnorm=2.167, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=2648
2023-03-15 14:43:54 - progress_bar.py[line:272] - INFO: epoch 004:   1826 / 2004 loss=0.895, loss_v1=0, loss_v2=0, nll_loss=0.895, ntokens=365.7, nsentences=8, sample_size=365.7, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=1053.4, ups=2.88, wpb=365.7, bsz=8, num_updates=7790, lr=9.31571e-05, gnorm=2.055, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=2652
2023-03-15 14:43:57 - progress_bar.py[line:272] - INFO: epoch 004:   1836 / 2004 loss=0.929, loss_v1=0, loss_v2=0, nll_loss=0.929, ntokens=327.2, nsentences=8, sample_size=327.2, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=969.9, ups=2.96, wpb=327.2, bsz=8, num_updates=7800, lr=9.3147e-05, gnorm=2.136, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=2655
2023-03-15 14:44:01 - progress_bar.py[line:272] - INFO: epoch 004:   1846 / 2004 loss=0.966, loss_v1=0, loss_v2=0, nll_loss=0.966, ntokens=360.5, nsentences=8, sample_size=360.5, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=1077.5, ups=2.99, wpb=360.5, bsz=8, num_updates=7810, lr=9.3137e-05, gnorm=2.149, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=2658
2023-03-15 14:44:04 - progress_bar.py[line:272] - INFO: epoch 004:   1856 / 2004 loss=0.926, loss_v1=0, loss_v2=0, nll_loss=0.926, ntokens=312.9, nsentences=8, sample_size=312.9, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=910.2, ups=2.91, wpb=312.9, bsz=8, num_updates=7820, lr=9.31269e-05, gnorm=2.186, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=2662
2023-03-15 14:44:07 - progress_bar.py[line:272] - INFO: epoch 004:   1866 / 2004 loss=0.942, loss_v1=0, loss_v2=0, nll_loss=0.942, ntokens=343.7, nsentences=8, sample_size=343.7, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=1005.3, ups=2.93, wpb=343.7, bsz=8, num_updates=7830, lr=9.31168e-05, gnorm=2.095, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=2665
2023-03-15 14:44:11 - progress_bar.py[line:272] - INFO: epoch 004:   1876 / 2004 loss=0.918, loss_v1=0, loss_v2=0, nll_loss=0.918, ntokens=337.8, nsentences=8, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=1002.5, ups=2.97, wpb=337.8, bsz=8, num_updates=7840, lr=9.31067e-05, gnorm=2.143, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=2668
2023-03-15 14:44:14 - progress_bar.py[line:272] - INFO: epoch 004:   1886 / 2004 loss=0.909, loss_v1=0, loss_v2=0, nll_loss=0.909, ntokens=324, nsentences=8, sample_size=324, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=964.9, ups=2.98, wpb=324, bsz=8, num_updates=7850, lr=9.30966e-05, gnorm=2.122, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=2672
2023-03-15 14:44:18 - progress_bar.py[line:272] - INFO: epoch 004:   1896 / 2004 loss=0.961, loss_v1=0, loss_v2=0, nll_loss=0.961, ntokens=336.9, nsentences=8, sample_size=336.9, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=990.6, ups=2.94, wpb=336.9, bsz=8, num_updates=7860, lr=9.30866e-05, gnorm=2.194, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=2675
2023-03-15 14:44:21 - progress_bar.py[line:272] - INFO: epoch 004:   1906 / 2004 loss=0.869, loss_v1=0, loss_v2=0, nll_loss=0.869, ntokens=348.4, nsentences=8, sample_size=348.4, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=1041.3, ups=2.99, wpb=348.4, bsz=8, num_updates=7870, lr=9.30765e-05, gnorm=2.086, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=2679
2023-03-15 14:44:24 - progress_bar.py[line:272] - INFO: epoch 004:   1916 / 2004 loss=0.892, loss_v1=0, loss_v2=0, nll_loss=0.892, ntokens=327.7, nsentences=8, sample_size=327.7, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=1007.8, ups=3.08, wpb=327.7, bsz=8, num_updates=7880, lr=9.30664e-05, gnorm=2.169, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=2682
2023-03-15 14:44:27 - progress_bar.py[line:272] - INFO: epoch 004:   1926 / 2004 loss=0.894, loss_v1=0, loss_v2=0, nll_loss=0.894, ntokens=325.2, nsentences=8, sample_size=325.2, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=1067.1, ups=3.28, wpb=325.2, bsz=8, num_updates=7890, lr=9.30563e-05, gnorm=2.124, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=2685
2023-03-15 14:44:31 - progress_bar.py[line:272] - INFO: epoch 004:   1936 / 2004 loss=0.858, loss_v1=0, loss_v2=0, nll_loss=0.858, ntokens=336.4, nsentences=8, sample_size=336.4, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=1022, ups=3.04, wpb=336.4, bsz=8, num_updates=7900, lr=9.30462e-05, gnorm=2.127, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=2688
2023-03-15 14:44:34 - progress_bar.py[line:272] - INFO: epoch 004:   1946 / 2004 loss=0.968, loss_v1=0, loss_v2=0, nll_loss=0.968, ntokens=358.9, nsentences=8, sample_size=358.9, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=1153, ups=3.21, wpb=358.9, bsz=8, num_updates=7910, lr=9.30361e-05, gnorm=2.154, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=2691
2023-03-15 14:44:37 - progress_bar.py[line:272] - INFO: epoch 004:   1956 / 2004 loss=0.839, loss_v1=0, loss_v2=0, nll_loss=0.839, ntokens=348, nsentences=8, sample_size=348, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=1108.7, ups=3.19, wpb=348, bsz=8, num_updates=7920, lr=9.30261e-05, gnorm=2.08, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=2694
2023-03-15 14:44:40 - progress_bar.py[line:272] - INFO: epoch 004:   1966 / 2004 loss=0.888, loss_v1=0, loss_v2=0, nll_loss=0.888, ntokens=356.9, nsentences=8, sample_size=356.9, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=1161.8, ups=3.26, wpb=356.9, bsz=8, num_updates=7930, lr=9.3016e-05, gnorm=2.042, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=2697
2023-03-15 14:44:43 - progress_bar.py[line:272] - INFO: epoch 004:   1976 / 2004 loss=0.922, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=340.3, nsentences=8, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=1119.5, ups=3.29, wpb=340.3, bsz=8, num_updates=7940, lr=9.30059e-05, gnorm=2.188, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=2701
2023-03-15 14:44:46 - progress_bar.py[line:272] - INFO: epoch 004:   1986 / 2004 loss=0.875, loss_v1=0, loss_v2=0, nll_loss=0.875, ntokens=311.3, nsentences=8, sample_size=311.3, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=996.8, ups=3.2, wpb=311.3, bsz=8, num_updates=7950, lr=9.29958e-05, gnorm=2.17, clip=0, loss_scale=2048, train_wall=3, gb_free=13.5, wall=2704
2023-03-15 14:44:49 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 14:44:49 - progress_bar.py[line:272] - INFO: epoch 004:   1997 / 2004 loss=0.961, loss_v1=0, loss_v2=0, nll_loss=0.961, ntokens=401.5, nsentences=8, sample_size=401.5, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=1184.9, ups=2.95, wpb=401.5, bsz=8, num_updates=7960, lr=9.29857e-05, gnorm=2.05, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=2707
2023-03-15 14:44:52 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 4 @ 7967 updates
2023-03-15 14:44:52 - trainer.py[line:431] - INFO: Saving checkpoint to ./checkpoints/checkpoint4.pt
2023-03-15 14:44:56 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./checkpoints/checkpoint4.pt
2023-03-15 14:44:58 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./checkpoints/checkpoint4.pt (epoch 4 @ 7967 updates, score None) (writing took 6.578621091321111 seconds)
2023-03-15 14:44:58 - train.py[line:332] - INFO: end of epoch 4 (average epoch stats below)
2023-03-15 14:44:58 - progress_bar.py[line:282] - INFO: epoch 004 | loss 0.991 | loss_v1 0 | loss_v2 0 | nll_loss 0.991 | ntokens 345.245 | nsentences 7.999 | sample_size 345.245 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.99 | wps 991.6 | ups 2.87 | wpb 345.2 | bsz 8 | num_updates 7967 | lr 9.29787e-05 | gnorm 2.103 | clip 0 | loss_scale 2048 | train_wall 666 | gb_free 13.9 | wall 2716
2023-03-15 14:44:58 - trainer.py[line:639] - INFO: loading train data for epoch 5
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 row count 8015 total row count 8015
slice_id 0 seek offset 0
2023-03-15 14:44:59 - trainer.py[line:703] - INFO: begin training epoch 5
2023-03-15 14:44:59 - train.py[line:305] - INFO: Start iterating over samples
2023-03-15 14:45:00 - progress_bar.py[line:272] - INFO: epoch 005:      3 / 2004 loss=0.988, loss_v1=0, loss_v2=0, nll_loss=0.988, ntokens=360.7, nsentences=8, sample_size=360.7, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=342.2, ups=0.95, wpb=360.7, bsz=8, num_updates=7970, lr=9.29757e-05, gnorm=2.178, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=2718
2023-03-15 14:45:03 - progress_bar.py[line:272] - INFO: epoch 005:     13 / 2004 loss=0.95, loss_v1=0, loss_v2=0, nll_loss=0.95, ntokens=327, nsentences=8, sample_size=327, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=1039.4, ups=3.18, wpb=327, bsz=8, num_updates=7980, lr=9.29656e-05, gnorm=2.173, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=2721
2023-03-15 14:45:07 - progress_bar.py[line:272] - INFO: epoch 005:     23 / 2004 loss=0.962, loss_v1=0, loss_v2=0, nll_loss=0.962, ntokens=357.1, nsentences=8, sample_size=357.1, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=1037.4, ups=2.91, wpb=357.1, bsz=8, num_updates=7990, lr=9.29555e-05, gnorm=2.138, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=2724
2023-03-15 14:45:09 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 14:45:10 - progress_bar.py[line:272] - INFO: epoch 005:     34 / 2004 loss=0.982, loss_v1=0, loss_v2=0, nll_loss=0.982, ntokens=357.4, nsentences=8, sample_size=357.4, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=949, ups=2.66, wpb=357.4, bsz=8, num_updates=8000, lr=9.29454e-05, gnorm=2.22, clip=0, loss_scale=1024, train_wall=4, gb_free=14.6, wall=2728
2023-03-15 14:45:14 - progress_bar.py[line:272] - INFO: epoch 005:     44 / 2004 loss=0.951, loss_v1=0, loss_v2=0, nll_loss=0.951, ntokens=354.6, nsentences=8, sample_size=354.6, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=1041.3, ups=2.94, wpb=354.6, bsz=8, num_updates=8010, lr=9.29353e-05, gnorm=2.19, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=2731
2023-03-15 14:45:17 - progress_bar.py[line:272] - INFO: epoch 005:     54 / 2004 loss=0.923, loss_v1=0, loss_v2=0, nll_loss=0.923, ntokens=351.6, nsentences=8, sample_size=351.6, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=1012.1, ups=2.88, wpb=351.6, bsz=8, num_updates=8020, lr=9.29253e-05, gnorm=2.106, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=2735
2023-03-15 14:45:20 - progress_bar.py[line:272] - INFO: epoch 005:     64 / 2004 loss=0.953, loss_v1=0, loss_v2=0, nll_loss=0.953, ntokens=320.8, nsentences=8, sample_size=320.8, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=1033.1, ups=3.22, wpb=320.8, bsz=8, num_updates=8030, lr=9.29152e-05, gnorm=2.28, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=2738
2023-03-15 14:45:23 - progress_bar.py[line:272] - INFO: epoch 005:     74 / 2004 loss=0.967, loss_v1=0, loss_v2=0, nll_loss=0.967, ntokens=359.2, nsentences=8, sample_size=359.2, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=1155.3, ups=3.22, wpb=359.2, bsz=8, num_updates=8040, lr=9.29051e-05, gnorm=2.136, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=2741
2023-03-15 14:45:27 - progress_bar.py[line:272] - INFO: epoch 005:     84 / 2004 loss=0.911, loss_v1=0, loss_v2=0, nll_loss=0.911, ntokens=335.3, nsentences=8, sample_size=335.3, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=1026.4, ups=3.06, wpb=335.3, bsz=8, num_updates=8050, lr=9.2895e-05, gnorm=2.166, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=2744
2023-03-15 14:45:30 - progress_bar.py[line:272] - INFO: epoch 005:     94 / 2004 loss=1.019, loss_v1=0, loss_v2=0, nll_loss=1.019, ntokens=369.4, nsentences=8, sample_size=369.4, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=1079.6, ups=2.92, wpb=369.4, bsz=8, num_updates=8060, lr=9.28849e-05, gnorm=2.139, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=2748
2023-03-15 14:45:34 - progress_bar.py[line:272] - INFO: epoch 005:    104 / 2004 loss=0.898, loss_v1=0, loss_v2=0, nll_loss=0.898, ntokens=374.2, nsentences=8, sample_size=374.2, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=1088.7, ups=2.91, wpb=374.2, bsz=8, num_updates=8070, lr=9.28749e-05, gnorm=2.117, clip=0, loss_scale=1024, train_wall=3, gb_free=13.7, wall=2751
2023-03-15 14:45:37 - progress_bar.py[line:272] - INFO: epoch 005:    114 / 2004 loss=0.97, loss_v1=0, loss_v2=0, nll_loss=0.97, ntokens=326.5, nsentences=8, sample_size=326.5, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=978.5, ups=3, wpb=326.5, bsz=8, num_updates=8080, lr=9.28648e-05, gnorm=2.229, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=2754
2023-03-15 14:45:40 - progress_bar.py[line:272] - INFO: epoch 005:    124 / 2004 loss=1.029, loss_v1=0, loss_v2=0, nll_loss=1.029, ntokens=351.1, nsentences=8, sample_size=351.1, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=1046, ups=2.98, wpb=351.1, bsz=8, num_updates=8090, lr=9.28547e-05, gnorm=2.179, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=2758
2023-03-15 14:45:44 - progress_bar.py[line:272] - INFO: epoch 005:    134 / 2004 loss=0.86, loss_v1=0, loss_v2=0, nll_loss=0.86, ntokens=316.3, nsentences=8, sample_size=316.3, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=943.1, ups=2.98, wpb=316.3, bsz=8, num_updates=8100, lr=9.28446e-05, gnorm=2.193, clip=0, loss_scale=1024, train_wall=3, gb_free=14, wall=2761
2023-03-15 14:45:47 - progress_bar.py[line:272] - INFO: epoch 005:    144 / 2004 loss=0.974, loss_v1=0, loss_v2=0, nll_loss=0.974, ntokens=352.7, nsentences=8, sample_size=352.7, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=1034.5, ups=2.93, wpb=352.7, bsz=8, num_updates=8110, lr=9.28345e-05, gnorm=2.167, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=2765
2023-03-15 14:45:50 - progress_bar.py[line:272] - INFO: epoch 005:    154 / 2004 loss=0.954, loss_v1=0, loss_v2=0, nll_loss=0.954, ntokens=328.5, nsentences=8, sample_size=328.5, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=1000.9, ups=3.05, wpb=328.5, bsz=8, num_updates=8120, lr=9.28245e-05, gnorm=2.217, clip=0, loss_scale=1024, train_wall=3, gb_free=14.2, wall=2768
2023-03-15 14:45:54 - progress_bar.py[line:272] - INFO: epoch 005:    164 / 2004 loss=0.893, loss_v1=0, loss_v2=0, nll_loss=0.893, ntokens=356.8, nsentences=8, sample_size=356.8, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=1019.4, ups=2.86, wpb=356.8, bsz=8, num_updates=8130, lr=9.28144e-05, gnorm=2.053, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=2771
2023-03-15 14:45:57 - progress_bar.py[line:272] - INFO: epoch 005:    174 / 2004 loss=0.863, loss_v1=0, loss_v2=0, nll_loss=0.863, ntokens=336.7, nsentences=8, sample_size=336.7, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=985.8, ups=2.93, wpb=336.7, bsz=8, num_updates=8140, lr=9.28043e-05, gnorm=2.072, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=2775
2023-03-15 14:46:01 - progress_bar.py[line:272] - INFO: epoch 005:    184 / 2004 loss=0.869, loss_v1=0, loss_v2=0, nll_loss=0.869, ntokens=328.6, nsentences=8, sample_size=328.6, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=973.9, ups=2.96, wpb=328.6, bsz=8, num_updates=8150, lr=9.27942e-05, gnorm=2.147, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=2778
2023-03-15 14:46:04 - progress_bar.py[line:272] - INFO: epoch 005:    194 / 2004 loss=0.814, loss_v1=0, loss_v2=0, nll_loss=0.814, ntokens=334.4, nsentences=8, sample_size=334.4, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=1003.8, ups=3, wpb=334.4, bsz=8, num_updates=8160, lr=9.27841e-05, gnorm=2.059, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=2782
2023-03-15 14:46:07 - progress_bar.py[line:272] - INFO: epoch 005:    204 / 2004 loss=0.948, loss_v1=0, loss_v2=0, nll_loss=0.948, ntokens=327.4, nsentences=8, sample_size=327.4, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=972.8, ups=2.97, wpb=327.4, bsz=8, num_updates=8170, lr=9.2774e-05, gnorm=2.221, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=2785
2023-03-15 14:46:11 - progress_bar.py[line:272] - INFO: epoch 005:    214 / 2004 loss=0.884, loss_v1=0, loss_v2=0, nll_loss=0.884, ntokens=332.9, nsentences=8, sample_size=332.9, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=996.8, ups=2.99, wpb=332.9, bsz=8, num_updates=8180, lr=9.2764e-05, gnorm=2.119, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=2788
2023-03-15 14:46:14 - progress_bar.py[line:272] - INFO: epoch 005:    224 / 2004 loss=0.81, loss_v1=0, loss_v2=0, nll_loss=0.81, ntokens=330.7, nsentences=8, sample_size=330.7, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=985, ups=2.98, wpb=330.7, bsz=8, num_updates=8190, lr=9.27539e-05, gnorm=2.077, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=2792
2023-03-15 14:46:17 - progress_bar.py[line:272] - INFO: epoch 005:    234 / 2004 loss=0.923, loss_v1=0, loss_v2=0, nll_loss=0.923, ntokens=373.2, nsentences=8, sample_size=373.2, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=1081.3, ups=2.9, wpb=373.2, bsz=8, num_updates=8200, lr=9.27438e-05, gnorm=2.129, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=2795
2023-03-15 14:46:21 - progress_bar.py[line:272] - INFO: epoch 005:    244 / 2004 loss=0.95, loss_v1=0, loss_v2=0, nll_loss=0.95, ntokens=354.4, nsentences=8, sample_size=354.4, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=1042.3, ups=2.94, wpb=354.4, bsz=8, num_updates=8210, lr=9.27337e-05, gnorm=2.19, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=2798
2023-03-15 14:46:24 - progress_bar.py[line:272] - INFO: epoch 005:    254 / 2004 loss=0.815, loss_v1=0, loss_v2=0, nll_loss=0.815, ntokens=337.2, nsentences=8, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=986.6, ups=2.93, wpb=337.2, bsz=8, num_updates=8220, lr=9.27236e-05, gnorm=2.105, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=2802
2023-03-15 14:46:28 - progress_bar.py[line:272] - INFO: epoch 005:    264 / 2004 loss=0.993, loss_v1=0, loss_v2=0, nll_loss=0.993, ntokens=358.3, nsentences=8, sample_size=358.3, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=1057.7, ups=2.95, wpb=358.3, bsz=8, num_updates=8230, lr=9.27136e-05, gnorm=2.223, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=2805
2023-03-15 14:46:31 - progress_bar.py[line:272] - INFO: epoch 005:    274 / 2004 loss=0.878, loss_v1=0, loss_v2=0, nll_loss=0.878, ntokens=330.1, nsentences=8, sample_size=330.1, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=978.8, ups=2.97, wpb=330.1, bsz=8, num_updates=8240, lr=9.27035e-05, gnorm=2.144, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=2809
2023-03-15 14:46:34 - progress_bar.py[line:272] - INFO: epoch 005:    284 / 2004 loss=0.962, loss_v1=0, loss_v2=0, nll_loss=0.962, ntokens=374.8, nsentences=8, sample_size=374.8, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=1105.3, ups=2.95, wpb=374.8, bsz=8, num_updates=8250, lr=9.26934e-05, gnorm=2.139, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=2812
2023-03-15 14:46:36 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 14:46:38 - progress_bar.py[line:272] - INFO: epoch 005:    295 / 2004 loss=0.87, loss_v1=0, loss_v2=0, nll_loss=0.87, ntokens=338.1, nsentences=8, sample_size=338.1, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=899.8, ups=2.66, wpb=338.1, bsz=8, num_updates=8260, lr=9.26833e-05, gnorm=2.062, clip=0, loss_scale=2048, train_wall=4, gb_free=15, wall=2816
2023-03-15 14:46:42 - progress_bar.py[line:272] - INFO: epoch 005:    305 / 2004 loss=0.93, loss_v1=0, loss_v2=0, nll_loss=0.93, ntokens=352.2, nsentences=8, sample_size=352.2, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=1047.7, ups=2.97, wpb=352.2, bsz=8, num_updates=8270, lr=9.26732e-05, gnorm=2.18, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=2819
2023-03-15 14:46:45 - progress_bar.py[line:272] - INFO: epoch 005:    315 / 2004 loss=0.94, loss_v1=0, loss_v2=0, nll_loss=0.94, ntokens=356.3, nsentences=8, sample_size=356.3, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=1019.4, ups=2.86, wpb=356.3, bsz=8, num_updates=8280, lr=9.26632e-05, gnorm=2.171, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=2823
2023-03-15 14:46:48 - progress_bar.py[line:272] - INFO: epoch 005:    325 / 2004 loss=0.865, loss_v1=0, loss_v2=0, nll_loss=0.865, ntokens=325.9, nsentences=8, sample_size=325.9, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=959.3, ups=2.94, wpb=325.9, bsz=8, num_updates=8290, lr=9.26531e-05, gnorm=2.13, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=2826
2023-03-15 14:46:52 - progress_bar.py[line:272] - INFO: epoch 005:    335 / 2004 loss=0.935, loss_v1=0, loss_v2=0, nll_loss=0.935, ntokens=320.6, nsentences=8, sample_size=320.6, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=953.7, ups=2.97, wpb=320.6, bsz=8, num_updates=8300, lr=9.2643e-05, gnorm=2.279, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=2829
2023-03-15 14:46:55 - progress_bar.py[line:272] - INFO: epoch 005:    345 / 2004 loss=1.024, loss_v1=0, loss_v2=0, nll_loss=1.024, ntokens=388.7, nsentences=8, sample_size=388.7, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=1128, ups=2.9, wpb=388.7, bsz=8, num_updates=8310, lr=9.26329e-05, gnorm=2.193, clip=0, loss_scale=2048, train_wall=3, gb_free=13.9, wall=2833
2023-03-15 14:46:59 - progress_bar.py[line:272] - INFO: epoch 005:    355 / 2004 loss=1.001, loss_v1=0, loss_v2=0, nll_loss=1.001, ntokens=337.5, nsentences=8, sample_size=337.5, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=997.6, ups=2.96, wpb=337.5, bsz=8, num_updates=8320, lr=9.26228e-05, gnorm=2.347, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=2836
2023-03-15 14:47:02 - progress_bar.py[line:272] - INFO: epoch 005:    365 / 2004 loss=0.942, loss_v1=0, loss_v2=0, nll_loss=0.942, ntokens=355.8, nsentences=8, sample_size=355.8, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=1048.1, ups=2.95, wpb=355.8, bsz=8, num_updates=8330, lr=9.26128e-05, gnorm=2.212, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=2840
2023-03-15 14:47:05 - progress_bar.py[line:272] - INFO: epoch 005:    375 / 2004 loss=0.86, loss_v1=0, loss_v2=0, nll_loss=0.86, ntokens=319.3, nsentences=8, sample_size=319.3, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=933.2, ups=2.92, wpb=319.3, bsz=8, num_updates=8340, lr=9.26027e-05, gnorm=2.208, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=2843
2023-03-15 14:47:09 - progress_bar.py[line:272] - INFO: epoch 005:    385 / 2004 loss=0.912, loss_v1=0, loss_v2=0, nll_loss=0.912, ntokens=326.1, nsentences=8, sample_size=326.1, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=968.2, ups=2.97, wpb=326.1, bsz=8, num_updates=8350, lr=9.25926e-05, gnorm=2.205, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=2846
2023-03-15 14:47:12 - progress_bar.py[line:272] - INFO: epoch 005:    395 / 2004 loss=0.934, loss_v1=0, loss_v2=0, nll_loss=0.934, ntokens=354.5, nsentences=8, sample_size=354.5, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=1064.6, ups=3, wpb=354.5, bsz=8, num_updates=8360, lr=9.25825e-05, gnorm=2.249, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=2850
2023-03-15 14:47:16 - progress_bar.py[line:272] - INFO: epoch 005:    405 / 2004 loss=0.895, loss_v1=0, loss_v2=0, nll_loss=0.895, ntokens=363.7, nsentences=8, sample_size=363.7, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=1056.5, ups=2.9, wpb=363.7, bsz=8, num_updates=8370, lr=9.25724e-05, gnorm=2.193, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=2853
2023-03-15 14:47:19 - progress_bar.py[line:272] - INFO: epoch 005:    415 / 2004 loss=0.851, loss_v1=0, loss_v2=0, nll_loss=0.851, ntokens=351.8, nsentences=8, sample_size=351.8, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=1046.2, ups=2.97, wpb=351.8, bsz=8, num_updates=8380, lr=9.25624e-05, gnorm=2.127, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=2857
2023-03-15 14:47:20 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 14:47:23 - progress_bar.py[line:272] - INFO: epoch 005:    426 / 2004 loss=0.812, loss_v1=0, loss_v2=0, nll_loss=0.812, ntokens=315.7, nsentences=8, sample_size=315.7, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=863.6, ups=2.74, wpb=315.7, bsz=8, num_updates=8390, lr=9.25523e-05, gnorm=2.127, clip=0, loss_scale=2048, train_wall=4, gb_free=15.1, wall=2860
2023-03-15 14:47:26 - progress_bar.py[line:272] - INFO: epoch 005:    436 / 2004 loss=0.933, loss_v1=0, loss_v2=0, nll_loss=0.933, ntokens=368.1, nsentences=8, sample_size=368.1, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=1064.3, ups=2.89, wpb=368.1, bsz=8, num_updates=8400, lr=9.25422e-05, gnorm=2.146, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=2864
2023-03-15 14:47:29 - progress_bar.py[line:272] - INFO: epoch 005:    446 / 2004 loss=0.967, loss_v1=0, loss_v2=0, nll_loss=0.967, ntokens=362.4, nsentences=8, sample_size=362.4, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=1076, ups=2.97, wpb=362.4, bsz=8, num_updates=8410, lr=9.25321e-05, gnorm=2.164, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=2867
2023-03-15 14:47:33 - progress_bar.py[line:272] - INFO: epoch 005:    456 / 2004 loss=1.047, loss_v1=0, loss_v2=0, nll_loss=1.047, ntokens=381.5, nsentences=8, sample_size=381.5, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=1127.7, ups=2.96, wpb=381.5, bsz=8, num_updates=8420, lr=9.2522e-05, gnorm=2.177, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=2870
2023-03-15 14:47:36 - progress_bar.py[line:272] - INFO: epoch 005:    466 / 2004 loss=1.069, loss_v1=0, loss_v2=0, nll_loss=1.069, ntokens=368.6, nsentences=8, sample_size=368.6, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=1078.2, ups=2.93, wpb=368.6, bsz=8, num_updates=8430, lr=9.25119e-05, gnorm=2.286, clip=0, loss_scale=2048, train_wall=3, gb_free=13.9, wall=2874
2023-03-15 14:47:39 - progress_bar.py[line:272] - INFO: epoch 005:    476 / 2004 loss=0.876, loss_v1=0, loss_v2=0, nll_loss=0.876, ntokens=344.6, nsentences=8, sample_size=344.6, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=1046.7, ups=3.04, wpb=344.6, bsz=8, num_updates=8440, lr=9.25019e-05, gnorm=2.078, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=2877
2023-03-15 14:47:43 - progress_bar.py[line:272] - INFO: epoch 005:    486 / 2004 loss=0.861, loss_v1=0, loss_v2=0, nll_loss=0.861, ntokens=375.3, nsentences=8, sample_size=375.3, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=1102.2, ups=2.94, wpb=375.3, bsz=8, num_updates=8450, lr=9.24918e-05, gnorm=2.076, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=2881
2023-03-15 14:47:46 - progress_bar.py[line:272] - INFO: epoch 005:    496 / 2004 loss=0.889, loss_v1=0, loss_v2=0, nll_loss=0.889, ntokens=366.5, nsentences=8, sample_size=366.5, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=1101.5, ups=3.01, wpb=366.5, bsz=8, num_updates=8460, lr=9.24817e-05, gnorm=2.009, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=2884
2023-03-15 14:47:50 - progress_bar.py[line:272] - INFO: epoch 005:    506 / 2004 loss=0.931, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=349.6, nsentences=8, sample_size=349.6, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=1031.9, ups=2.95, wpb=349.6, bsz=8, num_updates=8470, lr=9.24716e-05, gnorm=2.24, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=2887
2023-03-15 14:47:53 - progress_bar.py[line:272] - INFO: epoch 005:    516 / 2004 loss=0.958, loss_v1=0, loss_v2=0, nll_loss=0.958, ntokens=352.2, nsentences=8, sample_size=352.2, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=1012.3, ups=2.87, wpb=352.2, bsz=8, num_updates=8480, lr=9.24615e-05, gnorm=2.23, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=2891
2023-03-15 14:47:55 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 14:47:57 - progress_bar.py[line:272] - INFO: epoch 005:    527 / 2004 loss=0.963, loss_v1=0, loss_v2=0, nll_loss=0.963, ntokens=380.8, nsentences=7.8, sample_size=380.8, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=1036.2, ups=2.72, wpb=380.8, bsz=7.8, num_updates=8490, lr=9.24515e-05, gnorm=2.185, clip=0, loss_scale=1024, train_wall=4, gb_free=14.2, wall=2894
2023-03-15 14:48:00 - progress_bar.py[line:272] - INFO: epoch 005:    537 / 2004 loss=0.979, loss_v1=0, loss_v2=0, nll_loss=0.979, ntokens=384.8, nsentences=8, sample_size=384.8, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=1135.7, ups=2.95, wpb=384.8, bsz=8, num_updates=8500, lr=9.24414e-05, gnorm=2.153, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=2898
2023-03-15 14:48:04 - progress_bar.py[line:272] - INFO: epoch 005:    547 / 2004 loss=0.923, loss_v1=0, loss_v2=0, nll_loss=0.923, ntokens=348.2, nsentences=8, sample_size=348.2, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=1031.9, ups=2.96, wpb=348.2, bsz=8, num_updates=8510, lr=9.24313e-05, gnorm=2.287, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=2901
2023-03-15 14:48:07 - progress_bar.py[line:272] - INFO: epoch 005:    557 / 2004 loss=0.914, loss_v1=0, loss_v2=0, nll_loss=0.914, ntokens=382.8, nsentences=8, sample_size=382.8, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=1106.2, ups=2.89, wpb=382.8, bsz=8, num_updates=8520, lr=9.24212e-05, gnorm=2.088, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=2905
2023-03-15 14:48:10 - progress_bar.py[line:272] - INFO: epoch 005:    567 / 2004 loss=0.887, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=374.8, nsentences=8, sample_size=374.8, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=1096.5, ups=2.93, wpb=374.8, bsz=8, num_updates=8530, lr=9.24111e-05, gnorm=2.103, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=2908
2023-03-15 14:48:14 - progress_bar.py[line:272] - INFO: epoch 005:    577 / 2004 loss=0.915, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=337.8, nsentences=8, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=1003.8, ups=2.97, wpb=337.8, bsz=8, num_updates=8540, lr=9.24011e-05, gnorm=2.235, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=2911
2023-03-15 14:48:17 - progress_bar.py[line:272] - INFO: epoch 005:    587 / 2004 loss=0.866, loss_v1=0, loss_v2=0, nll_loss=0.866, ntokens=352.1, nsentences=8, sample_size=352.1, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=1029.1, ups=2.92, wpb=352.1, bsz=8, num_updates=8550, lr=9.2391e-05, gnorm=2.165, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=2915
2023-03-15 14:48:21 - progress_bar.py[line:272] - INFO: epoch 005:    597 / 2004 loss=0.918, loss_v1=0, loss_v2=0, nll_loss=0.918, ntokens=343.9, nsentences=8, sample_size=343.9, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=1022.3, ups=2.97, wpb=343.9, bsz=8, num_updates=8560, lr=9.23809e-05, gnorm=2.192, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=2918
2023-03-15 14:48:24 - progress_bar.py[line:272] - INFO: epoch 005:    607 / 2004 loss=0.957, loss_v1=0, loss_v2=0, nll_loss=0.957, ntokens=355.3, nsentences=8, sample_size=355.3, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=1033.3, ups=2.91, wpb=355.3, bsz=8, num_updates=8570, lr=9.23708e-05, gnorm=2.199, clip=0, loss_scale=1024, train_wall=3, gb_free=14.2, wall=2922
2023-03-15 14:48:27 - progress_bar.py[line:272] - INFO: epoch 005:    617 / 2004 loss=0.853, loss_v1=0, loss_v2=0, nll_loss=0.853, ntokens=348.8, nsentences=8, sample_size=348.8, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=1024.8, ups=2.94, wpb=348.8, bsz=8, num_updates=8580, lr=9.23607e-05, gnorm=2.035, clip=0, loss_scale=1024, train_wall=3, gb_free=14.1, wall=2925
2023-03-15 14:48:31 - progress_bar.py[line:272] - INFO: epoch 005:    627 / 2004 loss=0.85, loss_v1=0, loss_v2=0, nll_loss=0.85, ntokens=374.8, nsentences=8, sample_size=374.8, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=1104.3, ups=2.95, wpb=374.8, bsz=8, num_updates=8590, lr=9.23507e-05, gnorm=2.034, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=2928
2023-03-15 14:48:34 - progress_bar.py[line:272] - INFO: epoch 005:    637 / 2004 loss=0.832, loss_v1=0, loss_v2=0, nll_loss=0.832, ntokens=331.8, nsentences=8, sample_size=331.8, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=1021.7, ups=3.08, wpb=331.8, bsz=8, num_updates=8600, lr=9.23406e-05, gnorm=2.159, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=2932
2023-03-15 14:48:37 - progress_bar.py[line:272] - INFO: epoch 005:    647 / 2004 loss=0.905, loss_v1=0, loss_v2=0, nll_loss=0.905, ntokens=327.6, nsentences=8, sample_size=327.6, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=953.8, ups=2.91, wpb=327.6, bsz=8, num_updates=8610, lr=9.23305e-05, gnorm=2.344, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=2935
2023-03-15 14:48:41 - progress_bar.py[line:272] - INFO: epoch 005:    657 / 2004 loss=1.047, loss_v1=0, loss_v2=0, nll_loss=1.047, ntokens=355.4, nsentences=8, sample_size=355.4, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=1058.8, ups=2.98, wpb=355.4, bsz=8, num_updates=8620, lr=9.23204e-05, gnorm=2.314, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=2938
2023-03-15 14:48:44 - progress_bar.py[line:272] - INFO: epoch 005:    667 / 2004 loss=0.89, loss_v1=0, loss_v2=0, nll_loss=0.89, ntokens=301, nsentences=8, sample_size=301, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=904.3, ups=3, wpb=301, bsz=8, num_updates=8630, lr=9.23103e-05, gnorm=2.308, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=2942
2023-03-15 14:48:48 - progress_bar.py[line:272] - INFO: epoch 005:    677 / 2004 loss=0.857, loss_v1=0, loss_v2=0, nll_loss=0.857, ntokens=336.4, nsentences=8, sample_size=336.4, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=977, ups=2.9, wpb=336.4, bsz=8, num_updates=8640, lr=9.23002e-05, gnorm=2.119, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=2945
2023-03-15 14:48:51 - progress_bar.py[line:272] - INFO: epoch 005:    687 / 2004 loss=0.869, loss_v1=0, loss_v2=0, nll_loss=0.869, ntokens=351.4, nsentences=8, sample_size=351.4, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=1044, ups=2.97, wpb=351.4, bsz=8, num_updates=8650, lr=9.22902e-05, gnorm=2.18, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=2949
2023-03-15 14:48:54 - progress_bar.py[line:272] - INFO: epoch 005:    697 / 2004 loss=0.959, loss_v1=0, loss_v2=0, nll_loss=0.959, ntokens=357.5, nsentences=8, sample_size=357.5, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=1044, ups=2.92, wpb=357.5, bsz=8, num_updates=8660, lr=9.22801e-05, gnorm=2.283, clip=0, loss_scale=2048, train_wall=3, gb_free=13.8, wall=2952
2023-03-15 14:48:58 - progress_bar.py[line:272] - INFO: epoch 005:    707 / 2004 loss=0.917, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=349.6, nsentences=8, sample_size=349.6, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=1023.4, ups=2.93, wpb=349.6, bsz=8, num_updates=8670, lr=9.227e-05, gnorm=2.209, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=2955
2023-03-15 14:49:01 - progress_bar.py[line:272] - INFO: epoch 005:    717 / 2004 loss=0.91, loss_v1=0, loss_v2=0, nll_loss=0.91, ntokens=310.8, nsentences=8, sample_size=310.8, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=929.9, ups=2.99, wpb=310.8, bsz=8, num_updates=8680, lr=9.22599e-05, gnorm=2.332, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=2959
2023-03-15 14:49:05 - progress_bar.py[line:272] - INFO: epoch 005:    727 / 2004 loss=0.981, loss_v1=0, loss_v2=0, nll_loss=0.981, ntokens=369.1, nsentences=8, sample_size=369.1, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=1077.2, ups=2.92, wpb=369.1, bsz=8, num_updates=8690, lr=9.22498e-05, gnorm=2.293, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=2962
2023-03-15 14:49:08 - progress_bar.py[line:272] - INFO: epoch 005:    737 / 2004 loss=0.892, loss_v1=0, loss_v2=0, nll_loss=0.892, ntokens=344.2, nsentences=8, sample_size=344.2, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=1024.2, ups=2.98, wpb=344.2, bsz=8, num_updates=8700, lr=9.22398e-05, gnorm=2.217, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=2966
2023-03-15 14:49:11 - progress_bar.py[line:272] - INFO: epoch 005:    747 / 2004 loss=0.952, loss_v1=0, loss_v2=0, nll_loss=0.952, ntokens=352.4, nsentences=8, sample_size=352.4, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=1048.5, ups=2.98, wpb=352.4, bsz=8, num_updates=8710, lr=9.22297e-05, gnorm=2.298, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=2969
2023-03-15 14:49:15 - progress_bar.py[line:272] - INFO: epoch 005:    757 / 2004 loss=0.881, loss_v1=0, loss_v2=0, nll_loss=0.881, ntokens=311.3, nsentences=8, sample_size=311.3, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=916.6, ups=2.94, wpb=311.3, bsz=8, num_updates=8720, lr=9.22196e-05, gnorm=2.349, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=2972
2023-03-15 14:49:18 - progress_bar.py[line:272] - INFO: epoch 005:    767 / 2004 loss=0.984, loss_v1=0, loss_v2=0, nll_loss=0.984, ntokens=390.2, nsentences=8, sample_size=390.2, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=1110.6, ups=2.85, wpb=390.2, bsz=8, num_updates=8730, lr=9.22095e-05, gnorm=2.217, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=2976
2023-03-15 14:49:22 - progress_bar.py[line:272] - INFO: epoch 005:    777 / 2004 loss=1.035, loss_v1=0, loss_v2=0, nll_loss=1.035, ntokens=368.2, nsentences=8, sample_size=368.2, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=1087.3, ups=2.95, wpb=368.2, bsz=8, num_updates=8740, lr=9.21994e-05, gnorm=2.249, clip=0, loss_scale=4096, train_wall=3, gb_free=15.1, wall=2979
2023-03-15 14:49:24 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 14:49:25 - progress_bar.py[line:272] - INFO: epoch 005:    788 / 2004 loss=0.859, loss_v1=0, loss_v2=0, nll_loss=0.859, ntokens=333.1, nsentences=8, sample_size=333.1, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=905.8, ups=2.72, wpb=333.1, bsz=8, num_updates=8750, lr=9.21894e-05, gnorm=2.175, clip=0, loss_scale=2048, train_wall=4, gb_free=14.9, wall=2983
2023-03-15 14:49:29 - progress_bar.py[line:272] - INFO: epoch 005:    798 / 2004 loss=0.8, loss_v1=0, loss_v2=0, nll_loss=0.8, ntokens=320.1, nsentences=8, sample_size=320.1, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=937.1, ups=2.93, wpb=320.1, bsz=8, num_updates=8760, lr=9.21793e-05, gnorm=2.232, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=2986
2023-03-15 14:49:32 - progress_bar.py[line:272] - INFO: epoch 005:    808 / 2004 loss=0.891, loss_v1=0, loss_v2=0, nll_loss=0.891, ntokens=340, nsentences=8, sample_size=340, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=1002.5, ups=2.95, wpb=340, bsz=8, num_updates=8770, lr=9.21692e-05, gnorm=2.245, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=2990
2023-03-15 14:49:35 - progress_bar.py[line:272] - INFO: epoch 005:    818 / 2004 loss=0.781, loss_v1=0, loss_v2=0, nll_loss=0.781, ntokens=322.2, nsentences=8, sample_size=322.2, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=960.4, ups=2.98, wpb=322.2, bsz=8, num_updates=8780, lr=9.21591e-05, gnorm=2.158, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=2993
2023-03-15 14:49:39 - progress_bar.py[line:272] - INFO: epoch 005:    828 / 2004 loss=0.938, loss_v1=0, loss_v2=0, nll_loss=0.938, ntokens=383.7, nsentences=8, sample_size=383.7, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=1084.4, ups=2.83, wpb=383.7, bsz=8, num_updates=8790, lr=9.2149e-05, gnorm=2.113, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=2997
2023-03-15 14:49:42 - progress_bar.py[line:272] - INFO: epoch 005:    838 / 2004 loss=0.868, loss_v1=0, loss_v2=0, nll_loss=0.868, ntokens=323.7, nsentences=8, sample_size=323.7, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=961.9, ups=2.97, wpb=323.7, bsz=8, num_updates=8800, lr=9.2139e-05, gnorm=2.268, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=3000
2023-03-15 14:49:46 - progress_bar.py[line:272] - INFO: epoch 005:    848 / 2004 loss=0.842, loss_v1=0, loss_v2=0, nll_loss=0.842, ntokens=358.4, nsentences=8, sample_size=358.4, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=1075, ups=3, wpb=358.4, bsz=8, num_updates=8810, lr=9.21289e-05, gnorm=2.076, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=3003
2023-03-15 14:49:49 - progress_bar.py[line:272] - INFO: epoch 005:    858 / 2004 loss=0.945, loss_v1=0, loss_v2=0, nll_loss=0.945, ntokens=358, nsentences=8, sample_size=358, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=1048.4, ups=2.93, wpb=358, bsz=8, num_updates=8820, lr=9.21188e-05, gnorm=2.247, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=3007
2023-03-15 14:49:53 - progress_bar.py[line:272] - INFO: epoch 005:    868 / 2004 loss=0.908, loss_v1=0, loss_v2=0, nll_loss=0.908, ntokens=368.4, nsentences=8, sample_size=368.4, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=1080.4, ups=2.93, wpb=368.4, bsz=8, num_updates=8830, lr=9.21087e-05, gnorm=2.14, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=3010
2023-03-15 14:49:56 - progress_bar.py[line:272] - INFO: epoch 005:    878 / 2004 loss=0.84, loss_v1=0, loss_v2=0, nll_loss=0.84, ntokens=327.8, nsentences=8, sample_size=327.8, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=964.9, ups=2.94, wpb=327.8, bsz=8, num_updates=8840, lr=9.20986e-05, gnorm=2.206, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=3014
2023-03-15 14:49:59 - progress_bar.py[line:272] - INFO: epoch 005:    888 / 2004 loss=0.91, loss_v1=0, loss_v2=0, nll_loss=0.91, ntokens=321.3, nsentences=8, sample_size=321.3, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=949.1, ups=2.95, wpb=321.3, bsz=8, num_updates=8850, lr=9.20886e-05, gnorm=2.393, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=3017
2023-03-15 14:50:03 - progress_bar.py[line:272] - INFO: epoch 005:    898 / 2004 loss=0.906, loss_v1=0, loss_v2=0, nll_loss=0.906, ntokens=341.8, nsentences=8, sample_size=341.8, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=991.1, ups=2.9, wpb=341.8, bsz=8, num_updates=8860, lr=9.20785e-05, gnorm=2.282, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=3020
2023-03-15 14:50:06 - progress_bar.py[line:272] - INFO: epoch 005:    908 / 2004 loss=0.804, loss_v1=0, loss_v2=0, nll_loss=0.804, ntokens=363.1, nsentences=8, sample_size=363.1, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=1057.6, ups=2.91, wpb=363.1, bsz=8, num_updates=8870, lr=9.20684e-05, gnorm=2.084, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=3024
2023-03-15 14:50:08 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 14:50:10 - progress_bar.py[line:272] - INFO: epoch 005:    919 / 2004 loss=0.866, loss_v1=0, loss_v2=0, nll_loss=0.866, ntokens=346.9, nsentences=8, sample_size=346.9, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=930.6, ups=2.68, wpb=346.9, bsz=8, num_updates=8880, lr=9.20583e-05, gnorm=2.187, clip=0, loss_scale=2048, train_wall=4, gb_free=14.6, wall=3028
2023-03-15 14:50:13 - progress_bar.py[line:272] - INFO: epoch 005:    929 / 2004 loss=0.85, loss_v1=0, loss_v2=0, nll_loss=0.85, ntokens=326.3, nsentences=8, sample_size=326.3, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=971.2, ups=2.98, wpb=326.3, bsz=8, num_updates=8890, lr=9.20482e-05, gnorm=2.185, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=3031
2023-03-15 14:50:17 - progress_bar.py[line:272] - INFO: epoch 005:    939 / 2004 loss=0.898, loss_v1=0, loss_v2=0, nll_loss=0.898, ntokens=373, nsentences=8, sample_size=373, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=1087.2, ups=2.91, wpb=373, bsz=8, num_updates=8900, lr=9.20381e-05, gnorm=2.186, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=3034
2023-03-15 14:50:20 - progress_bar.py[line:272] - INFO: epoch 005:    949 / 2004 loss=0.865, loss_v1=0, loss_v2=0, nll_loss=0.865, ntokens=346.1, nsentences=8, sample_size=346.1, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=1012.5, ups=2.93, wpb=346.1, bsz=8, num_updates=8910, lr=9.20281e-05, gnorm=2.193, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=3038
2023-03-15 14:50:24 - progress_bar.py[line:272] - INFO: epoch 005:    959 / 2004 loss=0.925, loss_v1=0, loss_v2=0, nll_loss=0.925, ntokens=354, nsentences=8, sample_size=354, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=1023.7, ups=2.89, wpb=354, bsz=8, num_updates=8920, lr=9.2018e-05, gnorm=2.225, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=3041
2023-03-15 14:50:27 - progress_bar.py[line:272] - INFO: epoch 005:    969 / 2004 loss=0.876, loss_v1=0, loss_v2=0, nll_loss=0.876, ntokens=351.2, nsentences=8, sample_size=351.2, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=1027.7, ups=2.93, wpb=351.2, bsz=8, num_updates=8930, lr=9.20079e-05, gnorm=2.2, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=3045
2023-03-15 14:50:30 - progress_bar.py[line:272] - INFO: epoch 005:    979 / 2004 loss=0.898, loss_v1=0, loss_v2=0, nll_loss=0.898, ntokens=339.3, nsentences=8, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=987.7, ups=2.91, wpb=339.3, bsz=8, num_updates=8940, lr=9.19978e-05, gnorm=2.29, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=3048
2023-03-15 14:50:34 - progress_bar.py[line:272] - INFO: epoch 005:    989 / 2004 loss=0.896, loss_v1=0, loss_v2=0, nll_loss=0.896, ntokens=358.7, nsentences=8, sample_size=358.7, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=1051.6, ups=2.93, wpb=358.7, bsz=8, num_updates=8950, lr=9.19877e-05, gnorm=2.191, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=3051
2023-03-15 14:50:37 - progress_bar.py[line:272] - INFO: epoch 005:    999 / 2004 loss=0.869, loss_v1=0, loss_v2=0, nll_loss=0.869, ntokens=359.1, nsentences=8, sample_size=359.1, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=1054.1, ups=2.94, wpb=359.1, bsz=8, num_updates=8960, lr=9.19777e-05, gnorm=2.126, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=3055
2023-03-15 14:50:41 - progress_bar.py[line:272] - INFO: epoch 005:   1009 / 2004 loss=0.898, loss_v1=0, loss_v2=0, nll_loss=0.898, ntokens=298, nsentences=8, sample_size=298, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=880.1, ups=2.95, wpb=298, bsz=8, num_updates=8970, lr=9.19676e-05, gnorm=2.321, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=3058
2023-03-15 14:50:44 - progress_bar.py[line:272] - INFO: epoch 005:   1019 / 2004 loss=0.84, loss_v1=0, loss_v2=0, nll_loss=0.84, ntokens=342.6, nsentences=8, sample_size=342.6, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=1014.1, ups=2.96, wpb=342.6, bsz=8, num_updates=8980, lr=9.19575e-05, gnorm=2.191, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=3062
2023-03-15 14:50:47 - progress_bar.py[line:272] - INFO: epoch 005:   1029 / 2004 loss=0.858, loss_v1=0, loss_v2=0, nll_loss=0.858, ntokens=324, nsentences=8, sample_size=324, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=961.5, ups=2.97, wpb=324, bsz=8, num_updates=8990, lr=9.19474e-05, gnorm=2.281, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=3065
2023-03-15 14:50:51 - progress_bar.py[line:272] - INFO: epoch 005:   1039 / 2004 loss=0.872, loss_v1=0, loss_v2=0, nll_loss=0.872, ntokens=319.1, nsentences=8, sample_size=319.1, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=946.6, ups=2.97, wpb=319.1, bsz=8, num_updates=9000, lr=9.19373e-05, gnorm=2.273, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=3068
2023-03-15 14:50:51 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 14:50:55 - progress_bar.py[line:272] - INFO: epoch 005:   1050 / 2004 loss=0.931, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=378.9, nsentences=8, sample_size=378.9, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=1000.3, ups=2.64, wpb=378.9, bsz=8, num_updates=9010, lr=9.19273e-05, gnorm=2.2, clip=0, loss_scale=2048, train_wall=4, gb_free=15.4, wall=3072
2023-03-15 14:50:58 - progress_bar.py[line:272] - INFO: epoch 005:   1060 / 2004 loss=0.886, loss_v1=0, loss_v2=0, nll_loss=0.886, ntokens=347.8, nsentences=8, sample_size=347.8, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=1004.9, ups=2.89, wpb=347.8, bsz=8, num_updates=9020, lr=9.19172e-05, gnorm=2.196, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=3076
2023-03-15 14:51:01 - progress_bar.py[line:272] - INFO: epoch 005:   1070 / 2004 loss=0.95, loss_v1=0, loss_v2=0, nll_loss=0.95, ntokens=342.8, nsentences=8, sample_size=342.8, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=1006.9, ups=2.94, wpb=342.8, bsz=8, num_updates=9030, lr=9.19071e-05, gnorm=2.313, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=3079
2023-03-15 14:51:04 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 14:51:05 - progress_bar.py[line:272] - INFO: epoch 005:   1081 / 2004 loss=0.825, loss_v1=0, loss_v2=0, nll_loss=0.825, ntokens=370.2, nsentences=8, sample_size=370.2, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=958, ups=2.59, wpb=370.2, bsz=8, num_updates=9040, lr=9.1897e-05, gnorm=2.147, clip=0, loss_scale=1024, train_wall=4, gb_free=14.3, wall=3083
2023-03-15 14:51:07 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-03-15 14:51:09 - progress_bar.py[line:272] - INFO: epoch 005:   1092 / 2004 loss=0.934, loss_v1=0, loss_v2=0, nll_loss=0.934, ntokens=334.5, nsentences=8, sample_size=334.5, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=897.5, ups=2.68, wpb=334.5, bsz=8, num_updates=9050, lr=9.18869e-05, gnorm=2.326, clip=0, loss_scale=512, train_wall=4, gb_free=15, wall=3087
2023-03-15 14:51:12 - progress_bar.py[line:272] - INFO: epoch 005:   1102 / 2004 loss=1.012, loss_v1=0, loss_v2=0, nll_loss=1.012, ntokens=364.8, nsentences=8, sample_size=364.8, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=1061.8, ups=2.91, wpb=364.8, bsz=8, num_updates=9060, lr=9.18769e-05, gnorm=2.385, clip=0, loss_scale=512, train_wall=3, gb_free=14.3, wall=3090
2023-03-15 14:51:16 - progress_bar.py[line:272] - INFO: epoch 005:   1112 / 2004 loss=0.885, loss_v1=0, loss_v2=0, nll_loss=0.885, ntokens=351.9, nsentences=8, sample_size=351.9, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=1028.3, ups=2.92, wpb=351.9, bsz=8, num_updates=9070, lr=9.18668e-05, gnorm=2.174, clip=0, loss_scale=512, train_wall=3, gb_free=15.7, wall=3093
2023-03-15 14:51:19 - progress_bar.py[line:272] - INFO: epoch 005:   1122 / 2004 loss=0.75, loss_v1=0, loss_v2=0, nll_loss=0.75, ntokens=315.6, nsentences=8, sample_size=315.6, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=932.6, ups=2.96, wpb=315.6, bsz=8, num_updates=9080, lr=9.18567e-05, gnorm=2.092, clip=0, loss_scale=512, train_wall=3, gb_free=15.6, wall=3097
2023-03-15 14:51:23 - progress_bar.py[line:272] - INFO: epoch 005:   1132 / 2004 loss=0.917, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=376.8, nsentences=8, sample_size=376.8, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=1120.9, ups=2.97, wpb=376.8, bsz=8, num_updates=9090, lr=9.18466e-05, gnorm=2.215, clip=0, loss_scale=512, train_wall=3, gb_free=15, wall=3100
2023-03-15 14:51:26 - progress_bar.py[line:272] - INFO: epoch 005:   1142 / 2004 loss=0.877, loss_v1=0, loss_v2=0, nll_loss=0.877, ntokens=360.1, nsentences=8, sample_size=360.1, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=1033.2, ups=2.87, wpb=360.1, bsz=8, num_updates=9100, lr=9.18365e-05, gnorm=2.266, clip=0, loss_scale=512, train_wall=3, gb_free=15.3, wall=3104
2023-03-15 14:51:30 - progress_bar.py[line:272] - INFO: epoch 005:   1152 / 2004 loss=0.833, loss_v1=0, loss_v2=0, nll_loss=0.833, ntokens=375.7, nsentences=8, sample_size=375.7, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=1060.8, ups=2.82, wpb=375.7, bsz=8, num_updates=9110, lr=9.18264e-05, gnorm=2.128, clip=0, loss_scale=512, train_wall=3, gb_free=15, wall=3107
2023-03-15 14:51:34 - progress_bar.py[line:272] - INFO: epoch 005:   1162 / 2004 loss=0.893, loss_v1=0, loss_v2=0, nll_loss=0.893, ntokens=376.9, nsentences=8, sample_size=376.9, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=803.8, ups=2.13, wpb=376.9, bsz=8, num_updates=9120, lr=9.18164e-05, gnorm=2.197, clip=0, loss_scale=512, train_wall=5, gb_free=15.2, wall=3112
2023-03-15 14:51:38 - progress_bar.py[line:272] - INFO: epoch 005:   1172 / 2004 loss=0.858, loss_v1=0, loss_v2=0, nll_loss=0.858, ntokens=343.5, nsentences=8, sample_size=343.5, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=1004.2, ups=2.92, wpb=343.5, bsz=8, num_updates=9130, lr=9.18063e-05, gnorm=2.244, clip=0, loss_scale=512, train_wall=3, gb_free=15.3, wall=3115
2023-03-15 14:51:41 - progress_bar.py[line:272] - INFO: epoch 005:   1182 / 2004 loss=0.812, loss_v1=0, loss_v2=0, nll_loss=0.812, ntokens=352.3, nsentences=8, sample_size=352.3, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=1019.6, ups=2.89, wpb=352.3, bsz=8, num_updates=9140, lr=9.17962e-05, gnorm=2.116, clip=0, loss_scale=512, train_wall=3, gb_free=14.9, wall=3119
2023-03-15 14:51:45 - progress_bar.py[line:272] - INFO: epoch 005:   1192 / 2004 loss=0.766, loss_v1=0, loss_v2=0, nll_loss=0.766, ntokens=345.2, nsentences=8, sample_size=345.2, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=995.7, ups=2.88, wpb=345.2, bsz=8, num_updates=9150, lr=9.17861e-05, gnorm=2.114, clip=0, loss_scale=512, train_wall=3, gb_free=15.1, wall=3122
2023-03-15 14:51:48 - progress_bar.py[line:272] - INFO: epoch 005:   1202 / 2004 loss=0.893, loss_v1=0, loss_v2=0, nll_loss=0.893, ntokens=340.8, nsentences=8, sample_size=340.8, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=993.5, ups=2.92, wpb=340.8, bsz=8, num_updates=9160, lr=9.1776e-05, gnorm=2.334, clip=0, loss_scale=512, train_wall=3, gb_free=14.7, wall=3126
2023-03-15 14:51:52 - progress_bar.py[line:272] - INFO: epoch 005:   1212 / 2004 loss=0.852, loss_v1=0, loss_v2=0, nll_loss=0.852, ntokens=288.3, nsentences=8, sample_size=288.3, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=831.8, ups=2.89, wpb=288.3, bsz=8, num_updates=9170, lr=9.1766e-05, gnorm=2.339, clip=0, loss_scale=512, train_wall=3, gb_free=14, wall=3129
2023-03-15 14:51:55 - progress_bar.py[line:272] - INFO: epoch 005:   1222 / 2004 loss=0.843, loss_v1=0, loss_v2=0, nll_loss=0.843, ntokens=325.6, nsentences=8, sample_size=325.6, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=959.9, ups=2.95, wpb=325.6, bsz=8, num_updates=9180, lr=9.17559e-05, gnorm=2.272, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=3133
2023-03-15 14:51:57 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-03-15 14:51:59 - progress_bar.py[line:272] - INFO: epoch 005:   1233 / 2004 loss=0.788, loss_v1=0, loss_v2=0, nll_loss=0.788, ntokens=319.8, nsentences=8, sample_size=319.8, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=866.3, ups=2.71, wpb=319.8, bsz=8, num_updates=9190, lr=9.17458e-05, gnorm=2.262, clip=0, loss_scale=512, train_wall=4, gb_free=14.5, wall=3136
2023-03-15 14:52:02 - progress_bar.py[line:272] - INFO: epoch 005:   1243 / 2004 loss=0.947, loss_v1=0, loss_v2=0, nll_loss=0.947, ntokens=392.9, nsentences=8, sample_size=392.9, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=1118.4, ups=2.85, wpb=392.9, bsz=8, num_updates=9200, lr=9.17357e-05, gnorm=2.22, clip=0, loss_scale=512, train_wall=3, gb_free=14.3, wall=3140
2023-03-15 14:52:06 - progress_bar.py[line:272] - INFO: epoch 005:   1253 / 2004 loss=0.909, loss_v1=0, loss_v2=0, nll_loss=0.909, ntokens=350.1, nsentences=8, sample_size=350.1, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=1015.9, ups=2.9, wpb=350.1, bsz=8, num_updates=9210, lr=9.17256e-05, gnorm=2.344, clip=0, loss_scale=512, train_wall=3, gb_free=14.3, wall=3143
2023-03-15 14:52:09 - progress_bar.py[line:272] - INFO: epoch 005:   1263 / 2004 loss=0.821, loss_v1=0, loss_v2=0, nll_loss=0.821, ntokens=326.6, nsentences=8, sample_size=326.6, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=942.9, ups=2.89, wpb=326.6, bsz=8, num_updates=9220, lr=9.17156e-05, gnorm=2.25, clip=0, loss_scale=512, train_wall=3, gb_free=15.2, wall=3147
2023-03-15 14:52:13 - progress_bar.py[line:272] - INFO: epoch 005:   1273 / 2004 loss=0.862, loss_v1=0, loss_v2=0, nll_loss=0.862, ntokens=346.4, nsentences=8, sample_size=346.4, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=997, ups=2.88, wpb=346.4, bsz=8, num_updates=9230, lr=9.17055e-05, gnorm=2.209, clip=0, loss_scale=512, train_wall=3, gb_free=15.5, wall=3150
2023-03-15 14:52:16 - progress_bar.py[line:272] - INFO: epoch 005:   1283 / 2004 loss=0.815, loss_v1=0, loss_v2=0, nll_loss=0.815, ntokens=343.9, nsentences=8, sample_size=343.9, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=974.1, ups=2.83, wpb=343.9, bsz=8, num_updates=9240, lr=9.16954e-05, gnorm=2.264, clip=0, loss_scale=512, train_wall=3, gb_free=14.6, wall=3154
2023-03-15 14:52:20 - progress_bar.py[line:272] - INFO: epoch 005:   1293 / 2004 loss=0.719, loss_v1=0, loss_v2=0, nll_loss=0.719, ntokens=300.6, nsentences=8, sample_size=300.6, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=875.6, ups=2.91, wpb=300.6, bsz=8, num_updates=9250, lr=9.16853e-05, gnorm=2.18, clip=0, loss_scale=512, train_wall=3, gb_free=15.2, wall=3157
2023-03-15 14:52:23 - progress_bar.py[line:272] - INFO: epoch 005:   1303 / 2004 loss=0.934, loss_v1=0, loss_v2=0, nll_loss=0.934, ntokens=333.3, nsentences=8, sample_size=333.3, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=972.9, ups=2.92, wpb=333.3, bsz=8, num_updates=9260, lr=9.16752e-05, gnorm=2.338, clip=0, loss_scale=512, train_wall=3, gb_free=14.3, wall=3161
2023-03-15 14:52:26 - progress_bar.py[line:272] - INFO: epoch 005:   1313 / 2004 loss=0.838, loss_v1=0, loss_v2=0, nll_loss=0.838, ntokens=323.2, nsentences=8, sample_size=323.2, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=927.6, ups=2.87, wpb=323.2, bsz=8, num_updates=9270, lr=9.16652e-05, gnorm=2.245, clip=0, loss_scale=512, train_wall=3, gb_free=15.1, wall=3164
2023-03-15 14:52:30 - progress_bar.py[line:272] - INFO: epoch 005:   1323 / 2004 loss=0.924, loss_v1=0, loss_v2=0, nll_loss=0.924, ntokens=318.3, nsentences=8, sample_size=318.3, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=892.3, ups=2.8, wpb=318.3, bsz=8, num_updates=9280, lr=9.16551e-05, gnorm=2.545, clip=0, loss_scale=512, train_wall=3, gb_free=14.9, wall=3168
2023-03-15 14:52:33 - progress_bar.py[line:272] - INFO: epoch 005:   1333 / 2004 loss=0.95, loss_v1=0, loss_v2=0, nll_loss=0.95, ntokens=333.2, nsentences=8, sample_size=333.2, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=982.3, ups=2.95, wpb=333.2, bsz=8, num_updates=9290, lr=9.1645e-05, gnorm=2.423, clip=0, loss_scale=512, train_wall=3, gb_free=14.8, wall=3171
2023-03-15 14:52:37 - progress_bar.py[line:272] - INFO: epoch 005:   1343 / 2004 loss=0.845, loss_v1=0, loss_v2=0, nll_loss=0.845, ntokens=321, nsentences=8, sample_size=321, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=926.8, ups=2.89, wpb=321, bsz=8, num_updates=9300, lr=9.16349e-05, gnorm=2.274, clip=0, loss_scale=512, train_wall=3, gb_free=14.7, wall=3174
2023-03-15 14:52:40 - progress_bar.py[line:272] - INFO: epoch 005:   1353 / 2004 loss=0.91, loss_v1=0, loss_v2=0, nll_loss=0.91, ntokens=313, nsentences=8, sample_size=313, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=915.7, ups=2.93, wpb=313, bsz=8, num_updates=9310, lr=9.16248e-05, gnorm=2.449, clip=0, loss_scale=512, train_wall=3, gb_free=14.9, wall=3178
2023-03-15 14:52:44 - progress_bar.py[line:272] - INFO: epoch 005:   1363 / 2004 loss=0.9, loss_v1=0, loss_v2=0, nll_loss=0.9, ntokens=326.8, nsentences=8, sample_size=326.8, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=950.4, ups=2.91, wpb=326.8, bsz=8, num_updates=9320, lr=9.16148e-05, gnorm=2.35, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=3181
2023-03-15 14:52:47 - progress_bar.py[line:272] - INFO: epoch 005:   1373 / 2004 loss=0.811, loss_v1=0, loss_v2=0, nll_loss=0.811, ntokens=299.6, nsentences=8, sample_size=299.6, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=858.3, ups=2.86, wpb=299.6, bsz=8, num_updates=9330, lr=9.16047e-05, gnorm=2.366, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=3185
2023-03-15 14:52:51 - progress_bar.py[line:272] - INFO: epoch 005:   1383 / 2004 loss=0.95, loss_v1=0, loss_v2=0, nll_loss=0.95, ntokens=384.6, nsentences=8, sample_size=384.6, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=1087.2, ups=2.83, wpb=384.6, bsz=8, num_updates=9340, lr=9.15946e-05, gnorm=2.292, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=3188
2023-03-15 14:52:54 - progress_bar.py[line:272] - INFO: epoch 005:   1393 / 2004 loss=0.77, loss_v1=0, loss_v2=0, nll_loss=0.77, ntokens=362.5, nsentences=8, sample_size=362.5, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=1057.5, ups=2.92, wpb=362.5, bsz=8, num_updates=9350, lr=9.15845e-05, gnorm=2.063, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=3192
2023-03-15 14:52:58 - progress_bar.py[line:272] - INFO: epoch 005:   1403 / 2004 loss=0.791, loss_v1=0, loss_v2=0, nll_loss=0.791, ntokens=337.1, nsentences=8, sample_size=337.1, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=988.8, ups=2.93, wpb=337.1, bsz=8, num_updates=9360, lr=9.15744e-05, gnorm=2.179, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=3195
2023-03-15 14:53:01 - progress_bar.py[line:272] - INFO: epoch 005:   1413 / 2004 loss=0.967, loss_v1=0, loss_v2=0, nll_loss=0.967, ntokens=378.6, nsentences=8, sample_size=378.6, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=1086.3, ups=2.87, wpb=378.6, bsz=8, num_updates=9370, lr=9.15643e-05, gnorm=2.299, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=3199
2023-03-15 14:53:04 - progress_bar.py[line:272] - INFO: epoch 005:   1423 / 2004 loss=0.821, loss_v1=0, loss_v2=0, nll_loss=0.821, ntokens=317.9, nsentences=8, sample_size=317.9, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=933.1, ups=2.94, wpb=317.9, bsz=8, num_updates=9380, lr=9.15543e-05, gnorm=2.22, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=3202
2023-03-15 14:53:08 - progress_bar.py[line:272] - INFO: epoch 005:   1433 / 2004 loss=0.9, loss_v1=0, loss_v2=0, nll_loss=0.9, ntokens=347.9, nsentences=8, sample_size=347.9, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=988.9, ups=2.84, wpb=347.9, bsz=8, num_updates=9390, lr=9.15442e-05, gnorm=2.304, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=3206
2023-03-15 14:53:11 - progress_bar.py[line:272] - INFO: epoch 005:   1443 / 2004 loss=0.9, loss_v1=0, loss_v2=0, nll_loss=0.9, ntokens=340.6, nsentences=8, sample_size=340.6, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=999.9, ups=2.94, wpb=340.6, bsz=8, num_updates=9400, lr=9.15341e-05, gnorm=2.319, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=3209
2023-03-15 14:53:15 - progress_bar.py[line:272] - INFO: epoch 005:   1453 / 2004 loss=0.927, loss_v1=0, loss_v2=0, nll_loss=0.927, ntokens=353.2, nsentences=8, sample_size=353.2, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=1039.1, ups=2.94, wpb=353.2, bsz=8, num_updates=9410, lr=9.1524e-05, gnorm=2.303, clip=0, loss_scale=1024, train_wall=3, gb_free=12.5, wall=3212
2023-03-15 14:53:18 - progress_bar.py[line:272] - INFO: epoch 005:   1463 / 2004 loss=0.958, loss_v1=0, loss_v2=0, nll_loss=0.958, ntokens=382.5, nsentences=8, sample_size=382.5, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=1126, ups=2.94, wpb=382.5, bsz=8, num_updates=9420, lr=9.15139e-05, gnorm=2.314, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=3216
2023-03-15 14:53:22 - progress_bar.py[line:272] - INFO: epoch 005:   1473 / 2004 loss=0.868, loss_v1=0, loss_v2=0, nll_loss=0.868, ntokens=400.9, nsentences=8, sample_size=400.9, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=1163.5, ups=2.9, wpb=400.9, bsz=8, num_updates=9430, lr=9.15039e-05, gnorm=2.155, clip=0, loss_scale=1024, train_wall=3, gb_free=14.2, wall=3219
2023-03-15 14:53:25 - progress_bar.py[line:272] - INFO: epoch 005:   1483 / 2004 loss=0.892, loss_v1=0, loss_v2=0, nll_loss=0.892, ntokens=370.3, nsentences=8, sample_size=370.3, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=1067.6, ups=2.88, wpb=370.3, bsz=8, num_updates=9440, lr=9.14938e-05, gnorm=2.261, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=3223
2023-03-15 14:53:28 - progress_bar.py[line:272] - INFO: epoch 005:   1493 / 2004 loss=0.852, loss_v1=0, loss_v2=0, nll_loss=0.852, ntokens=310.3, nsentences=8, sample_size=310.3, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=933.4, ups=3.01, wpb=310.3, bsz=8, num_updates=9450, lr=9.14837e-05, gnorm=2.395, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=3226
2023-03-15 14:53:32 - progress_bar.py[line:272] - INFO: epoch 005:   1503 / 2004 loss=0.884, loss_v1=0, loss_v2=0, nll_loss=0.884, ntokens=341.9, nsentences=8, sample_size=341.9, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=1010, ups=2.95, wpb=341.9, bsz=8, num_updates=9460, lr=9.14736e-05, gnorm=2.349, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=3229
2023-03-15 14:53:35 - progress_bar.py[line:272] - INFO: epoch 005:   1513 / 2004 loss=0.827, loss_v1=0, loss_v2=0, nll_loss=0.827, ntokens=333.6, nsentences=8, sample_size=333.6, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=987.2, ups=2.96, wpb=333.6, bsz=8, num_updates=9470, lr=9.14635e-05, gnorm=2.311, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=3233
2023-03-15 14:53:39 - progress_bar.py[line:272] - INFO: epoch 005:   1523 / 2004 loss=0.837, loss_v1=0, loss_v2=0, nll_loss=0.837, ntokens=327.5, nsentences=8, sample_size=327.5, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=974.2, ups=2.97, wpb=327.5, bsz=8, num_updates=9480, lr=9.14535e-05, gnorm=2.362, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=3236
2023-03-15 14:53:42 - progress_bar.py[line:272] - INFO: epoch 005:   1533 / 2004 loss=0.893, loss_v1=0, loss_v2=0, nll_loss=0.893, ntokens=356.6, nsentences=8, sample_size=356.6, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=1043.3, ups=2.93, wpb=356.6, bsz=8, num_updates=9490, lr=9.14434e-05, gnorm=2.333, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=3240
2023-03-15 14:53:45 - progress_bar.py[line:272] - INFO: epoch 005:   1543 / 2004 loss=0.796, loss_v1=0, loss_v2=0, nll_loss=0.796, ntokens=316.9, nsentences=8, sample_size=316.9, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=934, ups=2.95, wpb=316.9, bsz=8, num_updates=9500, lr=9.14333e-05, gnorm=2.333, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=3243
2023-03-15 14:53:49 - progress_bar.py[line:272] - INFO: epoch 005:   1553 / 2004 loss=0.831, loss_v1=0, loss_v2=0, nll_loss=0.831, ntokens=321.4, nsentences=8, sample_size=321.4, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=932.7, ups=2.9, wpb=321.4, bsz=8, num_updates=9510, lr=9.14232e-05, gnorm=2.251, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=3246
2023-03-15 14:53:52 - progress_bar.py[line:272] - INFO: epoch 005:   1563 / 2004 loss=0.846, loss_v1=0, loss_v2=0, nll_loss=0.846, ntokens=360.8, nsentences=8, sample_size=360.8, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=1031.1, ups=2.86, wpb=360.8, bsz=8, num_updates=9520, lr=9.14131e-05, gnorm=2.249, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=3250
2023-03-15 14:53:56 - progress_bar.py[line:272] - INFO: epoch 005:   1573 / 2004 loss=0.82, loss_v1=0, loss_v2=0, nll_loss=0.82, ntokens=333.8, nsentences=8, sample_size=333.8, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=950.1, ups=2.85, wpb=333.8, bsz=8, num_updates=9530, lr=9.14031e-05, gnorm=2.26, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=3253
2023-03-15 14:53:59 - progress_bar.py[line:272] - INFO: epoch 005:   1583 / 2004 loss=0.837, loss_v1=0, loss_v2=0, nll_loss=0.837, ntokens=340.7, nsentences=8, sample_size=340.7, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=999.7, ups=2.93, wpb=340.7, bsz=8, num_updates=9540, lr=9.1393e-05, gnorm=2.201, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=3257
2023-03-15 14:54:03 - progress_bar.py[line:272] - INFO: epoch 005:   1593 / 2004 loss=0.92, loss_v1=0, loss_v2=0, nll_loss=0.92, ntokens=353.8, nsentences=8, sample_size=353.8, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=1049.8, ups=2.97, wpb=353.8, bsz=8, num_updates=9550, lr=9.13829e-05, gnorm=2.386, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=3260
2023-03-15 14:54:06 - progress_bar.py[line:272] - INFO: epoch 005:   1603 / 2004 loss=0.769, loss_v1=0, loss_v2=0, nll_loss=0.769, ntokens=330.8, nsentences=8, sample_size=330.8, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=980.1, ups=2.96, wpb=330.8, bsz=8, num_updates=9560, lr=9.13728e-05, gnorm=2.195, clip=0, loss_scale=2048, train_wall=3, gb_free=13.8, wall=3264
2023-03-15 14:54:09 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 14:54:10 - progress_bar.py[line:272] - INFO: epoch 005:   1614 / 2004 loss=0.844, loss_v1=0, loss_v2=0, nll_loss=0.844, ntokens=351.9, nsentences=8, sample_size=351.9, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=955.9, ups=2.72, wpb=351.9, bsz=8, num_updates=9570, lr=9.13627e-05, gnorm=2.252, clip=0, loss_scale=2048, train_wall=4, gb_free=14.8, wall=3267
2023-03-15 14:54:13 - progress_bar.py[line:272] - INFO: epoch 005:   1624 / 2004 loss=0.929, loss_v1=0, loss_v2=0, nll_loss=0.929, ntokens=345.8, nsentences=8, sample_size=345.8, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=1016.8, ups=2.94, wpb=345.8, bsz=8, num_updates=9580, lr=9.13526e-05, gnorm=2.378, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=3271
2023-03-15 14:54:16 - progress_bar.py[line:272] - INFO: epoch 005:   1634 / 2004 loss=0.875, loss_v1=0, loss_v2=0, nll_loss=0.875, ntokens=338.9, nsentences=8, sample_size=338.9, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=1001.3, ups=2.95, wpb=338.9, bsz=8, num_updates=9590, lr=9.13426e-05, gnorm=2.357, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=3274
2023-03-15 14:54:20 - progress_bar.py[line:272] - INFO: epoch 005:   1644 / 2004 loss=0.825, loss_v1=0, loss_v2=0, nll_loss=0.825, ntokens=309.4, nsentences=8, sample_size=309.4, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=912.3, ups=2.95, wpb=309.4, bsz=8, num_updates=9600, lr=9.13325e-05, gnorm=2.362, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=3277
2023-03-15 14:54:23 - progress_bar.py[line:272] - INFO: epoch 005:   1654 / 2004 loss=0.878, loss_v1=0, loss_v2=0, nll_loss=0.878, ntokens=338.6, nsentences=8, sample_size=338.6, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=1012.7, ups=2.99, wpb=338.6, bsz=8, num_updates=9610, lr=9.13224e-05, gnorm=2.343, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=3281
2023-03-15 14:54:27 - progress_bar.py[line:272] - INFO: epoch 005:   1664 / 2004 loss=0.851, loss_v1=0, loss_v2=0, nll_loss=0.851, ntokens=358.4, nsentences=8, sample_size=358.4, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=1048, ups=2.92, wpb=358.4, bsz=8, num_updates=9620, lr=9.13123e-05, gnorm=2.339, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=3284
2023-03-15 14:54:30 - progress_bar.py[line:272] - INFO: epoch 005:   1674 / 2004 loss=0.925, loss_v1=0, loss_v2=0, nll_loss=0.925, ntokens=316.3, nsentences=8, sample_size=316.3, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=946.8, ups=2.99, wpb=316.3, bsz=8, num_updates=9630, lr=9.13022e-05, gnorm=2.438, clip=0, loss_scale=2048, train_wall=3, gb_free=15.9, wall=3288
2023-03-15 14:54:33 - progress_bar.py[line:272] - INFO: epoch 005:   1684 / 2004 loss=0.862, loss_v1=0, loss_v2=0, nll_loss=0.862, ntokens=349.4, nsentences=8, sample_size=349.4, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=1036.5, ups=2.97, wpb=349.4, bsz=8, num_updates=9640, lr=9.12922e-05, gnorm=2.291, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=3291
2023-03-15 14:54:37 - progress_bar.py[line:272] - INFO: epoch 005:   1694 / 2004 loss=0.883, loss_v1=0, loss_v2=0, nll_loss=0.883, ntokens=338.3, nsentences=8, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=1009.2, ups=2.98, wpb=338.3, bsz=8, num_updates=9650, lr=9.12821e-05, gnorm=2.4, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=3294
2023-03-15 14:54:40 - progress_bar.py[line:272] - INFO: epoch 005:   1704 / 2004 loss=0.76, loss_v1=0, loss_v2=0, nll_loss=0.76, ntokens=334.7, nsentences=8, sample_size=334.7, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=996, ups=2.98, wpb=334.7, bsz=8, num_updates=9660, lr=9.1272e-05, gnorm=2.168, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=3298
2023-03-15 14:54:43 - progress_bar.py[line:272] - INFO: epoch 005:   1714 / 2004 loss=1.005, loss_v1=0, loss_v2=0, nll_loss=1.005, ntokens=364, nsentences=8, sample_size=364, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=1057.9, ups=2.91, wpb=364, bsz=8, num_updates=9670, lr=9.12619e-05, gnorm=2.478, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=3301
2023-03-15 14:54:47 - progress_bar.py[line:272] - INFO: epoch 005:   1724 / 2004 loss=0.828, loss_v1=0, loss_v2=0, nll_loss=0.828, ntokens=380.9, nsentences=8, sample_size=380.9, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=1121.5, ups=2.94, wpb=380.9, bsz=8, num_updates=9680, lr=9.12518e-05, gnorm=2.199, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=3305
2023-03-15 14:54:50 - progress_bar.py[line:272] - INFO: epoch 005:   1734 / 2004 loss=0.883, loss_v1=0, loss_v2=0, nll_loss=0.883, ntokens=350.8, nsentences=8, sample_size=350.8, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=1045.8, ups=2.98, wpb=350.8, bsz=8, num_updates=9690, lr=9.12418e-05, gnorm=2.295, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=3308
2023-03-15 14:54:53 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 14:54:54 - progress_bar.py[line:272] - INFO: epoch 005:   1745 / 2004 loss=0.849, loss_v1=0, loss_v2=0, nll_loss=0.849, ntokens=342.4, nsentences=8, sample_size=342.4, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=930.9, ups=2.72, wpb=342.4, bsz=8, num_updates=9700, lr=9.12317e-05, gnorm=2.329, clip=0, loss_scale=2048, train_wall=4, gb_free=15.2, wall=3312
2023-03-15 14:54:57 - progress_bar.py[line:272] - INFO: epoch 005:   1755 / 2004 loss=0.872, loss_v1=0, loss_v2=0, nll_loss=0.872, ntokens=348.1, nsentences=8, sample_size=348.1, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=1012.6, ups=2.91, wpb=348.1, bsz=8, num_updates=9710, lr=9.12216e-05, gnorm=2.272, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=3315
2023-03-15 14:55:01 - progress_bar.py[line:272] - INFO: epoch 005:   1765 / 2004 loss=0.911, loss_v1=0, loss_v2=0, nll_loss=0.911, ntokens=308.7, nsentences=8, sample_size=308.7, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=909.1, ups=2.94, wpb=308.7, bsz=8, num_updates=9720, lr=9.12115e-05, gnorm=2.511, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=3318
2023-03-15 14:55:04 - progress_bar.py[line:272] - INFO: epoch 005:   1775 / 2004 loss=0.898, loss_v1=0, loss_v2=0, nll_loss=0.898, ntokens=349.2, nsentences=8, sample_size=349.2, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=1014.2, ups=2.9, wpb=349.2, bsz=8, num_updates=9730, lr=9.12014e-05, gnorm=2.342, clip=0, loss_scale=2048, train_wall=3, gb_free=13.5, wall=3322
2023-03-15 14:55:08 - progress_bar.py[line:272] - INFO: epoch 005:   1785 / 2004 loss=0.857, loss_v1=0, loss_v2=0, nll_loss=0.857, ntokens=315, nsentences=8, sample_size=315, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=943.6, ups=3, wpb=315, bsz=8, num_updates=9740, lr=9.11914e-05, gnorm=2.4, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=3325
2023-03-15 14:55:11 - progress_bar.py[line:272] - INFO: epoch 005:   1795 / 2004 loss=0.832, loss_v1=0, loss_v2=0, nll_loss=0.832, ntokens=319.8, nsentences=8, sample_size=319.8, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=1050.8, ups=3.29, wpb=319.8, bsz=8, num_updates=9750, lr=9.11813e-05, gnorm=2.355, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=3328
2023-03-15 14:55:14 - progress_bar.py[line:272] - INFO: epoch 005:   1805 / 2004 loss=0.97, loss_v1=0, loss_v2=0, nll_loss=0.97, ntokens=353.2, nsentences=8, sample_size=353.2, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=1164.5, ups=3.3, wpb=353.2, bsz=8, num_updates=9760, lr=9.11712e-05, gnorm=2.486, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=3331
2023-03-15 14:55:17 - progress_bar.py[line:272] - INFO: epoch 005:   1815 / 2004 loss=0.887, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=359.4, nsentences=8, sample_size=359.4, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=1172.2, ups=3.26, wpb=359.4, bsz=8, num_updates=9770, lr=9.11611e-05, gnorm=2.37, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=3334
2023-03-15 14:55:20 - progress_bar.py[line:272] - INFO: epoch 005:   1825 / 2004 loss=0.785, loss_v1=0, loss_v2=0, nll_loss=0.785, ntokens=356.8, nsentences=8, sample_size=356.8, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=1154.3, ups=3.24, wpb=356.8, bsz=8, num_updates=9780, lr=9.1151e-05, gnorm=2.196, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=3337
2023-03-15 14:55:23 - progress_bar.py[line:272] - INFO: epoch 005:   1835 / 2004 loss=0.843, loss_v1=0, loss_v2=0, nll_loss=0.843, ntokens=333.7, nsentences=8, sample_size=333.7, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=1069.7, ups=3.21, wpb=333.7, bsz=8, num_updates=9790, lr=9.1141e-05, gnorm=2.285, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=3341
2023-03-15 14:55:26 - progress_bar.py[line:272] - INFO: epoch 005:   1845 / 2004 loss=0.879, loss_v1=0, loss_v2=0, nll_loss=0.879, ntokens=354.7, nsentences=8, sample_size=354.7, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=1146.7, ups=3.23, wpb=354.7, bsz=8, num_updates=9800, lr=9.11309e-05, gnorm=2.321, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=3344
2023-03-15 14:55:29 - progress_bar.py[line:272] - INFO: epoch 005:   1855 / 2004 loss=0.809, loss_v1=0, loss_v2=0, nll_loss=0.809, ntokens=323.3, nsentences=8, sample_size=323.3, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=968.8, ups=3, wpb=323.3, bsz=8, num_updates=9810, lr=9.11208e-05, gnorm=2.244, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=3347
2023-03-15 14:55:33 - progress_bar.py[line:272] - INFO: epoch 005:   1865 / 2004 loss=0.843, loss_v1=0, loss_v2=0, nll_loss=0.843, ntokens=338.8, nsentences=8, sample_size=338.8, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=1061.9, ups=3.13, wpb=338.8, bsz=8, num_updates=9820, lr=9.11107e-05, gnorm=2.31, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=3350
2023-03-15 14:55:34 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 14:55:36 - progress_bar.py[line:272] - INFO: epoch 005:   1876 / 2004 loss=0.782, loss_v1=0, loss_v2=0, nll_loss=0.782, ntokens=333.8, nsentences=8, sample_size=333.8, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=984.5, ups=2.95, wpb=333.8, bsz=8, num_updates=9830, lr=9.11006e-05, gnorm=2.219, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=3354
2023-03-15 14:55:39 - progress_bar.py[line:272] - INFO: epoch 005:   1886 / 2004 loss=0.822, loss_v1=0, loss_v2=0, nll_loss=0.822, ntokens=324, nsentences=8, sample_size=324, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=1004.1, ups=3.1, wpb=324, bsz=8, num_updates=9840, lr=9.10905e-05, gnorm=2.27, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=3357
2023-03-15 14:55:43 - progress_bar.py[line:272] - INFO: epoch 005:   1896 / 2004 loss=0.843, loss_v1=0, loss_v2=0, nll_loss=0.843, ntokens=336.9, nsentences=8, sample_size=336.9, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=985.1, ups=2.92, wpb=336.9, bsz=8, num_updates=9850, lr=9.10805e-05, gnorm=2.315, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=3360
2023-03-15 14:55:46 - progress_bar.py[line:272] - INFO: epoch 005:   1906 / 2004 loss=0.768, loss_v1=0, loss_v2=0, nll_loss=0.768, ntokens=348.4, nsentences=8, sample_size=348.4, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=1020.7, ups=2.93, wpb=348.4, bsz=8, num_updates=9860, lr=9.10704e-05, gnorm=2.235, clip=0, loss_scale=2048, train_wall=3, gb_free=15.9, wall=3364
2023-03-15 14:55:49 - progress_bar.py[line:272] - INFO: epoch 005:   1916 / 2004 loss=0.806, loss_v1=0, loss_v2=0, nll_loss=0.806, ntokens=327.7, nsentences=8, sample_size=327.7, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=986.5, ups=3.01, wpb=327.7, bsz=8, num_updates=9870, lr=9.10603e-05, gnorm=2.348, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=3367
2023-03-15 14:55:53 - progress_bar.py[line:272] - INFO: epoch 005:   1926 / 2004 loss=0.797, loss_v1=0, loss_v2=0, nll_loss=0.797, ntokens=325.2, nsentences=8, sample_size=325.2, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=970.7, ups=2.98, wpb=325.2, bsz=8, num_updates=9880, lr=9.10502e-05, gnorm=2.334, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=3370
2023-03-15 14:55:56 - progress_bar.py[line:272] - INFO: epoch 005:   1936 / 2004 loss=0.776, loss_v1=0, loss_v2=0, nll_loss=0.776, ntokens=336.4, nsentences=8, sample_size=336.4, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=997, ups=2.96, wpb=336.4, bsz=8, num_updates=9890, lr=9.10401e-05, gnorm=2.3, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=3374
2023-03-15 14:55:59 - progress_bar.py[line:272] - INFO: epoch 005:   1946 / 2004 loss=0.869, loss_v1=0, loss_v2=0, nll_loss=0.869, ntokens=358.9, nsentences=8, sample_size=358.9, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=1055.5, ups=2.94, wpb=358.9, bsz=8, num_updates=9900, lr=9.10301e-05, gnorm=2.302, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=3377
2023-03-15 14:56:03 - progress_bar.py[line:272] - INFO: epoch 005:   1956 / 2004 loss=0.747, loss_v1=0, loss_v2=0, nll_loss=0.747, ntokens=348, nsentences=8, sample_size=348, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=1014, ups=2.91, wpb=348, bsz=8, num_updates=9910, lr=9.102e-05, gnorm=2.282, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=3380
2023-03-15 14:56:06 - progress_bar.py[line:272] - INFO: epoch 005:   1966 / 2004 loss=0.81, loss_v1=0, loss_v2=0, nll_loss=0.81, ntokens=356.9, nsentences=8, sample_size=356.9, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=1064.5, ups=2.98, wpb=356.9, bsz=8, num_updates=9920, lr=9.10099e-05, gnorm=2.3, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=3384
2023-03-15 14:56:10 - progress_bar.py[line:272] - INFO: epoch 005:   1976 / 2004 loss=0.827, loss_v1=0, loss_v2=0, nll_loss=0.827, ntokens=340.3, nsentences=8, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=993.2, ups=2.92, wpb=340.3, bsz=8, num_updates=9930, lr=9.09998e-05, gnorm=2.39, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=3387
2023-03-15 14:56:13 - progress_bar.py[line:272] - INFO: epoch 005:   1986 / 2004 loss=0.78, loss_v1=0, loss_v2=0, nll_loss=0.78, ntokens=311.3, nsentences=8, sample_size=311.3, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=912.7, ups=2.93, wpb=311.3, bsz=8, num_updates=9940, lr=9.09897e-05, gnorm=2.388, clip=0, loss_scale=2048, train_wall=3, gb_free=13.5, wall=3391
2023-03-15 14:56:16 - progress_bar.py[line:272] - INFO: epoch 005:   1996 / 2004 loss=0.895, loss_v1=0, loss_v2=0, nll_loss=0.895, ntokens=398.9, nsentences=8, sample_size=398.9, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=1159.3, ups=2.91, wpb=398.9, bsz=8, num_updates=9950, lr=9.09797e-05, gnorm=2.296, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=3394
2023-03-15 14:56:18 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 14:56:19 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 5 @ 9957 updates
2023-03-15 14:56:19 - trainer.py[line:431] - INFO: Saving checkpoint to ./checkpoints/checkpoint5.pt
2023-03-15 14:56:24 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./checkpoints/checkpoint5.pt
2023-03-15 14:56:26 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./checkpoints/checkpoint5.pt (epoch 5 @ 9957 updates, score None) (writing took 7.36640509031713 seconds)
2023-03-15 14:56:26 - train.py[line:332] - INFO: end of epoch 5 (average epoch stats below)
2023-03-15 14:56:26 - progress_bar.py[line:282] - INFO: epoch 005 | loss 0.888 | loss_v1 0 | loss_v2 0 | nll_loss 0.888 | ntokens 345.304 | nsentences 7.999 | sample_size 345.304 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.85 | wps 998.4 | ups 2.89 | wpb 345.3 | bsz 8 | num_updates 9957 | lr 9.09726e-05 | gnorm 2.239 | clip 0 | loss_scale 2048 | train_wall 668 | gb_free 14.4 | wall 3404
2023-03-15 14:56:26 - trainer.py[line:639] - INFO: loading train data for epoch 6
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 row count 8015 total row count 8015
slice_id 0 seek offset 0
2023-03-15 14:56:27 - trainer.py[line:703] - INFO: begin training epoch 6
2023-03-15 14:56:27 - train.py[line:305] - INFO: Start iterating over samples
2023-03-15 14:56:28 - progress_bar.py[line:272] - INFO: epoch 006:      3 / 2004 loss=0.909, loss_v1=0, loss_v2=0, nll_loss=0.909, ntokens=370.6, nsentences=8, sample_size=370.6, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=312.3, ups=0.84, wpb=370.6, bsz=8, num_updates=9960, lr=9.09696e-05, gnorm=2.386, clip=0, loss_scale=2048, train_wall=4, gb_free=15.3, wall=3406
2023-03-15 14:56:32 - progress_bar.py[line:272] - INFO: epoch 006:     13 / 2004 loss=0.843, loss_v1=0, loss_v2=0, nll_loss=0.843, ntokens=327, nsentences=8, sample_size=327, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=973.5, ups=2.98, wpb=327, bsz=8, num_updates=9970, lr=9.09595e-05, gnorm=2.352, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=3409
2023-03-15 14:56:35 - progress_bar.py[line:272] - INFO: epoch 006:     23 / 2004 loss=0.841, loss_v1=0, loss_v2=0, nll_loss=0.841, ntokens=357.1, nsentences=8, sample_size=357.1, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=1065.5, ups=2.98, wpb=357.1, bsz=8, num_updates=9980, lr=9.09494e-05, gnorm=2.262, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=3413
2023-03-15 14:56:38 - progress_bar.py[line:272] - INFO: epoch 006:     33 / 2004 loss=0.911, loss_v1=0, loss_v2=0, nll_loss=0.911, ntokens=361.3, nsentences=8, sample_size=361.3, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=1070.2, ups=2.96, wpb=361.3, bsz=8, num_updates=9990, lr=9.09393e-05, gnorm=2.41, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=3416
2023-03-15 14:56:42 - progress_bar.py[line:272] - INFO: epoch 006:     43 / 2004 loss=0.853, loss_v1=0, loss_v2=0, nll_loss=0.853, ntokens=353.2, nsentences=8, sample_size=353.2, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=1059.1, ups=3, wpb=353.2, bsz=8, num_updates=10000, lr=9.09293e-05, gnorm=2.391, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=3419
2023-03-15 14:56:45 - progress_bar.py[line:272] - INFO: epoch 006:     53 / 2004 loss=0.819, loss_v1=0, loss_v2=0, nll_loss=0.819, ntokens=344.3, nsentences=8, sample_size=344.3, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=1071.1, ups=3.11, wpb=344.3, bsz=8, num_updates=10010, lr=9.09192e-05, gnorm=2.272, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=3423
2023-03-15 14:56:48 - progress_bar.py[line:272] - INFO: epoch 006:     63 / 2004 loss=0.861, loss_v1=0, loss_v2=0, nll_loss=0.861, ntokens=338.5, nsentences=8, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=1097.9, ups=3.24, wpb=338.5, bsz=8, num_updates=10020, lr=9.09091e-05, gnorm=2.422, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=3426
2023-03-15 14:56:51 - progress_bar.py[line:272] - INFO: epoch 006:     73 / 2004 loss=0.891, loss_v1=0, loss_v2=0, nll_loss=0.891, ntokens=348.7, nsentences=8, sample_size=348.7, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=1131.2, ups=3.24, wpb=348.7, bsz=8, num_updates=10030, lr=9.0899e-05, gnorm=2.379, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=3429
2023-03-15 14:56:54 - progress_bar.py[line:272] - INFO: epoch 006:     83 / 2004 loss=0.808, loss_v1=0, loss_v2=0, nll_loss=0.808, ntokens=328.5, nsentences=8, sample_size=328.5, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=1068.4, ups=3.25, wpb=328.5, bsz=8, num_updates=10040, lr=9.08889e-05, gnorm=2.322, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=3432
2023-03-15 14:56:57 - progress_bar.py[line:272] - INFO: epoch 006:     93 / 2004 loss=0.901, loss_v1=0, loss_v2=0, nll_loss=0.901, ntokens=369.6, nsentences=8, sample_size=369.6, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=1181.3, ups=3.2, wpb=369.6, bsz=8, num_updates=10050, lr=9.08788e-05, gnorm=2.258, clip=0, loss_scale=2048, train_wall=3, gb_free=12.9, wall=3435
2023-03-15 14:57:00 - progress_bar.py[line:272] - INFO: epoch 006:    103 / 2004 loss=0.833, loss_v1=0, loss_v2=0, nll_loss=0.833, ntokens=367.3, nsentences=8, sample_size=367.3, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=1193, ups=3.25, wpb=367.3, bsz=8, num_updates=10060, lr=9.08688e-05, gnorm=2.325, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=3438
2023-03-15 14:57:03 - progress_bar.py[line:272] - INFO: epoch 006:    113 / 2004 loss=0.851, loss_v1=0, loss_v2=0, nll_loss=0.851, ntokens=339.8, nsentences=8, sample_size=339.8, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=1119.4, ups=3.29, wpb=339.8, bsz=8, num_updates=10070, lr=9.08587e-05, gnorm=2.367, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=3441
2023-03-15 14:57:07 - progress_bar.py[line:272] - INFO: epoch 006:    123 / 2004 loss=0.9, loss_v1=0, loss_v2=0, nll_loss=0.9, ntokens=349.4, nsentences=8, sample_size=349.4, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=1067.2, ups=3.05, wpb=349.4, bsz=8, num_updates=10080, lr=9.08486e-05, gnorm=2.334, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=3444
2023-03-15 14:57:10 - progress_bar.py[line:272] - INFO: epoch 006:    133 / 2004 loss=0.781, loss_v1=0, loss_v2=0, nll_loss=0.781, ntokens=316.1, nsentences=8, sample_size=316.1, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=964.9, ups=3.05, wpb=316.1, bsz=8, num_updates=10090, lr=9.08385e-05, gnorm=2.309, clip=0, loss_scale=4096, train_wall=3, gb_free=14.9, wall=3448
2023-03-15 14:57:11 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 14:57:14 - progress_bar.py[line:272] - INFO: epoch 006:    144 / 2004 loss=0.855, loss_v1=0, loss_v2=0, nll_loss=0.855, ntokens=340.1, nsentences=8, sample_size=340.1, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=943.3, ups=2.77, wpb=340.1, bsz=8, num_updates=10100, lr=9.08284e-05, gnorm=2.318, clip=0, loss_scale=2048, train_wall=4, gb_free=15.1, wall=3451
2023-03-15 14:57:17 - progress_bar.py[line:272] - INFO: epoch 006:    154 / 2004 loss=0.845, loss_v1=0, loss_v2=0, nll_loss=0.845, ntokens=328.5, nsentences=8, sample_size=328.5, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=981.7, ups=2.99, wpb=328.5, bsz=8, num_updates=10110, lr=9.08184e-05, gnorm=2.415, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=3455
2023-03-15 14:57:20 - progress_bar.py[line:272] - INFO: epoch 006:    164 / 2004 loss=0.8, loss_v1=0, loss_v2=0, nll_loss=0.8, ntokens=356.8, nsentences=8, sample_size=356.8, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=1041.7, ups=2.92, wpb=356.8, bsz=8, num_updates=10120, lr=9.08083e-05, gnorm=2.174, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=3458
2023-03-15 14:57:24 - progress_bar.py[line:272] - INFO: epoch 006:    174 / 2004 loss=0.783, loss_v1=0, loss_v2=0, nll_loss=0.783, ntokens=336.7, nsentences=8, sample_size=336.7, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=1007.5, ups=2.99, wpb=336.7, bsz=8, num_updates=10130, lr=9.07982e-05, gnorm=2.236, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=3461
2023-03-15 14:57:27 - progress_bar.py[line:272] - INFO: epoch 006:    184 / 2004 loss=0.77, loss_v1=0, loss_v2=0, nll_loss=0.77, ntokens=328.6, nsentences=8, sample_size=328.6, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=984.4, ups=3, wpb=328.6, bsz=8, num_updates=10140, lr=9.07881e-05, gnorm=2.3, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=3465
2023-03-15 14:57:30 - progress_bar.py[line:272] - INFO: epoch 006:    194 / 2004 loss=0.731, loss_v1=0, loss_v2=0, nll_loss=0.731, ntokens=334.4, nsentences=8, sample_size=334.4, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=993.5, ups=2.97, wpb=334.4, bsz=8, num_updates=10150, lr=9.0778e-05, gnorm=2.205, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=3468
2023-03-15 14:57:34 - progress_bar.py[line:272] - INFO: epoch 006:    204 / 2004 loss=0.846, loss_v1=0, loss_v2=0, nll_loss=0.846, ntokens=327.4, nsentences=8, sample_size=327.4, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=1013, ups=3.09, wpb=327.4, bsz=8, num_updates=10160, lr=9.0768e-05, gnorm=2.421, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=3471
2023-03-15 14:57:37 - progress_bar.py[line:272] - INFO: epoch 006:    214 / 2004 loss=0.792, loss_v1=0, loss_v2=0, nll_loss=0.792, ntokens=332.9, nsentences=8, sample_size=332.9, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=1024.3, ups=3.08, wpb=332.9, bsz=8, num_updates=10170, lr=9.07579e-05, gnorm=2.323, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=3475
2023-03-15 14:57:40 - progress_bar.py[line:272] - INFO: epoch 006:    224 / 2004 loss=0.719, loss_v1=0, loss_v2=0, nll_loss=0.719, ntokens=330.7, nsentences=8, sample_size=330.7, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=993, ups=3, wpb=330.7, bsz=8, num_updates=10180, lr=9.07478e-05, gnorm=2.26, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=3478
2023-03-15 14:57:44 - progress_bar.py[line:272] - INFO: epoch 006:    234 / 2004 loss=0.841, loss_v1=0, loss_v2=0, nll_loss=0.841, ntokens=373.2, nsentences=8, sample_size=373.2, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=1055.7, ups=2.83, wpb=373.2, bsz=8, num_updates=10190, lr=9.07377e-05, gnorm=2.334, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=3481
2023-03-15 14:57:47 - progress_bar.py[line:272] - INFO: epoch 006:    244 / 2004 loss=0.843, loss_v1=0, loss_v2=0, nll_loss=0.843, ntokens=354.4, nsentences=8, sample_size=354.4, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=1034.4, ups=2.92, wpb=354.4, bsz=8, num_updates=10200, lr=9.07276e-05, gnorm=2.354, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=3485
2023-03-15 14:57:51 - progress_bar.py[line:272] - INFO: epoch 006:    254 / 2004 loss=0.728, loss_v1=0, loss_v2=0, nll_loss=0.728, ntokens=337.2, nsentences=8, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=981.8, ups=2.91, wpb=337.2, bsz=8, num_updates=10210, lr=9.07176e-05, gnorm=2.232, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=3488
2023-03-15 14:57:54 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 14:57:54 - progress_bar.py[line:272] - INFO: epoch 006:    265 / 2004 loss=0.858, loss_v1=0, loss_v2=0, nll_loss=0.858, ntokens=343.1, nsentences=8, sample_size=343.1, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=902.8, ups=2.63, wpb=343.1, bsz=8, num_updates=10220, lr=9.07075e-05, gnorm=2.397, clip=0, loss_scale=2048, train_wall=4, gb_free=14.1, wall=3492
2023-03-15 14:57:58 - progress_bar.py[line:272] - INFO: epoch 006:    275 / 2004 loss=0.786, loss_v1=0, loss_v2=0, nll_loss=0.786, ntokens=330.2, nsentences=8, sample_size=330.2, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=979.3, ups=2.97, wpb=330.2, bsz=8, num_updates=10230, lr=9.06974e-05, gnorm=2.255, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=3495
2023-03-15 14:58:01 - progress_bar.py[line:272] - INFO: epoch 006:    285 / 2004 loss=0.825, loss_v1=0, loss_v2=0, nll_loss=0.825, ntokens=376.6, nsentences=8, sample_size=376.6, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=1081.9, ups=2.87, wpb=376.6, bsz=8, num_updates=10240, lr=9.06873e-05, gnorm=2.23, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=3499
2023-03-15 14:58:05 - progress_bar.py[line:272] - INFO: epoch 006:    295 / 2004 loss=0.853, loss_v1=0, loss_v2=0, nll_loss=0.853, ntokens=351.5, nsentences=8, sample_size=351.5, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=1046.7, ups=2.98, wpb=351.5, bsz=8, num_updates=10250, lr=9.06772e-05, gnorm=2.255, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=3502
2023-03-15 14:58:08 - progress_bar.py[line:272] - INFO: epoch 006:    305 / 2004 loss=0.823, loss_v1=0, loss_v2=0, nll_loss=0.823, ntokens=352.2, nsentences=8, sample_size=352.2, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=1030.8, ups=2.93, wpb=352.2, bsz=8, num_updates=10260, lr=9.06672e-05, gnorm=2.334, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=3506
2023-03-15 14:58:11 - progress_bar.py[line:272] - INFO: epoch 006:    315 / 2004 loss=0.843, loss_v1=0, loss_v2=0, nll_loss=0.843, ntokens=356.3, nsentences=8, sample_size=356.3, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=1105.2, ups=3.1, wpb=356.3, bsz=8, num_updates=10270, lr=9.06571e-05, gnorm=2.355, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=3509
2023-03-15 14:58:14 - progress_bar.py[line:272] - INFO: epoch 006:    325 / 2004 loss=0.775, loss_v1=0, loss_v2=0, nll_loss=0.775, ntokens=325.9, nsentences=8, sample_size=325.9, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=1051.8, ups=3.23, wpb=325.9, bsz=8, num_updates=10280, lr=9.0647e-05, gnorm=2.314, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=3512
2023-03-15 14:58:18 - progress_bar.py[line:272] - INFO: epoch 006:    335 / 2004 loss=0.82, loss_v1=0, loss_v2=0, nll_loss=0.82, ntokens=320.6, nsentences=8, sample_size=320.6, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=965.1, ups=3.01, wpb=320.6, bsz=8, num_updates=10290, lr=9.06369e-05, gnorm=2.463, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=3515
2023-03-15 14:58:21 - progress_bar.py[line:272] - INFO: epoch 006:    345 / 2004 loss=0.915, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=388.7, nsentences=8, sample_size=388.7, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=1124.6, ups=2.89, wpb=388.7, bsz=8, num_updates=10300, lr=9.06268e-05, gnorm=2.314, clip=0, loss_scale=2048, train_wall=3, gb_free=13.9, wall=3519
2023-03-15 14:58:25 - progress_bar.py[line:272] - INFO: epoch 006:    355 / 2004 loss=0.872, loss_v1=0, loss_v2=0, nll_loss=0.872, ntokens=337.5, nsentences=8, sample_size=337.5, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=1007.6, ups=2.99, wpb=337.5, bsz=8, num_updates=10310, lr=9.06167e-05, gnorm=2.514, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=3522
2023-03-15 14:58:28 - progress_bar.py[line:272] - INFO: epoch 006:    365 / 2004 loss=0.839, loss_v1=0, loss_v2=0, nll_loss=0.839, ntokens=355.8, nsentences=8, sample_size=355.8, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=1039.6, ups=2.92, wpb=355.8, bsz=8, num_updates=10320, lr=9.06067e-05, gnorm=2.369, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=3526
2023-03-15 14:58:31 - progress_bar.py[line:272] - INFO: epoch 006:    375 / 2004 loss=0.769, loss_v1=0, loss_v2=0, nll_loss=0.769, ntokens=319.3, nsentences=8, sample_size=319.3, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=937.1, ups=2.93, wpb=319.3, bsz=8, num_updates=10330, lr=9.05966e-05, gnorm=2.324, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=3529
2023-03-15 14:58:35 - progress_bar.py[line:272] - INFO: epoch 006:    385 / 2004 loss=0.816, loss_v1=0, loss_v2=0, nll_loss=0.816, ntokens=326.1, nsentences=8, sample_size=326.1, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=967.7, ups=2.97, wpb=326.1, bsz=8, num_updates=10340, lr=9.05865e-05, gnorm=2.404, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=3532
2023-03-15 14:58:38 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 14:58:39 - progress_bar.py[line:272] - INFO: epoch 006:    396 / 2004 loss=0.827, loss_v1=0, loss_v2=0, nll_loss=0.827, ntokens=339, nsentences=8, sample_size=339, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=888.7, ups=2.62, wpb=339, bsz=8, num_updates=10350, lr=9.05764e-05, gnorm=2.372, clip=0, loss_scale=2048, train_wall=4, gb_free=15.4, wall=3536
2023-03-15 14:58:42 - progress_bar.py[line:272] - INFO: epoch 006:    406 / 2004 loss=0.794, loss_v1=0, loss_v2=0, nll_loss=0.794, ntokens=381.7, nsentences=8, sample_size=381.7, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=1094.1, ups=2.87, wpb=381.7, bsz=8, num_updates=10360, lr=9.05663e-05, gnorm=2.268, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=3540
2023-03-15 14:58:45 - progress_bar.py[line:272] - INFO: epoch 006:    416 / 2004 loss=0.793, loss_v1=0, loss_v2=0, nll_loss=0.793, ntokens=339.3, nsentences=8, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=1110.6, ups=3.27, wpb=339.3, bsz=8, num_updates=10370, lr=9.05563e-05, gnorm=2.392, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=3543
2023-03-15 14:58:48 - progress_bar.py[line:272] - INFO: epoch 006:    426 / 2004 loss=0.77, loss_v1=0, loss_v2=0, nll_loss=0.77, ntokens=330.6, nsentences=8, sample_size=330.6, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=1086.7, ups=3.29, wpb=330.6, bsz=8, num_updates=10380, lr=9.05462e-05, gnorm=2.34, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=3546
2023-03-15 14:58:51 - progress_bar.py[line:272] - INFO: epoch 006:    436 / 2004 loss=0.839, loss_v1=0, loss_v2=0, nll_loss=0.839, ntokens=368.1, nsentences=8, sample_size=368.1, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=1161.2, ups=3.15, wpb=368.1, bsz=8, num_updates=10390, lr=9.05361e-05, gnorm=2.358, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=3549
2023-03-15 14:58:54 - progress_bar.py[line:272] - INFO: epoch 006:    446 / 2004 loss=0.88, loss_v1=0, loss_v2=0, nll_loss=0.88, ntokens=362.4, nsentences=8, sample_size=362.4, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=1150.9, ups=3.18, wpb=362.4, bsz=8, num_updates=10400, lr=9.0526e-05, gnorm=2.324, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=3552
2023-03-15 14:58:58 - progress_bar.py[line:272] - INFO: epoch 006:    456 / 2004 loss=0.93, loss_v1=0, loss_v2=0, nll_loss=0.93, ntokens=381.5, nsentences=8, sample_size=381.5, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=1200.8, ups=3.15, wpb=381.5, bsz=8, num_updates=10410, lr=9.05159e-05, gnorm=2.311, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=3555
2023-03-15 14:59:01 - progress_bar.py[line:272] - INFO: epoch 006:    466 / 2004 loss=0.957, loss_v1=0, loss_v2=0, nll_loss=0.957, ntokens=368.6, nsentences=8, sample_size=368.6, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=1089.4, ups=2.96, wpb=368.6, bsz=8, num_updates=10420, lr=9.05059e-05, gnorm=2.511, clip=0, loss_scale=2048, train_wall=3, gb_free=12.4, wall=3559
2023-03-15 14:59:04 - progress_bar.py[line:272] - INFO: epoch 006:    476 / 2004 loss=0.783, loss_v1=0, loss_v2=0, nll_loss=0.783, ntokens=344.6, nsentences=8, sample_size=344.6, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=1004.4, ups=2.91, wpb=344.6, bsz=8, num_updates=10430, lr=9.04958e-05, gnorm=2.257, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=3562
2023-03-15 14:59:08 - progress_bar.py[line:272] - INFO: epoch 006:    486 / 2004 loss=0.779, loss_v1=0, loss_v2=0, nll_loss=0.779, ntokens=375.3, nsentences=8, sample_size=375.3, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=1106.6, ups=2.95, wpb=375.3, bsz=8, num_updates=10440, lr=9.04857e-05, gnorm=2.266, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=3565
2023-03-15 14:59:11 - progress_bar.py[line:272] - INFO: epoch 006:    496 / 2004 loss=0.805, loss_v1=0, loss_v2=0, nll_loss=0.805, ntokens=366.5, nsentences=8, sample_size=366.5, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=1066.3, ups=2.91, wpb=366.5, bsz=8, num_updates=10450, lr=9.04756e-05, gnorm=2.178, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=3569
2023-03-15 14:59:15 - progress_bar.py[line:272] - INFO: epoch 006:    506 / 2004 loss=0.819, loss_v1=0, loss_v2=0, nll_loss=0.819, ntokens=349.6, nsentences=8, sample_size=349.6, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=1041.1, ups=2.98, wpb=349.6, bsz=8, num_updates=10460, lr=9.04655e-05, gnorm=2.327, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=3572
2023-03-15 14:59:18 - progress_bar.py[line:272] - INFO: epoch 006:    516 / 2004 loss=0.865, loss_v1=0, loss_v2=0, nll_loss=0.865, ntokens=352.2, nsentences=8, sample_size=352.2, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=1028.5, ups=2.92, wpb=352.2, bsz=8, num_updates=10470, lr=9.04555e-05, gnorm=2.448, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=3576
2023-03-15 14:59:21 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 14:59:22 - progress_bar.py[line:272] - INFO: epoch 006:    527 / 2004 loss=0.847, loss_v1=0, loss_v2=0, nll_loss=0.847, ntokens=394.1, nsentences=8, sample_size=394.1, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=1028.2, ups=2.61, wpb=394.1, bsz=8, num_updates=10480, lr=9.04454e-05, gnorm=2.232, clip=0, loss_scale=2048, train_wall=4, gb_free=14.2, wall=3580
2023-03-15 14:59:25 - progress_bar.py[line:272] - INFO: epoch 006:    537 / 2004 loss=0.867, loss_v1=0, loss_v2=0, nll_loss=0.867, ntokens=381.1, nsentences=8, sample_size=381.1, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=1114.6, ups=2.92, wpb=381.1, bsz=8, num_updates=10490, lr=9.04353e-05, gnorm=2.262, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=3583
2023-03-15 14:59:29 - progress_bar.py[line:272] - INFO: epoch 006:    547 / 2004 loss=0.806, loss_v1=0, loss_v2=0, nll_loss=0.806, ntokens=352.4, nsentences=8, sample_size=352.4, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=1029.6, ups=2.92, wpb=352.4, bsz=8, num_updates=10500, lr=9.04252e-05, gnorm=2.392, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=3586
2023-03-15 14:59:32 - progress_bar.py[line:272] - INFO: epoch 006:    557 / 2004 loss=0.821, loss_v1=0, loss_v2=0, nll_loss=0.821, ntokens=382, nsentences=8, sample_size=382, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=1104, ups=2.89, wpb=382, bsz=8, num_updates=10510, lr=9.04151e-05, gnorm=2.255, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=3590
2023-03-15 14:59:36 - progress_bar.py[line:272] - INFO: epoch 006:    567 / 2004 loss=0.793, loss_v1=0, loss_v2=0, nll_loss=0.793, ntokens=372.3, nsentences=8, sample_size=372.3, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=1095.6, ups=2.94, wpb=372.3, bsz=8, num_updates=10520, lr=9.0405e-05, gnorm=2.238, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=3593
2023-03-15 14:59:39 - progress_bar.py[line:272] - INFO: epoch 006:    577 / 2004 loss=0.812, loss_v1=0, loss_v2=0, nll_loss=0.812, ntokens=336.7, nsentences=8, sample_size=336.7, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=972.4, ups=2.89, wpb=336.7, bsz=8, num_updates=10530, lr=9.0395e-05, gnorm=2.404, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=3597
2023-03-15 14:59:40 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 14:59:43 - progress_bar.py[line:272] - INFO: epoch 006:    588 / 2004 loss=0.733, loss_v1=0, loss_v2=0, nll_loss=0.733, ntokens=336.9, nsentences=8, sample_size=336.9, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=901.5, ups=2.68, wpb=336.9, bsz=8, num_updates=10540, lr=9.03849e-05, gnorm=2.334, clip=0, loss_scale=1024, train_wall=4, gb_free=14.8, wall=3600
2023-03-15 14:59:46 - progress_bar.py[line:272] - INFO: epoch 006:    598 / 2004 loss=0.814, loss_v1=0, loss_v2=0, nll_loss=0.814, ntokens=334.5, nsentences=8, sample_size=334.5, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=988.5, ups=2.96, wpb=334.5, bsz=8, num_updates=10550, lr=9.03748e-05, gnorm=2.437, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=3604
2023-03-15 14:59:50 - progress_bar.py[line:272] - INFO: epoch 006:    608 / 2004 loss=0.85, loss_v1=0, loss_v2=0, nll_loss=0.85, ntokens=351.9, nsentences=8, sample_size=351.9, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=1018.6, ups=2.89, wpb=351.9, bsz=8, num_updates=10560, lr=9.03647e-05, gnorm=2.374, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=3607
2023-03-15 14:59:53 - progress_bar.py[line:272] - INFO: epoch 006:    618 / 2004 loss=0.749, loss_v1=0, loss_v2=0, nll_loss=0.749, ntokens=354, nsentences=8, sample_size=354, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=1042.3, ups=2.94, wpb=354, bsz=8, num_updates=10570, lr=9.03546e-05, gnorm=2.254, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=3611
2023-03-15 14:59:56 - progress_bar.py[line:272] - INFO: epoch 006:    628 / 2004 loss=0.776, loss_v1=0, loss_v2=0, nll_loss=0.776, ntokens=368.7, nsentences=8, sample_size=368.7, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=1073.1, ups=2.91, wpb=368.7, bsz=8, num_updates=10580, lr=9.03446e-05, gnorm=2.267, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=3614
2023-03-15 15:00:00 - progress_bar.py[line:272] - INFO: epoch 006:    638 / 2004 loss=0.76, loss_v1=0, loss_v2=0, nll_loss=0.76, ntokens=331.9, nsentences=8, sample_size=331.9, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=985.8, ups=2.97, wpb=331.9, bsz=8, num_updates=10590, lr=9.03345e-05, gnorm=2.366, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=3617
2023-03-15 15:00:03 - progress_bar.py[line:272] - INFO: epoch 006:    648 / 2004 loss=0.846, loss_v1=0, loss_v2=0, nll_loss=0.846, ntokens=330.7, nsentences=8, sample_size=330.7, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=969.2, ups=2.93, wpb=330.7, bsz=8, num_updates=10600, lr=9.03244e-05, gnorm=2.501, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=3621
2023-03-15 15:00:07 - progress_bar.py[line:272] - INFO: epoch 006:    658 / 2004 loss=0.876, loss_v1=0, loss_v2=0, nll_loss=0.876, ntokens=352.5, nsentences=8, sample_size=352.5, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=1009.9, ups=2.86, wpb=352.5, bsz=8, num_updates=10610, lr=9.03143e-05, gnorm=2.413, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=3624
2023-03-15 15:00:10 - progress_bar.py[line:272] - INFO: epoch 006:    668 / 2004 loss=0.767, loss_v1=0, loss_v2=0, nll_loss=0.767, ntokens=299.1, nsentences=8, sample_size=299.1, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=889.4, ups=2.97, wpb=299.1, bsz=8, num_updates=10620, lr=9.03042e-05, gnorm=2.474, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=3628
2023-03-15 15:00:14 - progress_bar.py[line:272] - INFO: epoch 006:    678 / 2004 loss=0.771, loss_v1=0, loss_v2=0, nll_loss=0.771, ntokens=343.8, nsentences=8, sample_size=343.8, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=996.9, ups=2.9, wpb=343.8, bsz=8, num_updates=10630, lr=9.02942e-05, gnorm=2.282, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=3631
2023-03-15 15:00:17 - progress_bar.py[line:272] - INFO: epoch 006:    688 / 2004 loss=0.764, loss_v1=0, loss_v2=0, nll_loss=0.764, ntokens=345.4, nsentences=7.8, sample_size=345.4, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=1028.4, ups=2.98, wpb=345.4, bsz=7.8, num_updates=10640, lr=9.02841e-05, gnorm=2.349, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=3635
2023-03-15 15:00:20 - progress_bar.py[line:272] - INFO: epoch 006:    698 / 2004 loss=0.833, loss_v1=0, loss_v2=0, nll_loss=0.833, ntokens=352.9, nsentences=8, sample_size=352.9, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=1039.7, ups=2.95, wpb=352.9, bsz=8, num_updates=10650, lr=9.0274e-05, gnorm=2.424, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=3638
2023-03-15 15:00:24 - progress_bar.py[line:272] - INFO: epoch 006:    708 / 2004 loss=0.824, loss_v1=0, loss_v2=0, nll_loss=0.824, ntokens=331.3, nsentences=8, sample_size=331.3, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=970.2, ups=2.93, wpb=331.3, bsz=8, num_updates=10660, lr=9.02639e-05, gnorm=2.526, clip=0, loss_scale=1024, train_wall=3, gb_free=15.9, wall=3641
2023-03-15 15:00:27 - progress_bar.py[line:272] - INFO: epoch 006:    718 / 2004 loss=0.798, loss_v1=0, loss_v2=0, nll_loss=0.798, ntokens=335.1, nsentences=8, sample_size=335.1, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=992.7, ups=2.96, wpb=335.1, bsz=8, num_updates=10670, lr=9.02538e-05, gnorm=2.415, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=3645
2023-03-15 15:00:31 - progress_bar.py[line:272] - INFO: epoch 006:    728 / 2004 loss=0.867, loss_v1=0, loss_v2=0, nll_loss=0.867, ntokens=361.4, nsentences=8, sample_size=361.4, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=1030.6, ups=2.85, wpb=361.4, bsz=8, num_updates=10680, lr=9.02438e-05, gnorm=2.44, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=3648
2023-03-15 15:00:34 - progress_bar.py[line:272] - INFO: epoch 006:    738 / 2004 loss=0.783, loss_v1=0, loss_v2=0, nll_loss=0.783, ntokens=335.6, nsentences=8, sample_size=335.6, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=999.1, ups=2.98, wpb=335.6, bsz=8, num_updates=10690, lr=9.02337e-05, gnorm=2.351, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=3652
2023-03-15 15:00:37 - progress_bar.py[line:272] - INFO: epoch 006:    748 / 2004 loss=0.814, loss_v1=0, loss_v2=0, nll_loss=0.814, ntokens=363.7, nsentences=8, sample_size=363.7, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=1157.4, ups=3.18, wpb=363.7, bsz=8, num_updates=10700, lr=9.02236e-05, gnorm=2.381, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=3655
2023-03-15 15:00:39 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 15:00:40 - progress_bar.py[line:272] - INFO: epoch 006:    759 / 2004 loss=0.825, loss_v1=0, loss_v2=0, nll_loss=0.825, ntokens=304.2, nsentences=8, sample_size=304.2, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=932, ups=3.06, wpb=304.2, bsz=8, num_updates=10710, lr=9.02135e-05, gnorm=2.585, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=3658
2023-03-15 15:00:44 - progress_bar.py[line:272] - INFO: epoch 006:    769 / 2004 loss=0.924, loss_v1=0, loss_v2=0, nll_loss=0.924, ntokens=410.9, nsentences=8, sample_size=410.9, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=1310.6, ups=3.19, wpb=410.9, bsz=8, num_updates=10720, lr=9.02034e-05, gnorm=2.422, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=3661
2023-03-15 15:00:47 - progress_bar.py[line:272] - INFO: epoch 006:    779 / 2004 loss=0.849, loss_v1=0, loss_v2=0, nll_loss=0.849, ntokens=339.5, nsentences=8, sample_size=339.5, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=1116.7, ups=3.29, wpb=339.5, bsz=8, num_updates=10730, lr=9.01934e-05, gnorm=2.455, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=3664
2023-03-15 15:00:50 - progress_bar.py[line:272] - INFO: epoch 006:    789 / 2004 loss=0.774, loss_v1=0, loss_v2=0, nll_loss=0.774, ntokens=340.1, nsentences=8, sample_size=340.1, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=1066.2, ups=3.14, wpb=340.1, bsz=8, num_updates=10740, lr=9.01833e-05, gnorm=2.338, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=3667
2023-03-15 15:00:53 - progress_bar.py[line:272] - INFO: epoch 006:    799 / 2004 loss=0.734, loss_v1=0, loss_v2=0, nll_loss=0.734, ntokens=329.8, nsentences=8, sample_size=329.8, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=1037.7, ups=3.15, wpb=329.8, bsz=8, num_updates=10750, lr=9.01732e-05, gnorm=2.351, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=3671
2023-03-15 15:00:56 - progress_bar.py[line:272] - INFO: epoch 006:    809 / 2004 loss=0.796, loss_v1=0, loss_v2=0, nll_loss=0.796, ntokens=347.7, nsentences=8, sample_size=347.7, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=1137.9, ups=3.27, wpb=347.7, bsz=8, num_updates=10760, lr=9.01631e-05, gnorm=2.403, clip=0, loss_scale=1024, train_wall=3, gb_free=14.2, wall=3674
2023-03-15 15:00:59 - progress_bar.py[line:272] - INFO: epoch 006:    819 / 2004 loss=0.69, loss_v1=0, loss_v2=0, nll_loss=0.69, ntokens=323.4, nsentences=8, sample_size=323.4, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=1051.1, ups=3.25, wpb=323.4, bsz=8, num_updates=10770, lr=9.0153e-05, gnorm=2.324, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=3677
2023-03-15 15:01:02 - progress_bar.py[line:272] - INFO: epoch 006:    829 / 2004 loss=0.851, loss_v1=0, loss_v2=0, nll_loss=0.851, ntokens=368.8, nsentences=8, sample_size=368.8, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=1202.9, ups=3.26, wpb=368.8, bsz=8, num_updates=10780, lr=9.01429e-05, gnorm=2.354, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=3680
2023-03-15 15:01:05 - progress_bar.py[line:272] - INFO: epoch 006:    839 / 2004 loss=0.73, loss_v1=0, loss_v2=0, nll_loss=0.73, ntokens=332.7, nsentences=8, sample_size=332.7, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=1029.3, ups=3.09, wpb=332.7, bsz=8, num_updates=10790, lr=9.01329e-05, gnorm=2.323, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=3683
2023-03-15 15:01:09 - progress_bar.py[line:272] - INFO: epoch 006:    849 / 2004 loss=0.809, loss_v1=0, loss_v2=0, nll_loss=0.809, ntokens=374.6, nsentences=8, sample_size=374.6, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=1151.3, ups=3.07, wpb=374.6, bsz=8, num_updates=10800, lr=9.01228e-05, gnorm=2.32, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=3686
2023-03-15 15:01:12 - progress_bar.py[line:272] - INFO: epoch 006:    859 / 2004 loss=0.795, loss_v1=0, loss_v2=0, nll_loss=0.795, ntokens=343.3, nsentences=8, sample_size=343.3, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=1007.6, ups=2.94, wpb=343.3, bsz=8, num_updates=10810, lr=9.01127e-05, gnorm=2.38, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=3690
2023-03-15 15:01:15 - progress_bar.py[line:272] - INFO: epoch 006:    869 / 2004 loss=0.823, loss_v1=0, loss_v2=0, nll_loss=0.823, ntokens=368.4, nsentences=8, sample_size=368.4, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=1072.8, ups=2.91, wpb=368.4, bsz=8, num_updates=10820, lr=9.01026e-05, gnorm=2.328, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=3693
2023-03-15 15:01:19 - progress_bar.py[line:272] - INFO: epoch 006:    879 / 2004 loss=0.714, loss_v1=0, loss_v2=0, nll_loss=0.714, ntokens=317.3, nsentences=8, sample_size=317.3, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=937.2, ups=2.95, wpb=317.3, bsz=8, num_updates=10830, lr=9.00925e-05, gnorm=2.419, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=3696
2023-03-15 15:01:22 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 15:01:22 - progress_bar.py[line:272] - INFO: epoch 006:    890 / 2004 loss=0.826, loss_v1=0, loss_v2=0, nll_loss=0.826, ntokens=327.8, nsentences=8, sample_size=327.8, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=973.3, ups=2.97, wpb=327.8, bsz=8, num_updates=10840, lr=9.00825e-05, gnorm=2.563, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=3700
2023-03-15 15:01:25 - progress_bar.py[line:272] - INFO: epoch 006:    900 / 2004 loss=0.814, loss_v1=0, loss_v2=0, nll_loss=0.814, ntokens=365.1, nsentences=8, sample_size=365.1, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=1145.2, ups=3.14, wpb=365.1, bsz=8, num_updates=10850, lr=9.00724e-05, gnorm=2.483, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=3703
2023-03-15 15:01:28 - progress_bar.py[line:272] - INFO: epoch 006:    910 / 2004 loss=0.727, loss_v1=0, loss_v2=0, nll_loss=0.727, ntokens=366.2, nsentences=8, sample_size=366.2, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=1184.6, ups=3.23, wpb=366.2, bsz=8, num_updates=10860, lr=9.00623e-05, gnorm=2.236, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=3706
2023-03-15 15:01:32 - progress_bar.py[line:272] - INFO: epoch 006:    920 / 2004 loss=0.836, loss_v1=0, loss_v2=0, nll_loss=0.836, ntokens=343.9, nsentences=8, sample_size=343.9, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=1089, ups=3.17, wpb=343.9, bsz=8, num_updates=10870, lr=9.00522e-05, gnorm=2.514, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=3709
2023-03-15 15:01:35 - progress_bar.py[line:272] - INFO: epoch 006:    930 / 2004 loss=0.722, loss_v1=0, loss_v2=0, nll_loss=0.722, ntokens=331.7, nsentences=8, sample_size=331.7, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=1093.9, ups=3.3, wpb=331.7, bsz=8, num_updates=10880, lr=9.00421e-05, gnorm=2.307, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=3712
2023-03-15 15:01:38 - progress_bar.py[line:272] - INFO: epoch 006:    940 / 2004 loss=0.826, loss_v1=0, loss_v2=0, nll_loss=0.826, ntokens=359, nsentences=8, sample_size=359, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=1143.4, ups=3.19, wpb=359, bsz=8, num_updates=10890, lr=9.00321e-05, gnorm=2.484, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=3715
2023-03-15 15:01:41 - progress_bar.py[line:272] - INFO: epoch 006:    950 / 2004 loss=0.797, loss_v1=0, loss_v2=0, nll_loss=0.797, ntokens=361.5, nsentences=8, sample_size=361.5, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=1139, ups=3.15, wpb=361.5, bsz=8, num_updates=10900, lr=9.0022e-05, gnorm=2.41, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=3719
2023-03-15 15:01:44 - progress_bar.py[line:272] - INFO: epoch 006:    960 / 2004 loss=0.841, loss_v1=0, loss_v2=0, nll_loss=0.841, ntokens=355.6, nsentences=8, sample_size=355.6, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=1132.7, ups=3.19, wpb=355.6, bsz=8, num_updates=10910, lr=9.00119e-05, gnorm=2.466, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=3722
2023-03-15 15:01:47 - progress_bar.py[line:272] - INFO: epoch 006:    970 / 2004 loss=0.768, loss_v1=0, loss_v2=0, nll_loss=0.768, ntokens=341.3, nsentences=8, sample_size=341.3, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=1089.7, ups=3.19, wpb=341.3, bsz=8, num_updates=10920, lr=9.00018e-05, gnorm=2.365, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=3725
2023-03-15 15:01:50 - progress_bar.py[line:272] - INFO: epoch 006:    980 / 2004 loss=0.788, loss_v1=0, loss_v2=0, nll_loss=0.788, ntokens=333.8, nsentences=8, sample_size=333.8, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=1084.5, ups=3.25, wpb=333.8, bsz=8, num_updates=10930, lr=8.99917e-05, gnorm=2.444, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=3728
2023-03-15 15:01:53 - progress_bar.py[line:272] - INFO: epoch 006:    990 / 2004 loss=0.799, loss_v1=0, loss_v2=0, nll_loss=0.799, ntokens=374.7, nsentences=8, sample_size=374.7, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=1196.6, ups=3.19, wpb=374.7, bsz=8, num_updates=10940, lr=8.99817e-05, gnorm=2.318, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=3731
2023-03-15 15:01:57 - progress_bar.py[line:272] - INFO: epoch 006:   1000 / 2004 loss=0.78, loss_v1=0, loss_v2=0, nll_loss=0.78, ntokens=345.5, nsentences=8, sample_size=345.5, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=1113.4, ups=3.22, wpb=345.5, bsz=8, num_updates=10950, lr=8.99716e-05, gnorm=2.324, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=3734
2023-03-15 15:02:00 - progress_bar.py[line:272] - INFO: epoch 006:   1010 / 2004 loss=0.806, loss_v1=0, loss_v2=0, nll_loss=0.806, ntokens=313.2, nsentences=8, sample_size=313.2, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=1032.3, ups=3.3, wpb=313.2, bsz=8, num_updates=10960, lr=8.99615e-05, gnorm=2.457, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=3737
2023-03-15 15:02:03 - progress_bar.py[line:272] - INFO: epoch 006:   1020 / 2004 loss=0.753, loss_v1=0, loss_v2=0, nll_loss=0.753, ntokens=333.6, nsentences=8, sample_size=333.6, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=1100, ups=3.3, wpb=333.6, bsz=8, num_updates=10970, lr=8.99514e-05, gnorm=2.414, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=3740
2023-03-15 15:02:06 - progress_bar.py[line:272] - INFO: epoch 006:   1030 / 2004 loss=0.752, loss_v1=0, loss_v2=0, nll_loss=0.752, ntokens=323, nsentences=8, sample_size=323, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=1064.1, ups=3.29, wpb=323, bsz=8, num_updates=10980, lr=8.99413e-05, gnorm=2.41, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=3743
2023-03-15 15:02:09 - progress_bar.py[line:272] - INFO: epoch 006:   1040 / 2004 loss=0.802, loss_v1=0, loss_v2=0, nll_loss=0.802, ntokens=331.2, nsentences=8, sample_size=331.2, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=1042.6, ups=3.15, wpb=331.2, bsz=8, num_updates=10990, lr=8.99312e-05, gnorm=2.408, clip=0, loss_scale=2048, train_wall=3, gb_free=13, wall=3746
2023-03-15 15:02:12 - progress_bar.py[line:272] - INFO: epoch 006:   1050 / 2004 loss=0.804, loss_v1=0, loss_v2=0, nll_loss=0.804, ntokens=373.4, nsentences=8, sample_size=373.4, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=1197.5, ups=3.21, wpb=373.4, bsz=8, num_updates=11000, lr=8.99212e-05, gnorm=2.36, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=3750
2023-03-15 15:02:15 - progress_bar.py[line:272] - INFO: epoch 006:   1060 / 2004 loss=0.789, loss_v1=0, loss_v2=0, nll_loss=0.789, ntokens=347.8, nsentences=8, sample_size=347.8, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=1101.9, ups=3.17, wpb=347.8, bsz=8, num_updates=11010, lr=8.99111e-05, gnorm=2.412, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=3753
2023-03-15 15:02:18 - progress_bar.py[line:272] - INFO: epoch 006:   1070 / 2004 loss=0.83, loss_v1=0, loss_v2=0, nll_loss=0.83, ntokens=342.8, nsentences=8, sample_size=342.8, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=1095.5, ups=3.2, wpb=342.8, bsz=8, num_updates=11020, lr=8.9901e-05, gnorm=2.482, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=3756
2023-03-15 15:02:21 - progress_bar.py[line:272] - INFO: epoch 006:   1080 / 2004 loss=0.759, loss_v1=0, loss_v2=0, nll_loss=0.759, ntokens=359.4, nsentences=8, sample_size=359.4, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=1167.5, ups=3.25, wpb=359.4, bsz=8, num_updates=11030, lr=8.98909e-05, gnorm=2.42, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=3759
2023-03-15 15:02:24 - progress_bar.py[line:272] - INFO: epoch 006:   1090 / 2004 loss=0.871, loss_v1=0, loss_v2=0, nll_loss=0.871, ntokens=359.7, nsentences=8, sample_size=359.7, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=1158.2, ups=3.22, wpb=359.7, bsz=8, num_updates=11040, lr=8.98808e-05, gnorm=2.487, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=3762
2023-03-15 15:02:28 - progress_bar.py[line:272] - INFO: epoch 006:   1100 / 2004 loss=0.849, loss_v1=0, loss_v2=0, nll_loss=0.849, ntokens=343.1, nsentences=8, sample_size=343.1, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=1106.7, ups=3.23, wpb=343.1, bsz=8, num_updates=11050, lr=8.98708e-05, gnorm=2.546, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=3765
2023-03-15 15:02:31 - progress_bar.py[line:272] - INFO: epoch 006:   1110 / 2004 loss=0.831, loss_v1=0, loss_v2=0, nll_loss=0.831, ntokens=371.7, nsentences=8, sample_size=371.7, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=1188.6, ups=3.2, wpb=371.7, bsz=8, num_updates=11060, lr=8.98607e-05, gnorm=2.419, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=3768
2023-03-15 15:02:34 - progress_bar.py[line:272] - INFO: epoch 006:   1120 / 2004 loss=0.688, loss_v1=0, loss_v2=0, nll_loss=0.688, ntokens=318.9, nsentences=8, sample_size=318.9, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=1021.7, ups=3.2, wpb=318.9, bsz=8, num_updates=11070, lr=8.98506e-05, gnorm=2.321, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=3771
2023-03-15 15:02:37 - progress_bar.py[line:272] - INFO: epoch 006:   1130 / 2004 loss=0.771, loss_v1=0, loss_v2=0, nll_loss=0.771, ntokens=354.8, nsentences=8, sample_size=354.8, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=1114.9, ups=3.14, wpb=354.8, bsz=8, num_updates=11080, lr=8.98405e-05, gnorm=2.324, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=3775
2023-03-15 15:02:40 - progress_bar.py[line:272] - INFO: epoch 006:   1140 / 2004 loss=0.781, loss_v1=0, loss_v2=0, nll_loss=0.781, ntokens=375, nsentences=8, sample_size=375, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=1181.2, ups=3.15, wpb=375, bsz=8, num_updates=11090, lr=8.98304e-05, gnorm=2.405, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=3778
2023-03-15 15:02:43 - progress_bar.py[line:272] - INFO: epoch 006:   1150 / 2004 loss=0.738, loss_v1=0, loss_v2=0, nll_loss=0.738, ntokens=353.1, nsentences=8, sample_size=353.1, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=1123.1, ups=3.18, wpb=353.1, bsz=8, num_updates=11100, lr=8.98204e-05, gnorm=2.335, clip=0, loss_scale=4096, train_wall=3, gb_free=14.6, wall=3781
2023-03-15 15:02:44 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 15:02:47 - progress_bar.py[line:272] - INFO: epoch 006:   1161 / 2004 loss=0.79, loss_v1=0, loss_v2=0, nll_loss=0.79, ntokens=385.8, nsentences=8, sample_size=385.8, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=1129.8, ups=2.93, wpb=385.8, bsz=8, num_updates=11110, lr=8.98103e-05, gnorm=2.383, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=3784
2023-03-15 15:02:50 - progress_bar.py[line:272] - INFO: epoch 006:   1171 / 2004 loss=0.772, loss_v1=0, loss_v2=0, nll_loss=0.772, ntokens=346.1, nsentences=8, sample_size=346.1, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=1123.9, ups=3.25, wpb=346.1, bsz=8, num_updates=11120, lr=8.98002e-05, gnorm=2.441, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=3787
2023-03-15 15:02:53 - progress_bar.py[line:272] - INFO: epoch 006:   1181 / 2004 loss=0.734, loss_v1=0, loss_v2=0, nll_loss=0.734, ntokens=347.7, nsentences=8, sample_size=347.7, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=1111.7, ups=3.2, wpb=347.7, bsz=8, num_updates=11130, lr=8.97901e-05, gnorm=2.365, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=3791
2023-03-15 15:02:56 - progress_bar.py[line:272] - INFO: epoch 006:   1191 / 2004 loss=0.669, loss_v1=0, loss_v2=0, nll_loss=0.669, ntokens=339.3, nsentences=8, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=1096.8, ups=3.23, wpb=339.3, bsz=8, num_updates=11140, lr=8.978e-05, gnorm=2.227, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=3794
2023-03-15 15:02:59 - progress_bar.py[line:272] - INFO: epoch 006:   1201 / 2004 loss=0.784, loss_v1=0, loss_v2=0, nll_loss=0.784, ntokens=349.8, nsentences=8, sample_size=349.8, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=1172.4, ups=3.35, wpb=349.8, bsz=8, num_updates=11150, lr=8.977e-05, gnorm=2.443, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=3797
2023-03-15 15:03:02 - progress_bar.py[line:272] - INFO: epoch 006:   1211 / 2004 loss=0.763, loss_v1=0, loss_v2=0, nll_loss=0.763, ntokens=282.4, nsentences=8, sample_size=282.4, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=948.3, ups=3.36, wpb=282.4, bsz=8, num_updates=11160, lr=8.97599e-05, gnorm=2.61, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=3800
2023-03-15 15:03:05 - progress_bar.py[line:272] - INFO: epoch 006:   1221 / 2004 loss=0.763, loss_v1=0, loss_v2=0, nll_loss=0.763, ntokens=331.6, nsentences=8, sample_size=331.6, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=1092.9, ups=3.3, wpb=331.6, bsz=8, num_updates=11170, lr=8.97498e-05, gnorm=2.46, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=3803
2023-03-15 15:03:08 - progress_bar.py[line:272] - INFO: epoch 006:   1231 / 2004 loss=0.703, loss_v1=0, loss_v2=0, nll_loss=0.703, ntokens=301.1, nsentences=8, sample_size=301.1, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=988.3, ups=3.28, wpb=301.1, bsz=8, num_updates=11180, lr=8.97397e-05, gnorm=2.519, clip=0, loss_scale=2048, train_wall=3, gb_free=15.9, wall=3806
2023-03-15 15:03:11 - progress_bar.py[line:272] - INFO: epoch 006:   1241 / 2004 loss=0.815, loss_v1=0, loss_v2=0, nll_loss=0.815, ntokens=392.8, nsentences=8, sample_size=392.8, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=1229.3, ups=3.13, wpb=392.8, bsz=8, num_updates=11190, lr=8.97296e-05, gnorm=2.367, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=3809
2023-03-15 15:03:14 - progress_bar.py[line:272] - INFO: epoch 006:   1251 / 2004 loss=0.788, loss_v1=0, loss_v2=0, nll_loss=0.788, ntokens=338, nsentences=8, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=1095.9, ups=3.24, wpb=338, bsz=8, num_updates=11200, lr=8.97196e-05, gnorm=2.551, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=3812
2023-03-15 15:03:18 - progress_bar.py[line:272] - INFO: epoch 006:   1261 / 2004 loss=0.759, loss_v1=0, loss_v2=0, nll_loss=0.759, ntokens=349.1, nsentences=8, sample_size=349.1, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=1068.3, ups=3.06, wpb=349.1, bsz=8, num_updates=11210, lr=8.97095e-05, gnorm=2.409, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=3815
2023-03-15 15:03:21 - progress_bar.py[line:272] - INFO: epoch 006:   1271 / 2004 loss=0.792, loss_v1=0, loss_v2=0, nll_loss=0.792, ntokens=357.5, nsentences=8, sample_size=357.5, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=1114.6, ups=3.12, wpb=357.5, bsz=8, num_updates=11220, lr=8.96994e-05, gnorm=2.434, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=3818
2023-03-15 15:03:24 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 15:03:24 - progress_bar.py[line:272] - INFO: epoch 006:   1282 / 2004 loss=0.711, loss_v1=0, loss_v2=0, nll_loss=0.711, ntokens=325.1, nsentences=8, sample_size=325.1, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=890.1, ups=2.74, wpb=325.1, bsz=8, num_updates=11230, lr=8.96893e-05, gnorm=2.422, clip=0, loss_scale=2048, train_wall=4, gb_free=15.1, wall=3822
2023-03-15 15:03:28 - progress_bar.py[line:272] - INFO: epoch 006:   1292 / 2004 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.611, ntokens=312.9, nsentences=8, sample_size=312.9, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=935.2, ups=2.99, wpb=312.9, bsz=8, num_updates=11240, lr=8.96792e-05, gnorm=2.225, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=3825
2023-03-15 15:03:31 - progress_bar.py[line:272] - INFO: epoch 006:   1302 / 2004 loss=0.787, loss_v1=0, loss_v2=0, nll_loss=0.787, ntokens=314.8, nsentences=8, sample_size=314.8, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=943.1, ups=3, wpb=314.8, bsz=8, num_updates=11250, lr=8.96691e-05, gnorm=2.545, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=3829
2023-03-15 15:03:35 - progress_bar.py[line:272] - INFO: epoch 006:   1312 / 2004 loss=0.775, loss_v1=0, loss_v2=0, nll_loss=0.775, ntokens=337.2, nsentences=8, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=1001.5, ups=2.97, wpb=337.2, bsz=8, num_updates=11260, lr=8.96591e-05, gnorm=2.449, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=3832
2023-03-15 15:03:36 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 15:03:38 - progress_bar.py[line:272] - INFO: epoch 006:   1323 / 2004 loss=0.766, loss_v1=0, loss_v2=0, nll_loss=0.766, ntokens=315.6, nsentences=8, sample_size=315.6, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=843.7, ups=2.67, wpb=315.6, bsz=8, num_updates=11270, lr=8.9649e-05, gnorm=2.658, clip=0, loss_scale=1024, train_wall=4, gb_free=14.9, wall=3836
2023-03-15 15:03:42 - progress_bar.py[line:272] - INFO: epoch 006:   1333 / 2004 loss=0.852, loss_v1=0, loss_v2=0, nll_loss=0.852, ntokens=333.2, nsentences=8, sample_size=333.2, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=967, ups=2.9, wpb=333.2, bsz=8, num_updates=11280, lr=8.96389e-05, gnorm=2.627, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=3839
2023-03-15 15:03:45 - progress_bar.py[line:272] - INFO: epoch 006:   1343 / 2004 loss=0.764, loss_v1=0, loss_v2=0, nll_loss=0.764, ntokens=321, nsentences=8, sample_size=321, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=975, ups=3.04, wpb=321, bsz=8, num_updates=11290, lr=8.96288e-05, gnorm=2.499, clip=0, loss_scale=1024, train_wall=3, gb_free=14.2, wall=3843
2023-03-15 15:03:48 - progress_bar.py[line:272] - INFO: epoch 006:   1353 / 2004 loss=0.781, loss_v1=0, loss_v2=0, nll_loss=0.781, ntokens=313, nsentences=8, sample_size=313, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=955, ups=3.05, wpb=313, bsz=8, num_updates=11300, lr=8.96187e-05, gnorm=2.609, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=3846
2023-03-15 15:03:51 - progress_bar.py[line:272] - INFO: epoch 006:   1363 / 2004 loss=0.785, loss_v1=0, loss_v2=0, nll_loss=0.785, ntokens=326.8, nsentences=8, sample_size=326.8, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=1066.6, ups=3.26, wpb=326.8, bsz=8, num_updates=11310, lr=8.96087e-05, gnorm=2.468, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=3849
2023-03-15 15:03:54 - progress_bar.py[line:272] - INFO: epoch 006:   1373 / 2004 loss=0.711, loss_v1=0, loss_v2=0, nll_loss=0.711, ntokens=299.6, nsentences=8, sample_size=299.6, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=959, ups=3.2, wpb=299.6, bsz=8, num_updates=11320, lr=8.95986e-05, gnorm=2.51, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=3852
2023-03-15 15:03:58 - progress_bar.py[line:272] - INFO: epoch 006:   1383 / 2004 loss=0.847, loss_v1=0, loss_v2=0, nll_loss=0.847, ntokens=384.6, nsentences=8, sample_size=384.6, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=1217.7, ups=3.17, wpb=384.6, bsz=8, num_updates=11330, lr=8.95885e-05, gnorm=2.5, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=3855
2023-03-15 15:04:01 - progress_bar.py[line:272] - INFO: epoch 006:   1393 / 2004 loss=0.704, loss_v1=0, loss_v2=0, nll_loss=0.704, ntokens=362.5, nsentences=8, sample_size=362.5, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=1174, ups=3.24, wpb=362.5, bsz=8, num_updates=11340, lr=8.95784e-05, gnorm=2.246, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=3858
2023-03-15 15:04:04 - progress_bar.py[line:272] - INFO: epoch 006:   1403 / 2004 loss=0.701, loss_v1=0, loss_v2=0, nll_loss=0.701, ntokens=337.1, nsentences=8, sample_size=337.1, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=1067.8, ups=3.17, wpb=337.1, bsz=8, num_updates=11350, lr=8.95683e-05, gnorm=2.386, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=3861
2023-03-15 15:04:07 - progress_bar.py[line:272] - INFO: epoch 006:   1413 / 2004 loss=0.856, loss_v1=0, loss_v2=0, nll_loss=0.856, ntokens=378.6, nsentences=8, sample_size=378.6, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=1190, ups=3.14, wpb=378.6, bsz=8, num_updates=11360, lr=8.95583e-05, gnorm=2.483, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=3865
2023-03-15 15:04:10 - progress_bar.py[line:272] - INFO: epoch 006:   1423 / 2004 loss=0.719, loss_v1=0, loss_v2=0, nll_loss=0.719, ntokens=317.9, nsentences=8, sample_size=317.9, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=1043, ups=3.28, wpb=317.9, bsz=8, num_updates=11370, lr=8.95482e-05, gnorm=2.358, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=3868
2023-03-15 15:04:13 - progress_bar.py[line:272] - INFO: epoch 006:   1433 / 2004 loss=0.801, loss_v1=0, loss_v2=0, nll_loss=0.801, ntokens=347.9, nsentences=8, sample_size=347.9, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=1103.6, ups=3.17, wpb=347.9, bsz=8, num_updates=11380, lr=8.95381e-05, gnorm=2.466, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=3871
2023-03-15 15:04:17 - progress_bar.py[line:272] - INFO: epoch 006:   1443 / 2004 loss=0.82, loss_v1=0, loss_v2=0, nll_loss=0.82, ntokens=340.6, nsentences=8, sample_size=340.6, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=1042.9, ups=3.06, wpb=340.6, bsz=8, num_updates=11390, lr=8.9528e-05, gnorm=2.538, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=3874
2023-03-15 15:04:20 - progress_bar.py[line:272] - INFO: epoch 006:   1453 / 2004 loss=0.81, loss_v1=0, loss_v2=0, nll_loss=0.81, ntokens=353.2, nsentences=8, sample_size=353.2, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=1066.1, ups=3.02, wpb=353.2, bsz=8, num_updates=11400, lr=8.95179e-05, gnorm=2.459, clip=0, loss_scale=2048, train_wall=3, gb_free=13.5, wall=3877
2023-03-15 15:04:23 - progress_bar.py[line:272] - INFO: epoch 006:   1463 / 2004 loss=0.847, loss_v1=0, loss_v2=0, nll_loss=0.847, ntokens=382.5, nsentences=8, sample_size=382.5, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=1198.4, ups=3.13, wpb=382.5, bsz=8, num_updates=11410, lr=8.95079e-05, gnorm=2.474, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=3881
2023-03-15 15:04:26 - progress_bar.py[line:272] - INFO: epoch 006:   1473 / 2004 loss=0.774, loss_v1=0, loss_v2=0, nll_loss=0.774, ntokens=400.9, nsentences=8, sample_size=400.9, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=1254.8, ups=3.13, wpb=400.9, bsz=8, num_updates=11420, lr=8.94978e-05, gnorm=2.362, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=3884
2023-03-15 15:04:29 - progress_bar.py[line:272] - INFO: epoch 006:   1483 / 2004 loss=0.809, loss_v1=0, loss_v2=0, nll_loss=0.809, ntokens=370.3, nsentences=8, sample_size=370.3, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=1199.7, ups=3.24, wpb=370.3, bsz=8, num_updates=11430, lr=8.94877e-05, gnorm=2.498, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=3887
2023-03-15 15:04:32 - progress_bar.py[line:272] - INFO: epoch 006:   1493 / 2004 loss=0.74, loss_v1=0, loss_v2=0, nll_loss=0.74, ntokens=310.3, nsentences=8, sample_size=310.3, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=1000.1, ups=3.22, wpb=310.3, bsz=8, num_updates=11440, lr=8.94776e-05, gnorm=2.587, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=3890
2023-03-15 15:04:36 - progress_bar.py[line:272] - INFO: epoch 006:   1503 / 2004 loss=0.774, loss_v1=0, loss_v2=0, nll_loss=0.774, ntokens=341.9, nsentences=8, sample_size=341.9, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=1074.2, ups=3.14, wpb=341.9, bsz=8, num_updates=11450, lr=8.94675e-05, gnorm=2.501, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=3893
2023-03-15 15:04:39 - progress_bar.py[line:272] - INFO: epoch 006:   1513 / 2004 loss=0.719, loss_v1=0, loss_v2=0, nll_loss=0.719, ntokens=333.6, nsentences=8, sample_size=333.6, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=1071, ups=3.21, wpb=333.6, bsz=8, num_updates=11460, lr=8.94574e-05, gnorm=2.464, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=3896
2023-03-15 15:04:42 - progress_bar.py[line:272] - INFO: epoch 006:   1523 / 2004 loss=0.716, loss_v1=0, loss_v2=0, nll_loss=0.716, ntokens=327.5, nsentences=8, sample_size=327.5, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=1059.5, ups=3.24, wpb=327.5, bsz=8, num_updates=11470, lr=8.94474e-05, gnorm=2.505, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=3899
2023-03-15 15:04:45 - progress_bar.py[line:272] - INFO: epoch 006:   1533 / 2004 loss=0.796, loss_v1=0, loss_v2=0, nll_loss=0.796, ntokens=356.6, nsentences=8, sample_size=356.6, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=1139.5, ups=3.2, wpb=356.6, bsz=8, num_updates=11480, lr=8.94373e-05, gnorm=2.542, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=3903
2023-03-15 15:04:48 - progress_bar.py[line:272] - INFO: epoch 006:   1543 / 2004 loss=0.707, loss_v1=0, loss_v2=0, nll_loss=0.707, ntokens=316.9, nsentences=8, sample_size=316.9, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=1002.7, ups=3.16, wpb=316.9, bsz=8, num_updates=11490, lr=8.94272e-05, gnorm=2.513, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=3906
2023-03-15 15:04:51 - progress_bar.py[line:272] - INFO: epoch 006:   1553 / 2004 loss=0.722, loss_v1=0, loss_v2=0, nll_loss=0.722, ntokens=321.4, nsentences=8, sample_size=321.4, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=1039.7, ups=3.23, wpb=321.4, bsz=8, num_updates=11500, lr=8.94171e-05, gnorm=2.369, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=3909
2023-03-15 15:04:54 - progress_bar.py[line:272] - INFO: epoch 006:   1563 / 2004 loss=0.738, loss_v1=0, loss_v2=0, nll_loss=0.738, ntokens=360.8, nsentences=8, sample_size=360.8, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=1100.5, ups=3.05, wpb=360.8, bsz=8, num_updates=11510, lr=8.9407e-05, gnorm=2.414, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=3912
2023-03-15 15:04:58 - progress_bar.py[line:272] - INFO: epoch 006:   1573 / 2004 loss=0.723, loss_v1=0, loss_v2=0, nll_loss=0.723, ntokens=333.8, nsentences=8, sample_size=333.8, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=1034.1, ups=3.1, wpb=333.8, bsz=8, num_updates=11520, lr=8.9397e-05, gnorm=2.423, clip=0, loss_scale=4096, train_wall=3, gb_free=14.8, wall=3915
2023-03-15 15:04:58 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 15:05:01 - progress_bar.py[line:272] - INFO: epoch 006:   1584 / 2004 loss=0.708, loss_v1=0, loss_v2=0, nll_loss=0.708, ntokens=324.1, nsentences=8, sample_size=324.1, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=885.8, ups=2.73, wpb=324.1, bsz=8, num_updates=11530, lr=8.93869e-05, gnorm=2.447, clip=0, loss_scale=2048, train_wall=4, gb_free=15.2, wall=3919
2023-03-15 15:05:05 - progress_bar.py[line:272] - INFO: epoch 006:   1594 / 2004 loss=0.802, loss_v1=0, loss_v2=0, nll_loss=0.802, ntokens=360, nsentences=8, sample_size=360, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=1052.5, ups=2.92, wpb=360, bsz=8, num_updates=11540, lr=8.93768e-05, gnorm=2.501, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=3922
2023-03-15 15:05:08 - progress_bar.py[line:272] - INFO: epoch 006:   1604 / 2004 loss=0.729, loss_v1=0, loss_v2=0, nll_loss=0.729, ntokens=337, nsentences=8, sample_size=337, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=1012.6, ups=3, wpb=337, bsz=8, num_updates=11550, lr=8.93667e-05, gnorm=2.434, clip=0, loss_scale=2048, train_wall=3, gb_free=14, wall=3926
2023-03-15 15:05:11 - progress_bar.py[line:272] - INFO: epoch 006:   1614 / 2004 loss=0.753, loss_v1=0, loss_v2=0, nll_loss=0.753, ntokens=352.8, nsentences=8, sample_size=352.8, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=1143.4, ups=3.24, wpb=352.8, bsz=8, num_updates=11560, lr=8.93566e-05, gnorm=2.44, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=3929
2023-03-15 15:05:14 - progress_bar.py[line:272] - INFO: epoch 006:   1624 / 2004 loss=0.822, loss_v1=0, loss_v2=0, nll_loss=0.822, ntokens=345.8, nsentences=8, sample_size=345.8, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=1091.4, ups=3.16, wpb=345.8, bsz=8, num_updates=11570, lr=8.93466e-05, gnorm=2.595, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=3932
2023-03-15 15:05:17 - progress_bar.py[line:272] - INFO: epoch 006:   1634 / 2004 loss=0.773, loss_v1=0, loss_v2=0, nll_loss=0.773, ntokens=338.9, nsentences=8, sample_size=338.9, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=1103.1, ups=3.26, wpb=338.9, bsz=8, num_updates=11580, lr=8.93365e-05, gnorm=2.518, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=3935
2023-03-15 15:05:21 - progress_bar.py[line:272] - INFO: epoch 006:   1644 / 2004 loss=0.738, loss_v1=0, loss_v2=0, nll_loss=0.738, ntokens=309.4, nsentences=8, sample_size=309.4, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=990.6, ups=3.2, wpb=309.4, bsz=8, num_updates=11590, lr=8.93264e-05, gnorm=2.545, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=3938
2023-03-15 15:05:24 - progress_bar.py[line:272] - INFO: epoch 006:   1654 / 2004 loss=0.768, loss_v1=0, loss_v2=0, nll_loss=0.768, ntokens=338.6, nsentences=8, sample_size=338.6, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=1074.8, ups=3.17, wpb=338.6, bsz=8, num_updates=11600, lr=8.93163e-05, gnorm=2.553, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=3941
2023-03-15 15:05:27 - progress_bar.py[line:272] - INFO: epoch 006:   1664 / 2004 loss=0.76, loss_v1=0, loss_v2=0, nll_loss=0.76, ntokens=358.4, nsentences=8, sample_size=358.4, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=1157.1, ups=3.23, wpb=358.4, bsz=8, num_updates=11610, lr=8.93062e-05, gnorm=2.52, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=3944
2023-03-15 15:05:30 - progress_bar.py[line:272] - INFO: epoch 006:   1674 / 2004 loss=0.816, loss_v1=0, loss_v2=0, nll_loss=0.816, ntokens=316.3, nsentences=8, sample_size=316.3, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=1032.4, ups=3.26, wpb=316.3, bsz=8, num_updates=11620, lr=8.92962e-05, gnorm=2.651, clip=0, loss_scale=2048, train_wall=3, gb_free=15.9, wall=3947
2023-03-15 15:05:33 - progress_bar.py[line:272] - INFO: epoch 006:   1684 / 2004 loss=0.756, loss_v1=0, loss_v2=0, nll_loss=0.756, ntokens=349.4, nsentences=8, sample_size=349.4, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=1101.4, ups=3.15, wpb=349.4, bsz=8, num_updates=11630, lr=8.92861e-05, gnorm=2.452, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=3951
2023-03-15 15:05:36 - progress_bar.py[line:272] - INFO: epoch 006:   1694 / 2004 loss=0.777, loss_v1=0, loss_v2=0, nll_loss=0.777, ntokens=338.3, nsentences=8, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=1062.1, ups=3.14, wpb=338.3, bsz=8, num_updates=11640, lr=8.9276e-05, gnorm=2.57, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=3954
2023-03-15 15:05:39 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 15:05:40 - progress_bar.py[line:272] - INFO: epoch 006:   1705 / 2004 loss=0.726, loss_v1=0, loss_v2=0, nll_loss=0.726, ntokens=321.4, nsentences=8, sample_size=321.4, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=938.7, ups=2.92, wpb=321.4, bsz=8, num_updates=11650, lr=8.92659e-05, gnorm=2.516, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=3957
2023-03-15 15:05:43 - progress_bar.py[line:272] - INFO: epoch 006:   1715 / 2004 loss=0.853, loss_v1=0, loss_v2=0, nll_loss=0.853, ntokens=365.3, nsentences=8, sample_size=365.3, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=1148.3, ups=3.14, wpb=365.3, bsz=8, num_updates=11660, lr=8.92558e-05, gnorm=2.6, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=3960
2023-03-15 15:05:46 - progress_bar.py[line:272] - INFO: epoch 006:   1725 / 2004 loss=0.798, loss_v1=0, loss_v2=0, nll_loss=0.798, ntokens=389.9, nsentences=8, sample_size=389.9, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=1228.1, ups=3.15, wpb=389.9, bsz=8, num_updates=11670, lr=8.92458e-05, gnorm=2.455, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=3964
2023-03-15 15:05:49 - progress_bar.py[line:272] - INFO: epoch 006:   1735 / 2004 loss=0.734, loss_v1=0, loss_v2=0, nll_loss=0.734, ntokens=352, nsentences=8, sample_size=352, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=1132, ups=3.22, wpb=352, bsz=8, num_updates=11680, lr=8.92357e-05, gnorm=2.427, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=3967
2023-03-15 15:05:52 - progress_bar.py[line:272] - INFO: epoch 006:   1745 / 2004 loss=0.768, loss_v1=0, loss_v2=0, nll_loss=0.768, ntokens=338.3, nsentences=8, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=1117.2, ups=3.3, wpb=338.3, bsz=8, num_updates=11690, lr=8.92256e-05, gnorm=2.574, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=3970
2023-03-15 15:05:55 - progress_bar.py[line:272] - INFO: epoch 006:   1755 / 2004 loss=0.772, loss_v1=0, loss_v2=0, nll_loss=0.772, ntokens=348.1, nsentences=8, sample_size=348.1, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=1128.3, ups=3.24, wpb=348.1, bsz=8, num_updates=11700, lr=8.92155e-05, gnorm=2.454, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=3973
2023-03-15 15:05:58 - progress_bar.py[line:272] - INFO: epoch 006:   1765 / 2004 loss=0.801, loss_v1=0, loss_v2=0, nll_loss=0.801, ntokens=308.7, nsentences=8, sample_size=308.7, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=999.6, ups=3.24, wpb=308.7, bsz=8, num_updates=11710, lr=8.92054e-05, gnorm=2.743, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=3976
2023-03-15 15:06:01 - progress_bar.py[line:272] - INFO: epoch 006:   1775 / 2004 loss=0.788, loss_v1=0, loss_v2=0, nll_loss=0.788, ntokens=349.2, nsentences=8, sample_size=349.2, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=1139, ups=3.26, wpb=349.2, bsz=8, num_updates=11720, lr=8.91953e-05, gnorm=2.51, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=3979
2023-03-15 15:06:04 - progress_bar.py[line:272] - INFO: epoch 006:   1785 / 2004 loss=0.748, loss_v1=0, loss_v2=0, nll_loss=0.748, ntokens=315, nsentences=8, sample_size=315, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=1013.1, ups=3.22, wpb=315, bsz=8, num_updates=11730, lr=8.91853e-05, gnorm=2.535, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=3982
2023-03-15 15:06:08 - progress_bar.py[line:272] - INFO: epoch 006:   1795 / 2004 loss=0.721, loss_v1=0, loss_v2=0, nll_loss=0.721, ntokens=319.8, nsentences=8, sample_size=319.8, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=989.7, ups=3.09, wpb=319.8, bsz=8, num_updates=11740, lr=8.91752e-05, gnorm=2.484, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=3985
2023-03-15 15:06:11 - progress_bar.py[line:272] - INFO: epoch 006:   1805 / 2004 loss=0.852, loss_v1=0, loss_v2=0, nll_loss=0.852, ntokens=353.2, nsentences=8, sample_size=353.2, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=1102.4, ups=3.12, wpb=353.2, bsz=8, num_updates=11750, lr=8.91651e-05, gnorm=2.699, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=3989
2023-03-15 15:06:14 - progress_bar.py[line:272] - INFO: epoch 006:   1815 / 2004 loss=0.753, loss_v1=0, loss_v2=0, nll_loss=0.753, ntokens=359.4, nsentences=8, sample_size=359.4, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=1103.7, ups=3.07, wpb=359.4, bsz=8, num_updates=11760, lr=8.9155e-05, gnorm=2.538, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=3992
2023-03-15 15:06:17 - progress_bar.py[line:272] - INFO: epoch 006:   1825 / 2004 loss=0.694, loss_v1=0, loss_v2=0, nll_loss=0.694, ntokens=356.8, nsentences=8, sample_size=356.8, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=1080.7, ups=3.03, wpb=356.8, bsz=8, num_updates=11770, lr=8.91449e-05, gnorm=2.342, clip=0, loss_scale=2048, train_wall=3, gb_free=13.9, wall=3995
2023-03-15 15:06:21 - progress_bar.py[line:272] - INFO: epoch 006:   1835 / 2004 loss=0.74, loss_v1=0, loss_v2=0, nll_loss=0.74, ntokens=333.7, nsentences=8, sample_size=333.7, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=1007.6, ups=3.02, wpb=333.7, bsz=8, num_updates=11780, lr=8.91349e-05, gnorm=2.405, clip=0, loss_scale=4096, train_wall=3, gb_free=15.2, wall=3998
2023-03-15 15:06:22 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 15:06:24 - progress_bar.py[line:272] - INFO: epoch 006:   1846 / 2004 loss=0.771, loss_v1=0, loss_v2=0, nll_loss=0.771, ntokens=348.1, nsentences=8, sample_size=348.1, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=970.8, ups=2.79, wpb=348.1, bsz=8, num_updates=11790, lr=8.91248e-05, gnorm=2.528, clip=0, loss_scale=2048, train_wall=4, gb_free=14.5, wall=4002
2023-03-15 15:06:28 - progress_bar.py[line:272] - INFO: epoch 006:   1856 / 2004 loss=0.722, loss_v1=0, loss_v2=0, nll_loss=0.722, ntokens=312.9, nsentences=8, sample_size=312.9, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=972.2, ups=3.11, wpb=312.9, bsz=8, num_updates=11800, lr=8.91147e-05, gnorm=2.527, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=4005
2023-03-15 15:06:31 - progress_bar.py[line:272] - INFO: epoch 006:   1866 / 2004 loss=0.726, loss_v1=0, loss_v2=0, nll_loss=0.726, ntokens=343.7, nsentences=8, sample_size=343.7, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=1055, ups=3.07, wpb=343.7, bsz=8, num_updates=11810, lr=8.91046e-05, gnorm=2.418, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=4008
2023-03-15 15:06:34 - progress_bar.py[line:272] - INFO: epoch 006:   1876 / 2004 loss=0.752, loss_v1=0, loss_v2=0, nll_loss=0.752, ntokens=337.8, nsentences=8, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=1044.5, ups=3.09, wpb=337.8, bsz=8, num_updates=11820, lr=8.90945e-05, gnorm=2.502, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=4012
2023-03-15 15:06:37 - progress_bar.py[line:272] - INFO: epoch 006:   1886 / 2004 loss=0.697, loss_v1=0, loss_v2=0, nll_loss=0.697, ntokens=324, nsentences=8, sample_size=324, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=1002.1, ups=3.09, wpb=324, bsz=8, num_updates=11830, lr=8.90845e-05, gnorm=2.45, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=4015
2023-03-15 15:06:41 - progress_bar.py[line:272] - INFO: epoch 006:   1896 / 2004 loss=0.737, loss_v1=0, loss_v2=0, nll_loss=0.737, ntokens=336.9, nsentences=8, sample_size=336.9, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=1039.3, ups=3.09, wpb=336.9, bsz=8, num_updates=11840, lr=8.90744e-05, gnorm=2.509, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=4018
2023-03-15 15:06:45 - progress_bar.py[line:272] - INFO: epoch 006:   1906 / 2004 loss=0.679, loss_v1=0, loss_v2=0, nll_loss=0.679, ntokens=348.4, nsentences=8, sample_size=348.4, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=782.5, ups=2.25, wpb=348.4, bsz=8, num_updates=11850, lr=8.90643e-05, gnorm=2.438, clip=0, loss_scale=2048, train_wall=4, gb_free=15.5, wall=4023
2023-03-15 15:06:48 - progress_bar.py[line:272] - INFO: epoch 006:   1916 / 2004 loss=0.707, loss_v1=0, loss_v2=0, nll_loss=0.707, ntokens=327.7, nsentences=8, sample_size=327.7, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=957.6, ups=2.92, wpb=327.7, bsz=8, num_updates=11860, lr=8.90542e-05, gnorm=2.483, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=4026
2023-03-15 15:06:52 - progress_bar.py[line:272] - INFO: epoch 006:   1926 / 2004 loss=0.674, loss_v1=0, loss_v2=0, nll_loss=0.674, ntokens=325.2, nsentences=8, sample_size=325.2, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=952.5, ups=2.93, wpb=325.2, bsz=8, num_updates=11870, lr=8.90441e-05, gnorm=2.433, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=4029
2023-03-15 15:06:55 - progress_bar.py[line:272] - INFO: epoch 006:   1936 / 2004 loss=0.686, loss_v1=0, loss_v2=0, nll_loss=0.686, ntokens=336.4, nsentences=8, sample_size=336.4, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=970.1, ups=2.88, wpb=336.4, bsz=8, num_updates=11880, lr=8.90341e-05, gnorm=2.408, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=4033
2023-03-15 15:06:59 - progress_bar.py[line:272] - INFO: epoch 006:   1946 / 2004 loss=0.781, loss_v1=0, loss_v2=0, nll_loss=0.781, ntokens=358.9, nsentences=8, sample_size=358.9, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=1027.4, ups=2.86, wpb=358.9, bsz=8, num_updates=11890, lr=8.9024e-05, gnorm=2.599, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=4036
2023-03-15 15:07:02 - progress_bar.py[line:272] - INFO: epoch 006:   1956 / 2004 loss=0.678, loss_v1=0, loss_v2=0, nll_loss=0.678, ntokens=348, nsentences=8, sample_size=348, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=1089.6, ups=3.13, wpb=348, bsz=8, num_updates=11900, lr=8.90139e-05, gnorm=2.51, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=4040
2023-03-15 15:07:05 - progress_bar.py[line:272] - INFO: epoch 006:   1966 / 2004 loss=0.724, loss_v1=0, loss_v2=0, nll_loss=0.724, ntokens=356.9, nsentences=8, sample_size=356.9, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=1141.1, ups=3.2, wpb=356.9, bsz=8, num_updates=11910, lr=8.90038e-05, gnorm=2.439, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=4043
2023-03-15 15:07:07 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 15:07:09 - progress_bar.py[line:272] - INFO: epoch 006:   1977 / 2004 loss=0.678, loss_v1=0, loss_v2=0, nll_loss=0.678, ntokens=319.1, nsentences=8, sample_size=319.1, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=931.1, ups=2.92, wpb=319.1, bsz=8, num_updates=11920, lr=8.89937e-05, gnorm=2.441, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=4046
2023-03-15 15:07:12 - progress_bar.py[line:272] - INFO: epoch 006:   1987 / 2004 loss=0.707, loss_v1=0, loss_v2=0, nll_loss=0.707, ntokens=323.2, nsentences=8, sample_size=323.2, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=1013.2, ups=3.13, wpb=323.2, bsz=8, num_updates=11930, lr=8.89836e-05, gnorm=2.574, clip=0, loss_scale=2048, train_wall=3, gb_free=13.8, wall=4049
2023-03-15 15:07:15 - progress_bar.py[line:272] - INFO: epoch 006:   1997 / 2004 loss=0.8, loss_v1=0, loss_v2=0, nll_loss=0.8, ntokens=398.1, nsentences=8, sample_size=398.1, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=1257.3, ups=3.16, wpb=398.1, bsz=8, num_updates=11940, lr=8.89736e-05, gnorm=2.424, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=4053
2023-03-15 15:07:17 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 6 @ 11947 updates
2023-03-15 15:07:17 - trainer.py[line:431] - INFO: Saving checkpoint to ./checkpoints/checkpoint6.pt
2023-03-15 15:07:22 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./checkpoints/checkpoint6.pt
2023-03-15 15:07:24 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./checkpoints/checkpoint6.pt (epoch 6 @ 11947 updates, score None) (writing took 7.173035524785519 seconds)
2023-03-15 15:07:24 - train.py[line:332] - INFO: end of epoch 6 (average epoch stats below)
2023-03-15 15:07:24 - progress_bar.py[line:282] - INFO: epoch 006 | loss 0.79 | loss_v1 0 | loss_v2 0 | nll_loss 0.79 | ntokens 345.053 | nsentences 7.999 | sample_size 345.053 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.73 | wps 1043.8 | ups 3.02 | wpb 345.1 | bsz 8 | num_updates 11947 | lr 8.89665e-05 | gnorm 2.414 | clip 0 | loss_scale 2048 | train_wall 639 | gb_free 14.4 | wall 4062
2023-03-15 15:07:24 - trainer.py[line:639] - INFO: loading train data for epoch 7
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 row count 8015 total row count 8015
slice_id 0 seek offset 0
2023-03-15 15:07:25 - trainer.py[line:703] - INFO: begin training epoch 7
2023-03-15 15:07:25 - train.py[line:305] - INFO: Start iterating over samples
2023-03-15 15:07:26 - progress_bar.py[line:272] - INFO: epoch 007:      3 / 2004 loss=0.8, loss_v1=0, loss_v2=0, nll_loss=0.8, ntokens=360.7, nsentences=8, sample_size=360.7, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=319.8, ups=0.89, wpb=360.7, bsz=8, num_updates=11950, lr=8.89635e-05, gnorm=2.59, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=4064
2023-03-15 15:07:29 - progress_bar.py[line:272] - INFO: epoch 007:     13 / 2004 loss=0.746, loss_v1=0, loss_v2=0, nll_loss=0.746, ntokens=327, nsentences=8, sample_size=327, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=1010, ups=3.09, wpb=327, bsz=8, num_updates=11960, lr=8.89534e-05, gnorm=2.505, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=4067
2023-03-15 15:07:33 - progress_bar.py[line:272] - INFO: epoch 007:     23 / 2004 loss=0.749, loss_v1=0, loss_v2=0, nll_loss=0.749, ntokens=357.1, nsentences=8, sample_size=357.1, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=1065.9, ups=2.98, wpb=357.1, bsz=8, num_updates=11970, lr=8.89433e-05, gnorm=2.48, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=4070
2023-03-15 15:07:36 - progress_bar.py[line:272] - INFO: epoch 007:     33 / 2004 loss=0.798, loss_v1=0, loss_v2=0, nll_loss=0.798, ntokens=361.3, nsentences=8, sample_size=361.3, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=1032.3, ups=2.86, wpb=361.3, bsz=8, num_updates=11980, lr=8.89332e-05, gnorm=2.613, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=4074
2023-03-15 15:07:40 - progress_bar.py[line:272] - INFO: epoch 007:     43 / 2004 loss=0.755, loss_v1=0, loss_v2=0, nll_loss=0.755, ntokens=353.2, nsentences=8, sample_size=353.2, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=1057.9, ups=3, wpb=353.2, bsz=8, num_updates=11990, lr=8.89232e-05, gnorm=2.515, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=4077
2023-03-15 15:07:43 - progress_bar.py[line:272] - INFO: epoch 007:     53 / 2004 loss=0.726, loss_v1=0, loss_v2=0, nll_loss=0.726, ntokens=344.3, nsentences=8, sample_size=344.3, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=1004.6, ups=2.92, wpb=344.3, bsz=8, num_updates=12000, lr=8.89131e-05, gnorm=2.469, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=4081
2023-03-15 15:07:43 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 7 @ 12000 updates
2023-03-15 15:07:43 - trainer.py[line:431] - INFO: Saving checkpoint to ./checkpoints/checkpoint_7_12000.pt
2023-03-15 15:07:50 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./checkpoints/checkpoint_7_12000.pt
2023-03-15 15:07:53 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./checkpoints/checkpoint_7_12000.pt (epoch 7 @ 12000 updates, score None) (writing took 9.852861102670431 seconds)
2023-03-15 15:07:56 - progress_bar.py[line:272] - INFO: epoch 007:     63 / 2004 loss=0.745, loss_v1=0, loss_v2=0, nll_loss=0.745, ntokens=338.5, nsentences=8, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=259.6, ups=0.77, wpb=338.5, bsz=8, num_updates=12010, lr=8.8903e-05, gnorm=2.548, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=4094
2023-03-15 15:07:59 - progress_bar.py[line:272] - INFO: epoch 007:     73 / 2004 loss=0.779, loss_v1=0, loss_v2=0, nll_loss=0.779, ntokens=348.7, nsentences=8, sample_size=348.7, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=1099.9, ups=3.15, wpb=348.7, bsz=8, num_updates=12020, lr=8.88929e-05, gnorm=2.514, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=4097
2023-03-15 15:08:03 - progress_bar.py[line:272] - INFO: epoch 007:     83 / 2004 loss=0.719, loss_v1=0, loss_v2=0, nll_loss=0.719, ntokens=328.5, nsentences=8, sample_size=328.5, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=956.9, ups=2.91, wpb=328.5, bsz=8, num_updates=12030, lr=8.88828e-05, gnorm=2.527, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=4100
2023-03-15 15:08:06 - progress_bar.py[line:272] - INFO: epoch 007:     93 / 2004 loss=0.809, loss_v1=0, loss_v2=0, nll_loss=0.809, ntokens=369.6, nsentences=8, sample_size=369.6, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=1116.7, ups=3.02, wpb=369.6, bsz=8, num_updates=12040, lr=8.88728e-05, gnorm=2.505, clip=0, loss_scale=2048, train_wall=3, gb_free=13.9, wall=4104
2023-03-15 15:08:07 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 15:08:09 - progress_bar.py[line:272] - INFO: epoch 007:    104 / 2004 loss=0.721, loss_v1=0, loss_v2=0, nll_loss=0.721, ntokens=366.9, nsentences=8, sample_size=366.9, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=1070.4, ups=2.92, wpb=366.9, bsz=8, num_updates=12050, lr=8.88627e-05, gnorm=2.511, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=4107
2023-03-15 15:08:13 - progress_bar.py[line:272] - INFO: epoch 007:    114 / 2004 loss=0.765, loss_v1=0, loss_v2=0, nll_loss=0.765, ntokens=326.5, nsentences=8, sample_size=326.5, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=1057.1, ups=3.24, wpb=326.5, bsz=8, num_updates=12060, lr=8.88526e-05, gnorm=2.59, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=4110
2023-03-15 15:08:16 - progress_bar.py[line:272] - INFO: epoch 007:    124 / 2004 loss=0.801, loss_v1=0, loss_v2=0, nll_loss=0.801, ntokens=351.1, nsentences=8, sample_size=351.1, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=1126.2, ups=3.21, wpb=351.1, bsz=8, num_updates=12070, lr=8.88425e-05, gnorm=2.506, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=4113
2023-03-15 15:08:19 - progress_bar.py[line:272] - INFO: epoch 007:    134 / 2004 loss=0.683, loss_v1=0, loss_v2=0, nll_loss=0.683, ntokens=316.3, nsentences=8, sample_size=316.3, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=986.1, ups=3.12, wpb=316.3, bsz=8, num_updates=12080, lr=8.88324e-05, gnorm=2.465, clip=0, loss_scale=2048, train_wall=3, gb_free=14, wall=4116
2023-03-15 15:08:22 - progress_bar.py[line:272] - INFO: epoch 007:    144 / 2004 loss=0.789, loss_v1=0, loss_v2=0, nll_loss=0.789, ntokens=352.7, nsentences=8, sample_size=352.7, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=1103.6, ups=3.13, wpb=352.7, bsz=8, num_updates=12090, lr=8.88224e-05, gnorm=2.623, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=4120
2023-03-15 15:08:25 - progress_bar.py[line:272] - INFO: epoch 007:    154 / 2004 loss=0.739, loss_v1=0, loss_v2=0, nll_loss=0.739, ntokens=328.5, nsentences=8, sample_size=328.5, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=1033.8, ups=3.15, wpb=328.5, bsz=8, num_updates=12100, lr=8.88123e-05, gnorm=2.66, clip=0, loss_scale=2048, train_wall=3, gb_free=13.8, wall=4123
2023-03-15 15:08:28 - progress_bar.py[line:272] - INFO: epoch 007:    164 / 2004 loss=0.728, loss_v1=0, loss_v2=0, nll_loss=0.728, ntokens=356.8, nsentences=8, sample_size=356.8, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=1134.5, ups=3.18, wpb=356.8, bsz=8, num_updates=12110, lr=8.88022e-05, gnorm=2.414, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=4126
2023-03-15 15:08:32 - progress_bar.py[line:272] - INFO: epoch 007:    174 / 2004 loss=0.681, loss_v1=0, loss_v2=0, nll_loss=0.681, ntokens=336.7, nsentences=8, sample_size=336.7, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=1062.3, ups=3.15, wpb=336.7, bsz=8, num_updates=12120, lr=8.87921e-05, gnorm=2.379, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=4129
2023-03-15 15:08:35 - progress_bar.py[line:272] - INFO: epoch 007:    184 / 2004 loss=0.672, loss_v1=0, loss_v2=0, nll_loss=0.672, ntokens=328.6, nsentences=8, sample_size=328.6, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=1037.7, ups=3.16, wpb=328.6, bsz=8, num_updates=12130, lr=8.8782e-05, gnorm=2.433, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=4132
2023-03-15 15:08:38 - progress_bar.py[line:272] - INFO: epoch 007:    194 / 2004 loss=0.666, loss_v1=0, loss_v2=0, nll_loss=0.666, ntokens=334.4, nsentences=8, sample_size=334.4, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=1044.8, ups=3.12, wpb=334.4, bsz=8, num_updates=12140, lr=8.8772e-05, gnorm=2.416, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=4136
2023-03-15 15:08:41 - progress_bar.py[line:272] - INFO: epoch 007:    204 / 2004 loss=0.754, loss_v1=0, loss_v2=0, nll_loss=0.754, ntokens=327.4, nsentences=8, sample_size=327.4, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=1036.1, ups=3.16, wpb=327.4, bsz=8, num_updates=12150, lr=8.87619e-05, gnorm=2.612, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=4139
2023-03-15 15:08:44 - progress_bar.py[line:272] - INFO: epoch 007:    214 / 2004 loss=0.686, loss_v1=0, loss_v2=0, nll_loss=0.686, ntokens=332.9, nsentences=8, sample_size=332.9, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=1056, ups=3.17, wpb=332.9, bsz=8, num_updates=12160, lr=8.87518e-05, gnorm=2.483, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=4142
2023-03-15 15:08:47 - progress_bar.py[line:272] - INFO: epoch 007:    224 / 2004 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.635, ntokens=330.7, nsentences=8, sample_size=330.7, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=1045.5, ups=3.16, wpb=330.7, bsz=8, num_updates=12170, lr=8.87417e-05, gnorm=2.422, clip=0, loss_scale=4096, train_wall=3, gb_free=14.6, wall=4145
2023-03-15 15:08:48 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 15:08:49 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 15:08:51 - progress_bar.py[line:272] - INFO: epoch 007:    236 / 2004 loss=0.743, loss_v1=0, loss_v2=0, nll_loss=0.743, ntokens=387.2, nsentences=8, sample_size=387.2, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=991.2, ups=2.56, wpb=387.2, bsz=8, num_updates=12180, lr=8.87316e-05, gnorm=2.475, clip=0, loss_scale=1024, train_wall=4, gb_free=14.4, wall=4149
2023-03-15 15:08:54 - progress_bar.py[line:272] - INFO: epoch 007:    246 / 2004 loss=0.767, loss_v1=0, loss_v2=0, nll_loss=0.767, ntokens=352.2, nsentences=8, sample_size=352.2, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=1109.1, ups=3.15, wpb=352.2, bsz=8, num_updates=12190, lr=8.87215e-05, gnorm=2.677, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=4152
2023-03-15 15:08:58 - progress_bar.py[line:272] - INFO: epoch 007:    256 / 2004 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.653, ntokens=329.3, nsentences=8, sample_size=329.3, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=1035.4, ups=3.14, wpb=329.3, bsz=8, num_updates=12200, lr=8.87115e-05, gnorm=2.497, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=4155
2023-03-15 15:09:01 - progress_bar.py[line:272] - INFO: epoch 007:    266 / 2004 loss=0.815, loss_v1=0, loss_v2=0, nll_loss=0.815, ntokens=357, nsentences=8, sample_size=357, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=1120.9, ups=3.14, wpb=357, bsz=8, num_updates=12210, lr=8.87014e-05, gnorm=2.625, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=4158
2023-03-15 15:09:04 - progress_bar.py[line:272] - INFO: epoch 007:    276 / 2004 loss=0.747, loss_v1=0, loss_v2=0, nll_loss=0.747, ntokens=342.3, nsentences=8, sample_size=342.3, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=1078, ups=3.15, wpb=342.3, bsz=8, num_updates=12220, lr=8.86913e-05, gnorm=2.432, clip=0, loss_scale=1024, train_wall=3, gb_free=13.7, wall=4162
2023-03-15 15:09:07 - progress_bar.py[line:272] - INFO: epoch 007:    286 / 2004 loss=0.716, loss_v1=0, loss_v2=0, nll_loss=0.716, ntokens=366.8, nsentences=8, sample_size=366.8, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=1133.3, ups=3.09, wpb=366.8, bsz=8, num_updates=12230, lr=8.86812e-05, gnorm=2.379, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=4165
2023-03-15 15:09:11 - progress_bar.py[line:272] - INFO: epoch 007:    296 / 2004 loss=0.744, loss_v1=0, loss_v2=0, nll_loss=0.744, ntokens=352.6, nsentences=8, sample_size=352.6, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=1090.7, ups=3.09, wpb=352.6, bsz=8, num_updates=12240, lr=8.86711e-05, gnorm=2.389, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=4168
2023-03-15 15:09:14 - progress_bar.py[line:272] - INFO: epoch 007:    306 / 2004 loss=0.753, loss_v1=0, loss_v2=0, nll_loss=0.753, ntokens=340.2, nsentences=8, sample_size=340.2, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=1063.7, ups=3.13, wpb=340.2, bsz=8, num_updates=12250, lr=8.86611e-05, gnorm=2.515, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=4171
2023-03-15 15:09:17 - progress_bar.py[line:272] - INFO: epoch 007:    316 / 2004 loss=0.73, loss_v1=0, loss_v2=0, nll_loss=0.73, ntokens=362.2, nsentences=8, sample_size=362.2, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=1092, ups=3.01, wpb=362.2, bsz=8, num_updates=12260, lr=8.8651e-05, gnorm=2.519, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=4175
2023-03-15 15:09:20 - progress_bar.py[line:272] - INFO: epoch 007:    326 / 2004 loss=0.685, loss_v1=0, loss_v2=0, nll_loss=0.685, ntokens=324.5, nsentences=8, sample_size=324.5, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=1018.7, ups=3.14, wpb=324.5, bsz=8, num_updates=12270, lr=8.86409e-05, gnorm=2.475, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=4178
2023-03-15 15:09:23 - progress_bar.py[line:272] - INFO: epoch 007:    336 / 2004 loss=0.771, loss_v1=0, loss_v2=0, nll_loss=0.771, ntokens=339, nsentences=8, sample_size=339, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=1067.5, ups=3.15, wpb=339, bsz=8, num_updates=12280, lr=8.86308e-05, gnorm=2.678, clip=0, loss_scale=1024, train_wall=3, gb_free=13.9, wall=4181
2023-03-15 15:09:27 - progress_bar.py[line:272] - INFO: epoch 007:    346 / 2004 loss=0.774, loss_v1=0, loss_v2=0, nll_loss=0.774, ntokens=374, nsentences=8, sample_size=374, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=1144.3, ups=3.06, wpb=374, bsz=8, num_updates=12290, lr=8.86207e-05, gnorm=2.547, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=4184
2023-03-15 15:09:30 - progress_bar.py[line:272] - INFO: epoch 007:    356 / 2004 loss=0.747, loss_v1=0, loss_v2=0, nll_loss=0.747, ntokens=335.2, nsentences=8, sample_size=335.2, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=1051, ups=3.14, wpb=335.2, bsz=8, num_updates=12300, lr=8.86107e-05, gnorm=2.611, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=4187
2023-03-15 15:09:33 - progress_bar.py[line:272] - INFO: epoch 007:    366 / 2004 loss=0.744, loss_v1=0, loss_v2=0, nll_loss=0.744, ntokens=366.6, nsentences=8, sample_size=366.6, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=1139.5, ups=3.11, wpb=366.6, bsz=8, num_updates=12310, lr=8.86006e-05, gnorm=2.578, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=4191
2023-03-15 15:09:36 - progress_bar.py[line:272] - INFO: epoch 007:    376 / 2004 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.652, ntokens=307.5, nsentences=8, sample_size=307.5, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=952.9, ups=3.1, wpb=307.5, bsz=8, num_updates=12320, lr=8.85905e-05, gnorm=2.49, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=4194
2023-03-15 15:09:39 - progress_bar.py[line:272] - INFO: epoch 007:    386 / 2004 loss=0.705, loss_v1=0, loss_v2=0, nll_loss=0.705, ntokens=325.8, nsentences=8, sample_size=325.8, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=1019.4, ups=3.13, wpb=325.8, bsz=8, num_updates=12330, lr=8.85804e-05, gnorm=2.53, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=4197
2023-03-15 15:09:43 - progress_bar.py[line:272] - INFO: epoch 007:    396 / 2004 loss=0.765, loss_v1=0, loss_v2=0, nll_loss=0.765, ntokens=352.3, nsentences=8, sample_size=352.3, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=1105.1, ups=3.14, wpb=352.3, bsz=8, num_updates=12340, lr=8.85703e-05, gnorm=2.653, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=4200
2023-03-15 15:09:46 - progress_bar.py[line:272] - INFO: epoch 007:    406 / 2004 loss=0.693, loss_v1=0, loss_v2=0, nll_loss=0.693, ntokens=381.7, nsentences=8, sample_size=381.7, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=1093.5, ups=2.86, wpb=381.7, bsz=8, num_updates=12350, lr=8.85603e-05, gnorm=2.4, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=4204
2023-03-15 15:09:50 - progress_bar.py[line:272] - INFO: epoch 007:    416 / 2004 loss=0.677, loss_v1=0, loss_v2=0, nll_loss=0.677, ntokens=339.3, nsentences=8, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=980, ups=2.89, wpb=339.3, bsz=8, num_updates=12360, lr=8.85502e-05, gnorm=2.479, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=4207
2023-03-15 15:09:53 - progress_bar.py[line:272] - INFO: epoch 007:    426 / 2004 loss=0.684, loss_v1=0, loss_v2=0, nll_loss=0.684, ntokens=330.6, nsentences=8, sample_size=330.6, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=944.6, ups=2.86, wpb=330.6, bsz=8, num_updates=12370, lr=8.85401e-05, gnorm=2.496, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=4211
2023-03-15 15:09:56 - progress_bar.py[line:272] - INFO: epoch 007:    436 / 2004 loss=0.727, loss_v1=0, loss_v2=0, nll_loss=0.727, ntokens=368.1, nsentences=8, sample_size=368.1, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=1143.1, ups=3.11, wpb=368.1, bsz=8, num_updates=12380, lr=8.853e-05, gnorm=2.509, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=4214
2023-03-15 15:10:00 - progress_bar.py[line:272] - INFO: epoch 007:    446 / 2004 loss=0.784, loss_v1=0, loss_v2=0, nll_loss=0.784, ntokens=362.4, nsentences=8, sample_size=362.4, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=1095.3, ups=3.02, wpb=362.4, bsz=8, num_updates=12390, lr=8.85199e-05, gnorm=2.558, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=4217
2023-03-15 15:10:03 - progress_bar.py[line:272] - INFO: epoch 007:    456 / 2004 loss=0.838, loss_v1=0, loss_v2=0, nll_loss=0.838, ntokens=381.5, nsentences=8, sample_size=381.5, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=1101.1, ups=2.89, wpb=381.5, bsz=8, num_updates=12400, lr=8.85098e-05, gnorm=2.499, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=4221
2023-03-15 15:10:07 - progress_bar.py[line:272] - INFO: epoch 007:    466 / 2004 loss=0.858, loss_v1=0, loss_v2=0, nll_loss=0.858, ntokens=368.6, nsentences=8, sample_size=368.6, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=1063.8, ups=2.89, wpb=368.6, bsz=8, num_updates=12410, lr=8.84998e-05, gnorm=2.735, clip=0, loss_scale=2048, train_wall=3, gb_free=13.9, wall=4224
2023-03-15 15:10:10 - progress_bar.py[line:272] - INFO: epoch 007:    476 / 2004 loss=0.695, loss_v1=0, loss_v2=0, nll_loss=0.695, ntokens=344.6, nsentences=8, sample_size=344.6, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=995.5, ups=2.89, wpb=344.6, bsz=8, num_updates=12420, lr=8.84897e-05, gnorm=2.437, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=4228
2023-03-15 15:10:13 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 15:10:14 - progress_bar.py[line:272] - INFO: epoch 007:    487 / 2004 loss=0.732, loss_v1=0, loss_v2=0, nll_loss=0.732, ntokens=385.2, nsentences=8, sample_size=385.2, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=1028, ups=2.67, wpb=385.2, bsz=8, num_updates=12430, lr=8.84796e-05, gnorm=2.438, clip=0, loss_scale=2048, train_wall=4, gb_free=14.8, wall=4231
2023-03-15 15:10:17 - progress_bar.py[line:272] - INFO: epoch 007:    497 / 2004 loss=0.724, loss_v1=0, loss_v2=0, nll_loss=0.724, ntokens=371, nsentences=8, sample_size=371, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=1050.2, ups=2.83, wpb=371, bsz=8, num_updates=12440, lr=8.84695e-05, gnorm=2.382, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=4235
2023-03-15 15:10:21 - progress_bar.py[line:272] - INFO: epoch 007:    507 / 2004 loss=0.74, loss_v1=0, loss_v2=0, nll_loss=0.74, ntokens=341.1, nsentences=8, sample_size=341.1, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=999.1, ups=2.93, wpb=341.1, bsz=8, num_updates=12450, lr=8.84594e-05, gnorm=2.521, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=4238
2023-03-15 15:10:24 - progress_bar.py[line:272] - INFO: epoch 007:    517 / 2004 loss=0.758, loss_v1=0, loss_v2=0, nll_loss=0.758, ntokens=353.3, nsentences=8, sample_size=353.3, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=1103.3, ups=3.12, wpb=353.3, bsz=8, num_updates=12460, lr=8.84494e-05, gnorm=2.63, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=4242
2023-03-15 15:10:27 - progress_bar.py[line:272] - INFO: epoch 007:    527 / 2004 loss=0.791, loss_v1=0, loss_v2=0, nll_loss=0.791, ntokens=401.8, nsentences=8, sample_size=401.8, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=1239.6, ups=3.09, wpb=401.8, bsz=8, num_updates=12470, lr=8.84393e-05, gnorm=2.499, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=4245
2023-03-15 15:10:31 - progress_bar.py[line:272] - INFO: epoch 007:    537 / 2004 loss=0.747, loss_v1=0, loss_v2=0, nll_loss=0.747, ntokens=381.1, nsentences=8, sample_size=381.1, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=1130, ups=2.97, wpb=381.1, bsz=8, num_updates=12480, lr=8.84292e-05, gnorm=2.476, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=4248
2023-03-15 15:10:34 - progress_bar.py[line:272] - INFO: epoch 007:    547 / 2004 loss=0.7, loss_v1=0, loss_v2=0, nll_loss=0.7, ntokens=352.4, nsentences=8, sample_size=352.4, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=1086.7, ups=3.08, wpb=352.4, bsz=8, num_updates=12490, lr=8.84191e-05, gnorm=2.507, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=4251
2023-03-15 15:10:37 - progress_bar.py[line:272] - INFO: epoch 007:    557 / 2004 loss=0.728, loss_v1=0, loss_v2=0, nll_loss=0.728, ntokens=382, nsentences=8, sample_size=382, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=1198.5, ups=3.14, wpb=382, bsz=8, num_updates=12500, lr=8.8409e-05, gnorm=2.466, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=4255
2023-03-15 15:10:40 - progress_bar.py[line:272] - INFO: epoch 007:    567 / 2004 loss=0.722, loss_v1=0, loss_v2=0, nll_loss=0.722, ntokens=372.3, nsentences=8, sample_size=372.3, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=1155.3, ups=3.1, wpb=372.3, bsz=8, num_updates=12510, lr=8.8399e-05, gnorm=2.467, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=4258
2023-03-15 15:10:43 - progress_bar.py[line:272] - INFO: epoch 007:    577 / 2004 loss=0.7, loss_v1=0, loss_v2=0, nll_loss=0.7, ntokens=336.7, nsentences=8, sample_size=336.7, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=1036.1, ups=3.08, wpb=336.7, bsz=8, num_updates=12520, lr=8.83889e-05, gnorm=2.543, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=4261
2023-03-15 15:10:45 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 15:10:47 - progress_bar.py[line:272] - INFO: epoch 007:    588 / 2004 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.65, ntokens=336.9, nsentences=8, sample_size=336.9, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=915.2, ups=2.72, wpb=336.9, bsz=8, num_updates=12530, lr=8.83788e-05, gnorm=2.464, clip=0, loss_scale=1024, train_wall=4, gb_free=14.7, wall=4265
2023-03-15 15:10:50 - progress_bar.py[line:272] - INFO: epoch 007:    598 / 2004 loss=0.699, loss_v1=0, loss_v2=0, nll_loss=0.699, ntokens=334.5, nsentences=8, sample_size=334.5, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=1048, ups=3.13, wpb=334.5, bsz=8, num_updates=12540, lr=8.83687e-05, gnorm=2.582, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=4268
2023-03-15 15:10:54 - progress_bar.py[line:272] - INFO: epoch 007:    608 / 2004 loss=0.789, loss_v1=0, loss_v2=0, nll_loss=0.789, ntokens=351.9, nsentences=8, sample_size=351.9, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=1099.4, ups=3.12, wpb=351.9, bsz=8, num_updates=12550, lr=8.83586e-05, gnorm=2.634, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=4271
2023-03-15 15:10:57 - progress_bar.py[line:272] - INFO: epoch 007:    618 / 2004 loss=0.663, loss_v1=0, loss_v2=0, nll_loss=0.663, ntokens=354, nsentences=8, sample_size=354, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=1105.6, ups=3.12, wpb=354, bsz=8, num_updates=12560, lr=8.83486e-05, gnorm=2.435, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=4274
2023-03-15 15:11:00 - progress_bar.py[line:272] - INFO: epoch 007:    628 / 2004 loss=0.688, loss_v1=0, loss_v2=0, nll_loss=0.688, ntokens=368.7, nsentences=8, sample_size=368.7, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=1165.7, ups=3.16, wpb=368.7, bsz=8, num_updates=12570, lr=8.83385e-05, gnorm=2.423, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=4278
2023-03-15 15:11:03 - progress_bar.py[line:272] - INFO: epoch 007:    638 / 2004 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.647, ntokens=331.9, nsentences=8, sample_size=331.9, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=1045.8, ups=3.15, wpb=331.9, bsz=8, num_updates=12580, lr=8.83284e-05, gnorm=2.504, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=4281
2023-03-15 15:11:06 - progress_bar.py[line:272] - INFO: epoch 007:    648 / 2004 loss=0.718, loss_v1=0, loss_v2=0, nll_loss=0.718, ntokens=330.7, nsentences=8, sample_size=330.7, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=1029.3, ups=3.11, wpb=330.7, bsz=8, num_updates=12590, lr=8.83183e-05, gnorm=2.617, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=4284
2023-03-15 15:11:09 - progress_bar.py[line:272] - INFO: epoch 007:    658 / 2004 loss=0.773, loss_v1=0, loss_v2=0, nll_loss=0.773, ntokens=352.5, nsentences=8, sample_size=352.5, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=1109.4, ups=3.15, wpb=352.5, bsz=8, num_updates=12600, lr=8.83082e-05, gnorm=2.639, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=4287
2023-03-15 15:11:13 - progress_bar.py[line:272] - INFO: epoch 007:    668 / 2004 loss=0.678, loss_v1=0, loss_v2=0, nll_loss=0.678, ntokens=299.1, nsentences=8, sample_size=299.1, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=940.5, ups=3.14, wpb=299.1, bsz=8, num_updates=12610, lr=8.82982e-05, gnorm=2.619, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=4290
2023-03-15 15:11:16 - progress_bar.py[line:272] - INFO: epoch 007:    678 / 2004 loss=0.681, loss_v1=0, loss_v2=0, nll_loss=0.681, ntokens=343.8, nsentences=8, sample_size=343.8, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=1079.3, ups=3.14, wpb=343.8, bsz=8, num_updates=12620, lr=8.82881e-05, gnorm=2.424, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=4293
2023-03-15 15:11:19 - progress_bar.py[line:272] - INFO: epoch 007:    688 / 2004 loss=0.693, loss_v1=0, loss_v2=0, nll_loss=0.693, ntokens=355.9, nsentences=8, sample_size=355.9, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=1124.8, ups=3.16, wpb=355.9, bsz=8, num_updates=12630, lr=8.8278e-05, gnorm=2.551, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=4297
2023-03-15 15:11:22 - progress_bar.py[line:272] - INFO: epoch 007:    698 / 2004 loss=0.731, loss_v1=0, loss_v2=0, nll_loss=0.731, ntokens=354.1, nsentences=8, sample_size=354.1, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=1117.9, ups=3.16, wpb=354.1, bsz=8, num_updates=12640, lr=8.82679e-05, gnorm=2.626, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=4300
2023-03-15 15:11:26 - progress_bar.py[line:272] - INFO: epoch 007:    708 / 2004 loss=0.708, loss_v1=0, loss_v2=0, nll_loss=0.708, ntokens=324.6, nsentences=8, sample_size=324.6, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=939.1, ups=2.89, wpb=324.6, bsz=8, num_updates=12650, lr=8.82578e-05, gnorm=2.609, clip=0, loss_scale=1024, train_wall=3, gb_free=15.7, wall=4303
2023-03-15 15:11:29 - progress_bar.py[line:272] - INFO: epoch 007:    718 / 2004 loss=0.718, loss_v1=0, loss_v2=0, nll_loss=0.718, ntokens=336.8, nsentences=8, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=968.4, ups=2.88, wpb=336.8, bsz=8, num_updates=12660, lr=8.82477e-05, gnorm=2.564, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=4307
2023-03-15 15:11:33 - progress_bar.py[line:272] - INFO: epoch 007:    728 / 2004 loss=0.739, loss_v1=0, loss_v2=0, nll_loss=0.739, ntokens=365.3, nsentences=8, sample_size=365.3, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=1049.2, ups=2.87, wpb=365.3, bsz=8, num_updates=12670, lr=8.82377e-05, gnorm=2.68, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=4310
2023-03-15 15:11:36 - progress_bar.py[line:272] - INFO: epoch 007:    738 / 2004 loss=0.686, loss_v1=0, loss_v2=0, nll_loss=0.686, ntokens=331.6, nsentences=8, sample_size=331.6, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=1056.3, ups=3.19, wpb=331.6, bsz=8, num_updates=12680, lr=8.82276e-05, gnorm=2.565, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=4313
2023-03-15 15:11:39 - progress_bar.py[line:272] - INFO: epoch 007:    748 / 2004 loss=0.743, loss_v1=0, loss_v2=0, nll_loss=0.743, ntokens=375, nsentences=8, sample_size=375, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=1183.2, ups=3.16, wpb=375, bsz=8, num_updates=12690, lr=8.82175e-05, gnorm=2.651, clip=0, loss_scale=2048, train_wall=3, gb_free=13.7, wall=4317
2023-03-15 15:11:42 - progress_bar.py[line:272] - INFO: epoch 007:    758 / 2004 loss=0.703, loss_v1=0, loss_v2=0, nll_loss=0.703, ntokens=295.1, nsentences=8, sample_size=295.1, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=929, ups=3.15, wpb=295.1, bsz=8, num_updates=12700, lr=8.82074e-05, gnorm=2.788, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=4320
2023-03-15 15:11:45 - progress_bar.py[line:272] - INFO: epoch 007:    768 / 2004 loss=0.809, loss_v1=0, loss_v2=0, nll_loss=0.809, ntokens=408.6, nsentences=8, sample_size=408.6, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=1211.6, ups=2.97, wpb=408.6, bsz=8, num_updates=12710, lr=8.81973e-05, gnorm=2.688, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=4323
2023-03-15 15:11:49 - progress_bar.py[line:272] - INFO: epoch 007:    778 / 2004 loss=0.77, loss_v1=0, loss_v2=0, nll_loss=0.77, ntokens=351.3, nsentences=8, sample_size=351.3, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=1086.4, ups=3.09, wpb=351.3, bsz=8, num_updates=12720, lr=8.81873e-05, gnorm=2.66, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=4326
2023-03-15 15:11:52 - progress_bar.py[line:272] - INFO: epoch 007:    788 / 2004 loss=0.684, loss_v1=0, loss_v2=0, nll_loss=0.684, ntokens=343.7, nsentences=8, sample_size=343.7, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=1080.3, ups=3.14, wpb=343.7, bsz=8, num_updates=12730, lr=8.81772e-05, gnorm=2.564, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=4329
2023-03-15 15:11:55 - progress_bar.py[line:272] - INFO: epoch 007:    798 / 2004 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.64, ntokens=318.4, nsentences=8, sample_size=318.4, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=1019.4, ups=3.2, wpb=318.4, bsz=8, num_updates=12740, lr=8.81671e-05, gnorm=2.541, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=4333
2023-03-15 15:11:58 - progress_bar.py[line:272] - INFO: epoch 007:    808 / 2004 loss=0.703, loss_v1=0, loss_v2=0, nll_loss=0.703, ntokens=349.8, nsentences=8, sample_size=349.8, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=1107.8, ups=3.17, wpb=349.8, bsz=8, num_updates=12750, lr=8.8157e-05, gnorm=2.715, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=4336
2023-03-15 15:12:01 - progress_bar.py[line:272] - INFO: epoch 007:    818 / 2004 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.624, ntokens=312.9, nsentences=8, sample_size=312.9, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=991.2, ups=3.17, wpb=312.9, bsz=8, num_updates=12760, lr=8.81469e-05, gnorm=2.604, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=4339
2023-03-15 15:12:05 - progress_bar.py[line:272] - INFO: epoch 007:    828 / 2004 loss=0.753, loss_v1=0, loss_v2=0, nll_loss=0.753, ntokens=378.6, nsentences=8, sample_size=378.6, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=1176.8, ups=3.11, wpb=378.6, bsz=8, num_updates=12770, lr=8.81369e-05, gnorm=2.593, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=4342
2023-03-15 15:12:08 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 15:12:08 - progress_bar.py[line:272] - INFO: epoch 007:    839 / 2004 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.628, ntokens=326.4, nsentences=8, sample_size=326.4, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=899.7, ups=2.76, wpb=326.4, bsz=8, num_updates=12780, lr=8.81268e-05, gnorm=2.574, clip=0, loss_scale=2048, train_wall=4, gb_free=14.4, wall=4346
2023-03-15 15:12:12 - progress_bar.py[line:272] - INFO: epoch 007:    849 / 2004 loss=0.711, loss_v1=0, loss_v2=0, nll_loss=0.711, ntokens=365.8, nsentences=8, sample_size=365.8, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=1043.6, ups=2.85, wpb=365.8, bsz=8, num_updates=12790, lr=8.81167e-05, gnorm=2.533, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=4349
2023-03-15 15:12:15 - progress_bar.py[line:272] - INFO: epoch 007:    859 / 2004 loss=0.728, loss_v1=0, loss_v2=0, nll_loss=0.728, ntokens=346.7, nsentences=8, sample_size=346.7, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=984.1, ups=2.84, wpb=346.7, bsz=8, num_updates=12800, lr=8.81066e-05, gnorm=2.654, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=4353
2023-03-15 15:12:19 - progress_bar.py[line:272] - INFO: epoch 007:    869 / 2004 loss=0.718, loss_v1=0, loss_v2=0, nll_loss=0.718, ntokens=365.4, nsentences=8, sample_size=365.4, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=1036.1, ups=2.84, wpb=365.4, bsz=8, num_updates=12810, lr=8.80965e-05, gnorm=2.557, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=4356
2023-03-15 15:12:22 - progress_bar.py[line:272] - INFO: epoch 007:    879 / 2004 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.634, ntokens=325.6, nsentences=8, sample_size=325.6, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=937.3, ups=2.88, wpb=325.6, bsz=8, num_updates=12820, lr=8.80865e-05, gnorm=2.557, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=4360
2023-03-15 15:12:26 - progress_bar.py[line:272] - INFO: epoch 007:    889 / 2004 loss=0.679, loss_v1=0, loss_v2=0, nll_loss=0.679, ntokens=311.6, nsentences=8, sample_size=311.6, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=867.3, ups=2.78, wpb=311.6, bsz=8, num_updates=12830, lr=8.80764e-05, gnorm=2.702, clip=0, loss_scale=2048, train_wall=4, gb_free=15.6, wall=4363
2023-03-15 15:12:29 - progress_bar.py[line:272] - INFO: epoch 007:    899 / 2004 loss=0.718, loss_v1=0, loss_v2=0, nll_loss=0.718, ntokens=368.5, nsentences=8, sample_size=368.5, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=1034.6, ups=2.81, wpb=368.5, bsz=8, num_updates=12840, lr=8.80663e-05, gnorm=2.623, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=4367
2023-03-15 15:12:33 - progress_bar.py[line:272] - INFO: epoch 007:    909 / 2004 loss=0.656, loss_v1=0, loss_v2=0, nll_loss=0.656, ntokens=357, nsentences=8, sample_size=357, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=1004.6, ups=2.81, wpb=357, bsz=8, num_updates=12850, lr=8.80562e-05, gnorm=2.451, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=4370
2023-03-15 15:12:36 - progress_bar.py[line:272] - INFO: epoch 007:    919 / 2004 loss=0.722, loss_v1=0, loss_v2=0, nll_loss=0.722, ntokens=353.3, nsentences=8, sample_size=353.3, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=990.3, ups=2.8, wpb=353.3, bsz=8, num_updates=12860, lr=8.80461e-05, gnorm=2.674, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=4374
2023-03-15 15:12:40 - progress_bar.py[line:272] - INFO: epoch 007:    929 / 2004 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.652, ntokens=325.6, nsentences=8, sample_size=325.6, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=920.3, ups=2.83, wpb=325.6, bsz=8, num_updates=12870, lr=8.8036e-05, gnorm=2.582, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=4378
2023-03-15 15:12:44 - progress_bar.py[line:272] - INFO: epoch 007:    939 / 2004 loss=0.711, loss_v1=0, loss_v2=0, nll_loss=0.711, ntokens=373, nsentences=8, sample_size=373, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=1056.7, ups=2.83, wpb=373, bsz=8, num_updates=12880, lr=8.8026e-05, gnorm=2.565, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=4381
2023-03-15 15:12:47 - progress_bar.py[line:272] - INFO: epoch 007:    949 / 2004 loss=0.687, loss_v1=0, loss_v2=0, nll_loss=0.687, ntokens=344, nsentences=8, sample_size=344, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=976.8, ups=2.84, wpb=344, bsz=8, num_updates=12890, lr=8.80159e-05, gnorm=2.607, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=4385
2023-03-15 15:12:51 - progress_bar.py[line:272] - INFO: epoch 007:    959 / 2004 loss=0.749, loss_v1=0, loss_v2=0, nll_loss=0.749, ntokens=361.6, nsentences=8, sample_size=361.6, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=1022.5, ups=2.83, wpb=361.6, bsz=8, num_updates=12900, lr=8.80058e-05, gnorm=2.663, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=4388
2023-03-15 15:12:53 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 15:12:54 - progress_bar.py[line:272] - INFO: epoch 007:    970 / 2004 loss=0.677, loss_v1=0, loss_v2=0, nll_loss=0.677, ntokens=342, nsentences=8, sample_size=342, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=891.5, ups=2.61, wpb=342, bsz=8, num_updates=12910, lr=8.79957e-05, gnorm=2.63, clip=0, loss_scale=2048, train_wall=4, gb_free=15.2, wall=4392
2023-03-15 15:12:58 - progress_bar.py[line:272] - INFO: epoch 007:    980 / 2004 loss=0.69, loss_v1=0, loss_v2=0, nll_loss=0.69, ntokens=329.2, nsentences=8, sample_size=329.2, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=945.8, ups=2.87, wpb=329.2, bsz=8, num_updates=12920, lr=8.79856e-05, gnorm=2.64, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=4396
2023-03-15 15:13:01 - progress_bar.py[line:272] - INFO: epoch 007:    990 / 2004 loss=0.702, loss_v1=0, loss_v2=0, nll_loss=0.702, ntokens=377.1, nsentences=8, sample_size=377.1, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=1072.1, ups=2.84, wpb=377.1, bsz=8, num_updates=12930, lr=8.79756e-05, gnorm=2.487, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=4399
2023-03-15 15:13:05 - progress_bar.py[line:272] - INFO: epoch 007:   1000 / 2004 loss=0.686, loss_v1=0, loss_v2=0, nll_loss=0.686, ntokens=343.4, nsentences=8, sample_size=343.4, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=1040.1, ups=3.03, wpb=343.4, bsz=8, num_updates=12940, lr=8.79655e-05, gnorm=2.536, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=4402
2023-03-15 15:13:08 - progress_bar.py[line:272] - INFO: epoch 007:   1010 / 2004 loss=0.693, loss_v1=0, loss_v2=0, nll_loss=0.693, ntokens=317.5, nsentences=8, sample_size=317.5, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=986.1, ups=3.11, wpb=317.5, bsz=8, num_updates=12950, lr=8.79554e-05, gnorm=2.759, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=4406
2023-03-15 15:13:11 - progress_bar.py[line:272] - INFO: epoch 007:   1020 / 2004 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.658, ntokens=329.8, nsentences=8, sample_size=329.8, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=1059.9, ups=3.21, wpb=329.8, bsz=8, num_updates=12960, lr=8.79453e-05, gnorm=2.625, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=4409
2023-03-15 15:13:14 - progress_bar.py[line:272] - INFO: epoch 007:   1030 / 2004 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.653, ntokens=326.8, nsentences=8, sample_size=326.8, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=1039.9, ups=3.18, wpb=326.8, bsz=8, num_updates=12970, lr=8.79352e-05, gnorm=2.556, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=4412
2023-03-15 15:13:17 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 15:13:18 - progress_bar.py[line:272] - INFO: epoch 007:   1041 / 2004 loss=0.701, loss_v1=0, loss_v2=0, nll_loss=0.701, ntokens=330.8, nsentences=8, sample_size=330.8, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=958.8, ups=2.9, wpb=330.8, bsz=8, num_updates=12980, lr=8.79252e-05, gnorm=2.582, clip=0, loss_scale=1024, train_wall=3, gb_free=13.7, wall=4415
2023-03-15 15:13:21 - progress_bar.py[line:272] - INFO: epoch 007:   1051 / 2004 loss=0.725, loss_v1=0, loss_v2=0, nll_loss=0.725, ntokens=371.9, nsentences=8, sample_size=371.9, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=1154.1, ups=3.1, wpb=371.9, bsz=8, num_updates=12990, lr=8.79151e-05, gnorm=2.653, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=4418
2023-03-15 15:13:24 - progress_bar.py[line:272] - INFO: epoch 007:   1061 / 2004 loss=0.71, loss_v1=0, loss_v2=0, nll_loss=0.71, ntokens=328.8, nsentences=8, sample_size=328.8, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=1035.4, ups=3.15, wpb=328.8, bsz=8, num_updates=13000, lr=8.7905e-05, gnorm=2.652, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=4422
2023-03-15 15:13:27 - progress_bar.py[line:272] - INFO: epoch 007:   1071 / 2004 loss=0.743, loss_v1=0, loss_v2=0, nll_loss=0.743, ntokens=361, nsentences=8, sample_size=361, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=1118.5, ups=3.1, wpb=361, bsz=8, num_updates=13010, lr=8.78949e-05, gnorm=2.682, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=4425
2023-03-15 15:13:30 - progress_bar.py[line:272] - INFO: epoch 007:   1081 / 2004 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.646, ntokens=358.8, nsentences=8, sample_size=358.8, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=1121.2, ups=3.12, wpb=358.8, bsz=8, num_updates=13020, lr=8.78848e-05, gnorm=2.552, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=4428
2023-03-15 15:13:32 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-03-15 15:13:34 - progress_bar.py[line:272] - INFO: epoch 007:   1092 / 2004 loss=0.743, loss_v1=0, loss_v2=0, nll_loss=0.743, ntokens=341.5, nsentences=8, sample_size=341.5, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=986.9, ups=2.89, wpb=341.5, bsz=8, num_updates=13030, lr=8.78748e-05, gnorm=2.658, clip=0, loss_scale=512, train_wall=3, gb_free=14.9, wall=4432
2023-03-15 15:13:37 - progress_bar.py[line:272] - INFO: epoch 007:   1102 / 2004 loss=0.774, loss_v1=0, loss_v2=0, nll_loss=0.774, ntokens=362, nsentences=8, sample_size=362, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=1138.5, ups=3.15, wpb=362, bsz=8, num_updates=13040, lr=8.78647e-05, gnorm=2.784, clip=0, loss_scale=512, train_wall=3, gb_free=14.5, wall=4435
2023-03-15 15:13:40 - progress_bar.py[line:272] - INFO: epoch 007:   1112 / 2004 loss=0.701, loss_v1=0, loss_v2=0, nll_loss=0.701, ntokens=360.1, nsentences=8, sample_size=360.1, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=1129.4, ups=3.14, wpb=360.1, bsz=8, num_updates=13050, lr=8.78546e-05, gnorm=2.51, clip=0, loss_scale=512, train_wall=3, gb_free=14.6, wall=4438
2023-03-15 15:13:43 - progress_bar.py[line:272] - INFO: epoch 007:   1122 / 2004 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.552, ntokens=307.3, nsentences=8, sample_size=307.3, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=976.5, ups=3.18, wpb=307.3, bsz=8, num_updates=13060, lr=8.78445e-05, gnorm=2.381, clip=0, loss_scale=512, train_wall=3, gb_free=15.9, wall=4441
2023-03-15 15:13:47 - progress_bar.py[line:272] - INFO: epoch 007:   1132 / 2004 loss=0.753, loss_v1=0, loss_v2=0, nll_loss=0.753, ntokens=378.4, nsentences=8, sample_size=378.4, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=1160, ups=3.07, wpb=378.4, bsz=8, num_updates=13070, lr=8.78344e-05, gnorm=2.593, clip=0, loss_scale=512, train_wall=3, gb_free=15, wall=4444
2023-03-15 15:13:50 - progress_bar.py[line:272] - INFO: epoch 007:   1142 / 2004 loss=0.701, loss_v1=0, loss_v2=0, nll_loss=0.701, ntokens=361.2, nsentences=8, sample_size=361.2, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=1159.4, ups=3.21, wpb=361.2, bsz=8, num_updates=13080, lr=8.78244e-05, gnorm=2.65, clip=0, loss_scale=512, train_wall=3, gb_free=15.3, wall=4447
2023-03-15 15:13:53 - progress_bar.py[line:272] - INFO: epoch 007:   1152 / 2004 loss=0.682, loss_v1=0, loss_v2=0, nll_loss=0.682, ntokens=377.5, nsentences=8, sample_size=377.5, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=1148, ups=3.04, wpb=377.5, bsz=8, num_updates=13090, lr=8.78143e-05, gnorm=2.447, clip=0, loss_scale=512, train_wall=3, gb_free=14.3, wall=4451
2023-03-15 15:13:56 - progress_bar.py[line:272] - INFO: epoch 007:   1162 / 2004 loss=0.708, loss_v1=0, loss_v2=0, nll_loss=0.708, ntokens=376.5, nsentences=8, sample_size=376.5, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=1158.1, ups=3.08, wpb=376.5, bsz=8, num_updates=13100, lr=8.78042e-05, gnorm=2.604, clip=0, loss_scale=512, train_wall=3, gb_free=15.5, wall=4454
2023-03-15 15:14:00 - progress_bar.py[line:272] - INFO: epoch 007:   1172 / 2004 loss=0.663, loss_v1=0, loss_v2=0, nll_loss=0.663, ntokens=344.4, nsentences=8, sample_size=344.4, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=1063.8, ups=3.09, wpb=344.4, bsz=8, num_updates=13110, lr=8.77941e-05, gnorm=2.62, clip=0, loss_scale=512, train_wall=3, gb_free=15.2, wall=4457
2023-03-15 15:14:03 - progress_bar.py[line:272] - INFO: epoch 007:   1182 / 2004 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.631, ntokens=348.5, nsentences=8, sample_size=348.5, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=1106, ups=3.17, wpb=348.5, bsz=8, num_updates=13120, lr=8.7784e-05, gnorm=2.424, clip=0, loss_scale=512, train_wall=3, gb_free=14.9, wall=4460
2023-03-15 15:14:06 - progress_bar.py[line:272] - INFO: epoch 007:   1192 / 2004 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.606, ntokens=346.6, nsentences=8, sample_size=346.6, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=1083.8, ups=3.13, wpb=346.6, bsz=8, num_updates=13130, lr=8.77739e-05, gnorm=2.407, clip=0, loss_scale=512, train_wall=3, gb_free=14.9, wall=4464
2023-03-15 15:14:09 - progress_bar.py[line:272] - INFO: epoch 007:   1202 / 2004 loss=0.672, loss_v1=0, loss_v2=0, nll_loss=0.672, ntokens=343.5, nsentences=8, sample_size=343.5, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=1070.5, ups=3.12, wpb=343.5, bsz=8, num_updates=13140, lr=8.77639e-05, gnorm=2.595, clip=0, loss_scale=512, train_wall=3, gb_free=14.9, wall=4467
2023-03-15 15:14:12 - progress_bar.py[line:272] - INFO: epoch 007:   1212 / 2004 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.647, ntokens=283.2, nsentences=8, sample_size=283.2, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=911.8, ups=3.22, wpb=283.2, bsz=8, num_updates=13150, lr=8.77538e-05, gnorm=2.713, clip=0, loss_scale=512, train_wall=3, gb_free=14.2, wall=4470
2023-03-15 15:14:15 - progress_bar.py[line:272] - INFO: epoch 007:   1222 / 2004 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.639, ntokens=331.2, nsentences=8, sample_size=331.2, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=1036.7, ups=3.13, wpb=331.2, bsz=8, num_updates=13160, lr=8.77437e-05, gnorm=2.572, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=4473
2023-03-15 15:14:19 - progress_bar.py[line:272] - INFO: epoch 007:   1232 / 2004 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.602, ntokens=304, nsentences=8, sample_size=304, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=970.8, ups=3.19, wpb=304, bsz=8, num_updates=13170, lr=8.77336e-05, gnorm=2.661, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=4476
2023-03-15 15:14:22 - progress_bar.py[line:272] - INFO: epoch 007:   1242 / 2004 loss=0.731, loss_v1=0, loss_v2=0, nll_loss=0.731, ntokens=391.4, nsentences=8, sample_size=391.4, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=1194.6, ups=3.05, wpb=391.4, bsz=8, num_updates=13180, lr=8.77235e-05, gnorm=2.659, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=4479
2023-03-15 15:14:25 - progress_bar.py[line:272] - INFO: epoch 007:   1252 / 2004 loss=0.673, loss_v1=0, loss_v2=0, nll_loss=0.673, ntokens=352.7, nsentences=8, sample_size=352.7, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=1108, ups=3.14, wpb=352.7, bsz=8, num_updates=13190, lr=8.77135e-05, gnorm=2.664, clip=0, loss_scale=1024, train_wall=3, gb_free=14.2, wall=4483
2023-03-15 15:14:28 - progress_bar.py[line:272] - INFO: epoch 007:   1262 / 2004 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.658, ntokens=338.5, nsentences=8, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=1073.3, ups=3.17, wpb=338.5, bsz=8, num_updates=13200, lr=8.77034e-05, gnorm=2.564, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=4486
2023-03-15 15:14:31 - progress_bar.py[line:272] - INFO: epoch 007:   1272 / 2004 loss=0.675, loss_v1=0, loss_v2=0, nll_loss=0.675, ntokens=345.3, nsentences=8, sample_size=345.3, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=1084.7, ups=3.14, wpb=345.3, bsz=8, num_updates=13210, lr=8.76933e-05, gnorm=2.653, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=4489
2023-03-15 15:14:35 - progress_bar.py[line:272] - INFO: epoch 007:   1282 / 2004 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.648, ntokens=328.1, nsentences=8, sample_size=328.1, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=1054, ups=3.21, wpb=328.1, bsz=8, num_updates=13220, lr=8.76832e-05, gnorm=2.685, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=4492
2023-03-15 15:14:38 - progress_bar.py[line:272] - INFO: epoch 007:   1292 / 2004 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.563, ntokens=314.5, nsentences=8, sample_size=314.5, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=984.8, ups=3.13, wpb=314.5, bsz=8, num_updates=13230, lr=8.76731e-05, gnorm=2.487, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=4495
2023-03-15 15:14:41 - progress_bar.py[line:272] - INFO: epoch 007:   1302 / 2004 loss=0.697, loss_v1=0, loss_v2=0, nll_loss=0.697, ntokens=319, nsentences=8, sample_size=319, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=998.8, ups=3.13, wpb=319, bsz=8, num_updates=13240, lr=8.76631e-05, gnorm=2.832, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=4499
2023-03-15 15:14:44 - progress_bar.py[line:272] - INFO: epoch 007:   1312 / 2004 loss=0.703, loss_v1=0, loss_v2=0, nll_loss=0.703, ntokens=335.7, nsentences=8, sample_size=335.7, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=1063.6, ups=3.17, wpb=335.7, bsz=8, num_updates=13250, lr=8.7653e-05, gnorm=2.627, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=4502
2023-03-15 15:14:47 - progress_bar.py[line:272] - INFO: epoch 007:   1322 / 2004 loss=0.691, loss_v1=0, loss_v2=0, nll_loss=0.691, ntokens=316.2, nsentences=8, sample_size=316.2, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=1020.1, ups=3.23, wpb=316.2, bsz=8, num_updates=13260, lr=8.76429e-05, gnorm=2.847, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=4505
2023-03-15 15:14:50 - progress_bar.py[line:272] - INFO: epoch 007:   1332 / 2004 loss=0.688, loss_v1=0, loss_v2=0, nll_loss=0.688, ntokens=325.6, nsentences=8, sample_size=325.6, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=1030.4, ups=3.16, wpb=325.6, bsz=8, num_updates=13270, lr=8.76328e-05, gnorm=2.783, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=4508
2023-03-15 15:14:53 - progress_bar.py[line:272] - INFO: epoch 007:   1342 / 2004 loss=0.706, loss_v1=0, loss_v2=0, nll_loss=0.706, ntokens=325, nsentences=8, sample_size=325, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=1049, ups=3.23, wpb=325, bsz=8, num_updates=13280, lr=8.76227e-05, gnorm=2.764, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=4511
2023-03-15 15:14:57 - progress_bar.py[line:272] - INFO: epoch 007:   1352 / 2004 loss=0.701, loss_v1=0, loss_v2=0, nll_loss=0.701, ntokens=318.2, nsentences=8, sample_size=318.2, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=1002.1, ups=3.15, wpb=318.2, bsz=8, num_updates=13290, lr=8.76127e-05, gnorm=2.835, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=4514
2023-03-15 15:15:00 - progress_bar.py[line:272] - INFO: epoch 007:   1362 / 2004 loss=0.696, loss_v1=0, loss_v2=0, nll_loss=0.696, ntokens=326.7, nsentences=8, sample_size=326.7, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=995.4, ups=3.05, wpb=326.7, bsz=8, num_updates=13300, lr=8.76026e-05, gnorm=2.794, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=4517
2023-03-15 15:15:03 - progress_bar.py[line:272] - INFO: epoch 007:   1372 / 2004 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.615, ntokens=303.6, nsentences=8, sample_size=303.6, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=886.3, ups=2.92, wpb=303.6, bsz=8, num_updates=13310, lr=8.75925e-05, gnorm=2.661, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=4521
2023-03-15 15:15:07 - progress_bar.py[line:272] - INFO: epoch 007:   1382 / 2004 loss=0.731, loss_v1=0, loss_v2=0, nll_loss=0.731, ntokens=375.5, nsentences=8, sample_size=375.5, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=1047.3, ups=2.79, wpb=375.5, bsz=8, num_updates=13320, lr=8.75824e-05, gnorm=2.731, clip=0, loss_scale=2048, train_wall=4, gb_free=14.5, wall=4524
2023-03-15 15:15:08 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 15:15:11 - progress_bar.py[line:272] - INFO: epoch 007:   1393 / 2004 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.625, ntokens=355.5, nsentences=8, sample_size=355.5, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=931.8, ups=2.62, wpb=355.5, bsz=8, num_updates=13330, lr=8.75723e-05, gnorm=2.485, clip=0, loss_scale=1024, train_wall=4, gb_free=14.7, wall=4528
2023-03-15 15:15:14 - progress_bar.py[line:272] - INFO: epoch 007:   1403 / 2004 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.608, ntokens=335, nsentences=8, sample_size=335, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=963.3, ups=2.88, wpb=335, bsz=8, num_updates=13340, lr=8.75622e-05, gnorm=2.635, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=4532
2023-03-15 15:15:18 - progress_bar.py[line:272] - INFO: epoch 007:   1413 / 2004 loss=0.765, loss_v1=0, loss_v2=0, nll_loss=0.765, ntokens=370.2, nsentences=7.8, sample_size=370.2, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=1080.7, ups=2.92, wpb=370.2, bsz=7.8, num_updates=13350, lr=8.75522e-05, gnorm=2.737, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=4535
2023-03-15 15:15:21 - progress_bar.py[line:272] - INFO: epoch 007:   1423 / 2004 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.645, ntokens=317.9, nsentences=8, sample_size=317.9, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=1006.2, ups=3.17, wpb=317.9, bsz=8, num_updates=13360, lr=8.75421e-05, gnorm=2.551, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=4538
2023-03-15 15:15:24 - progress_bar.py[line:272] - INFO: epoch 007:   1433 / 2004 loss=0.698, loss_v1=0, loss_v2=0, nll_loss=0.698, ntokens=347.9, nsentences=8, sample_size=347.9, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=1090.9, ups=3.14, wpb=347.9, bsz=8, num_updates=13370, lr=8.7532e-05, gnorm=2.619, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=4542
2023-03-15 15:15:27 - progress_bar.py[line:272] - INFO: epoch 007:   1443 / 2004 loss=0.709, loss_v1=0, loss_v2=0, nll_loss=0.709, ntokens=340.6, nsentences=8, sample_size=340.6, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=1072.9, ups=3.15, wpb=340.6, bsz=8, num_updates=13380, lr=8.75219e-05, gnorm=2.723, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=4545
2023-03-15 15:15:30 - progress_bar.py[line:272] - INFO: epoch 007:   1453 / 2004 loss=0.726, loss_v1=0, loss_v2=0, nll_loss=0.726, ntokens=353.2, nsentences=8, sample_size=353.2, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=1107.4, ups=3.14, wpb=353.2, bsz=8, num_updates=13390, lr=8.75118e-05, gnorm=2.697, clip=0, loss_scale=1024, train_wall=3, gb_free=12.5, wall=4548
2023-03-15 15:15:34 - progress_bar.py[line:272] - INFO: epoch 007:   1463 / 2004 loss=0.738, loss_v1=0, loss_v2=0, nll_loss=0.738, ntokens=382.5, nsentences=8, sample_size=382.5, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=1166.6, ups=3.05, wpb=382.5, bsz=8, num_updates=13400, lr=8.75018e-05, gnorm=2.646, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=4551
2023-03-15 15:15:37 - progress_bar.py[line:272] - INFO: epoch 007:   1473 / 2004 loss=0.713, loss_v1=0, loss_v2=0, nll_loss=0.713, ntokens=400.9, nsentences=8, sample_size=400.9, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=1244.2, ups=3.1, wpb=400.9, bsz=8, num_updates=13410, lr=8.74917e-05, gnorm=2.565, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=4554
2023-03-15 15:15:40 - progress_bar.py[line:272] - INFO: epoch 007:   1483 / 2004 loss=0.701, loss_v1=0, loss_v2=0, nll_loss=0.701, ntokens=370.3, nsentences=8, sample_size=370.3, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=1138.2, ups=3.07, wpb=370.3, bsz=8, num_updates=13420, lr=8.74816e-05, gnorm=2.641, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=4558
2023-03-15 15:15:43 - progress_bar.py[line:272] - INFO: epoch 007:   1493 / 2004 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.647, ntokens=310.3, nsentences=8, sample_size=310.3, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=935, ups=3.01, wpb=310.3, bsz=8, num_updates=13430, lr=8.74715e-05, gnorm=2.709, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=4561
2023-03-15 15:15:47 - progress_bar.py[line:272] - INFO: epoch 007:   1503 / 2004 loss=0.683, loss_v1=0, loss_v2=0, nll_loss=0.683, ntokens=341.9, nsentences=8, sample_size=341.9, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=1060.2, ups=3.1, wpb=341.9, bsz=8, num_updates=13440, lr=8.74614e-05, gnorm=2.735, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=4564
2023-03-15 15:15:50 - progress_bar.py[line:272] - INFO: epoch 007:   1513 / 2004 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.641, ntokens=333.6, nsentences=8, sample_size=333.6, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=1027.1, ups=3.08, wpb=333.6, bsz=8, num_updates=13450, lr=8.74514e-05, gnorm=2.637, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=4567
2023-03-15 15:15:50 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 15:15:53 - progress_bar.py[line:272] - INFO: epoch 007:   1524 / 2004 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.629, ntokens=323.4, nsentences=8, sample_size=323.4, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=939.1, ups=2.9, wpb=323.4, bsz=8, num_updates=13460, lr=8.74413e-05, gnorm=2.676, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=4571
2023-03-15 15:15:56 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-03-15 15:15:57 - progress_bar.py[line:272] - INFO: epoch 007:   1535 / 2004 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.655, ntokens=351.9, nsentences=8, sample_size=351.9, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=928.2, ups=2.64, wpb=351.9, bsz=8, num_updates=13470, lr=8.74312e-05, gnorm=2.718, clip=0, loss_scale=512, train_wall=4, gb_free=14.2, wall=4575
2023-03-15 15:16:01 - progress_bar.py[line:272] - INFO: epoch 007:   1545 / 2004 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.599, ntokens=309.5, nsentences=8, sample_size=309.5, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=888.9, ups=2.87, wpb=309.5, bsz=8, num_updates=13480, lr=8.74211e-05, gnorm=2.718, clip=0, loss_scale=512, train_wall=3, gb_free=15.5, wall=4578
2023-03-15 15:16:04 - progress_bar.py[line:272] - INFO: epoch 007:   1555 / 2004 loss=0.759, loss_v1=0, loss_v2=0, nll_loss=0.759, ntokens=355.3, nsentences=8, sample_size=355.3, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=1010.8, ups=2.84, wpb=355.3, bsz=8, num_updates=13490, lr=8.7411e-05, gnorm=2.695, clip=0, loss_scale=512, train_wall=3, gb_free=14.3, wall=4582
2023-03-15 15:16:08 - progress_bar.py[line:272] - INFO: epoch 007:   1565 / 2004 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.605, ntokens=347, nsentences=8, sample_size=347, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=1016.6, ups=2.93, wpb=347, bsz=8, num_updates=13500, lr=8.7401e-05, gnorm=2.545, clip=0, loss_scale=512, train_wall=3, gb_free=14.9, wall=4585
2023-03-15 15:16:11 - progress_bar.py[line:272] - INFO: epoch 007:   1575 / 2004 loss=0.719, loss_v1=0, loss_v2=0, nll_loss=0.719, ntokens=336.5, nsentences=8, sample_size=336.5, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=998.7, ups=2.97, wpb=336.5, bsz=8, num_updates=13510, lr=8.73909e-05, gnorm=2.715, clip=0, loss_scale=512, train_wall=3, gb_free=15.1, wall=4588
2023-03-15 15:16:14 - progress_bar.py[line:272] - INFO: epoch 007:   1585 / 2004 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.602, ntokens=321.1, nsentences=8, sample_size=321.1, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=1019.1, ups=3.17, wpb=321.1, bsz=8, num_updates=13520, lr=8.73808e-05, gnorm=2.502, clip=0, loss_scale=512, train_wall=3, gb_free=14.9, wall=4592
2023-03-15 15:16:17 - progress_bar.py[line:272] - INFO: epoch 007:   1595 / 2004 loss=0.709, loss_v1=0, loss_v2=0, nll_loss=0.709, ntokens=362.8, nsentences=8, sample_size=362.8, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=1150.8, ups=3.17, wpb=362.8, bsz=8, num_updates=13530, lr=8.73707e-05, gnorm=2.684, clip=0, loss_scale=512, train_wall=3, gb_free=14.4, wall=4595
2023-03-15 15:16:20 - progress_bar.py[line:272] - INFO: epoch 007:   1605 / 2004 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.635, ntokens=337.9, nsentences=8, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=1056.6, ups=3.13, wpb=337.9, bsz=8, num_updates=13540, lr=8.73606e-05, gnorm=2.516, clip=0, loss_scale=512, train_wall=3, gb_free=14.8, wall=4598
2023-03-15 15:16:24 - progress_bar.py[line:272] - INFO: epoch 007:   1615 / 2004 loss=0.685, loss_v1=0, loss_v2=0, nll_loss=0.685, ntokens=341.2, nsentences=8, sample_size=341.2, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=1057.1, ups=3.1, wpb=341.2, bsz=8, num_updates=13550, lr=8.73506e-05, gnorm=2.737, clip=0, loss_scale=512, train_wall=3, gb_free=15.6, wall=4601
2023-03-15 15:16:27 - progress_bar.py[line:272] - INFO: epoch 007:   1625 / 2004 loss=0.683, loss_v1=0, loss_v2=0, nll_loss=0.683, ntokens=352.5, nsentences=8, sample_size=352.5, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=1091.3, ups=3.1, wpb=352.5, bsz=8, num_updates=13560, lr=8.73405e-05, gnorm=2.681, clip=0, loss_scale=512, train_wall=3, gb_free=14.5, wall=4604
2023-03-15 15:16:30 - progress_bar.py[line:272] - INFO: epoch 007:   1635 / 2004 loss=0.673, loss_v1=0, loss_v2=0, nll_loss=0.673, ntokens=332.2, nsentences=8, sample_size=332.2, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=1042.4, ups=3.14, wpb=332.2, bsz=8, num_updates=13570, lr=8.73304e-05, gnorm=2.649, clip=0, loss_scale=512, train_wall=3, gb_free=15.2, wall=4608
2023-03-15 15:16:33 - progress_bar.py[line:272] - INFO: epoch 007:   1645 / 2004 loss=0.667, loss_v1=0, loss_v2=0, nll_loss=0.667, ntokens=309.9, nsentences=8, sample_size=309.9, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=952.5, ups=3.07, wpb=309.9, bsz=8, num_updates=13580, lr=8.73203e-05, gnorm=2.796, clip=0, loss_scale=512, train_wall=3, gb_free=15.4, wall=4611
2023-03-15 15:16:37 - progress_bar.py[line:272] - INFO: epoch 007:   1655 / 2004 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.655, ntokens=346.4, nsentences=8, sample_size=346.4, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=1072.1, ups=3.09, wpb=346.4, bsz=8, num_updates=13590, lr=8.73102e-05, gnorm=2.724, clip=0, loss_scale=512, train_wall=3, gb_free=15.2, wall=4614
2023-03-15 15:16:40 - progress_bar.py[line:272] - INFO: epoch 007:   1665 / 2004 loss=0.683, loss_v1=0, loss_v2=0, nll_loss=0.683, ntokens=352.8, nsentences=8, sample_size=352.8, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=1094.6, ups=3.1, wpb=352.8, bsz=8, num_updates=13600, lr=8.73001e-05, gnorm=2.666, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=4617
2023-03-15 15:16:43 - progress_bar.py[line:272] - INFO: epoch 007:   1675 / 2004 loss=0.675, loss_v1=0, loss_v2=0, nll_loss=0.675, ntokens=327.8, nsentences=8, sample_size=327.8, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=1006.1, ups=3.07, wpb=327.8, bsz=8, num_updates=13610, lr=8.72901e-05, gnorm=2.678, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=4621
2023-03-15 15:16:46 - progress_bar.py[line:272] - INFO: epoch 007:   1685 / 2004 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.66, ntokens=333.6, nsentences=8, sample_size=333.6, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=1030, ups=3.09, wpb=333.6, bsz=8, num_updates=13620, lr=8.728e-05, gnorm=2.66, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=4624
2023-03-15 15:16:49 - progress_bar.py[line:272] - INFO: epoch 007:   1695 / 2004 loss=0.673, loss_v1=0, loss_v2=0, nll_loss=0.673, ntokens=341.4, nsentences=8, sample_size=341.4, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=1051.8, ups=3.08, wpb=341.4, bsz=8, num_updates=13630, lr=8.72699e-05, gnorm=2.667, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=4627
2023-03-15 15:16:53 - progress_bar.py[line:272] - INFO: epoch 007:   1705 / 2004 loss=0.657, loss_v1=0, loss_v2=0, nll_loss=0.657, ntokens=335.2, nsentences=8, sample_size=335.2, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=1057.1, ups=3.15, wpb=335.2, bsz=8, num_updates=13640, lr=8.72598e-05, gnorm=2.711, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=4630
2023-03-15 15:16:56 - progress_bar.py[line:272] - INFO: epoch 007:   1715 / 2004 loss=0.735, loss_v1=0, loss_v2=0, nll_loss=0.735, ntokens=365.3, nsentences=8, sample_size=365.3, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=1099.5, ups=3.01, wpb=365.3, bsz=8, num_updates=13650, lr=8.72497e-05, gnorm=2.765, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=4634
2023-03-15 15:16:59 - progress_bar.py[line:272] - INFO: epoch 007:   1725 / 2004 loss=0.683, loss_v1=0, loss_v2=0, nll_loss=0.683, ntokens=389.9, nsentences=8, sample_size=389.9, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=1143.5, ups=2.93, wpb=389.9, bsz=8, num_updates=13660, lr=8.72397e-05, gnorm=2.624, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=4637
2023-03-15 15:17:03 - progress_bar.py[line:272] - INFO: epoch 007:   1735 / 2004 loss=0.662, loss_v1=0, loss_v2=0, nll_loss=0.662, ntokens=352, nsentences=8, sample_size=352, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=996.1, ups=2.83, wpb=352, bsz=8, num_updates=13670, lr=8.72296e-05, gnorm=2.659, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=4641
2023-03-15 15:17:06 - progress_bar.py[line:272] - INFO: epoch 007:   1745 / 2004 loss=0.665, loss_v1=0, loss_v2=0, nll_loss=0.665, ntokens=338.3, nsentences=8, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=973.6, ups=2.88, wpb=338.3, bsz=8, num_updates=13680, lr=8.72195e-05, gnorm=2.738, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=4644
2023-03-15 15:17:10 - progress_bar.py[line:272] - INFO: epoch 007:   1755 / 2004 loss=0.674, loss_v1=0, loss_v2=0, nll_loss=0.674, ntokens=348.1, nsentences=8, sample_size=348.1, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=989.3, ups=2.84, wpb=348.1, bsz=8, num_updates=13690, lr=8.72094e-05, gnorm=2.65, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=4648
2023-03-15 15:17:13 - progress_bar.py[line:272] - INFO: epoch 007:   1765 / 2004 loss=0.667, loss_v1=0, loss_v2=0, nll_loss=0.667, ntokens=308.7, nsentences=8, sample_size=308.7, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=899.3, ups=2.91, wpb=308.7, bsz=8, num_updates=13700, lr=8.71993e-05, gnorm=2.751, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=4651
2023-03-15 15:17:17 - progress_bar.py[line:272] - INFO: epoch 007:   1775 / 2004 loss=0.666, loss_v1=0, loss_v2=0, nll_loss=0.666, ntokens=349.2, nsentences=8, sample_size=349.2, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=1003.3, ups=2.87, wpb=349.2, bsz=8, num_updates=13710, lr=8.71893e-05, gnorm=2.596, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=4654
2023-03-15 15:17:20 - progress_bar.py[line:272] - INFO: epoch 007:   1785 / 2004 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.652, ntokens=315, nsentences=8, sample_size=315, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=910.6, ups=2.89, wpb=315, bsz=8, num_updates=13720, lr=8.71792e-05, gnorm=2.751, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=4658
2023-03-15 15:17:24 - progress_bar.py[line:272] - INFO: epoch 007:   1795 / 2004 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.641, ntokens=319.8, nsentences=8, sample_size=319.8, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=934.1, ups=2.92, wpb=319.8, bsz=8, num_updates=13730, lr=8.71691e-05, gnorm=2.734, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=4661
2023-03-15 15:17:27 - progress_bar.py[line:272] - INFO: epoch 007:   1805 / 2004 loss=0.73, loss_v1=0, loss_v2=0, nll_loss=0.73, ntokens=353.2, nsentences=8, sample_size=353.2, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=1024.3, ups=2.9, wpb=353.2, bsz=8, num_updates=13740, lr=8.7159e-05, gnorm=2.916, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=4665
2023-03-15 15:17:31 - progress_bar.py[line:272] - INFO: epoch 007:   1815 / 2004 loss=0.667, loss_v1=0, loss_v2=0, nll_loss=0.667, ntokens=359.4, nsentences=8, sample_size=359.4, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=1020.4, ups=2.84, wpb=359.4, bsz=8, num_updates=13750, lr=8.71489e-05, gnorm=2.735, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=4668
2023-03-15 15:17:34 - progress_bar.py[line:272] - INFO: epoch 007:   1825 / 2004 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.61, ntokens=356.8, nsentences=8, sample_size=356.8, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=1008.4, ups=2.83, wpb=356.8, bsz=8, num_updates=13760, lr=8.71389e-05, gnorm=2.524, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=4672
2023-03-15 15:17:38 - progress_bar.py[line:272] - INFO: epoch 007:   1835 / 2004 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.638, ntokens=333.7, nsentences=8, sample_size=333.7, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=943.8, ups=2.83, wpb=333.7, bsz=8, num_updates=13770, lr=8.71288e-05, gnorm=2.669, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=4675
2023-03-15 15:17:41 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 15:17:42 - progress_bar.py[line:272] - INFO: epoch 007:   1846 / 2004 loss=0.696, loss_v1=0, loss_v2=0, nll_loss=0.696, ntokens=341, nsentences=8, sample_size=341, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=877.2, ups=2.57, wpb=341, bsz=8, num_updates=13780, lr=8.71187e-05, gnorm=2.759, clip=0, loss_scale=1024, train_wall=4, gb_free=14, wall=4679
2023-03-15 15:17:45 - progress_bar.py[line:272] - INFO: epoch 007:   1856 / 2004 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.611, ntokens=312.9, nsentences=8, sample_size=312.9, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=899.2, ups=2.87, wpb=312.9, bsz=8, num_updates=13790, lr=8.71086e-05, gnorm=2.572, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=4683
2023-03-15 15:17:49 - progress_bar.py[line:272] - INFO: epoch 007:   1866 / 2004 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.637, ntokens=343.7, nsentences=8, sample_size=343.7, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=965.4, ups=2.81, wpb=343.7, bsz=8, num_updates=13800, lr=8.70985e-05, gnorm=2.604, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=4686
2023-03-15 15:17:52 - progress_bar.py[line:272] - INFO: epoch 007:   1876 / 2004 loss=0.664, loss_v1=0, loss_v2=0, nll_loss=0.664, ntokens=337.8, nsentences=8, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=958, ups=2.84, wpb=337.8, bsz=8, num_updates=13810, lr=8.70884e-05, gnorm=2.678, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=4690
2023-03-15 15:17:56 - progress_bar.py[line:272] - INFO: epoch 007:   1886 / 2004 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.634, ntokens=324, nsentences=8, sample_size=324, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=935.8, ups=2.89, wpb=324, bsz=8, num_updates=13820, lr=8.70784e-05, gnorm=2.673, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=4693
2023-03-15 15:17:59 - progress_bar.py[line:272] - INFO: epoch 007:   1896 / 2004 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.654, ntokens=336.9, nsentences=8, sample_size=336.9, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=981, ups=2.91, wpb=336.9, bsz=8, num_updates=13830, lr=8.70683e-05, gnorm=2.721, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=4697
2023-03-15 15:18:03 - progress_bar.py[line:272] - INFO: epoch 007:   1906 / 2004 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.585, ntokens=348.4, nsentences=8, sample_size=348.4, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=990.6, ups=2.84, wpb=348.4, bsz=8, num_updates=13840, lr=8.70582e-05, gnorm=2.589, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=4700
2023-03-15 15:18:06 - progress_bar.py[line:272] - INFO: epoch 007:   1916 / 2004 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.63, ntokens=327.7, nsentences=8, sample_size=327.7, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=964.7, ups=2.94, wpb=327.7, bsz=8, num_updates=13850, lr=8.70481e-05, gnorm=2.683, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=4704
2023-03-15 15:18:09 - progress_bar.py[line:272] - INFO: epoch 007:   1926 / 2004 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.61, ntokens=325.2, nsentences=8, sample_size=325.2, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=938, ups=2.88, wpb=325.2, bsz=8, num_updates=13860, lr=8.7038e-05, gnorm=2.729, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=4707
2023-03-15 15:18:13 - progress_bar.py[line:272] - INFO: epoch 007:   1936 / 2004 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.625, ntokens=336.4, nsentences=8, sample_size=336.4, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=978.5, ups=2.91, wpb=336.4, bsz=8, num_updates=13870, lr=8.7028e-05, gnorm=2.698, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=4711
2023-03-15 15:18:16 - progress_bar.py[line:272] - INFO: epoch 007:   1946 / 2004 loss=0.67, loss_v1=0, loss_v2=0, nll_loss=0.67, ntokens=358.9, nsentences=8, sample_size=358.9, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=1025, ups=2.86, wpb=358.9, bsz=8, num_updates=13880, lr=8.70179e-05, gnorm=2.648, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=4714
2023-03-15 15:18:20 - progress_bar.py[line:272] - INFO: epoch 007:   1956 / 2004 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.607, ntokens=348, nsentences=8, sample_size=348, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=981.9, ups=2.82, wpb=348, bsz=8, num_updates=13890, lr=8.70078e-05, gnorm=2.652, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=4718
2023-03-15 15:18:23 - progress_bar.py[line:272] - INFO: epoch 007:   1966 / 2004 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.628, ntokens=356.9, nsentences=8, sample_size=356.9, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=1032.4, ups=2.89, wpb=356.9, bsz=8, num_updates=13900, lr=8.69977e-05, gnorm=2.662, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=4721
2023-03-15 15:18:27 - progress_bar.py[line:272] - INFO: epoch 007:   1976 / 2004 loss=0.656, loss_v1=0, loss_v2=0, nll_loss=0.656, ntokens=340.3, nsentences=8, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=970.6, ups=2.85, wpb=340.3, bsz=8, num_updates=13910, lr=8.69876e-05, gnorm=2.623, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=4725
2023-03-15 15:18:30 - progress_bar.py[line:272] - INFO: epoch 007:   1986 / 2004 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.593, ntokens=311.3, nsentences=8, sample_size=311.3, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=894.6, ups=2.87, wpb=311.3, bsz=8, num_updates=13920, lr=8.69776e-05, gnorm=2.659, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=4728
2023-03-15 15:18:34 - progress_bar.py[line:272] - INFO: epoch 007:   1996 / 2004 loss=0.699, loss_v1=0, loss_v2=0, nll_loss=0.699, ntokens=398.9, nsentences=8, sample_size=398.9, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=1131.4, ups=2.84, wpb=398.9, bsz=8, num_updates=13930, lr=8.69675e-05, gnorm=2.686, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=4732
2023-03-15 15:18:37 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 7 @ 13938 updates
2023-03-15 15:18:37 - trainer.py[line:431] - INFO: Saving checkpoint to ./checkpoints/checkpoint7.pt
2023-03-15 15:18:43 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./checkpoints/checkpoint7.pt
2023-03-15 15:18:46 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./checkpoints/checkpoint7.pt (epoch 7 @ 13938 updates, score None) (writing took 8.901225196197629 seconds)
2023-03-15 15:18:46 - train.py[line:332] - INFO: end of epoch 7 (average epoch stats below)
2023-03-15 15:18:46 - progress_bar.py[line:282] - INFO: epoch 007 | loss 0.697 | loss_v1 0 | loss_v2 0 | nll_loss 0.697 | ntokens 345.214 | nsentences 7.999 | sample_size 345.214 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.62 | wps 1008.9 | ups 2.92 | wpb 345.2 | bsz 8 | num_updates 13938 | lr 8.69594e-05 | gnorm 2.603 | clip 0 | loss_scale 2048 | train_wall 650 | gb_free 13.9 | wall 4743
2023-03-15 15:18:46 - trainer.py[line:639] - INFO: loading train data for epoch 8
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 row count 8015 total row count 8015
slice_id 0 seek offset 0
2023-03-15 15:18:46 - trainer.py[line:703] - INFO: begin training epoch 8
2023-03-15 15:18:46 - train.py[line:305] - INFO: Start iterating over samples
2023-03-15 15:18:47 - progress_bar.py[line:272] - INFO: epoch 008:      2 / 2004 loss=0.705, loss_v1=0, loss_v2=0, nll_loss=0.705, ntokens=367.8, nsentences=8, sample_size=367.8, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=280.4, ups=0.76, wpb=367.8, bsz=8, num_updates=13940, lr=8.69574e-05, gnorm=2.764, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=4745
2023-03-15 15:18:50 - progress_bar.py[line:272] - INFO: epoch 008:     12 / 2004 loss=0.681, loss_v1=0, loss_v2=0, nll_loss=0.681, ntokens=340.2, nsentences=8, sample_size=340.2, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=1014.6, ups=2.98, wpb=340.2, bsz=8, num_updates=13950, lr=8.69473e-05, gnorm=2.773, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=4748
2023-03-15 15:18:54 - progress_bar.py[line:272] - INFO: epoch 008:     22 / 2004 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.64, ntokens=343.7, nsentences=8, sample_size=343.7, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=975.3, ups=2.84, wpb=343.7, bsz=8, num_updates=13960, lr=8.69372e-05, gnorm=2.659, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=4752
2023-03-15 15:18:57 - progress_bar.py[line:272] - INFO: epoch 008:     32 / 2004 loss=0.677, loss_v1=0, loss_v2=0, nll_loss=0.677, ntokens=343.2, nsentences=7.8, sample_size=343.2, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=986.6, ups=2.87, wpb=343.2, bsz=7.8, num_updates=13970, lr=8.69272e-05, gnorm=2.783, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=4755
2023-03-15 15:19:01 - progress_bar.py[line:272] - INFO: epoch 008:     42 / 2004 loss=0.667, loss_v1=0, loss_v2=0, nll_loss=0.667, ntokens=356.4, nsentences=8, sample_size=356.4, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=1004, ups=2.82, wpb=356.4, bsz=8, num_updates=13980, lr=8.69171e-05, gnorm=2.765, clip=0, loss_scale=2048, train_wall=3, gb_free=13.6, wall=4759
2023-03-15 15:19:05 - progress_bar.py[line:272] - INFO: epoch 008:     52 / 2004 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.653, ntokens=351.5, nsentences=8, sample_size=351.5, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=992.9, ups=2.82, wpb=351.5, bsz=8, num_updates=13990, lr=8.6907e-05, gnorm=2.641, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=4762
2023-03-15 15:19:08 - progress_bar.py[line:272] - INFO: epoch 008:     62 / 2004 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.639, ntokens=325.9, nsentences=8, sample_size=325.9, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=941.4, ups=2.89, wpb=325.9, bsz=8, num_updates=14000, lr=8.68969e-05, gnorm=2.776, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=4766
2023-03-15 15:19:11 - progress_bar.py[line:272] - INFO: epoch 008:     72 / 2004 loss=0.707, loss_v1=0, loss_v2=0, nll_loss=0.707, ntokens=359.5, nsentences=8, sample_size=359.5, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=1024.8, ups=2.85, wpb=359.5, bsz=8, num_updates=14010, lr=8.68868e-05, gnorm=2.742, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=4769
2023-03-15 15:19:15 - progress_bar.py[line:272] - INFO: epoch 008:     82 / 2004 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.632, ntokens=336, nsentences=8, sample_size=336, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=957.8, ups=2.85, wpb=336, bsz=8, num_updates=14020, lr=8.68768e-05, gnorm=2.759, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=4773
2023-03-15 15:19:18 - progress_bar.py[line:272] - INFO: epoch 008:     92 / 2004 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.651, ntokens=348.5, nsentences=8, sample_size=348.5, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=1017.4, ups=2.92, wpb=348.5, bsz=8, num_updates=14030, lr=8.68667e-05, gnorm=2.684, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=4776
2023-03-15 15:19:21 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 15:19:22 - progress_bar.py[line:272] - INFO: epoch 008:    103 / 2004 loss=0.702, loss_v1=0, loss_v2=0, nll_loss=0.702, ntokens=368.2, nsentences=8, sample_size=368.2, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=964.7, ups=2.62, wpb=368.2, bsz=8, num_updates=14040, lr=8.68566e-05, gnorm=2.715, clip=0, loss_scale=2048, train_wall=4, gb_free=15.1, wall=4780
2023-03-15 15:19:26 - progress_bar.py[line:272] - INFO: epoch 008:    113 / 2004 loss=0.662, loss_v1=0, loss_v2=0, nll_loss=0.662, ntokens=339, nsentences=8, sample_size=339, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=963.7, ups=2.84, wpb=339, bsz=8, num_updates=14050, lr=8.68465e-05, gnorm=2.665, clip=0, loss_scale=2048, train_wall=3, gb_free=13.7, wall=4783
2023-03-15 15:19:29 - progress_bar.py[line:272] - INFO: epoch 008:    123 / 2004 loss=0.698, loss_v1=0, loss_v2=0, nll_loss=0.698, ntokens=347.8, nsentences=8, sample_size=347.8, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=976.6, ups=2.81, wpb=347.8, bsz=8, num_updates=14060, lr=8.68364e-05, gnorm=2.746, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=4787
2023-03-15 15:19:33 - progress_bar.py[line:272] - INFO: epoch 008:    133 / 2004 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.613, ntokens=310.3, nsentences=8, sample_size=310.3, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=898.5, ups=2.9, wpb=310.3, bsz=8, num_updates=14070, lr=8.68263e-05, gnorm=2.715, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=4790
2023-03-15 15:19:36 - progress_bar.py[line:272] - INFO: epoch 008:    143 / 2004 loss=0.696, loss_v1=0, loss_v2=0, nll_loss=0.696, ntokens=355.3, nsentences=8, sample_size=355.3, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=1017.5, ups=2.86, wpb=355.3, bsz=8, num_updates=14080, lr=8.68163e-05, gnorm=2.808, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=4794
2023-03-15 15:19:40 - progress_bar.py[line:272] - INFO: epoch 008:    153 / 2004 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.634, ntokens=323.7, nsentences=8, sample_size=323.7, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=934.1, ups=2.89, wpb=323.7, bsz=8, num_updates=14090, lr=8.68062e-05, gnorm=2.796, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=4797
2023-03-15 15:19:43 - progress_bar.py[line:272] - INFO: epoch 008:    163 / 2004 loss=0.686, loss_v1=0, loss_v2=0, nll_loss=0.686, ntokens=371.8, nsentences=8, sample_size=371.8, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=1062.4, ups=2.86, wpb=371.8, bsz=8, num_updates=14100, lr=8.67961e-05, gnorm=2.709, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=4801
2023-03-15 15:19:47 - progress_bar.py[line:272] - INFO: epoch 008:    173 / 2004 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.602, ntokens=331.7, nsentences=8, sample_size=331.7, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=963.3, ups=2.9, wpb=331.7, bsz=8, num_updates=14110, lr=8.6786e-05, gnorm=2.615, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=4804
2023-03-15 15:19:50 - progress_bar.py[line:272] - INFO: epoch 008:    183 / 2004 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.595, ntokens=325.3, nsentences=8, sample_size=325.3, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=944.7, ups=2.9, wpb=325.3, bsz=8, num_updates=14120, lr=8.67759e-05, gnorm=2.696, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=4808
2023-03-15 15:19:54 - progress_bar.py[line:272] - INFO: epoch 008:    193 / 2004 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.567, ntokens=337.2, nsentences=8, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=979.9, ups=2.91, wpb=337.2, bsz=8, num_updates=14130, lr=8.67659e-05, gnorm=2.536, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=4811
2023-03-15 15:19:57 - progress_bar.py[line:272] - INFO: epoch 008:    203 / 2004 loss=0.672, loss_v1=0, loss_v2=0, nll_loss=0.672, ntokens=329.1, nsentences=8, sample_size=329.1, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=941.2, ups=2.86, wpb=329.1, bsz=8, num_updates=14140, lr=8.67558e-05, gnorm=2.839, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=4815
2023-03-15 15:20:00 - progress_bar.py[line:272] - INFO: epoch 008:    213 / 2004 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.613, ntokens=332.3, nsentences=8, sample_size=332.3, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=966.3, ups=2.91, wpb=332.3, bsz=8, num_updates=14150, lr=8.67457e-05, gnorm=2.658, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=4818
2023-03-15 15:20:04 - progress_bar.py[line:272] - INFO: epoch 008:    223 / 2004 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.542, ntokens=332.8, nsentences=8, sample_size=332.8, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=969.6, ups=2.91, wpb=332.8, bsz=8, num_updates=14160, lr=8.67356e-05, gnorm=2.59, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=4822
2023-03-15 15:20:06 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 15:20:08 - progress_bar.py[line:272] - INFO: epoch 008:    234 / 2004 loss=0.687, loss_v1=0, loss_v2=0, nll_loss=0.687, ntokens=368.7, nsentences=8, sample_size=368.7, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=957.2, ups=2.6, wpb=368.7, bsz=8, num_updates=14170, lr=8.67255e-05, gnorm=2.79, clip=0, loss_scale=2048, train_wall=4, gb_free=14.7, wall=4825
2023-03-15 15:20:11 - progress_bar.py[line:272] - INFO: epoch 008:    244 / 2004 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.64, ntokens=351.7, nsentences=8, sample_size=351.7, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=1017.9, ups=2.89, wpb=351.7, bsz=8, num_updates=14180, lr=8.67155e-05, gnorm=2.727, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=4829
2023-03-15 15:20:13 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 15:20:15 - progress_bar.py[line:272] - INFO: epoch 008:    255 / 2004 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.592, ntokens=334.9, nsentences=8, sample_size=334.9, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=893.2, ups=2.67, wpb=334.9, bsz=8, num_updates=14190, lr=8.67054e-05, gnorm=2.6, clip=0, loss_scale=1024, train_wall=4, gb_free=14.4, wall=4833
2023-03-15 15:20:19 - progress_bar.py[line:272] - INFO: epoch 008:    265 / 2004 loss=0.722, loss_v1=0, loss_v2=0, nll_loss=0.722, ntokens=358.8, nsentences=8, sample_size=358.8, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=1005.8, ups=2.8, wpb=358.8, bsz=8, num_updates=14200, lr=8.66953e-05, gnorm=2.782, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=4836
2023-03-15 15:20:22 - progress_bar.py[line:272] - INFO: epoch 008:    275 / 2004 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.605, ntokens=330, nsentences=8, sample_size=330, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=957.4, ups=2.9, wpb=330, bsz=8, num_updates=14210, lr=8.66852e-05, gnorm=2.567, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=4840
2023-03-15 15:20:26 - progress_bar.py[line:272] - INFO: epoch 008:    285 / 2004 loss=0.656, loss_v1=0, loss_v2=0, nll_loss=0.656, ntokens=374.5, nsentences=8, sample_size=374.5, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=1044.8, ups=2.79, wpb=374.5, bsz=8, num_updates=14220, lr=8.66751e-05, gnorm=2.702, clip=0, loss_scale=1024, train_wall=4, gb_free=14.6, wall=4843
2023-03-15 15:20:29 - progress_bar.py[line:272] - INFO: epoch 008:    295 / 2004 loss=0.661, loss_v1=0, loss_v2=0, nll_loss=0.661, ntokens=350.4, nsentences=8, sample_size=350.4, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=1006.7, ups=2.87, wpb=350.4, bsz=8, num_updates=14230, lr=8.66651e-05, gnorm=2.646, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=4847
2023-03-15 15:20:33 - progress_bar.py[line:272] - INFO: epoch 008:    305 / 2004 loss=0.666, loss_v1=0, loss_v2=0, nll_loss=0.666, ntokens=352.5, nsentences=8, sample_size=352.5, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=1028.1, ups=2.92, wpb=352.5, bsz=8, num_updates=14240, lr=8.6655e-05, gnorm=2.749, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=4850
2023-03-15 15:20:36 - progress_bar.py[line:272] - INFO: epoch 008:    315 / 2004 loss=0.663, loss_v1=0, loss_v2=0, nll_loss=0.663, ntokens=354.3, nsentences=8, sample_size=354.3, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=1015, ups=2.86, wpb=354.3, bsz=8, num_updates=14250, lr=8.66449e-05, gnorm=2.81, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=4854
2023-03-15 15:20:39 - progress_bar.py[line:272] - INFO: epoch 008:    325 / 2004 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.59, ntokens=325.8, nsentences=8, sample_size=325.8, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=966.5, ups=2.97, wpb=325.8, bsz=8, num_updates=14260, lr=8.66348e-05, gnorm=2.727, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=4857
2023-03-15 15:20:43 - progress_bar.py[line:272] - INFO: epoch 008:    335 / 2004 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.63, ntokens=323.6, nsentences=8, sample_size=323.6, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=941.5, ups=2.91, wpb=323.6, bsz=8, num_updates=14270, lr=8.66247e-05, gnorm=2.804, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=4860
2023-03-15 15:20:46 - progress_bar.py[line:272] - INFO: epoch 008:    345 / 2004 loss=0.734, loss_v1=0, loss_v2=0, nll_loss=0.734, ntokens=379.6, nsentences=8, sample_size=379.6, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=1077.3, ups=2.84, wpb=379.6, bsz=8, num_updates=14280, lr=8.66146e-05, gnorm=2.836, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=4864
2023-03-15 15:20:50 - progress_bar.py[line:272] - INFO: epoch 008:    355 / 2004 loss=0.671, loss_v1=0, loss_v2=0, nll_loss=0.671, ntokens=349.4, nsentences=8, sample_size=349.4, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=1000.7, ups=2.86, wpb=349.4, bsz=8, num_updates=14290, lr=8.66046e-05, gnorm=2.864, clip=0, loss_scale=1024, train_wall=3, gb_free=14, wall=4867
2023-03-15 15:20:53 - progress_bar.py[line:272] - INFO: epoch 008:    365 / 2004 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.648, ntokens=356.6, nsentences=8, sample_size=356.6, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=1003.3, ups=2.81, wpb=356.6, bsz=8, num_updates=14300, lr=8.65945e-05, gnorm=2.711, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=4871
2023-03-15 15:20:57 - progress_bar.py[line:272] - INFO: epoch 008:    375 / 2004 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.598, ntokens=314.5, nsentences=8, sample_size=314.5, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=917, ups=2.92, wpb=314.5, bsz=8, num_updates=14310, lr=8.65844e-05, gnorm=2.756, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=4874
2023-03-15 15:21:00 - progress_bar.py[line:272] - INFO: epoch 008:    385 / 2004 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.617, ntokens=324.8, nsentences=8, sample_size=324.8, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=929.9, ups=2.86, wpb=324.8, bsz=8, num_updates=14320, lr=8.65743e-05, gnorm=2.805, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=4878
2023-03-15 15:21:04 - progress_bar.py[line:272] - INFO: epoch 008:    395 / 2004 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.639, ntokens=359.4, nsentences=8, sample_size=359.4, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=1022, ups=2.84, wpb=359.4, bsz=8, num_updates=14330, lr=8.65642e-05, gnorm=2.736, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=4881
2023-03-15 15:21:07 - progress_bar.py[line:272] - INFO: epoch 008:    405 / 2004 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.604, ntokens=364.9, nsentences=8, sample_size=364.9, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=1061.3, ups=2.91, wpb=364.9, bsz=8, num_updates=14340, lr=8.65542e-05, gnorm=2.642, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=4885
2023-03-15 15:21:11 - progress_bar.py[line:272] - INFO: epoch 008:    415 / 2004 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.579, ntokens=351.2, nsentences=8, sample_size=351.2, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=1028.3, ups=2.93, wpb=351.2, bsz=8, num_updates=14350, lr=8.65441e-05, gnorm=2.576, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=4888
2023-03-15 15:21:14 - progress_bar.py[line:272] - INFO: epoch 008:    425 / 2004 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.612, ntokens=327.2, nsentences=8, sample_size=327.2, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=955.8, ups=2.92, wpb=327.2, bsz=8, num_updates=14360, lr=8.6534e-05, gnorm=2.748, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=4892
2023-03-15 15:21:18 - progress_bar.py[line:272] - INFO: epoch 008:    435 / 2004 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.636, ntokens=366.5, nsentences=8, sample_size=366.5, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=1043.8, ups=2.85, wpb=366.5, bsz=8, num_updates=14370, lr=8.65239e-05, gnorm=2.743, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=4895
2023-03-15 15:21:21 - progress_bar.py[line:272] - INFO: epoch 008:    445 / 2004 loss=0.679, loss_v1=0, loss_v2=0, nll_loss=0.679, ntokens=367, nsentences=8, sample_size=367, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=1035.5, ups=2.82, wpb=367, bsz=8, num_updates=14380, lr=8.65138e-05, gnorm=2.791, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=4899
2023-03-15 15:21:25 - progress_bar.py[line:272] - INFO: epoch 008:    455 / 2004 loss=0.712, loss_v1=0, loss_v2=0, nll_loss=0.712, ntokens=380, nsentences=8, sample_size=380, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=1085, ups=2.86, wpb=380, bsz=8, num_updates=14390, lr=8.65038e-05, gnorm=2.774, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=4902
2023-03-15 15:21:28 - progress_bar.py[line:272] - INFO: epoch 008:    465 / 2004 loss=0.68, loss_v1=0, loss_v2=0, nll_loss=0.68, ntokens=339.5, nsentences=8, sample_size=339.5, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=960.5, ups=2.83, wpb=339.5, bsz=8, num_updates=14400, lr=8.64937e-05, gnorm=2.862, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=4906
2023-03-15 15:21:32 - progress_bar.py[line:272] - INFO: epoch 008:    475 / 2004 loss=0.672, loss_v1=0, loss_v2=0, nll_loss=0.672, ntokens=375.5, nsentences=8, sample_size=375.5, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=1066.1, ups=2.84, wpb=375.5, bsz=8, num_updates=14410, lr=8.64836e-05, gnorm=2.675, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=4909
2023-03-15 15:21:35 - progress_bar.py[line:272] - INFO: epoch 008:    485 / 2004 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.625, ntokens=369.3, nsentences=8, sample_size=369.3, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=1064.6, ups=2.88, wpb=369.3, bsz=8, num_updates=14420, lr=8.64735e-05, gnorm=2.687, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=4913
2023-03-15 15:21:39 - progress_bar.py[line:272] - INFO: epoch 008:    495 / 2004 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.603, ntokens=357.5, nsentences=8, sample_size=357.5, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=1046.2, ups=2.93, wpb=357.5, bsz=8, num_updates=14430, lr=8.64634e-05, gnorm=2.572, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=4916
2023-03-15 15:21:42 - progress_bar.py[line:272] - INFO: epoch 008:    505 / 2004 loss=0.663, loss_v1=0, loss_v2=0, nll_loss=0.663, ntokens=357.6, nsentences=8, sample_size=357.6, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=1041.6, ups=2.91, wpb=357.6, bsz=8, num_updates=14440, lr=8.64534e-05, gnorm=2.791, clip=0, loss_scale=4096, train_wall=3, gb_free=14.8, wall=4920
2023-03-15 15:21:42 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 15:21:46 - progress_bar.py[line:272] - INFO: epoch 008:    516 / 2004 loss=0.663, loss_v1=0, loss_v2=0, nll_loss=0.663, ntokens=358.1, nsentences=8, sample_size=358.1, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=933.5, ups=2.61, wpb=358.1, bsz=8, num_updates=14450, lr=8.64433e-05, gnorm=2.837, clip=0, loss_scale=2048, train_wall=4, gb_free=14.3, wall=4923
2023-03-15 15:21:49 - progress_bar.py[line:272] - INFO: epoch 008:    526 / 2004 loss=0.7, loss_v1=0, loss_v2=0, nll_loss=0.7, ntokens=386.6, nsentences=8, sample_size=386.6, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=1194.2, ups=3.09, wpb=386.6, bsz=8, num_updates=14460, lr=8.64332e-05, gnorm=2.738, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=4927
2023-03-15 15:21:52 - progress_bar.py[line:272] - INFO: epoch 008:    536 / 2004 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.641, ntokens=384.6, nsentences=8, sample_size=384.6, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=1211.7, ups=3.15, wpb=384.6, bsz=8, num_updates=14470, lr=8.64231e-05, gnorm=2.626, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=4930
2023-03-15 15:21:54 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 15:21:56 - progress_bar.py[line:272] - INFO: epoch 008:    547 / 2004 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.615, ntokens=348.2, nsentences=8, sample_size=348.2, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=955.6, ups=2.74, wpb=348.2, bsz=8, num_updates=14480, lr=8.6413e-05, gnorm=2.676, clip=0, loss_scale=1024, train_wall=4, gb_free=14.9, wall=4934
2023-03-15 15:21:59 - progress_bar.py[line:272] - INFO: epoch 008:    557 / 2004 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.645, ntokens=382.8, nsentences=8, sample_size=382.8, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=1101.3, ups=2.88, wpb=382.8, bsz=8, num_updates=14490, lr=8.6403e-05, gnorm=2.658, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=4937
2023-03-15 15:22:03 - progress_bar.py[line:272] - INFO: epoch 008:    567 / 2004 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.626, ntokens=374.8, nsentences=8, sample_size=374.8, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=1082.1, ups=2.89, wpb=374.8, bsz=8, num_updates=14500, lr=8.63929e-05, gnorm=2.605, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=4940
2023-03-15 15:22:06 - progress_bar.py[line:272] - INFO: epoch 008:    577 / 2004 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.646, ntokens=337.8, nsentences=8, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=1000.7, ups=2.96, wpb=337.8, bsz=8, num_updates=14510, lr=8.63828e-05, gnorm=2.779, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=4944
2023-03-15 15:22:10 - progress_bar.py[line:272] - INFO: epoch 008:    587 / 2004 loss=0.666, loss_v1=0, loss_v2=0, nll_loss=0.666, ntokens=352.1, nsentences=8, sample_size=352.1, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=1012.4, ups=2.88, wpb=352.1, bsz=8, num_updates=14520, lr=8.63727e-05, gnorm=2.647, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=4947
2023-03-15 15:22:13 - progress_bar.py[line:272] - INFO: epoch 008:    597 / 2004 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.616, ntokens=343.9, nsentences=8, sample_size=343.9, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=965.6, ups=2.81, wpb=343.9, bsz=8, num_updates=14530, lr=8.63626e-05, gnorm=2.746, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=4951
2023-03-15 15:22:17 - progress_bar.py[line:272] - INFO: epoch 008:    607 / 2004 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.658, ntokens=355.3, nsentences=8, sample_size=355.3, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=1021.7, ups=2.88, wpb=355.3, bsz=8, num_updates=14540, lr=8.63525e-05, gnorm=2.702, clip=0, loss_scale=1024, train_wall=3, gb_free=14.2, wall=4954
2023-03-15 15:22:22 - progress_bar.py[line:272] - INFO: epoch 008:    617 / 2004 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.59, ntokens=348.8, nsentences=8, sample_size=348.8, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=680.8, ups=1.95, wpb=348.8, bsz=8, num_updates=14550, lr=8.63425e-05, gnorm=2.542, clip=0, loss_scale=1024, train_wall=5, gb_free=14.1, wall=4959
2023-03-15 15:22:25 - progress_bar.py[line:272] - INFO: epoch 008:    627 / 2004 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.596, ntokens=374.8, nsentences=8, sample_size=374.8, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=1078.5, ups=2.88, wpb=374.8, bsz=8, num_updates=14560, lr=8.63324e-05, gnorm=2.578, clip=0, loss_scale=1024, train_wall=3, gb_free=14.1, wall=4963
2023-03-15 15:22:29 - progress_bar.py[line:272] - INFO: epoch 008:    637 / 2004 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.559, ntokens=331.8, nsentences=8, sample_size=331.8, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=976.8, ups=2.94, wpb=331.8, bsz=8, num_updates=14570, lr=8.63223e-05, gnorm=2.627, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=4966
2023-03-15 15:22:32 - progress_bar.py[line:272] - INFO: epoch 008:    647 / 2004 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.566, ntokens=327.6, nsentences=8, sample_size=327.6, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=941.2, ups=2.87, wpb=327.6, bsz=8, num_updates=14580, lr=8.63122e-05, gnorm=2.618, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=4970
2023-03-15 15:22:36 - progress_bar.py[line:272] - INFO: epoch 008:    657 / 2004 loss=0.718, loss_v1=0, loss_v2=0, nll_loss=0.718, ntokens=355.4, nsentences=8, sample_size=355.4, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=1031.1, ups=2.9, wpb=355.4, bsz=8, num_updates=14590, lr=8.63021e-05, gnorm=2.945, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=4973
2023-03-15 15:22:39 - progress_bar.py[line:272] - INFO: epoch 008:    667 / 2004 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.589, ntokens=301, nsentences=8, sample_size=301, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=878.3, ups=2.92, wpb=301, bsz=8, num_updates=14600, lr=8.62921e-05, gnorm=2.772, clip=0, loss_scale=1024, train_wall=3, gb_free=14, wall=4977
2023-03-15 15:22:43 - progress_bar.py[line:272] - INFO: epoch 008:    677 / 2004 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.586, ntokens=336.4, nsentences=8, sample_size=336.4, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=960, ups=2.85, wpb=336.4, bsz=8, num_updates=14610, lr=8.6282e-05, gnorm=2.696, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=4980
2023-03-15 15:22:46 - progress_bar.py[line:272] - INFO: epoch 008:    687 / 2004 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.597, ntokens=351.4, nsentences=8, sample_size=351.4, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=996.7, ups=2.84, wpb=351.4, bsz=8, num_updates=14620, lr=8.62719e-05, gnorm=2.75, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=4984
2023-03-15 15:22:50 - progress_bar.py[line:272] - INFO: epoch 008:    697 / 2004 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.647, ntokens=357.5, nsentences=8, sample_size=357.5, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=1015.2, ups=2.84, wpb=357.5, bsz=8, num_updates=14630, lr=8.62618e-05, gnorm=2.777, clip=0, loss_scale=2048, train_wall=3, gb_free=13.8, wall=4987
2023-03-15 15:22:53 - progress_bar.py[line:272] - INFO: epoch 008:    707 / 2004 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.611, ntokens=349.6, nsentences=8, sample_size=349.6, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=1000.5, ups=2.86, wpb=349.6, bsz=8, num_updates=14640, lr=8.62517e-05, gnorm=2.759, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=4991
2023-03-15 15:22:57 - progress_bar.py[line:272] - INFO: epoch 008:    717 / 2004 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.609, ntokens=310.8, nsentences=8, sample_size=310.8, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=904.2, ups=2.91, wpb=310.8, bsz=8, num_updates=14650, lr=8.62417e-05, gnorm=2.878, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=4994
2023-03-15 15:23:00 - progress_bar.py[line:272] - INFO: epoch 008:    727 / 2004 loss=0.657, loss_v1=0, loss_v2=0, nll_loss=0.657, ntokens=369.1, nsentences=8, sample_size=369.1, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=1033.8, ups=2.8, wpb=369.1, bsz=8, num_updates=14660, lr=8.62316e-05, gnorm=2.833, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=4998
2023-03-15 15:23:04 - progress_bar.py[line:272] - INFO: epoch 008:    737 / 2004 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.628, ntokens=344.2, nsentences=8, sample_size=344.2, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=957.7, ups=2.78, wpb=344.2, bsz=8, num_updates=14670, lr=8.62215e-05, gnorm=2.86, clip=0, loss_scale=2048, train_wall=4, gb_free=15.4, wall=5001
2023-03-15 15:23:07 - progress_bar.py[line:272] - INFO: epoch 008:    747 / 2004 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.645, ntokens=352.4, nsentences=8, sample_size=352.4, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=1026.5, ups=2.91, wpb=352.4, bsz=8, num_updates=14680, lr=8.62114e-05, gnorm=2.815, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=5005
2023-03-15 15:23:11 - progress_bar.py[line:272] - INFO: epoch 008:    757 / 2004 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.58, ntokens=311.3, nsentences=8, sample_size=311.3, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=902.7, ups=2.9, wpb=311.3, bsz=8, num_updates=14690, lr=8.62013e-05, gnorm=2.83, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=5008
2023-03-15 15:23:14 - progress_bar.py[line:272] - INFO: epoch 008:    767 / 2004 loss=0.685, loss_v1=0, loss_v2=0, nll_loss=0.685, ntokens=390.2, nsentences=8, sample_size=390.2, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=1117.2, ups=2.86, wpb=390.2, bsz=8, num_updates=14700, lr=8.61913e-05, gnorm=2.772, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=5012
2023-03-15 15:23:17 - progress_bar.py[line:272] - INFO: epoch 008:    777 / 2004 loss=0.738, loss_v1=0, loss_v2=0, nll_loss=0.738, ntokens=368.2, nsentences=8, sample_size=368.2, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=1098.8, ups=2.98, wpb=368.2, bsz=8, num_updates=14710, lr=8.61812e-05, gnorm=2.86, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=5015
2023-03-15 15:23:21 - progress_bar.py[line:272] - INFO: epoch 008:    787 / 2004 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.574, ntokens=338.8, nsentences=8, sample_size=338.8, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=1088.6, ups=3.21, wpb=338.8, bsz=8, num_updates=14720, lr=8.61711e-05, gnorm=2.684, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=5018
2023-03-15 15:23:24 - progress_bar.py[line:272] - INFO: epoch 008:    797 / 2004 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.57, ntokens=322.3, nsentences=8, sample_size=322.3, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=1004.8, ups=3.12, wpb=322.3, bsz=8, num_updates=14730, lr=8.6161e-05, gnorm=2.743, clip=0, loss_scale=4096, train_wall=3, gb_free=15.5, wall=5021
2023-03-15 15:23:24 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 15:23:28 - progress_bar.py[line:272] - INFO: epoch 008:    808 / 2004 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.618, ntokens=340, nsentences=8, sample_size=340, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=897.3, ups=2.64, wpb=340, bsz=8, num_updates=14740, lr=8.61509e-05, gnorm=2.91, clip=0, loss_scale=2048, train_wall=4, gb_free=15.4, wall=5025
2023-03-15 15:23:31 - progress_bar.py[line:272] - INFO: epoch 008:    818 / 2004 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=322.2, nsentences=8, sample_size=322.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=924.6, ups=2.87, wpb=322.2, bsz=8, num_updates=14750, lr=8.61408e-05, gnorm=2.644, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=5029
2023-03-15 15:23:35 - progress_bar.py[line:272] - INFO: epoch 008:    828 / 2004 loss=0.669, loss_v1=0, loss_v2=0, nll_loss=0.669, ntokens=383.7, nsentences=8, sample_size=383.7, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=1087.6, ups=2.83, wpb=383.7, bsz=8, num_updates=14760, lr=8.61308e-05, gnorm=2.725, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=5032
2023-03-15 15:23:38 - progress_bar.py[line:272] - INFO: epoch 008:    838 / 2004 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.599, ntokens=323.7, nsentences=8, sample_size=323.7, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=971.2, ups=3, wpb=323.7, bsz=8, num_updates=14770, lr=8.61207e-05, gnorm=2.76, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=5036
2023-03-15 15:23:41 - progress_bar.py[line:272] - INFO: epoch 008:    848 / 2004 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.584, ntokens=358.4, nsentences=8, sample_size=358.4, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=1148.2, ups=3.2, wpb=358.4, bsz=8, num_updates=14780, lr=8.61106e-05, gnorm=2.643, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=5039
2023-03-15 15:23:44 - progress_bar.py[line:272] - INFO: epoch 008:    858 / 2004 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.649, ntokens=358, nsentences=8, sample_size=358, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=1135.3, ups=3.17, wpb=358, bsz=8, num_updates=14790, lr=8.61005e-05, gnorm=2.738, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=5042
2023-03-15 15:23:47 - progress_bar.py[line:272] - INFO: epoch 008:    868 / 2004 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.617, ntokens=368.4, nsentences=8, sample_size=368.4, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=1181.2, ups=3.21, wpb=368.4, bsz=8, num_updates=14800, lr=8.60904e-05, gnorm=2.673, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=5045
2023-03-15 15:23:50 - progress_bar.py[line:272] - INFO: epoch 008:    878 / 2004 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.562, ntokens=327.8, nsentences=8, sample_size=327.8, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=1045.2, ups=3.19, wpb=327.8, bsz=8, num_updates=14810, lr=8.60804e-05, gnorm=2.672, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=5048
2023-03-15 15:23:54 - progress_bar.py[line:272] - INFO: epoch 008:    888 / 2004 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.606, ntokens=321.3, nsentences=8, sample_size=321.3, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=1023.7, ups=3.19, wpb=321.3, bsz=8, num_updates=14820, lr=8.60703e-05, gnorm=2.956, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=5051
2023-03-15 15:23:57 - progress_bar.py[line:272] - INFO: epoch 008:    898 / 2004 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.62, ntokens=341.8, nsentences=8, sample_size=341.8, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=1091, ups=3.19, wpb=341.8, bsz=8, num_updates=14830, lr=8.60602e-05, gnorm=2.887, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=5054
2023-03-15 15:24:00 - progress_bar.py[line:272] - INFO: epoch 008:    908 / 2004 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.567, ntokens=363.1, nsentences=8, sample_size=363.1, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=1089, ups=3, wpb=363.1, bsz=8, num_updates=14840, lr=8.60501e-05, gnorm=2.759, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=5058
2023-03-15 15:24:04 - progress_bar.py[line:272] - INFO: epoch 008:    918 / 2004 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.636, ntokens=358.3, nsentences=8, sample_size=358.3, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=1044.1, ups=2.91, wpb=358.3, bsz=8, num_updates=14850, lr=8.604e-05, gnorm=2.766, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=5061
2023-03-15 15:24:07 - progress_bar.py[line:272] - INFO: epoch 008:    928 / 2004 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.589, ntokens=333, nsentences=8, sample_size=333, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=949.9, ups=2.85, wpb=333, bsz=8, num_updates=14860, lr=8.603e-05, gnorm=2.797, clip=0, loss_scale=4096, train_wall=3, gb_free=15.2, wall=5065
2023-03-15 15:24:08 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 15:24:11 - progress_bar.py[line:272] - INFO: epoch 008:    939 / 2004 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.61, ntokens=365, nsentences=8, sample_size=365, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=941, ups=2.58, wpb=365, bsz=8, num_updates=14870, lr=8.60199e-05, gnorm=2.753, clip=0, loss_scale=2048, train_wall=4, gb_free=14.6, wall=5069
2023-03-15 15:24:14 - progress_bar.py[line:272] - INFO: epoch 008:    949 / 2004 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.599, ntokens=346.1, nsentences=8, sample_size=346.1, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=1003.4, ups=2.9, wpb=346.1, bsz=8, num_updates=14880, lr=8.60098e-05, gnorm=2.864, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=5072
2023-03-15 15:24:18 - progress_bar.py[line:272] - INFO: epoch 008:    959 / 2004 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.618, ntokens=354, nsentences=8, sample_size=354, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=1015.4, ups=2.87, wpb=354, bsz=8, num_updates=14890, lr=8.59997e-05, gnorm=2.786, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=5075
2023-03-15 15:24:21 - progress_bar.py[line:272] - INFO: epoch 008:    969 / 2004 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.642, ntokens=351.2, nsentences=8, sample_size=351.2, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=1001.2, ups=2.85, wpb=351.2, bsz=8, num_updates=14900, lr=8.59896e-05, gnorm=2.779, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=5079
2023-03-15 15:24:25 - progress_bar.py[line:272] - INFO: epoch 008:    979 / 2004 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.608, ntokens=339.3, nsentences=8, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=987.1, ups=2.91, wpb=339.3, bsz=8, num_updates=14910, lr=8.59796e-05, gnorm=2.839, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=5082
2023-03-15 15:24:28 - progress_bar.py[line:272] - INFO: epoch 008:    989 / 2004 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.627, ntokens=358.7, nsentences=8, sample_size=358.7, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=1011.7, ups=2.82, wpb=358.7, bsz=8, num_updates=14920, lr=8.59695e-05, gnorm=2.772, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=5086
2023-03-15 15:24:32 - progress_bar.py[line:272] - INFO: epoch 008:    999 / 2004 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.618, ntokens=359.1, nsentences=8, sample_size=359.1, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=1033, ups=2.88, wpb=359.1, bsz=8, num_updates=14930, lr=8.59594e-05, gnorm=2.719, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=5089
2023-03-15 15:24:35 - progress_bar.py[line:272] - INFO: epoch 008:   1009 / 2004 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.598, ntokens=298, nsentences=8, sample_size=298, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=853.9, ups=2.87, wpb=298, bsz=8, num_updates=14940, lr=8.59493e-05, gnorm=2.818, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=5093
2023-03-15 15:24:39 - progress_bar.py[line:272] - INFO: epoch 008:   1019 / 2004 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.573, ntokens=342.6, nsentences=8, sample_size=342.6, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=979.2, ups=2.86, wpb=342.6, bsz=8, num_updates=14950, lr=8.59392e-05, gnorm=2.805, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=5096
2023-03-15 15:24:42 - progress_bar.py[line:272] - INFO: epoch 008:   1029 / 2004 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.573, ntokens=324, nsentences=8, sample_size=324, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=899.6, ups=2.78, wpb=324, bsz=8, num_updates=14960, lr=8.59292e-05, gnorm=2.778, clip=0, loss_scale=2048, train_wall=4, gb_free=14.8, wall=5100
2023-03-15 15:24:46 - progress_bar.py[line:272] - INFO: epoch 008:   1039 / 2004 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.581, ntokens=319.1, nsentences=8, sample_size=319.1, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=910.2, ups=2.85, wpb=319.1, bsz=8, num_updates=14970, lr=8.59191e-05, gnorm=2.779, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=5104
2023-03-15 15:24:50 - progress_bar.py[line:272] - INFO: epoch 008:   1049 / 2004 loss=0.705, loss_v1=0, loss_v2=0, nll_loss=0.705, ntokens=392.2, nsentences=8, sample_size=392.2, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=1073.6, ups=2.74, wpb=392.2, bsz=8, num_updates=14980, lr=8.5909e-05, gnorm=2.885, clip=0, loss_scale=2048, train_wall=4, gb_free=14.7, wall=5107
2023-03-15 15:24:53 - progress_bar.py[line:272] - INFO: epoch 008:   1059 / 2004 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.576, ntokens=337.6, nsentences=8, sample_size=337.6, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=960.3, ups=2.84, wpb=337.6, bsz=8, num_updates=14990, lr=8.58989e-05, gnorm=2.657, clip=0, loss_scale=4096, train_wall=3, gb_free=15.4, wall=5111
2023-03-15 15:24:53 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 15:24:57 - progress_bar.py[line:272] - INFO: epoch 008:   1070 / 2004 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.643, ntokens=342.8, nsentences=8, sample_size=342.8, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=909.8, ups=2.65, wpb=342.8, bsz=8, num_updates=15000, lr=8.58888e-05, gnorm=2.961, clip=0, loss_scale=2048, train_wall=4, gb_free=14.7, wall=5114
2023-03-15 15:25:00 - progress_bar.py[line:272] - INFO: epoch 008:   1080 / 2004 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.599, ntokens=359.4, nsentences=8, sample_size=359.4, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=1039.4, ups=2.89, wpb=359.4, bsz=8, num_updates=15010, lr=8.58787e-05, gnorm=2.832, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=5118
2023-03-15 15:25:04 - progress_bar.py[line:272] - INFO: epoch 008:   1090 / 2004 loss=0.692, loss_v1=0, loss_v2=0, nll_loss=0.692, ntokens=359.7, nsentences=8, sample_size=359.7, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=1021.3, ups=2.84, wpb=359.7, bsz=8, num_updates=15020, lr=8.58687e-05, gnorm=2.909, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=5121
2023-03-15 15:25:07 - progress_bar.py[line:272] - INFO: epoch 008:   1100 / 2004 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.62, ntokens=343.1, nsentences=8, sample_size=343.1, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=975.8, ups=2.84, wpb=343.1, bsz=8, num_updates=15030, lr=8.58586e-05, gnorm=2.775, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=5125
2023-03-15 15:25:11 - progress_bar.py[line:272] - INFO: epoch 008:   1110 / 2004 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.634, ntokens=371.7, nsentences=8, sample_size=371.7, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=1048.9, ups=2.82, wpb=371.7, bsz=8, num_updates=15040, lr=8.58485e-05, gnorm=2.744, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=5129
2023-03-15 15:25:14 - progress_bar.py[line:272] - INFO: epoch 008:   1120 / 2004 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.512, ntokens=318.9, nsentences=8, sample_size=318.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=913.9, ups=2.87, wpb=318.9, bsz=8, num_updates=15050, lr=8.58384e-05, gnorm=2.628, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=5132
2023-03-15 15:25:18 - progress_bar.py[line:272] - INFO: epoch 008:   1130 / 2004 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.612, ntokens=354.8, nsentences=8, sample_size=354.8, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=1022.5, ups=2.88, wpb=354.8, bsz=8, num_updates=15060, lr=8.58283e-05, gnorm=2.722, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=5135
2023-03-15 15:25:21 - progress_bar.py[line:272] - INFO: epoch 008:   1140 / 2004 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.596, ntokens=375, nsentences=8, sample_size=375, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=1092.5, ups=2.91, wpb=375, bsz=8, num_updates=15070, lr=8.58183e-05, gnorm=2.68, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=5139
2023-03-15 15:25:25 - progress_bar.py[line:272] - INFO: epoch 008:   1150 / 2004 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.544, ntokens=353.1, nsentences=8, sample_size=353.1, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=1003.3, ups=2.84, wpb=353.1, bsz=8, num_updates=15080, lr=8.58082e-05, gnorm=2.636, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=5142
2023-03-15 15:25:28 - progress_bar.py[line:272] - INFO: epoch 008:   1160 / 2004 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.638, ntokens=407.3, nsentences=8, sample_size=407.3, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=1231.1, ups=3.02, wpb=407.3, bsz=8, num_updates=15090, lr=8.57981e-05, gnorm=2.703, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=5146
2023-03-15 15:25:31 - progress_bar.py[line:272] - INFO: epoch 008:   1170 / 2004 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.59, ntokens=334.7, nsentences=8, sample_size=334.7, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=1045.7, ups=3.12, wpb=334.7, bsz=8, num_updates=15100, lr=8.5788e-05, gnorm=2.715, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=5149
2023-03-15 15:25:35 - progress_bar.py[line:272] - INFO: epoch 008:   1180 / 2004 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.592, ntokens=350.6, nsentences=8, sample_size=350.6, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=1008.9, ups=2.88, wpb=350.6, bsz=8, num_updates=15110, lr=8.57779e-05, gnorm=2.728, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=5152
2023-03-15 15:25:38 - progress_bar.py[line:272] - INFO: epoch 008:   1190 / 2004 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.525, ntokens=327.4, nsentences=8, sample_size=327.4, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=925.7, ups=2.83, wpb=327.4, bsz=8, num_updates=15120, lr=8.57679e-05, gnorm=2.609, clip=0, loss_scale=4096, train_wall=3, gb_free=14.9, wall=5156
2023-03-15 15:25:39 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 15:25:42 - progress_bar.py[line:272] - INFO: epoch 008:   1201 / 2004 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.584, ntokens=349.8, nsentences=8, sample_size=349.8, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=891.7, ups=2.55, wpb=349.8, bsz=8, num_updates=15130, lr=8.57578e-05, gnorm=2.783, clip=0, loss_scale=2048, train_wall=4, gb_free=15, wall=5160
2023-03-15 15:25:46 - progress_bar.py[line:272] - INFO: epoch 008:   1211 / 2004 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.536, ntokens=282.4, nsentences=8, sample_size=282.4, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=824.3, ups=2.92, wpb=282.4, bsz=8, num_updates=15140, lr=8.57477e-05, gnorm=2.693, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=5163
2023-03-15 15:25:49 - progress_bar.py[line:272] - INFO: epoch 008:   1221 / 2004 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.595, ntokens=331.6, nsentences=8, sample_size=331.6, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=962, ups=2.9, wpb=331.6, bsz=8, num_updates=15150, lr=8.57376e-05, gnorm=2.786, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=5167
2023-03-15 15:25:53 - progress_bar.py[line:272] - INFO: epoch 008:   1231 / 2004 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.523, ntokens=301.1, nsentences=8, sample_size=301.1, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=883.3, ups=2.93, wpb=301.1, bsz=8, num_updates=15160, lr=8.57275e-05, gnorm=2.751, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=5170
2023-03-15 15:25:56 - progress_bar.py[line:272] - INFO: epoch 008:   1241 / 2004 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.631, ntokens=392.8, nsentences=8, sample_size=392.8, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=1120.2, ups=2.85, wpb=392.8, bsz=8, num_updates=15170, lr=8.57175e-05, gnorm=2.782, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=5174
2023-03-15 15:25:59 - progress_bar.py[line:272] - INFO: epoch 008:   1251 / 2004 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.598, ntokens=338, nsentences=8, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=1005.1, ups=2.97, wpb=338, bsz=8, num_updates=15180, lr=8.57074e-05, gnorm=3.028, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=5177
2023-03-15 15:26:03 - progress_bar.py[line:272] - INFO: epoch 008:   1261 / 2004 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.575, ntokens=349.1, nsentences=8, sample_size=349.1, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=1012.4, ups=2.9, wpb=349.1, bsz=8, num_updates=15190, lr=8.56973e-05, gnorm=2.768, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=5180
2023-03-15 15:26:06 - progress_bar.py[line:272] - INFO: epoch 008:   1271 / 2004 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.598, ntokens=357.5, nsentences=8, sample_size=357.5, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=1085.2, ups=3.04, wpb=357.5, bsz=8, num_updates=15200, lr=8.56872e-05, gnorm=2.79, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=5184
2023-03-15 15:26:10 - progress_bar.py[line:272] - INFO: epoch 008:   1281 / 2004 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.555, ntokens=325.3, nsentences=8, sample_size=325.3, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=941.9, ups=2.9, wpb=325.3, bsz=8, num_updates=15210, lr=8.56771e-05, gnorm=2.786, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=5187
2023-03-15 15:26:13 - progress_bar.py[line:272] - INFO: epoch 008:   1291 / 2004 loss=0.453, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=304.1, nsentences=8, sample_size=304.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=896.7, ups=2.95, wpb=304.1, bsz=8, num_updates=15220, lr=8.5667e-05, gnorm=2.492, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=5191
2023-03-15 15:26:16 - progress_bar.py[line:272] - INFO: epoch 008:   1301 / 2004 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.586, ntokens=316, nsentences=8, sample_size=316, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=929.1, ups=2.94, wpb=316, bsz=8, num_updates=15230, lr=8.5657e-05, gnorm=2.743, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=5194
2023-03-15 15:26:20 - progress_bar.py[line:272] - INFO: epoch 008:   1311 / 2004 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.63, ntokens=349.7, nsentences=8, sample_size=349.7, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=1013.3, ups=2.9, wpb=349.7, bsz=8, num_updates=15240, lr=8.56469e-05, gnorm=2.862, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=5197
2023-03-15 15:26:23 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 15:26:24 - progress_bar.py[line:272] - INFO: epoch 008:   1322 / 2004 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.579, ntokens=313.6, nsentences=8, sample_size=313.6, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=831.1, ups=2.65, wpb=313.6, bsz=8, num_updates=15250, lr=8.56368e-05, gnorm=2.856, clip=0, loss_scale=2048, train_wall=4, gb_free=15.1, wall=5201
2023-03-15 15:26:27 - progress_bar.py[line:272] - INFO: epoch 008:   1332 / 2004 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.599, ntokens=321.9, nsentences=8, sample_size=321.9, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=938.7, ups=2.92, wpb=321.9, bsz=8, num_updates=15260, lr=8.56267e-05, gnorm=2.973, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=5205
2023-03-15 15:26:31 - progress_bar.py[line:272] - INFO: epoch 008:   1342 / 2004 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.622, ntokens=329.3, nsentences=8, sample_size=329.3, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=950.1, ups=2.89, wpb=329.3, bsz=8, num_updates=15270, lr=8.56166e-05, gnorm=2.917, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=5208
2023-03-15 15:26:34 - progress_bar.py[line:272] - INFO: epoch 008:   1352 / 2004 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.601, ntokens=323.5, nsentences=8, sample_size=323.5, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=946, ups=2.92, wpb=323.5, bsz=8, num_updates=15280, lr=8.56066e-05, gnorm=2.877, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=5212
2023-03-15 15:26:37 - progress_bar.py[line:272] - INFO: epoch 008:   1362 / 2004 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.594, ntokens=324.4, nsentences=8, sample_size=324.4, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=929.9, ups=2.87, wpb=324.4, bsz=8, num_updates=15290, lr=8.55965e-05, gnorm=2.788, clip=0, loss_scale=2048, train_wall=3, gb_free=13.9, wall=5215
2023-03-15 15:26:41 - progress_bar.py[line:272] - INFO: epoch 008:   1372 / 2004 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.534, ntokens=298.5, nsentences=8, sample_size=298.5, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=863.3, ups=2.89, wpb=298.5, bsz=8, num_updates=15300, lr=8.55864e-05, gnorm=2.849, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=5218
2023-03-15 15:26:44 - progress_bar.py[line:272] - INFO: epoch 008:   1382 / 2004 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.63, ntokens=381.1, nsentences=8, sample_size=381.1, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=1092, ups=2.87, wpb=381.1, bsz=8, num_updates=15310, lr=8.55763e-05, gnorm=2.948, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=5222
2023-03-15 15:26:45 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 15:26:48 - progress_bar.py[line:272] - INFO: epoch 008:   1393 / 2004 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.558, ntokens=360.1, nsentences=8, sample_size=360.1, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=956.6, ups=2.66, wpb=360.1, bsz=8, num_updates=15320, lr=8.55662e-05, gnorm=2.635, clip=0, loss_scale=1024, train_wall=4, gb_free=15.4, wall=5226
2023-03-15 15:26:52 - progress_bar.py[line:272] - INFO: epoch 008:   1403 / 2004 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.544, ntokens=337.1, nsentences=8, sample_size=337.1, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=982.2, ups=2.91, wpb=337.1, bsz=8, num_updates=15330, lr=8.55562e-05, gnorm=2.76, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=5229
2023-03-15 15:26:55 - progress_bar.py[line:272] - INFO: epoch 008:   1413 / 2004 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.655, ntokens=378.6, nsentences=8, sample_size=378.6, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=1085.9, ups=2.87, wpb=378.6, bsz=8, num_updates=15340, lr=8.55461e-05, gnorm=2.882, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=5233
2023-03-15 15:26:59 - progress_bar.py[line:272] - INFO: epoch 008:   1423 / 2004 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.558, ntokens=317.9, nsentences=8, sample_size=317.9, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=912.2, ups=2.87, wpb=317.9, bsz=8, num_updates=15350, lr=8.5536e-05, gnorm=2.619, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=5236
2023-03-15 15:27:02 - progress_bar.py[line:272] - INFO: epoch 008:   1433 / 2004 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.614, ntokens=347.9, nsentences=8, sample_size=347.9, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=989.5, ups=2.84, wpb=347.9, bsz=8, num_updates=15360, lr=8.55259e-05, gnorm=2.755, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=5240
2023-03-15 15:27:06 - progress_bar.py[line:272] - INFO: epoch 008:   1443 / 2004 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.635, ntokens=340.6, nsentences=8, sample_size=340.6, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=964.3, ups=2.83, wpb=340.6, bsz=8, num_updates=15370, lr=8.55158e-05, gnorm=2.856, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=5243
2023-03-15 15:27:09 - progress_bar.py[line:272] - INFO: epoch 008:   1453 / 2004 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.636, ntokens=353.2, nsentences=8, sample_size=353.2, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=995.9, ups=2.82, wpb=353.2, bsz=8, num_updates=15380, lr=8.55058e-05, gnorm=2.848, clip=0, loss_scale=1024, train_wall=3, gb_free=12.5, wall=5247
2023-03-15 15:27:13 - progress_bar.py[line:272] - INFO: epoch 008:   1463 / 2004 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.64, ntokens=382.5, nsentences=8, sample_size=382.5, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=1092.8, ups=2.86, wpb=382.5, bsz=8, num_updates=15390, lr=8.54957e-05, gnorm=2.778, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=5250
2023-03-15 15:27:16 - progress_bar.py[line:272] - INFO: epoch 008:   1473 / 2004 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.627, ntokens=400.9, nsentences=8, sample_size=400.9, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=1137.7, ups=2.84, wpb=400.9, bsz=8, num_updates=15400, lr=8.54856e-05, gnorm=2.747, clip=0, loss_scale=1024, train_wall=3, gb_free=14.2, wall=5254
2023-03-15 15:27:20 - progress_bar.py[line:272] - INFO: epoch 008:   1483 / 2004 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.621, ntokens=370.3, nsentences=8, sample_size=370.3, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=1073.1, ups=2.9, wpb=370.3, bsz=8, num_updates=15410, lr=8.54755e-05, gnorm=2.833, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=5257
2023-03-15 15:27:23 - progress_bar.py[line:272] - INFO: epoch 008:   1493 / 2004 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.558, ntokens=310.3, nsentences=8, sample_size=310.3, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=898.5, ups=2.9, wpb=310.3, bsz=8, num_updates=15420, lr=8.54654e-05, gnorm=2.857, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=5261
2023-03-15 15:27:27 - progress_bar.py[line:272] - INFO: epoch 008:   1503 / 2004 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.582, ntokens=341.9, nsentences=8, sample_size=341.9, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=978.4, ups=2.86, wpb=341.9, bsz=8, num_updates=15430, lr=8.54554e-05, gnorm=2.798, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=5264
2023-03-15 15:27:30 - progress_bar.py[line:272] - INFO: epoch 008:   1513 / 2004 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.552, ntokens=333.6, nsentences=8, sample_size=333.6, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=958.8, ups=2.87, wpb=333.6, bsz=8, num_updates=15440, lr=8.54453e-05, gnorm=2.819, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=5268
2023-03-15 15:27:33 - progress_bar.py[line:272] - INFO: epoch 008:   1523 / 2004 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.568, ntokens=327.5, nsentences=8, sample_size=327.5, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=949.4, ups=2.9, wpb=327.5, bsz=8, num_updates=15450, lr=8.54352e-05, gnorm=2.89, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=5271
2023-03-15 15:27:37 - progress_bar.py[line:272] - INFO: epoch 008:   1533 / 2004 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.628, ntokens=356.6, nsentences=8, sample_size=356.6, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=1045.5, ups=2.93, wpb=356.6, bsz=8, num_updates=15460, lr=8.54251e-05, gnorm=2.847, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=5275
2023-03-15 15:27:40 - progress_bar.py[line:272] - INFO: epoch 008:   1543 / 2004 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.541, ntokens=316.9, nsentences=8, sample_size=316.9, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=925.2, ups=2.92, wpb=316.9, bsz=8, num_updates=15470, lr=8.5415e-05, gnorm=2.818, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=5278
2023-03-15 15:27:44 - progress_bar.py[line:272] - INFO: epoch 008:   1553 / 2004 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.562, ntokens=321.4, nsentences=8, sample_size=321.4, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=926, ups=2.88, wpb=321.4, bsz=8, num_updates=15480, lr=8.54049e-05, gnorm=2.712, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=5281
2023-03-15 15:27:47 - progress_bar.py[line:272] - INFO: epoch 008:   1563 / 2004 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.57, ntokens=360.8, nsentences=8, sample_size=360.8, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=1035.8, ups=2.87, wpb=360.8, bsz=8, num_updates=15490, lr=8.53949e-05, gnorm=2.729, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=5285
2023-03-15 15:27:51 - progress_bar.py[line:272] - INFO: epoch 008:   1573 / 2004 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.571, ntokens=333.8, nsentences=8, sample_size=333.8, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=953.8, ups=2.86, wpb=333.8, bsz=8, num_updates=15500, lr=8.53848e-05, gnorm=2.753, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=5288
2023-03-15 15:27:54 - progress_bar.py[line:272] - INFO: epoch 008:   1583 / 2004 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.584, ntokens=340.7, nsentences=8, sample_size=340.7, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=987.4, ups=2.9, wpb=340.7, bsz=8, num_updates=15510, lr=8.53747e-05, gnorm=2.726, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=5292
2023-03-15 15:27:58 - progress_bar.py[line:272] - INFO: epoch 008:   1593 / 2004 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.613, ntokens=353.8, nsentences=8, sample_size=353.8, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=1007.2, ups=2.85, wpb=353.8, bsz=8, num_updates=15520, lr=8.53646e-05, gnorm=2.851, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=5295
2023-03-15 15:28:01 - progress_bar.py[line:272] - INFO: epoch 008:   1603 / 2004 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.536, ntokens=330.8, nsentences=8, sample_size=330.8, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=954, ups=2.88, wpb=330.8, bsz=8, num_updates=15530, lr=8.53545e-05, gnorm=2.735, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=5299
2023-03-15 15:28:05 - progress_bar.py[line:272] - INFO: epoch 008:   1613 / 2004 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.593, ntokens=360.7, nsentences=8, sample_size=360.7, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=1011.9, ups=2.81, wpb=360.7, bsz=8, num_updates=15540, lr=8.53445e-05, gnorm=2.724, clip=0, loss_scale=2048, train_wall=4, gb_free=14.8, wall=5302
2023-03-15 15:28:08 - progress_bar.py[line:272] - INFO: epoch 008:   1623 / 2004 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.633, ntokens=346.4, nsentences=8, sample_size=346.4, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=1013.6, ups=2.93, wpb=346.4, bsz=8, num_updates=15550, lr=8.53344e-05, gnorm=2.918, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=5306
2023-03-15 15:28:12 - progress_bar.py[line:272] - INFO: epoch 008:   1633 / 2004 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.583, ntokens=334.5, nsentences=8, sample_size=334.5, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=958.4, ups=2.87, wpb=334.5, bsz=8, num_updates=15560, lr=8.53243e-05, gnorm=2.931, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=5309
2023-03-15 15:28:15 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 15:28:16 - progress_bar.py[line:272] - INFO: epoch 008:   1644 / 2004 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.537, ntokens=307.8, nsentences=8, sample_size=307.8, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=804.7, ups=2.61, wpb=307.8, bsz=8, num_updates=15570, lr=8.53142e-05, gnorm=2.852, clip=0, loss_scale=2048, train_wall=4, gb_free=14.9, wall=5313
2023-03-15 15:28:19 - progress_bar.py[line:272] - INFO: epoch 008:   1654 / 2004 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.584, ntokens=338.6, nsentences=8, sample_size=338.6, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=993.4, ups=2.93, wpb=338.6, bsz=8, num_updates=15580, lr=8.53041e-05, gnorm=2.895, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=5317
2023-03-15 15:28:22 - progress_bar.py[line:272] - INFO: epoch 008:   1664 / 2004 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.592, ntokens=358.4, nsentences=8, sample_size=358.4, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=1025.6, ups=2.86, wpb=358.4, bsz=8, num_updates=15590, lr=8.52941e-05, gnorm=2.942, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=5320
2023-03-15 15:28:26 - progress_bar.py[line:272] - INFO: epoch 008:   1674 / 2004 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.602, ntokens=316.3, nsentences=8, sample_size=316.3, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=920.6, ups=2.91, wpb=316.3, bsz=8, num_updates=15600, lr=8.5284e-05, gnorm=3.031, clip=0, loss_scale=2048, train_wall=3, gb_free=15.9, wall=5323
2023-03-15 15:28:29 - progress_bar.py[line:272] - INFO: epoch 008:   1684 / 2004 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.555, ntokens=349.4, nsentences=8, sample_size=349.4, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=1014.7, ups=2.9, wpb=349.4, bsz=8, num_updates=15610, lr=8.52739e-05, gnorm=2.776, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=5327
2023-03-15 15:28:33 - progress_bar.py[line:272] - INFO: epoch 008:   1694 / 2004 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.583, ntokens=338.3, nsentences=8, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=954.4, ups=2.82, wpb=338.3, bsz=8, num_updates=15620, lr=8.52638e-05, gnorm=2.874, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=5330
2023-03-15 15:28:36 - progress_bar.py[line:272] - INFO: epoch 008:   1704 / 2004 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.543, ntokens=334.7, nsentences=8, sample_size=334.7, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=977.8, ups=2.92, wpb=334.7, bsz=8, num_updates=15630, lr=8.52537e-05, gnorm=2.756, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=5334
2023-03-15 15:28:40 - progress_bar.py[line:272] - INFO: epoch 008:   1714 / 2004 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.645, ntokens=364, nsentences=8, sample_size=364, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=990.2, ups=2.72, wpb=364, bsz=8, num_updates=15640, lr=8.52437e-05, gnorm=3.013, clip=0, loss_scale=2048, train_wall=4, gb_free=14.3, wall=5338
2023-03-15 15:28:43 - progress_bar.py[line:272] - INFO: epoch 008:   1724 / 2004 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.558, ntokens=380.9, nsentences=8, sample_size=380.9, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=1077, ups=2.83, wpb=380.9, bsz=8, num_updates=15650, lr=8.52336e-05, gnorm=2.764, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=5341
2023-03-15 15:28:47 - progress_bar.py[line:272] - INFO: epoch 008:   1734 / 2004 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.591, ntokens=350.8, nsentences=8, sample_size=350.8, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=1016.1, ups=2.9, wpb=350.8, bsz=8, num_updates=15660, lr=8.52235e-05, gnorm=2.832, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=5345
2023-03-15 15:28:50 - progress_bar.py[line:272] - INFO: epoch 008:   1744 / 2004 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.574, ntokens=346.2, nsentences=8, sample_size=346.2, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=996.9, ups=2.88, wpb=346.2, bsz=8, num_updates=15670, lr=8.52134e-05, gnorm=2.924, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=5348
2023-03-15 15:28:54 - progress_bar.py[line:272] - INFO: epoch 008:   1754 / 2004 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.584, ntokens=347.7, nsentences=8, sample_size=347.7, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=994.9, ups=2.86, wpb=347.7, bsz=8, num_updates=15680, lr=8.52033e-05, gnorm=2.737, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=5352
2023-03-15 15:28:57 - progress_bar.py[line:272] - INFO: epoch 008:   1764 / 2004 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.578, ntokens=303.9, nsentences=8, sample_size=303.9, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=859.3, ups=2.83, wpb=303.9, bsz=8, num_updates=15690, lr=8.51932e-05, gnorm=2.918, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=5355
2023-03-15 15:29:00 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 15:29:01 - progress_bar.py[line:272] - INFO: epoch 008:   1775 / 2004 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.615, ntokens=349.7, nsentences=8, sample_size=349.7, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=901.3, ups=2.58, wpb=349.7, bsz=8, num_updates=15700, lr=8.51832e-05, gnorm=2.841, clip=0, loss_scale=2048, train_wall=4, gb_free=14.3, wall=5359
2023-03-15 15:29:05 - progress_bar.py[line:272] - INFO: epoch 008:   1785 / 2004 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.529, ntokens=315, nsentences=8, sample_size=315, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=918.2, ups=2.92, wpb=315, bsz=8, num_updates=15710, lr=8.51731e-05, gnorm=2.762, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=5362
2023-03-15 15:29:08 - progress_bar.py[line:272] - INFO: epoch 008:   1795 / 2004 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.537, ntokens=319.8, nsentences=8, sample_size=319.8, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=922.8, ups=2.89, wpb=319.8, bsz=8, num_updates=15720, lr=8.5163e-05, gnorm=2.691, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=5366
2023-03-15 15:29:12 - progress_bar.py[line:272] - INFO: epoch 008:   1805 / 2004 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.652, ntokens=353.2, nsentences=8, sample_size=353.2, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=1012.9, ups=2.87, wpb=353.2, bsz=8, num_updates=15730, lr=8.51529e-05, gnorm=3.097, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=5369
2023-03-15 15:29:15 - progress_bar.py[line:272] - INFO: epoch 008:   1815 / 2004 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.589, ntokens=359.4, nsentences=8, sample_size=359.4, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=1020.5, ups=2.84, wpb=359.4, bsz=8, num_updates=15740, lr=8.51428e-05, gnorm=2.965, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=5373
2023-03-15 15:29:16 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 15:29:19 - progress_bar.py[line:272] - INFO: epoch 008:   1826 / 2004 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.582, ntokens=361.7, nsentences=8, sample_size=361.7, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=918.2, ups=2.54, wpb=361.7, bsz=8, num_updates=15750, lr=8.51328e-05, gnorm=2.904, clip=0, loss_scale=1024, train_wall=4, gb_free=14.6, wall=5377
2023-03-15 15:29:23 - progress_bar.py[line:272] - INFO: epoch 008:   1836 / 2004 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.568, ntokens=327.2, nsentences=8, sample_size=327.2, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=919.6, ups=2.81, wpb=327.2, bsz=8, num_updates=15760, lr=8.51227e-05, gnorm=2.839, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=5380
2023-03-15 15:29:26 - progress_bar.py[line:272] - INFO: epoch 008:   1846 / 2004 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.647, ntokens=360.5, nsentences=8, sample_size=360.5, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=1034.4, ups=2.87, wpb=360.5, bsz=8, num_updates=15770, lr=8.51126e-05, gnorm=2.929, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=5384
2023-03-15 15:29:30 - progress_bar.py[line:272] - INFO: epoch 008:   1856 / 2004 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.536, ntokens=312.9, nsentences=8, sample_size=312.9, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=900.9, ups=2.88, wpb=312.9, bsz=8, num_updates=15780, lr=8.51025e-05, gnorm=2.73, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=5387
2023-03-15 15:29:33 - progress_bar.py[line:272] - INFO: epoch 008:   1866 / 2004 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.574, ntokens=343.7, nsentences=8, sample_size=343.7, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=981.9, ups=2.86, wpb=343.7, bsz=8, num_updates=15790, lr=8.50924e-05, gnorm=2.748, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=5391
2023-03-15 15:29:37 - progress_bar.py[line:272] - INFO: epoch 008:   1876 / 2004 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.569, ntokens=337.8, nsentences=8, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=952.2, ups=2.82, wpb=337.8, bsz=8, num_updates=15800, lr=8.50824e-05, gnorm=2.756, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=5394
2023-03-15 15:29:40 - progress_bar.py[line:272] - INFO: epoch 008:   1886 / 2004 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.513, ntokens=324, nsentences=8, sample_size=324, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=930.9, ups=2.87, wpb=324, bsz=8, num_updates=15810, lr=8.50723e-05, gnorm=2.693, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=5398
2023-03-15 15:29:44 - progress_bar.py[line:272] - INFO: epoch 008:   1896 / 2004 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.55, ntokens=336.9, nsentences=8, sample_size=336.9, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=965.2, ups=2.86, wpb=336.9, bsz=8, num_updates=15820, lr=8.50622e-05, gnorm=2.786, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=5401
2023-03-15 15:29:47 - progress_bar.py[line:272] - INFO: epoch 008:   1906 / 2004 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.513, ntokens=348.4, nsentences=8, sample_size=348.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=1000.9, ups=2.87, wpb=348.4, bsz=8, num_updates=15830, lr=8.50521e-05, gnorm=2.819, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=5405
2023-03-15 15:29:51 - progress_bar.py[line:272] - INFO: epoch 008:   1916 / 2004 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.543, ntokens=327.7, nsentences=8, sample_size=327.7, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=943.2, ups=2.88, wpb=327.7, bsz=8, num_updates=15840, lr=8.5042e-05, gnorm=2.753, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=5408
2023-03-15 15:29:54 - progress_bar.py[line:272] - INFO: epoch 008:   1926 / 2004 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.536, ntokens=325.2, nsentences=8, sample_size=325.2, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=929.1, ups=2.86, wpb=325.2, bsz=8, num_updates=15850, lr=8.5032e-05, gnorm=2.94, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=5412
2023-03-15 15:29:58 - progress_bar.py[line:272] - INFO: epoch 008:   1936 / 2004 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.53, ntokens=336.4, nsentences=8, sample_size=336.4, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=962.5, ups=2.86, wpb=336.4, bsz=8, num_updates=15860, lr=8.50219e-05, gnorm=2.769, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=5415
2023-03-15 15:30:01 - progress_bar.py[line:272] - INFO: epoch 008:   1946 / 2004 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.589, ntokens=358.9, nsentences=8, sample_size=358.9, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=1002.3, ups=2.79, wpb=358.9, bsz=8, num_updates=15870, lr=8.50118e-05, gnorm=2.859, clip=0, loss_scale=2048, train_wall=4, gb_free=14.7, wall=5419
2023-03-15 15:30:05 - progress_bar.py[line:272] - INFO: epoch 008:   1956 / 2004 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.529, ntokens=348, nsentences=8, sample_size=348, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=990.1, ups=2.85, wpb=348, bsz=8, num_updates=15880, lr=8.50017e-05, gnorm=2.896, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=5422
2023-03-15 15:30:08 - progress_bar.py[line:272] - INFO: epoch 008:   1966 / 2004 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.545, ntokens=356.9, nsentences=8, sample_size=356.9, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=1004.2, ups=2.81, wpb=356.9, bsz=8, num_updates=15890, lr=8.49916e-05, gnorm=2.768, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=5426
2023-03-15 15:30:12 - progress_bar.py[line:272] - INFO: epoch 008:   1976 / 2004 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.594, ntokens=340.3, nsentences=8, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=949.3, ups=2.79, wpb=340.3, bsz=8, num_updates=15900, lr=8.49816e-05, gnorm=2.918, clip=0, loss_scale=2048, train_wall=4, gb_free=14.9, wall=5430
2023-03-15 15:30:15 - progress_bar.py[line:272] - INFO: epoch 008:   1986 / 2004 loss=0.489, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=311.3, nsentences=8, sample_size=311.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=920.1, ups=2.96, wpb=311.3, bsz=8, num_updates=15910, lr=8.49715e-05, gnorm=2.718, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=5433
2023-03-15 15:30:19 - progress_bar.py[line:272] - INFO: epoch 008:   1996 / 2004 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.612, ntokens=398.9, nsentences=8, sample_size=398.9, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=1101.3, ups=2.76, wpb=398.9, bsz=8, num_updates=15920, lr=8.49614e-05, gnorm=2.761, clip=0, loss_scale=2048, train_wall=4, gb_free=14.5, wall=5437
2023-03-15 15:30:22 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 8 @ 15928 updates
2023-03-15 15:30:22 - trainer.py[line:431] - INFO: Saving checkpoint to ./checkpoints/checkpoint8.pt
2023-03-15 15:30:27 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./checkpoints/checkpoint8.pt
2023-03-15 15:30:28 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./checkpoints/checkpoint8.pt (epoch 8 @ 15928 updates, score None) (writing took 6.642085721716285 seconds)
2023-03-15 15:30:28 - train.py[line:332] - INFO: end of epoch 8 (average epoch stats below)
2023-03-15 15:30:28 - progress_bar.py[line:282] - INFO: epoch 008 | loss 0.61 | loss_v1 0 | loss_v2 0 | nll_loss 0.61 | ntokens 345.392 | nsentences 7.999 | sample_size 345.392 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.53 | wps 978.2 | ups 2.83 | wpb 345.4 | bsz 8 | num_updates 15928 | lr 8.49533e-05 | gnorm 2.773 | clip 0 | loss_scale 2048 | train_wall 682 | gb_free 14.4 | wall 5446
2023-03-15 15:30:28 - trainer.py[line:639] - INFO: loading train data for epoch 9
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 row count 8015 total row count 8015
slice_id 0 seek offset 0
2023-03-15 15:30:29 - trainer.py[line:703] - INFO: begin training epoch 9
2023-03-15 15:30:29 - train.py[line:305] - INFO: Start iterating over samples
2023-03-15 15:30:30 - progress_bar.py[line:272] - INFO: epoch 009:      2 / 2004 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.627, ntokens=367.8, nsentences=8, sample_size=367.8, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=337, ups=0.92, wpb=367.8, bsz=8, num_updates=15930, lr=8.49513e-05, gnorm=2.924, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=5447
2023-03-15 15:30:33 - progress_bar.py[line:272] - INFO: epoch 009:     12 / 2004 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.597, ntokens=340.2, nsentences=8, sample_size=340.2, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=967.9, ups=2.84, wpb=340.2, bsz=8, num_updates=15940, lr=8.49412e-05, gnorm=2.915, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=5451
2023-03-15 15:30:37 - progress_bar.py[line:272] - INFO: epoch 009:     22 / 2004 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.591, ntokens=343.7, nsentences=8, sample_size=343.7, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=983.5, ups=2.86, wpb=343.7, bsz=8, num_updates=15950, lr=8.49311e-05, gnorm=2.875, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=5454
2023-03-15 15:30:40 - progress_bar.py[line:272] - INFO: epoch 009:     32 / 2004 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.588, ntokens=353.3, nsentences=8, sample_size=353.3, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=1042.6, ups=2.95, wpb=353.3, bsz=8, num_updates=15960, lr=8.49211e-05, gnorm=2.886, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=5458
2023-03-15 15:30:43 - progress_bar.py[line:272] - INFO: epoch 009:     42 / 2004 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.588, ntokens=364.2, nsentences=8, sample_size=364.2, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=1115.9, ups=3.06, wpb=364.2, bsz=8, num_updates=15970, lr=8.4911e-05, gnorm=2.896, clip=0, loss_scale=2048, train_wall=3, gb_free=13.6, wall=5461
2023-03-15 15:30:47 - progress_bar.py[line:272] - INFO: epoch 009:     52 / 2004 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.563, ntokens=339.6, nsentences=8, sample_size=339.6, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=964.2, ups=2.84, wpb=339.6, bsz=8, num_updates=15980, lr=8.49009e-05, gnorm=2.867, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=5465
2023-03-15 15:30:50 - progress_bar.py[line:272] - INFO: epoch 009:     62 / 2004 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.546, ntokens=330.6, nsentences=8, sample_size=330.6, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=1066, ups=3.22, wpb=330.6, bsz=8, num_updates=15990, lr=8.48908e-05, gnorm=2.84, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=5468
2023-03-15 15:30:54 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 15:30:54 - progress_bar.py[line:272] - INFO: epoch 009:     73 / 2004 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.607, ntokens=345.6, nsentences=8, sample_size=345.6, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=923.3, ups=2.67, wpb=345.6, bsz=8, num_updates=16000, lr=8.48807e-05, gnorm=2.845, clip=0, loss_scale=2048, train_wall=4, gb_free=14.3, wall=5471
2023-03-15 15:30:57 - progress_bar.py[line:272] - INFO: epoch 009:     83 / 2004 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.562, ntokens=328.5, nsentences=8, sample_size=328.5, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=937.9, ups=2.86, wpb=328.5, bsz=8, num_updates=16010, lr=8.48707e-05, gnorm=2.938, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=5475
2023-03-15 15:31:01 - progress_bar.py[line:272] - INFO: epoch 009:     93 / 2004 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.618, ntokens=369.6, nsentences=8, sample_size=369.6, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=1040.1, ups=2.81, wpb=369.6, bsz=8, num_updates=16020, lr=8.48606e-05, gnorm=2.877, clip=0, loss_scale=2048, train_wall=3, gb_free=12.9, wall=5479
2023-03-15 15:31:04 - progress_bar.py[line:272] - INFO: epoch 009:    103 / 2004 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.604, ntokens=367.3, nsentences=8, sample_size=367.3, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=1059.7, ups=2.89, wpb=367.3, bsz=8, num_updates=16030, lr=8.48505e-05, gnorm=2.969, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=5482
2023-03-15 15:31:08 - progress_bar.py[line:272] - INFO: epoch 009:    113 / 2004 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.604, ntokens=339.8, nsentences=8, sample_size=339.8, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=968.2, ups=2.85, wpb=339.8, bsz=8, num_updates=16040, lr=8.48404e-05, gnorm=3.025, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=5486
2023-03-15 15:31:11 - progress_bar.py[line:272] - INFO: epoch 009:    123 / 2004 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.578, ntokens=349.4, nsentences=8, sample_size=349.4, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=988.3, ups=2.83, wpb=349.4, bsz=8, num_updates=16050, lr=8.48303e-05, gnorm=2.816, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=5489
2023-03-15 15:31:15 - progress_bar.py[line:272] - INFO: epoch 009:    133 / 2004 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.54, ntokens=316.1, nsentences=8, sample_size=316.1, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=920.9, ups=2.91, wpb=316.1, bsz=8, num_updates=16060, lr=8.48203e-05, gnorm=2.827, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=5492
2023-03-15 15:31:18 - progress_bar.py[line:272] - INFO: epoch 009:    143 / 2004 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.589, ntokens=348.9, nsentences=8, sample_size=348.9, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=985.6, ups=2.82, wpb=348.9, bsz=8, num_updates=16070, lr=8.48102e-05, gnorm=2.896, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=5496
2023-03-15 15:31:22 - progress_bar.py[line:272] - INFO: epoch 009:    153 / 2004 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.535, ntokens=323, nsentences=8, sample_size=323, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=944.1, ups=2.92, wpb=323, bsz=8, num_updates=16080, lr=8.48001e-05, gnorm=2.851, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=5499
2023-03-15 15:31:25 - progress_bar.py[line:272] - INFO: epoch 009:    163 / 2004 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.594, ntokens=369.2, nsentences=8, sample_size=369.2, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=1071, ups=2.9, wpb=369.2, bsz=8, num_updates=16090, lr=8.479e-05, gnorm=2.831, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=5503
2023-03-15 15:31:29 - progress_bar.py[line:272] - INFO: epoch 009:    173 / 2004 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.536, ntokens=335, nsentences=8, sample_size=335, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=970.1, ups=2.9, wpb=335, bsz=8, num_updates=16100, lr=8.47799e-05, gnorm=2.812, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=5506
2023-03-15 15:31:32 - progress_bar.py[line:272] - INFO: epoch 009:    183 / 2004 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.511, ntokens=322.9, nsentences=8, sample_size=322.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=954, ups=2.95, wpb=322.9, bsz=8, num_updates=16110, lr=8.47699e-05, gnorm=2.74, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=5510
2023-03-15 15:31:36 - progress_bar.py[line:272] - INFO: epoch 009:    193 / 2004 loss=0.493, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=334.5, nsentences=8, sample_size=334.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=978.7, ups=2.93, wpb=334.5, bsz=8, num_updates=16120, lr=8.47598e-05, gnorm=2.778, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=5513
2023-03-15 15:31:38 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 15:31:39 - progress_bar.py[line:272] - INFO: epoch 009:    204 / 2004 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.557, ntokens=322.9, nsentences=8, sample_size=322.9, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=839.9, ups=2.6, wpb=322.9, bsz=8, num_updates=16130, lr=8.47497e-05, gnorm=2.935, clip=0, loss_scale=2048, train_wall=4, gb_free=15.2, wall=5517
2023-03-15 15:31:43 - progress_bar.py[line:272] - INFO: epoch 009:    214 / 2004 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.542, ntokens=332.9, nsentences=8, sample_size=332.9, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=958.6, ups=2.88, wpb=332.9, bsz=8, num_updates=16140, lr=8.47396e-05, gnorm=2.881, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=5520
2023-03-15 15:31:46 - progress_bar.py[line:272] - INFO: epoch 009:    224 / 2004 loss=0.469, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=330.7, nsentences=8, sample_size=330.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=941.2, ups=2.85, wpb=330.7, bsz=8, num_updates=16150, lr=8.47295e-05, gnorm=2.64, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=5524
2023-03-15 15:31:50 - progress_bar.py[line:272] - INFO: epoch 009:    234 / 2004 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.604, ntokens=373.2, nsentences=8, sample_size=373.2, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=1056, ups=2.83, wpb=373.2, bsz=8, num_updates=16160, lr=8.47194e-05, gnorm=2.951, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=5528
2023-03-15 15:31:53 - progress_bar.py[line:272] - INFO: epoch 009:    244 / 2004 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.566, ntokens=354.4, nsentences=8, sample_size=354.4, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=1027, ups=2.9, wpb=354.4, bsz=8, num_updates=16170, lr=8.47094e-05, gnorm=2.881, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=5531
2023-03-15 15:31:57 - progress_bar.py[line:272] - INFO: epoch 009:    254 / 2004 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=337.2, nsentences=8, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=1036.3, ups=3.07, wpb=337.2, bsz=8, num_updates=16180, lr=8.46993e-05, gnorm=2.752, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=5534
2023-03-15 15:32:00 - progress_bar.py[line:272] - INFO: epoch 009:    264 / 2004 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.618, ntokens=358.3, nsentences=8, sample_size=358.3, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=1091, ups=3.04, wpb=358.3, bsz=8, num_updates=16190, lr=8.46892e-05, gnorm=2.973, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=5537
2023-03-15 15:32:03 - progress_bar.py[line:272] - INFO: epoch 009:    274 / 2004 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.529, ntokens=330.1, nsentences=8, sample_size=330.1, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=1050.8, ups=3.18, wpb=330.1, bsz=8, num_updates=16200, lr=8.46791e-05, gnorm=2.759, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=5541
2023-03-15 15:32:06 - progress_bar.py[line:272] - INFO: epoch 009:    284 / 2004 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.573, ntokens=374.8, nsentences=8, sample_size=374.8, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=1181.2, ups=3.15, wpb=374.8, bsz=8, num_updates=16210, lr=8.4669e-05, gnorm=2.791, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=5544
2023-03-15 15:32:09 - progress_bar.py[line:272] - INFO: epoch 009:    294 / 2004 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.567, ntokens=345.5, nsentences=8, sample_size=345.5, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=1072.3, ups=3.1, wpb=345.5, bsz=8, num_updates=16220, lr=8.4659e-05, gnorm=2.742, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=5547
2023-03-15 15:32:13 - progress_bar.py[line:272] - INFO: epoch 009:    304 / 2004 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.572, ntokens=357.7, nsentences=8, sample_size=357.7, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=1123.9, ups=3.14, wpb=357.7, bsz=8, num_updates=16230, lr=8.46489e-05, gnorm=2.831, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=5550
2023-03-15 15:32:16 - progress_bar.py[line:272] - INFO: epoch 009:    314 / 2004 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.583, ntokens=361.4, nsentences=8, sample_size=361.4, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=1135.7, ups=3.14, wpb=361.4, bsz=8, num_updates=16240, lr=8.46388e-05, gnorm=2.868, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=5553
2023-03-15 15:32:19 - progress_bar.py[line:272] - INFO: epoch 009:    324 / 2004 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=323.2, nsentences=8, sample_size=323.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=1028.4, ups=3.18, wpb=323.2, bsz=8, num_updates=16250, lr=8.46287e-05, gnorm=2.749, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=5557
2023-03-15 15:32:21 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 15:32:22 - progress_bar.py[line:272] - INFO: epoch 009:    335 / 2004 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.535, ntokens=314.2, nsentences=8, sample_size=314.2, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=918.8, ups=2.92, wpb=314.2, bsz=8, num_updates=16260, lr=8.46186e-05, gnorm=2.87, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=5560
2023-03-15 15:32:26 - progress_bar.py[line:272] - INFO: epoch 009:    345 / 2004 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.634, ntokens=388.7, nsentences=8, sample_size=388.7, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=1199.5, ups=3.09, wpb=388.7, bsz=8, num_updates=16270, lr=8.46086e-05, gnorm=2.892, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=5563
2023-03-15 15:32:29 - progress_bar.py[line:272] - INFO: epoch 009:    355 / 2004 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.561, ntokens=337.5, nsentences=8, sample_size=337.5, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=1065.1, ups=3.16, wpb=337.5, bsz=8, num_updates=16280, lr=8.45985e-05, gnorm=3.043, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=5566
2023-03-15 15:32:32 - progress_bar.py[line:272] - INFO: epoch 009:    365 / 2004 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.56, ntokens=355.8, nsentences=8, sample_size=355.8, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=1114.5, ups=3.13, wpb=355.8, bsz=8, num_updates=16290, lr=8.45884e-05, gnorm=2.804, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=5570
2023-03-15 15:32:35 - progress_bar.py[line:272] - INFO: epoch 009:    375 / 2004 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=319.3, nsentences=8, sample_size=319.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=963.7, ups=3.02, wpb=319.3, bsz=8, num_updates=16300, lr=8.45783e-05, gnorm=2.907, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=5573
2023-03-15 15:32:39 - progress_bar.py[line:272] - INFO: epoch 009:    385 / 2004 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.522, ntokens=326.1, nsentences=8, sample_size=326.1, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=936, ups=2.87, wpb=326.1, bsz=8, num_updates=16310, lr=8.45682e-05, gnorm=2.836, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=5576
2023-03-15 15:32:42 - progress_bar.py[line:272] - INFO: epoch 009:    395 / 2004 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.587, ntokens=354.5, nsentences=8, sample_size=354.5, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=1016.1, ups=2.87, wpb=354.5, bsz=8, num_updates=16320, lr=8.45582e-05, gnorm=3.06, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=5580
2023-03-15 15:32:46 - progress_bar.py[line:272] - INFO: epoch 009:    405 / 2004 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.536, ntokens=363.7, nsentences=8, sample_size=363.7, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=1029, ups=2.83, wpb=363.7, bsz=8, num_updates=16330, lr=8.45481e-05, gnorm=2.737, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=5583
2023-03-15 15:32:49 - progress_bar.py[line:272] - INFO: epoch 009:    415 / 2004 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.538, ntokens=351.8, nsentences=8, sample_size=351.8, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=1012.4, ups=2.88, wpb=351.8, bsz=8, num_updates=16340, lr=8.4538e-05, gnorm=2.844, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=5587
2023-03-15 15:32:53 - progress_bar.py[line:272] - INFO: epoch 009:    425 / 2004 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.513, ntokens=331.5, nsentences=8, sample_size=331.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=962.7, ups=2.9, wpb=331.5, bsz=8, num_updates=16350, lr=8.45279e-05, gnorm=2.683, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=5590
2023-03-15 15:32:56 - progress_bar.py[line:272] - INFO: epoch 009:    435 / 2004 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.551, ntokens=363.6, nsentences=8, sample_size=363.6, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=1133, ups=3.12, wpb=363.6, bsz=8, num_updates=16360, lr=8.45178e-05, gnorm=2.796, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=5594
2023-03-15 15:32:59 - progress_bar.py[line:272] - INFO: epoch 009:    445 / 2004 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.611, ntokens=366.6, nsentences=8, sample_size=366.6, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=1155.6, ups=3.15, wpb=366.6, bsz=8, num_updates=16370, lr=8.45078e-05, gnorm=2.956, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=5597
2023-03-15 15:33:02 - progress_bar.py[line:272] - INFO: epoch 009:    455 / 2004 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.63, ntokens=380.2, nsentences=8, sample_size=380.2, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=1219.3, ups=3.21, wpb=380.2, bsz=8, num_updates=16380, lr=8.44977e-05, gnorm=2.916, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=5600
2023-03-15 15:33:03 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 15:33:06 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 15:33:06 - progress_bar.py[line:272] - INFO: epoch 009:    467 / 2004 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.588, ntokens=338, nsentences=8, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=885.8, ups=2.62, wpb=338, bsz=8, num_updates=16390, lr=8.44876e-05, gnorm=2.963, clip=0, loss_scale=1024, train_wall=4, gb_free=13.3, wall=5604
2023-03-15 15:33:09 - progress_bar.py[line:272] - INFO: epoch 009:    477 / 2004 loss=0.499, loss_v1=0, loss_v2=0, nll_loss=0.499, ntokens=334.5, nsentences=8, sample_size=334.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=986.3, ups=2.95, wpb=334.5, bsz=8, num_updates=16400, lr=8.44775e-05, gnorm=2.72, clip=0, loss_scale=1024, train_wall=3, gb_free=15.7, wall=5607
2023-03-15 15:33:13 - progress_bar.py[line:272] - INFO: epoch 009:    487 / 2004 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.563, ntokens=391.9, nsentences=8, sample_size=391.9, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=1091.3, ups=2.78, wpb=391.9, bsz=8, num_updates=16410, lr=8.44674e-05, gnorm=2.807, clip=0, loss_scale=1024, train_wall=4, gb_free=14.8, wall=5611
2023-03-15 15:33:17 - progress_bar.py[line:272] - INFO: epoch 009:    497 / 2004 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.582, ntokens=371, nsentences=8, sample_size=371, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=1050.8, ups=2.83, wpb=371, bsz=8, num_updates=16420, lr=8.44573e-05, gnorm=2.811, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=5614
2023-03-15 15:33:20 - progress_bar.py[line:272] - INFO: epoch 009:    507 / 2004 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.593, ntokens=341.1, nsentences=8, sample_size=341.1, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=991.7, ups=2.91, wpb=341.1, bsz=8, num_updates=16430, lr=8.44473e-05, gnorm=2.922, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=5618
2023-03-15 15:33:23 - progress_bar.py[line:272] - INFO: epoch 009:    517 / 2004 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.576, ntokens=353.3, nsentences=8, sample_size=353.3, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=1017.8, ups=2.88, wpb=353.3, bsz=8, num_updates=16440, lr=8.44372e-05, gnorm=2.95, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=5621
2023-03-15 15:33:27 - progress_bar.py[line:272] - INFO: epoch 009:    527 / 2004 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.605, ntokens=401.8, nsentences=8, sample_size=401.8, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=1132.9, ups=2.82, wpb=401.8, bsz=8, num_updates=16450, lr=8.44271e-05, gnorm=2.816, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=5625
2023-03-15 15:33:30 - progress_bar.py[line:272] - INFO: epoch 009:    537 / 2004 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.596, ntokens=381.1, nsentences=8, sample_size=381.1, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=1085.2, ups=2.85, wpb=381.1, bsz=8, num_updates=16460, lr=8.4417e-05, gnorm=2.969, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=5628
2023-03-15 15:33:34 - progress_bar.py[line:272] - INFO: epoch 009:    547 / 2004 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.56, ntokens=352.4, nsentences=8, sample_size=352.4, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=1010.2, ups=2.87, wpb=352.4, bsz=8, num_updates=16470, lr=8.44069e-05, gnorm=2.972, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=5632
2023-03-15 15:33:37 - progress_bar.py[line:272] - INFO: epoch 009:    557 / 2004 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.578, ntokens=382, nsentences=8, sample_size=382, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=1137.8, ups=2.98, wpb=382, bsz=8, num_updates=16480, lr=8.43969e-05, gnorm=2.832, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=5635
2023-03-15 15:33:41 - progress_bar.py[line:272] - INFO: epoch 009:    567 / 2004 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.557, ntokens=372.3, nsentences=8, sample_size=372.3, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=1166.9, ups=3.13, wpb=372.3, bsz=8, num_updates=16490, lr=8.43868e-05, gnorm=2.771, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=5638
2023-03-15 15:33:44 - progress_bar.py[line:272] - INFO: epoch 009:    577 / 2004 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.54, ntokens=336.7, nsentences=8, sample_size=336.7, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=1083.9, ups=3.22, wpb=336.7, bsz=8, num_updates=16500, lr=8.43767e-05, gnorm=2.797, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=5641
2023-03-15 15:33:47 - progress_bar.py[line:272] - INFO: epoch 009:    587 / 2004 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.594, ntokens=361, nsentences=8, sample_size=361, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=1117.7, ups=3.1, wpb=361, bsz=8, num_updates=16510, lr=8.43666e-05, gnorm=2.907, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=5644
2023-03-15 15:33:50 - progress_bar.py[line:272] - INFO: epoch 009:    597 / 2004 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.539, ntokens=333.2, nsentences=8, sample_size=333.2, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=1016.5, ups=3.05, wpb=333.2, bsz=8, num_updates=16520, lr=8.43565e-05, gnorm=2.927, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=5648
2023-03-15 15:33:54 - progress_bar.py[line:272] - INFO: epoch 009:    607 / 2004 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.582, ntokens=360.5, nsentences=8, sample_size=360.5, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=1011.2, ups=2.8, wpb=360.5, bsz=8, num_updates=16530, lr=8.43465e-05, gnorm=2.863, clip=0, loss_scale=2048, train_wall=3, gb_free=13.9, wall=5651
2023-03-15 15:33:57 - progress_bar.py[line:272] - INFO: epoch 009:    617 / 2004 loss=0.498, loss_v1=0, loss_v2=0, nll_loss=0.498, ntokens=347.5, nsentences=8, sample_size=347.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=979.2, ups=2.82, wpb=347.5, bsz=8, num_updates=16540, lr=8.43364e-05, gnorm=2.69, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=5655
2023-03-15 15:34:01 - progress_bar.py[line:272] - INFO: epoch 009:    627 / 2004 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=373.6, nsentences=8, sample_size=373.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=1057.3, ups=2.83, wpb=373.6, bsz=8, num_updates=16550, lr=8.43263e-05, gnorm=2.699, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=5658
2023-03-15 15:34:04 - progress_bar.py[line:272] - INFO: epoch 009:    637 / 2004 loss=0.492, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=332.2, nsentences=8, sample_size=332.2, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=945.9, ups=2.85, wpb=332.2, bsz=8, num_updates=16560, lr=8.43162e-05, gnorm=2.837, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=5662
2023-03-15 15:34:08 - progress_bar.py[line:272] - INFO: epoch 009:    647 / 2004 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.521, ntokens=327.4, nsentences=8, sample_size=327.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=924.4, ups=2.82, wpb=327.4, bsz=8, num_updates=16570, lr=8.43061e-05, gnorm=2.871, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=5665
2023-03-15 15:34:11 - progress_bar.py[line:272] - INFO: epoch 009:    657 / 2004 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.609, ntokens=356.4, nsentences=8, sample_size=356.4, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=1021.6, ups=2.87, wpb=356.4, bsz=8, num_updates=16580, lr=8.42961e-05, gnorm=3.021, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=5669
2023-03-15 15:34:15 - progress_bar.py[line:272] - INFO: epoch 009:    667 / 2004 loss=0.497, loss_v1=0, loss_v2=0, nll_loss=0.497, ntokens=305.5, nsentences=8, sample_size=305.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=870.8, ups=2.85, wpb=305.5, bsz=8, num_updates=16590, lr=8.4286e-05, gnorm=2.758, clip=0, loss_scale=2048, train_wall=3, gb_free=13.9, wall=5672
2023-03-15 15:34:18 - progress_bar.py[line:272] - INFO: epoch 009:    677 / 2004 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.532, ntokens=335.2, nsentences=8, sample_size=335.2, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=950, ups=2.83, wpb=335.2, bsz=8, num_updates=16600, lr=8.42759e-05, gnorm=2.797, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=5676
2023-03-15 15:34:22 - progress_bar.py[line:272] - INFO: epoch 009:    687 / 2004 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.512, ntokens=349.7, nsentences=8, sample_size=349.7, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=1006.7, ups=2.88, wpb=349.7, bsz=8, num_updates=16610, lr=8.42658e-05, gnorm=2.854, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=5679
2023-03-15 15:34:25 - progress_bar.py[line:272] - INFO: epoch 009:    697 / 2004 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.582, ntokens=358.2, nsentences=8, sample_size=358.2, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=994.8, ups=2.78, wpb=358.2, bsz=8, num_updates=16620, lr=8.42557e-05, gnorm=2.978, clip=0, loss_scale=2048, train_wall=4, gb_free=14, wall=5683
2023-03-15 15:34:29 - progress_bar.py[line:272] - INFO: epoch 009:    707 / 2004 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=342.8, nsentences=8, sample_size=342.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=921, ups=2.69, wpb=342.8, bsz=8, num_updates=16630, lr=8.42457e-05, gnorm=2.781, clip=0, loss_scale=2048, train_wall=4, gb_free=14.1, wall=5687
2023-03-15 15:34:33 - progress_bar.py[line:272] - INFO: epoch 009:    717 / 2004 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.519, ntokens=316.9, nsentences=8, sample_size=316.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=893.4, ups=2.82, wpb=316.9, bsz=8, num_updates=16640, lr=8.42356e-05, gnorm=2.792, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=5690
2023-03-15 15:34:35 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 15:34:37 - progress_bar.py[line:272] - INFO: epoch 009:    728 / 2004 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.562, ntokens=370.2, nsentences=8, sample_size=370.2, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=970.1, ups=2.62, wpb=370.2, bsz=8, num_updates=16650, lr=8.42255e-05, gnorm=2.924, clip=0, loss_scale=2048, train_wall=4, gb_free=15, wall=5694
2023-03-15 15:34:40 - progress_bar.py[line:272] - INFO: epoch 009:    738 / 2004 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=331.6, nsentences=8, sample_size=331.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=941.1, ups=2.84, wpb=331.6, bsz=8, num_updates=16660, lr=8.42154e-05, gnorm=2.947, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=5698
2023-03-15 15:34:44 - progress_bar.py[line:272] - INFO: epoch 009:    748 / 2004 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.565, ntokens=375, nsentences=8, sample_size=375, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=1071.6, ups=2.86, wpb=375, bsz=8, num_updates=16670, lr=8.42053e-05, gnorm=3.015, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=5701
2023-03-15 15:34:47 - progress_bar.py[line:272] - INFO: epoch 009:    758 / 2004 loss=0.489, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=295.1, nsentences=8, sample_size=295.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=851, ups=2.88, wpb=295.1, bsz=8, num_updates=16680, lr=8.41952e-05, gnorm=3.019, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=5705
2023-03-15 15:34:50 - progress_bar.py[line:272] - INFO: epoch 009:    768 / 2004 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.623, ntokens=408.6, nsentences=8, sample_size=408.6, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=1183.8, ups=2.9, wpb=408.6, bsz=8, num_updates=16690, lr=8.41852e-05, gnorm=3.015, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=5708
2023-03-15 15:34:54 - progress_bar.py[line:272] - INFO: epoch 009:    778 / 2004 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.566, ntokens=351.3, nsentences=8, sample_size=351.3, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=1075, ups=3.06, wpb=351.3, bsz=8, num_updates=16700, lr=8.41751e-05, gnorm=3.023, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=5711
2023-03-15 15:34:57 - progress_bar.py[line:272] - INFO: epoch 009:    788 / 2004 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.528, ntokens=343.7, nsentences=8, sample_size=343.7, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=974.3, ups=2.83, wpb=343.7, bsz=8, num_updates=16710, lr=8.4165e-05, gnorm=2.847, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=5715
2023-03-15 15:35:01 - progress_bar.py[line:272] - INFO: epoch 009:    798 / 2004 loss=0.501, loss_v1=0, loss_v2=0, nll_loss=0.501, ntokens=318.4, nsentences=8, sample_size=318.4, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=924, ups=2.9, wpb=318.4, bsz=8, num_updates=16720, lr=8.41549e-05, gnorm=2.921, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=5718
2023-03-15 15:35:04 - progress_bar.py[line:272] - INFO: epoch 009:    808 / 2004 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.559, ntokens=349.8, nsentences=8, sample_size=349.8, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=1026.2, ups=2.93, wpb=349.8, bsz=8, num_updates=16730, lr=8.41448e-05, gnorm=3, clip=0, loss_scale=2048, train_wall=3, gb_free=13.7, wall=5722
2023-03-15 15:35:08 - progress_bar.py[line:272] - INFO: epoch 009:    818 / 2004 loss=0.463, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=312.9, nsentences=8, sample_size=312.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=894.7, ups=2.86, wpb=312.9, bsz=8, num_updates=16740, lr=8.41348e-05, gnorm=2.891, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=5725
2023-03-15 15:35:11 - progress_bar.py[line:272] - INFO: epoch 009:    828 / 2004 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.592, ntokens=378.6, nsentences=8, sample_size=378.6, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=1079, ups=2.85, wpb=378.6, bsz=8, num_updates=16750, lr=8.41247e-05, gnorm=2.989, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=5729
2023-03-15 15:35:15 - progress_bar.py[line:272] - INFO: epoch 009:    838 / 2004 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.527, ntokens=327.8, nsentences=8, sample_size=327.8, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=970, ups=2.96, wpb=327.8, bsz=8, num_updates=16760, lr=8.41146e-05, gnorm=2.934, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=5732
2023-03-15 15:35:18 - progress_bar.py[line:272] - INFO: epoch 009:    848 / 2004 loss=0.501, loss_v1=0, loss_v2=0, nll_loss=0.501, ntokens=361.2, nsentences=8, sample_size=361.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=1041.7, ups=2.88, wpb=361.2, bsz=8, num_updates=16770, lr=8.41045e-05, gnorm=2.768, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=5736
2023-03-15 15:35:20 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 15:35:22 - progress_bar.py[line:272] - INFO: epoch 009:    859 / 2004 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.564, ntokens=352.3, nsentences=8, sample_size=352.3, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=916.2, ups=2.6, wpb=352.3, bsz=8, num_updates=16780, lr=8.40944e-05, gnorm=2.946, clip=0, loss_scale=2048, train_wall=4, gb_free=14.8, wall=5739
2023-03-15 15:35:25 - progress_bar.py[line:272] - INFO: epoch 009:    869 / 2004 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.55, ntokens=365.4, nsentences=8, sample_size=365.4, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=1119.3, ups=3.06, wpb=365.4, bsz=8, num_updates=16790, lr=8.40844e-05, gnorm=2.902, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=5743
2023-03-15 15:35:29 - progress_bar.py[line:272] - INFO: epoch 009:    879 / 2004 loss=0.484, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=325.6, nsentences=8, sample_size=325.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=956.3, ups=2.94, wpb=325.6, bsz=8, num_updates=16800, lr=8.40743e-05, gnorm=2.868, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=5746
2023-03-15 15:35:32 - progress_bar.py[line:272] - INFO: epoch 009:    889 / 2004 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=311.6, nsentences=8, sample_size=311.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=921.1, ups=2.96, wpb=311.6, bsz=8, num_updates=16810, lr=8.40642e-05, gnorm=3.055, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=5750
2023-03-15 15:35:35 - progress_bar.py[line:272] - INFO: epoch 009:    899 / 2004 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.584, ntokens=368.5, nsentences=8, sample_size=368.5, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=1065.5, ups=2.89, wpb=368.5, bsz=8, num_updates=16820, lr=8.40541e-05, gnorm=3.172, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=5753
2023-03-15 15:35:39 - progress_bar.py[line:272] - INFO: epoch 009:    909 / 2004 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.522, ntokens=357, nsentences=8, sample_size=357, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=1023.9, ups=2.87, wpb=357, bsz=8, num_updates=16830, lr=8.4044e-05, gnorm=2.953, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=5756
2023-03-15 15:35:42 - progress_bar.py[line:272] - INFO: epoch 009:    919 / 2004 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.554, ntokens=353.3, nsentences=8, sample_size=353.3, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=1014.4, ups=2.87, wpb=353.3, bsz=8, num_updates=16840, lr=8.4034e-05, gnorm=3.061, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=5760
2023-03-15 15:35:46 - progress_bar.py[line:272] - INFO: epoch 009:    929 / 2004 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=325.6, nsentences=8, sample_size=325.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=937.2, ups=2.88, wpb=325.6, bsz=8, num_updates=16850, lr=8.40239e-05, gnorm=3.091, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=5763
2023-03-15 15:35:49 - progress_bar.py[line:272] - INFO: epoch 009:    939 / 2004 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.573, ntokens=373, nsentences=8, sample_size=373, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=1064.1, ups=2.85, wpb=373, bsz=8, num_updates=16860, lr=8.40138e-05, gnorm=2.942, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=5767
2023-03-15 15:35:53 - progress_bar.py[line:272] - INFO: epoch 009:    949 / 2004 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.535, ntokens=344, nsentences=8, sample_size=344, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=954.8, ups=2.78, wpb=344, bsz=8, num_updates=16870, lr=8.40037e-05, gnorm=2.927, clip=0, loss_scale=2048, train_wall=4, gb_free=15.6, wall=5771
2023-03-15 15:35:56 - progress_bar.py[line:272] - INFO: epoch 009:    959 / 2004 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.554, ntokens=361.6, nsentences=8, sample_size=361.6, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=1038, ups=2.87, wpb=361.6, bsz=8, num_updates=16880, lr=8.39936e-05, gnorm=2.853, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=5774
2023-03-15 15:36:00 - progress_bar.py[line:272] - INFO: epoch 009:    969 / 2004 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.533, ntokens=347.8, nsentences=8, sample_size=347.8, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=988.6, ups=2.84, wpb=347.8, bsz=8, num_updates=16890, lr=8.39835e-05, gnorm=2.839, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=5778
2023-03-15 15:36:03 - progress_bar.py[line:272] - INFO: epoch 009:    979 / 2004 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.528, ntokens=337.9, nsentences=8, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=985.5, ups=2.92, wpb=337.9, bsz=8, num_updates=16900, lr=8.39735e-05, gnorm=2.985, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=5781
2023-03-15 15:36:05 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 15:36:07 - progress_bar.py[line:272] - INFO: epoch 009:    990 / 2004 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.541, ntokens=363.1, nsentences=8, sample_size=363.1, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=970.8, ups=2.67, wpb=363.1, bsz=8, num_updates=16910, lr=8.39634e-05, gnorm=2.81, clip=0, loss_scale=2048, train_wall=4, gb_free=15.1, wall=5785
2023-03-15 15:36:11 - progress_bar.py[line:272] - INFO: epoch 009:   1000 / 2004 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.525, ntokens=343.4, nsentences=8, sample_size=343.4, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=986.6, ups=2.87, wpb=343.4, bsz=8, num_updates=16920, lr=8.39533e-05, gnorm=2.861, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=5788
2023-03-15 15:36:14 - progress_bar.py[line:272] - INFO: epoch 009:   1010 / 2004 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.513, ntokens=317.5, nsentences=8, sample_size=317.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=907.6, ups=2.86, wpb=317.5, bsz=8, num_updates=16930, lr=8.39432e-05, gnorm=3.079, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=5792
2023-03-15 15:36:18 - progress_bar.py[line:272] - INFO: epoch 009:   1020 / 2004 loss=0.493, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=329.8, nsentences=8, sample_size=329.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=933.2, ups=2.83, wpb=329.8, bsz=8, num_updates=16940, lr=8.39331e-05, gnorm=2.863, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=5795
2023-03-15 15:36:21 - progress_bar.py[line:272] - INFO: epoch 009:   1030 / 2004 loss=0.498, loss_v1=0, loss_v2=0, nll_loss=0.498, ntokens=326.8, nsentences=8, sample_size=326.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=924.9, ups=2.83, wpb=326.8, bsz=8, num_updates=16950, lr=8.39231e-05, gnorm=2.844, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=5799
2023-03-15 15:36:25 - progress_bar.py[line:272] - INFO: epoch 009:   1040 / 2004 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.544, ntokens=326.5, nsentences=8, sample_size=326.5, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=917.3, ups=2.81, wpb=326.5, bsz=8, num_updates=16960, lr=8.3913e-05, gnorm=2.95, clip=0, loss_scale=2048, train_wall=3, gb_free=13, wall=5802
2023-03-15 15:36:28 - progress_bar.py[line:272] - INFO: epoch 009:   1050 / 2004 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.574, ntokens=372.9, nsentences=8, sample_size=372.9, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=1043.8, ups=2.8, wpb=372.9, bsz=8, num_updates=16970, lr=8.39029e-05, gnorm=2.98, clip=0, loss_scale=2048, train_wall=4, gb_free=15.5, wall=5806
2023-03-15 15:36:32 - progress_bar.py[line:272] - INFO: epoch 009:   1060 / 2004 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.532, ntokens=344.2, nsentences=8, sample_size=344.2, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=966.7, ups=2.81, wpb=344.2, bsz=8, num_updates=16980, lr=8.38928e-05, gnorm=2.942, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=5809
2023-03-15 15:36:34 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 15:36:36 - progress_bar.py[line:272] - INFO: epoch 009:   1071 / 2004 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.543, ntokens=359.1, nsentences=8, sample_size=359.1, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=917.5, ups=2.56, wpb=359.1, bsz=8, num_updates=16990, lr=8.38827e-05, gnorm=2.963, clip=0, loss_scale=1024, train_wall=4, gb_free=14.8, wall=5813
2023-03-15 15:36:39 - progress_bar.py[line:272] - INFO: epoch 009:   1081 / 2004 loss=0.498, loss_v1=0, loss_v2=0, nll_loss=0.498, ntokens=358.8, nsentences=8, sample_size=358.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=1014.2, ups=2.83, wpb=358.8, bsz=8, num_updates=17000, lr=8.38727e-05, gnorm=2.856, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=5817
2023-03-15 15:36:43 - progress_bar.py[line:272] - INFO: epoch 009:   1091 / 2004 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.589, ntokens=338, nsentences=8, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=970, ups=2.87, wpb=338, bsz=8, num_updates=17010, lr=8.38626e-05, gnorm=3.115, clip=0, loss_scale=1024, train_wall=3, gb_free=15.9, wall=5820
2023-03-15 15:36:46 - progress_bar.py[line:272] - INFO: epoch 009:   1101 / 2004 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.576, ntokens=356.1, nsentences=8, sample_size=356.1, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=1029.9, ups=2.89, wpb=356.1, bsz=8, num_updates=17020, lr=8.38525e-05, gnorm=3.02, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=5824
2023-03-15 15:36:50 - progress_bar.py[line:272] - INFO: epoch 009:   1111 / 2004 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.551, ntokens=369.6, nsentences=8, sample_size=369.6, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=1064.2, ups=2.88, wpb=369.6, bsz=8, num_updates=17030, lr=8.38424e-05, gnorm=2.861, clip=0, loss_scale=1024, train_wall=3, gb_free=14.2, wall=5827
2023-03-15 15:36:53 - progress_bar.py[line:272] - INFO: epoch 009:   1121 / 2004 loss=0.44, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=316.2, nsentences=8, sample_size=316.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=908.2, ups=2.87, wpb=316.2, bsz=8, num_updates=17040, lr=8.38323e-05, gnorm=2.73, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=5831
2023-03-15 15:36:57 - progress_bar.py[line:272] - INFO: epoch 009:   1131 / 2004 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.553, ntokens=368.5, nsentences=8, sample_size=368.5, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=1065.4, ups=2.89, wpb=368.5, bsz=8, num_updates=17050, lr=8.38223e-05, gnorm=2.872, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=5834
2023-03-15 15:37:00 - progress_bar.py[line:272] - INFO: epoch 009:   1141 / 2004 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.515, ntokens=358.2, nsentences=8, sample_size=358.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=1022.5, ups=2.85, wpb=358.2, bsz=8, num_updates=17060, lr=8.38122e-05, gnorm=2.892, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=5838
2023-03-15 15:37:04 - progress_bar.py[line:272] - INFO: epoch 009:   1151 / 2004 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.521, ntokens=368.8, nsentences=8, sample_size=368.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=1037.5, ups=2.81, wpb=368.8, bsz=8, num_updates=17070, lr=8.38021e-05, gnorm=2.717, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=5841
2023-03-15 15:37:07 - progress_bar.py[line:272] - INFO: epoch 009:   1161 / 2004 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.538, ntokens=384.3, nsentences=8, sample_size=384.3, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=1086.6, ups=2.83, wpb=384.3, bsz=8, num_updates=17080, lr=8.3792e-05, gnorm=2.791, clip=0, loss_scale=1024, train_wall=3, gb_free=15.8, wall=5845
2023-03-15 15:37:11 - progress_bar.py[line:272] - INFO: epoch 009:   1171 / 2004 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.509, ntokens=349.4, nsentences=8, sample_size=349.4, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=970.2, ups=2.78, wpb=349.4, bsz=8, num_updates=17090, lr=8.37819e-05, gnorm=2.777, clip=0, loss_scale=1024, train_wall=4, gb_free=15, wall=5848
2023-03-15 15:37:14 - progress_bar.py[line:272] - INFO: epoch 009:   1181 / 2004 loss=0.502, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=345.1, nsentences=8, sample_size=345.1, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=986.2, ups=2.86, wpb=345.1, bsz=8, num_updates=17100, lr=8.37719e-05, gnorm=2.782, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=5852
2023-03-15 15:37:18 - progress_bar.py[line:272] - INFO: epoch 009:   1191 / 2004 loss=0.489, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=345, nsentences=8, sample_size=345, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=1001.8, ups=2.9, wpb=345, bsz=8, num_updates=17110, lr=8.37618e-05, gnorm=2.72, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=5855
2023-03-15 15:37:21 - progress_bar.py[line:272] - INFO: epoch 009:   1201 / 2004 loss=0.488, loss_v1=0, loss_v2=0, nll_loss=0.488, ntokens=348.3, nsentences=8, sample_size=348.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=971.1, ups=2.79, wpb=348.3, bsz=8, num_updates=17120, lr=8.37517e-05, gnorm=2.783, clip=0, loss_scale=2048, train_wall=4, gb_free=14.6, wall=5859
2023-03-15 15:37:24 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 15:37:25 - progress_bar.py[line:272] - INFO: epoch 009:   1212 / 2004 loss=0.456, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=284.8, nsentences=8, sample_size=284.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=752.5, ups=2.64, wpb=284.8, bsz=8, num_updates=17130, lr=8.37416e-05, gnorm=2.768, clip=0, loss_scale=1024, train_wall=4, gb_free=14.8, wall=5863
2023-03-15 15:37:29 - progress_bar.py[line:272] - INFO: epoch 009:   1222 / 2004 loss=0.507, loss_v1=0, loss_v2=0, nll_loss=0.507, ntokens=331.2, nsentences=8, sample_size=331.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=947.3, ups=2.86, wpb=331.2, bsz=8, num_updates=17140, lr=8.37315e-05, gnorm=2.891, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=5866
2023-03-15 15:37:32 - progress_bar.py[line:272] - INFO: epoch 009:   1232 / 2004 loss=0.457, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=304, nsentences=8, sample_size=304, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=865.9, ups=2.85, wpb=304, bsz=8, num_updates=17150, lr=8.37214e-05, gnorm=2.853, clip=0, loss_scale=1024, train_wall=3, gb_free=13.6, wall=5870
2023-03-15 15:37:36 - progress_bar.py[line:272] - INFO: epoch 009:   1242 / 2004 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.58, ntokens=391.4, nsentences=8, sample_size=391.4, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=1092.8, ups=2.79, wpb=391.4, bsz=8, num_updates=17160, lr=8.37114e-05, gnorm=2.946, clip=0, loss_scale=1024, train_wall=4, gb_free=14.6, wall=5873
2023-03-15 15:37:39 - progress_bar.py[line:272] - INFO: epoch 009:   1252 / 2004 loss=0.491, loss_v1=0, loss_v2=0, nll_loss=0.491, ntokens=352.7, nsentences=8, sample_size=352.7, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=1002, ups=2.84, wpb=352.7, bsz=8, num_updates=17170, lr=8.37013e-05, gnorm=2.925, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=5877
2023-03-15 15:37:43 - progress_bar.py[line:272] - INFO: epoch 009:   1262 / 2004 loss=0.493, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=338.5, nsentences=8, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=959.2, ups=2.83, wpb=338.5, bsz=8, num_updates=17180, lr=8.36912e-05, gnorm=2.913, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=5880
2023-03-15 15:37:46 - progress_bar.py[line:272] - INFO: epoch 009:   1272 / 2004 loss=0.496, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=345.3, nsentences=8, sample_size=345.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=988.4, ups=2.86, wpb=345.3, bsz=8, num_updates=17190, lr=8.36811e-05, gnorm=2.91, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=5884
2023-03-15 15:37:50 - progress_bar.py[line:272] - INFO: epoch 009:   1282 / 2004 loss=0.494, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=328.1, nsentences=8, sample_size=328.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=926.5, ups=2.82, wpb=328.1, bsz=8, num_updates=17200, lr=8.3671e-05, gnorm=2.991, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=5887
2023-03-15 15:37:53 - progress_bar.py[line:272] - INFO: epoch 009:   1292 / 2004 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=306.3, nsentences=7.8, sample_size=306.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=890.2, ups=2.91, wpb=306.3, bsz=7.8, num_updates=17210, lr=8.3661e-05, gnorm=2.728, clip=0, loss_scale=1024, train_wall=3, gb_free=16.2, wall=5891
2023-03-15 15:37:57 - progress_bar.py[line:272] - INFO: epoch 009:   1302 / 2004 loss=0.501, loss_v1=0, loss_v2=0, nll_loss=0.501, ntokens=314.8, nsentences=8, sample_size=314.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=905.7, ups=2.88, wpb=314.8, bsz=8, num_updates=17220, lr=8.36509e-05, gnorm=2.979, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=5894
2023-03-15 15:38:00 - progress_bar.py[line:272] - INFO: epoch 009:   1312 / 2004 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.523, ntokens=337.2, nsentences=8, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=961.4, ups=2.85, wpb=337.2, bsz=8, num_updates=17230, lr=8.36408e-05, gnorm=2.869, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=5898
2023-03-15 15:38:04 - progress_bar.py[line:272] - INFO: epoch 009:   1322 / 2004 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.542, ntokens=317.7, nsentences=8, sample_size=317.7, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=922, ups=2.9, wpb=317.7, bsz=8, num_updates=17240, lr=8.36307e-05, gnorm=3.207, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=5901
2023-03-15 15:38:07 - progress_bar.py[line:272] - INFO: epoch 009:   1332 / 2004 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=321.9, nsentences=8, sample_size=321.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=924.9, ups=2.87, wpb=321.9, bsz=8, num_updates=17250, lr=8.36206e-05, gnorm=3.012, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=5905
2023-03-15 15:38:11 - progress_bar.py[line:272] - INFO: epoch 009:   1342 / 2004 loss=0.499, loss_v1=0, loss_v2=0, nll_loss=0.499, ntokens=329.3, nsentences=8, sample_size=329.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=964, ups=2.93, wpb=329.3, bsz=8, num_updates=17260, lr=8.36106e-05, gnorm=2.816, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=5908
2023-03-15 15:38:14 - progress_bar.py[line:272] - INFO: epoch 009:   1352 / 2004 loss=0.507, loss_v1=0, loss_v2=0, nll_loss=0.507, ntokens=323.5, nsentences=8, sample_size=323.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=930.5, ups=2.88, wpb=323.5, bsz=8, num_updates=17270, lr=8.36005e-05, gnorm=3.032, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=5912
2023-03-15 15:38:18 - progress_bar.py[line:272] - INFO: epoch 009:   1362 / 2004 loss=0.501, loss_v1=0, loss_v2=0, nll_loss=0.501, ntokens=324.4, nsentences=8, sample_size=324.4, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=932.7, ups=2.88, wpb=324.4, bsz=8, num_updates=17280, lr=8.35904e-05, gnorm=2.939, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=5915
2023-03-15 15:38:21 - progress_bar.py[line:272] - INFO: epoch 009:   1372 / 2004 loss=0.47, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=298.5, nsentences=8, sample_size=298.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=843.9, ups=2.83, wpb=298.5, bsz=8, num_updates=17290, lr=8.35803e-05, gnorm=2.97, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=5919
2023-03-15 15:38:25 - progress_bar.py[line:272] - INFO: epoch 009:   1382 / 2004 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.56, ntokens=381.1, nsentences=8, sample_size=381.1, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=1069.8, ups=2.81, wpb=381.1, bsz=8, num_updates=17300, lr=8.35702e-05, gnorm=2.984, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=5922
2023-03-15 15:38:26 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 15:38:28 - progress_bar.py[line:272] - INFO: epoch 009:   1393 / 2004 loss=0.49, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=360.1, nsentences=8, sample_size=360.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=954.1, ups=2.65, wpb=360.1, bsz=8, num_updates=17310, lr=8.35602e-05, gnorm=2.755, clip=0, loss_scale=1024, train_wall=4, gb_free=15, wall=5926
2023-03-15 15:38:32 - progress_bar.py[line:272] - INFO: epoch 009:   1403 / 2004 loss=0.495, loss_v1=0, loss_v2=0, nll_loss=0.495, ntokens=337.1, nsentences=8, sample_size=337.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=962, ups=2.85, wpb=337.1, bsz=8, num_updates=17320, lr=8.35501e-05, gnorm=2.839, clip=0, loss_scale=1024, train_wall=3, gb_free=15.7, wall=5930
2023-03-15 15:38:35 - progress_bar.py[line:272] - INFO: epoch 009:   1413 / 2004 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.578, ntokens=378.6, nsentences=8, sample_size=378.6, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=1062, ups=2.81, wpb=378.6, bsz=8, num_updates=17330, lr=8.354e-05, gnorm=3.018, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=5933
2023-03-15 15:38:40 - progress_bar.py[line:272] - INFO: epoch 009:   1423 / 2004 loss=0.492, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=317.9, nsentences=8, sample_size=317.9, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=734.4, ups=2.31, wpb=317.9, bsz=8, num_updates=17340, lr=8.35299e-05, gnorm=2.845, clip=0, loss_scale=1024, train_wall=4, gb_free=15.5, wall=5937
2023-03-15 15:38:43 - progress_bar.py[line:272] - INFO: epoch 009:   1433 / 2004 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.538, ntokens=347.9, nsentences=8, sample_size=347.9, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=1097.6, ups=3.15, wpb=347.9, bsz=8, num_updates=17350, lr=8.35198e-05, gnorm=2.912, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=5941
2023-03-15 15:38:46 - progress_bar.py[line:272] - INFO: epoch 009:   1443 / 2004 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=340.6, nsentences=8, sample_size=340.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=1110, ups=3.26, wpb=340.6, bsz=8, num_updates=17360, lr=8.35097e-05, gnorm=2.937, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=5944
2023-03-15 15:38:49 - progress_bar.py[line:272] - INFO: epoch 009:   1453 / 2004 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.532, ntokens=353.2, nsentences=8, sample_size=353.2, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=1089.3, ups=3.08, wpb=353.2, bsz=8, num_updates=17370, lr=8.34997e-05, gnorm=2.936, clip=0, loss_scale=1024, train_wall=3, gb_free=12.5, wall=5947
2023-03-15 15:38:53 - progress_bar.py[line:272] - INFO: epoch 009:   1463 / 2004 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.538, ntokens=382.5, nsentences=8, sample_size=382.5, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=1109.5, ups=2.9, wpb=382.5, bsz=8, num_updates=17380, lr=8.34896e-05, gnorm=2.928, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=5950
2023-03-15 15:38:56 - progress_bar.py[line:272] - INFO: epoch 009:   1473 / 2004 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.557, ntokens=400.9, nsentences=8, sample_size=400.9, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=1200.9, ups=3, wpb=400.9, bsz=8, num_updates=17390, lr=8.34795e-05, gnorm=2.984, clip=0, loss_scale=1024, train_wall=3, gb_free=14.2, wall=5954
2023-03-15 15:39:00 - progress_bar.py[line:272] - INFO: epoch 009:   1483 / 2004 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.525, ntokens=370.3, nsentences=8, sample_size=370.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=1064.9, ups=2.88, wpb=370.3, bsz=8, num_updates=17400, lr=8.34694e-05, gnorm=2.93, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=5957
2023-03-15 15:39:03 - progress_bar.py[line:272] - INFO: epoch 009:   1493 / 2004 loss=0.478, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=310.3, nsentences=8, sample_size=310.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=907.5, ups=2.92, wpb=310.3, bsz=8, num_updates=17410, lr=8.34593e-05, gnorm=2.893, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=5961
2023-03-15 15:39:06 - progress_bar.py[line:272] - INFO: epoch 009:   1503 / 2004 loss=0.503, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=341.9, nsentences=8, sample_size=341.9, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=983, ups=2.88, wpb=341.9, bsz=8, num_updates=17420, lr=8.34493e-05, gnorm=2.864, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=5964
2023-03-15 15:39:10 - progress_bar.py[line:272] - INFO: epoch 009:   1513 / 2004 loss=0.471, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=333.6, nsentences=8, sample_size=333.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=977.4, ups=2.93, wpb=333.6, bsz=8, num_updates=17430, lr=8.34392e-05, gnorm=2.87, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=5967
2023-03-15 15:39:13 - progress_bar.py[line:272] - INFO: epoch 009:   1523 / 2004 loss=0.485, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=327.5, nsentences=8, sample_size=327.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=1055.6, ups=3.22, wpb=327.5, bsz=8, num_updates=17440, lr=8.34291e-05, gnorm=2.916, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=5971
2023-03-15 15:39:16 - progress_bar.py[line:272] - INFO: epoch 009:   1533 / 2004 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.538, ntokens=356.6, nsentences=8, sample_size=356.6, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=1147.3, ups=3.22, wpb=356.6, bsz=8, num_updates=17450, lr=8.3419e-05, gnorm=2.993, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=5974
2023-03-15 15:39:19 - progress_bar.py[line:272] - INFO: epoch 009:   1543 / 2004 loss=0.449, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=316.9, nsentences=8, sample_size=316.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=977.2, ups=3.08, wpb=316.9, bsz=8, num_updates=17460, lr=8.34089e-05, gnorm=2.753, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=5977
2023-03-15 15:39:23 - progress_bar.py[line:272] - INFO: epoch 009:   1553 / 2004 loss=0.498, loss_v1=0, loss_v2=0, nll_loss=0.498, ntokens=321.4, nsentences=8, sample_size=321.4, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=930, ups=2.89, wpb=321.4, bsz=8, num_updates=17470, lr=8.33989e-05, gnorm=2.85, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=5980
2023-03-15 15:39:26 - progress_bar.py[line:272] - INFO: epoch 009:   1563 / 2004 loss=0.475, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=360.8, nsentences=8, sample_size=360.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=1014.7, ups=2.81, wpb=360.8, bsz=8, num_updates=17480, lr=8.33888e-05, gnorm=2.723, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=5984
2023-03-15 15:39:30 - progress_bar.py[line:272] - INFO: epoch 009:   1573 / 2004 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.51, ntokens=333.8, nsentences=8, sample_size=333.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=951.1, ups=2.85, wpb=333.8, bsz=8, num_updates=17490, lr=8.33787e-05, gnorm=2.918, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=5987
2023-03-15 15:39:33 - progress_bar.py[line:272] - INFO: epoch 009:   1583 / 2004 loss=0.491, loss_v1=0, loss_v2=0, nll_loss=0.491, ntokens=340.7, nsentences=8, sample_size=340.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=962.3, ups=2.82, wpb=340.7, bsz=8, num_updates=17500, lr=8.33686e-05, gnorm=2.773, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=5991
2023-03-15 15:39:37 - progress_bar.py[line:272] - INFO: epoch 009:   1593 / 2004 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.532, ntokens=353.8, nsentences=8, sample_size=353.8, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=995.9, ups=2.81, wpb=353.8, bsz=8, num_updates=17510, lr=8.33585e-05, gnorm=2.965, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=5995
2023-03-15 15:39:40 - progress_bar.py[line:272] - INFO: epoch 009:   1603 / 2004 loss=0.466, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=330.8, nsentences=8, sample_size=330.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=933.5, ups=2.82, wpb=330.8, bsz=8, num_updates=17520, lr=8.33485e-05, gnorm=2.908, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=5998
2023-03-15 15:39:44 - progress_bar.py[line:272] - INFO: epoch 009:   1613 / 2004 loss=0.507, loss_v1=0, loss_v2=0, nll_loss=0.507, ntokens=360.7, nsentences=8, sample_size=360.7, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=1016.2, ups=2.82, wpb=360.7, bsz=8, num_updates=17530, lr=8.33384e-05, gnorm=2.898, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=6002
2023-03-15 15:39:48 - progress_bar.py[line:272] - INFO: epoch 009:   1623 / 2004 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.529, ntokens=346.4, nsentences=8, sample_size=346.4, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=992.6, ups=2.87, wpb=346.4, bsz=8, num_updates=17540, lr=8.33283e-05, gnorm=3.078, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=6005
2023-03-15 15:39:51 - progress_bar.py[line:272] - INFO: epoch 009:   1633 / 2004 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.51, ntokens=334.5, nsentences=8, sample_size=334.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=971.7, ups=2.9, wpb=334.5, bsz=8, num_updates=17550, lr=8.33182e-05, gnorm=2.923, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=6009
2023-03-15 15:39:54 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 15:39:55 - progress_bar.py[line:272] - INFO: epoch 009:   1644 / 2004 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=307.8, nsentences=8, sample_size=307.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=804.9, ups=2.62, wpb=307.8, bsz=8, num_updates=17560, lr=8.33081e-05, gnorm=2.736, clip=0, loss_scale=2048, train_wall=4, gb_free=14.9, wall=6012
2023-03-15 15:39:58 - progress_bar.py[line:272] - INFO: epoch 009:   1654 / 2004 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=338.6, nsentences=8, sample_size=338.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=958.9, ups=2.83, wpb=338.6, bsz=8, num_updates=17570, lr=8.32981e-05, gnorm=2.898, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=6016
2023-03-15 15:40:02 - progress_bar.py[line:272] - INFO: epoch 009:   1664 / 2004 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.513, ntokens=358.4, nsentences=8, sample_size=358.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=1018.8, ups=2.84, wpb=358.4, bsz=8, num_updates=17580, lr=8.3288e-05, gnorm=2.954, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=6019
2023-03-15 15:40:05 - progress_bar.py[line:272] - INFO: epoch 009:   1674 / 2004 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=316.3, nsentences=8, sample_size=316.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=918.3, ups=2.9, wpb=316.3, bsz=8, num_updates=17590, lr=8.32779e-05, gnorm=3.052, clip=0, loss_scale=2048, train_wall=3, gb_free=15.9, wall=6023
2023-03-15 15:40:09 - progress_bar.py[line:272] - INFO: epoch 009:   1684 / 2004 loss=0.492, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=349.4, nsentences=8, sample_size=349.4, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=1010.7, ups=2.89, wpb=349.4, bsz=8, num_updates=17600, lr=8.32678e-05, gnorm=2.87, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=6026
2023-03-15 15:40:12 - progress_bar.py[line:272] - INFO: epoch 009:   1694 / 2004 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.521, ntokens=338.3, nsentences=8, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=973.4, ups=2.88, wpb=338.3, bsz=8, num_updates=17610, lr=8.32577e-05, gnorm=3.033, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=6030
2023-03-15 15:40:16 - progress_bar.py[line:272] - INFO: epoch 009:   1704 / 2004 loss=0.475, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=334.7, nsentences=8, sample_size=334.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=985.5, ups=2.94, wpb=334.7, bsz=8, num_updates=17620, lr=8.32476e-05, gnorm=2.961, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=6033
2023-03-15 15:40:19 - progress_bar.py[line:272] - INFO: epoch 009:   1714 / 2004 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.551, ntokens=364, nsentences=8, sample_size=364, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=1050.6, ups=2.89, wpb=364, bsz=8, num_updates=17630, lr=8.32376e-05, gnorm=3.03, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=6037
2023-03-15 15:40:22 - progress_bar.py[line:272] - INFO: epoch 009:   1724 / 2004 loss=0.492, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=380.9, nsentences=8, sample_size=380.9, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=1118.7, ups=2.94, wpb=380.9, bsz=8, num_updates=17640, lr=8.32275e-05, gnorm=2.879, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=6040
2023-03-15 15:40:26 - progress_bar.py[line:272] - INFO: epoch 009:   1734 / 2004 loss=0.498, loss_v1=0, loss_v2=0, nll_loss=0.498, ntokens=350.8, nsentences=8, sample_size=350.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=982.2, ups=2.8, wpb=350.8, bsz=8, num_updates=17650, lr=8.32174e-05, gnorm=2.951, clip=0, loss_scale=2048, train_wall=4, gb_free=15, wall=6044
2023-03-15 15:40:27 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 15:40:30 - progress_bar.py[line:272] - INFO: epoch 009:   1745 / 2004 loss=0.49, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=342.8, nsentences=8, sample_size=342.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=889.8, ups=2.6, wpb=342.8, bsz=8, num_updates=17660, lr=8.32073e-05, gnorm=2.958, clip=0, loss_scale=1024, train_wall=4, gb_free=15.2, wall=6048
2023-03-15 15:40:33 - progress_bar.py[line:272] - INFO: epoch 009:   1755 / 2004 loss=0.494, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=348.1, nsentences=8, sample_size=348.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=995.6, ups=2.86, wpb=348.1, bsz=8, num_updates=17670, lr=8.31972e-05, gnorm=2.851, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=6051
2023-03-15 15:40:37 - progress_bar.py[line:272] - INFO: epoch 009:   1765 / 2004 loss=0.493, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=308.7, nsentences=8, sample_size=308.7, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=891.4, ups=2.89, wpb=308.7, bsz=8, num_updates=17680, lr=8.31872e-05, gnorm=3.076, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=6054
2023-03-15 15:40:40 - progress_bar.py[line:272] - INFO: epoch 009:   1775 / 2004 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.567, ntokens=349.2, nsentences=8, sample_size=349.2, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=1003.9, ups=2.87, wpb=349.2, bsz=8, num_updates=17690, lr=8.31771e-05, gnorm=3.154, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=6058
2023-03-15 15:40:44 - progress_bar.py[line:272] - INFO: epoch 009:   1785 / 2004 loss=0.478, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=315, nsentences=8, sample_size=315, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=909.5, ups=2.89, wpb=315, bsz=8, num_updates=17700, lr=8.3167e-05, gnorm=3.032, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=6061
2023-03-15 15:40:47 - progress_bar.py[line:272] - INFO: epoch 009:   1795 / 2004 loss=0.478, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=319.8, nsentences=8, sample_size=319.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=938.4, ups=2.93, wpb=319.8, bsz=8, num_updates=17710, lr=8.31569e-05, gnorm=2.834, clip=0, loss_scale=1024, train_wall=3, gb_free=15.7, wall=6065
2023-03-15 15:40:51 - progress_bar.py[line:272] - INFO: epoch 009:   1805 / 2004 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.542, ntokens=353.2, nsentences=8, sample_size=353.2, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=1048.6, ups=2.97, wpb=353.2, bsz=8, num_updates=17720, lr=8.31468e-05, gnorm=3.14, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=6068
2023-03-15 15:40:54 - progress_bar.py[line:272] - INFO: epoch 009:   1815 / 2004 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=359.4, nsentences=8, sample_size=359.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=1040.7, ups=2.9, wpb=359.4, bsz=8, num_updates=17730, lr=8.31368e-05, gnorm=3.077, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=6072
2023-03-15 15:40:58 - progress_bar.py[line:272] - INFO: epoch 009:   1825 / 2004 loss=0.478, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=356.8, nsentences=8, sample_size=356.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=1032.2, ups=2.89, wpb=356.8, bsz=8, num_updates=17740, lr=8.31267e-05, gnorm=2.858, clip=0, loss_scale=1024, train_wall=3, gb_free=13.9, wall=6075
2023-03-15 15:41:01 - progress_bar.py[line:272] - INFO: epoch 009:   1835 / 2004 loss=0.483, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=333.7, nsentences=8, sample_size=333.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=949.5, ups=2.85, wpb=333.7, bsz=8, num_updates=17750, lr=8.31166e-05, gnorm=2.811, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=6079
2023-03-15 15:41:05 - progress_bar.py[line:272] - INFO: epoch 009:   1845 / 2004 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.542, ntokens=354.7, nsentences=8, sample_size=354.7, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=1016, ups=2.86, wpb=354.7, bsz=8, num_updates=17760, lr=8.31065e-05, gnorm=2.966, clip=0, loss_scale=1024, train_wall=3, gb_free=14, wall=6082
2023-03-15 15:41:08 - progress_bar.py[line:272] - INFO: epoch 009:   1855 / 2004 loss=0.454, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=323.3, nsentences=8, sample_size=323.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=914.7, ups=2.83, wpb=323.3, bsz=8, num_updates=17770, lr=8.30964e-05, gnorm=2.85, clip=0, loss_scale=1024, train_wall=3, gb_free=14.2, wall=6086
2023-03-15 15:41:12 - progress_bar.py[line:272] - INFO: epoch 009:   1865 / 2004 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=338.8, nsentences=8, sample_size=338.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=964.8, ups=2.85, wpb=338.8, bsz=8, num_updates=17780, lr=8.30864e-05, gnorm=2.98, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=6089
2023-03-15 15:41:15 - progress_bar.py[line:272] - INFO: epoch 009:   1875 / 2004 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=339.2, nsentences=8, sample_size=339.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=975.9, ups=2.88, wpb=339.2, bsz=8, num_updates=17790, lr=8.30763e-05, gnorm=2.925, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=6093
2023-03-15 15:41:19 - progress_bar.py[line:272] - INFO: epoch 009:   1885 / 2004 loss=0.462, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=323.1, nsentences=8, sample_size=323.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=924.7, ups=2.86, wpb=323.1, bsz=8, num_updates=17800, lr=8.30662e-05, gnorm=2.915, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=6096
2023-03-15 15:41:22 - progress_bar.py[line:272] - INFO: epoch 009:   1895 / 2004 loss=0.465, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=338.2, nsentences=8, sample_size=338.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=1055.4, ups=3.12, wpb=338.2, bsz=8, num_updates=17810, lr=8.30561e-05, gnorm=2.824, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=6099
2023-03-15 15:41:25 - progress_bar.py[line:272] - INFO: epoch 009:   1905 / 2004 loss=0.457, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=352.6, nsentences=8, sample_size=352.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=1112.7, ups=3.16, wpb=352.6, bsz=8, num_updates=17820, lr=8.3046e-05, gnorm=2.874, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=6103
2023-03-15 15:41:28 - progress_bar.py[line:272] - INFO: epoch 009:   1915 / 2004 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=306.6, nsentences=8, sample_size=306.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=993, ups=3.24, wpb=306.6, bsz=8, num_updates=17830, lr=8.30359e-05, gnorm=2.884, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=6106
2023-03-15 15:41:31 - progress_bar.py[line:272] - INFO: epoch 009:   1925 / 2004 loss=0.491, loss_v1=0, loss_v2=0, nll_loss=0.491, ntokens=340.3, nsentences=8, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=1111.8, ups=3.27, wpb=340.3, bsz=8, num_updates=17840, lr=8.30259e-05, gnorm=2.908, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=6109
2023-03-15 15:41:34 - progress_bar.py[line:272] - INFO: epoch 009:   1935 / 2004 loss=0.46, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=327.9, nsentences=8, sample_size=327.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=1054.4, ups=3.22, wpb=327.9, bsz=8, num_updates=17850, lr=8.30158e-05, gnorm=2.878, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=6112
2023-03-15 15:41:37 - progress_bar.py[line:272] - INFO: epoch 009:   1945 / 2004 loss=0.486, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=355.2, nsentences=8, sample_size=355.2, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=1120.7, ups=3.16, wpb=355.2, bsz=8, num_updates=17860, lr=8.30057e-05, gnorm=2.867, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=6115
2023-03-15 15:41:41 - progress_bar.py[line:272] - INFO: epoch 009:   1955 / 2004 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=355, nsentences=8, sample_size=355, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=1083.3, ups=3.05, wpb=355, bsz=8, num_updates=17870, lr=8.29956e-05, gnorm=2.84, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=6118
2023-03-15 15:41:44 - progress_bar.py[line:272] - INFO: epoch 009:   1965 / 2004 loss=0.47, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=349.1, nsentences=8, sample_size=349.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=1065.4, ups=3.05, wpb=349.1, bsz=8, num_updates=17880, lr=8.29855e-05, gnorm=2.949, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=6122
2023-03-15 15:41:47 - progress_bar.py[line:272] - INFO: epoch 009:   1975 / 2004 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=344.5, nsentences=8, sample_size=344.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=986.9, ups=2.86, wpb=344.5, bsz=8, num_updates=17890, lr=8.29755e-05, gnorm=3.032, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=6125
2023-03-15 15:41:51 - progress_bar.py[line:272] - INFO: epoch 009:   1985 / 2004 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=307.7, nsentences=8, sample_size=307.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=878.9, ups=2.86, wpb=307.7, bsz=8, num_updates=17900, lr=8.29654e-05, gnorm=2.759, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=6129
2023-03-15 15:41:54 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 15:41:55 - progress_bar.py[line:272] - INFO: epoch 009:   1996 / 2004 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.541, ntokens=402.9, nsentences=8, sample_size=402.9, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=1054.7, ups=2.62, wpb=402.9, bsz=8, num_updates=17910, lr=8.29553e-05, gnorm=2.972, clip=0, loss_scale=2048, train_wall=4, gb_free=14.6, wall=6132
2023-03-15 15:41:57 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 9 @ 17918 updates
2023-03-15 15:41:57 - trainer.py[line:431] - INFO: Saving checkpoint to ./checkpoints/checkpoint9.pt
2023-03-15 15:42:05 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./checkpoints/checkpoint9.pt
2023-03-15 15:42:07 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./checkpoints/checkpoint9.pt (epoch 9 @ 17918 updates, score None) (writing took 10.046940727159381 seconds)
2023-03-15 15:42:07 - train.py[line:332] - INFO: end of epoch 9 (average epoch stats below)
2023-03-15 15:42:07 - progress_bar.py[line:282] - INFO: epoch 009 | loss 0.53 | loss_v1 0 | loss_v2 0 | nll_loss 0.53 | ntokens 345.292 | nsentences 7.999 | sample_size 345.292 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.44 | wps 982.7 | ups 2.85 | wpb 345.3 | bsz 8 | num_updates 17918 | lr 8.29472e-05 | gnorm 2.897 | clip 0 | loss_scale 2048 | train_wall 675 | gb_free 13.9 | wall 6145
2023-03-15 15:42:07 - trainer.py[line:639] - INFO: loading train data for epoch 10
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 row count 8015 total row count 8015
slice_id 0 seek offset 0
2023-03-15 15:42:08 - trainer.py[line:703] - INFO: begin training epoch 10
2023-03-15 15:42:08 - train.py[line:305] - INFO: Start iterating over samples
2023-03-15 15:42:09 - progress_bar.py[line:272] - INFO: epoch 010:      2 / 2004 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.53, ntokens=367.8, nsentences=8, sample_size=367.8, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=258.8, ups=0.7, wpb=367.8, bsz=8, num_updates=17920, lr=8.29452e-05, gnorm=2.986, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=6147
2023-03-15 15:42:10 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 15:42:13 - progress_bar.py[line:272] - INFO: epoch 010:     13 / 2004 loss=0.491, loss_v1=0, loss_v2=0, nll_loss=0.491, ntokens=321.4, nsentences=8, sample_size=321.4, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=826, ups=2.57, wpb=321.4, bsz=8, num_updates=17930, lr=8.29351e-05, gnorm=3.03, clip=0, loss_scale=1024, train_wall=4, gb_free=15.7, wall=6150
2023-03-15 15:42:16 - progress_bar.py[line:272] - INFO: epoch 010:     23 / 2004 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=357.1, nsentences=8, sample_size=357.1, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=1005.7, ups=2.82, wpb=357.1, bsz=8, num_updates=17940, lr=8.29251e-05, gnorm=2.912, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=6154
2023-03-15 15:42:20 - progress_bar.py[line:272] - INFO: epoch 010:     33 / 2004 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=361.3, nsentences=8, sample_size=361.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=1024.6, ups=2.84, wpb=361.3, bsz=8, num_updates=17950, lr=8.2915e-05, gnorm=3.059, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=6158
2023-03-15 15:42:23 - progress_bar.py[line:272] - INFO: epoch 010:     43 / 2004 loss=0.502, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=353.2, nsentences=8, sample_size=353.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=1008.6, ups=2.86, wpb=353.2, bsz=8, num_updates=17960, lr=8.29049e-05, gnorm=2.89, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=6161
2023-03-15 15:42:27 - progress_bar.py[line:272] - INFO: epoch 010:     53 / 2004 loss=0.482, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=344.3, nsentences=8, sample_size=344.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=1054.1, ups=3.06, wpb=344.3, bsz=8, num_updates=17970, lr=8.28948e-05, gnorm=2.923, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=6164
2023-03-15 15:42:30 - progress_bar.py[line:272] - INFO: epoch 010:     63 / 2004 loss=0.466, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=338.5, nsentences=8, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=1014.9, ups=3, wpb=338.5, bsz=8, num_updates=17980, lr=8.28847e-05, gnorm=2.964, clip=0, loss_scale=1024, train_wall=3, gb_free=13.8, wall=6168
2023-03-15 15:42:34 - progress_bar.py[line:272] - INFO: epoch 010:     73 / 2004 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.537, ntokens=348.7, nsentences=8, sample_size=348.7, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=985.6, ups=2.83, wpb=348.7, bsz=8, num_updates=17990, lr=8.28747e-05, gnorm=2.972, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=6171
2023-03-15 15:42:37 - progress_bar.py[line:272] - INFO: epoch 010:     83 / 2004 loss=0.452, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=328.5, nsentences=8, sample_size=328.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=933.3, ups=2.84, wpb=328.5, bsz=8, num_updates=18000, lr=8.28646e-05, gnorm=2.924, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=6175
2023-03-15 15:42:37 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 10 @ 18000 updates
2023-03-15 15:42:37 - trainer.py[line:431] - INFO: Saving checkpoint to ./checkpoints/checkpoint_10_18000.pt
2023-03-15 15:42:45 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./checkpoints/checkpoint_10_18000.pt
2023-03-15 15:42:48 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./checkpoints/checkpoint_10_18000.pt (epoch 10 @ 18000 updates, score None) (writing took 10.758331220597029 seconds)
2023-03-15 15:42:51 - progress_bar.py[line:272] - INFO: epoch 010:     93 / 2004 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.53, ntokens=369.6, nsentences=8, sample_size=369.6, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=264.9, ups=0.72, wpb=369.6, bsz=8, num_updates=18010, lr=8.28545e-05, gnorm=2.927, clip=0, loss_scale=1024, train_wall=3, gb_free=13.9, wall=6189
2023-03-15 15:42:54 - progress_bar.py[line:272] - INFO: epoch 010:    103 / 2004 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.512, ntokens=367.3, nsentences=8, sample_size=367.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=1132.3, ups=3.08, wpb=367.3, bsz=8, num_updates=18020, lr=8.28444e-05, gnorm=3.048, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=6192
2023-03-15 15:42:57 - progress_bar.py[line:272] - INFO: epoch 010:    113 / 2004 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=339.8, nsentences=8, sample_size=339.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=1093.1, ups=3.22, wpb=339.8, bsz=8, num_updates=18030, lr=8.28343e-05, gnorm=3.037, clip=0, loss_scale=1024, train_wall=3, gb_free=13.7, wall=6195
2023-03-15 15:43:01 - progress_bar.py[line:272] - INFO: epoch 010:    123 / 2004 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.521, ntokens=349.4, nsentences=8, sample_size=349.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=1106.9, ups=3.17, wpb=349.4, bsz=8, num_updates=18040, lr=8.28243e-05, gnorm=2.971, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=6198
2023-03-15 15:43:04 - progress_bar.py[line:272] - INFO: epoch 010:    133 / 2004 loss=0.468, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=299.5, nsentences=7.8, sample_size=299.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=973.1, ups=3.25, wpb=299.5, bsz=7.8, num_updates=18050, lr=8.28142e-05, gnorm=3, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=6201
2023-03-15 15:43:04 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 15:43:07 - progress_bar.py[line:272] - INFO: epoch 010:    144 / 2004 loss=0.49, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=354.3, nsentences=8, sample_size=354.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=1049.3, ups=2.96, wpb=354.3, bsz=8, num_updates=18060, lr=8.28041e-05, gnorm=2.918, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=6205
2023-03-15 15:43:10 - progress_bar.py[line:272] - INFO: epoch 010:    154 / 2004 loss=0.483, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=322.3, nsentences=8, sample_size=322.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=1037.1, ups=3.22, wpb=322.3, bsz=8, num_updates=18070, lr=8.2794e-05, gnorm=2.93, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=6208
2023-03-15 15:43:13 - progress_bar.py[line:272] - INFO: epoch 010:    164 / 2004 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.512, ntokens=363.7, nsentences=8, sample_size=363.7, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=1147.3, ups=3.15, wpb=363.7, bsz=8, num_updates=18080, lr=8.27839e-05, gnorm=2.969, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=6211
2023-03-15 15:43:16 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-03-15 15:43:17 - progress_bar.py[line:272] - INFO: epoch 010:    175 / 2004 loss=0.468, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=339.8, nsentences=8, sample_size=339.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=924.1, ups=2.72, wpb=339.8, bsz=8, num_updates=18090, lr=8.27738e-05, gnorm=2.783, clip=0, loss_scale=512, train_wall=4, gb_free=15, wall=6215
2023-03-15 15:43:20 - progress_bar.py[line:272] - INFO: epoch 010:    185 / 2004 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=336.3, nsentences=8, sample_size=336.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=1078.3, ups=3.21, wpb=336.3, bsz=8, num_updates=18100, lr=8.27638e-05, gnorm=2.926, clip=0, loss_scale=512, train_wall=3, gb_free=14.8, wall=6218
2023-03-15 15:43:23 - progress_bar.py[line:272] - INFO: epoch 010:    195 / 2004 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=324, nsentences=8, sample_size=324, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=1056.5, ups=3.26, wpb=324, bsz=8, num_updates=18110, lr=8.27537e-05, gnorm=2.989, clip=0, loss_scale=512, train_wall=3, gb_free=15.1, wall=6221
2023-03-15 15:43:26 - progress_bar.py[line:272] - INFO: epoch 010:    205 / 2004 loss=0.505, loss_v1=0, loss_v2=0, nll_loss=0.505, ntokens=331, nsentences=8, sample_size=331, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=1083.2, ups=3.27, wpb=331, bsz=8, num_updates=18120, lr=8.27436e-05, gnorm=3.215, clip=0, loss_scale=512, train_wall=3, gb_free=14.8, wall=6224
2023-03-15 15:43:29 - progress_bar.py[line:272] - INFO: epoch 010:    215 / 2004 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=338.7, nsentences=8, sample_size=338.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=1110.2, ups=3.28, wpb=338.7, bsz=8, num_updates=18130, lr=8.27335e-05, gnorm=2.99, clip=0, loss_scale=512, train_wall=3, gb_free=14.8, wall=6227
2023-03-15 15:43:32 - progress_bar.py[line:272] - INFO: epoch 010:    225 / 2004 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=324.6, nsentences=8, sample_size=324.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=993.3, ups=3.06, wpb=324.6, bsz=8, num_updates=18140, lr=8.27234e-05, gnorm=2.843, clip=0, loss_scale=512, train_wall=3, gb_free=15.1, wall=6230
2023-03-15 15:43:36 - progress_bar.py[line:272] - INFO: epoch 010:    235 / 2004 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.52, ntokens=374.5, nsentences=8, sample_size=374.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=1113.2, ups=2.97, wpb=374.5, bsz=8, num_updates=18150, lr=8.27134e-05, gnorm=2.954, clip=0, loss_scale=512, train_wall=3, gb_free=15.4, wall=6233
2023-03-15 15:43:39 - progress_bar.py[line:272] - INFO: epoch 010:    245 / 2004 loss=0.502, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=359, nsentences=8, sample_size=359, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=1138.8, ups=3.17, wpb=359, bsz=8, num_updates=18160, lr=8.27033e-05, gnorm=3.004, clip=0, loss_scale=512, train_wall=3, gb_free=14.2, wall=6237
2023-03-15 15:43:42 - progress_bar.py[line:272] - INFO: epoch 010:    255 / 2004 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=337.7, nsentences=8, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=1069.5, ups=3.17, wpb=337.7, bsz=8, num_updates=18170, lr=8.26932e-05, gnorm=2.979, clip=0, loss_scale=512, train_wall=3, gb_free=14.4, wall=6240
2023-03-15 15:43:45 - progress_bar.py[line:272] - INFO: epoch 010:    265 / 2004 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.549, ntokens=358.8, nsentences=8, sample_size=358.8, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=1139, ups=3.17, wpb=358.8, bsz=8, num_updates=18180, lr=8.26831e-05, gnorm=3.113, clip=0, loss_scale=512, train_wall=3, gb_free=14.7, wall=6243
2023-03-15 15:43:48 - progress_bar.py[line:272] - INFO: epoch 010:    275 / 2004 loss=0.476, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=330, nsentences=8, sample_size=330, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=1042.8, ups=3.16, wpb=330, bsz=8, num_updates=18190, lr=8.2673e-05, gnorm=2.975, clip=0, loss_scale=512, train_wall=3, gb_free=14.5, wall=6246
2023-03-15 15:43:52 - progress_bar.py[line:272] - INFO: epoch 010:    285 / 2004 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=374.5, nsentences=8, sample_size=374.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=1182.5, ups=3.16, wpb=374.5, bsz=8, num_updates=18200, lr=8.2663e-05, gnorm=2.848, clip=0, loss_scale=512, train_wall=3, gb_free=14.9, wall=6249
2023-03-15 15:43:55 - progress_bar.py[line:272] - INFO: epoch 010:    295 / 2004 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.512, ntokens=350.4, nsentences=8, sample_size=350.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=1064.5, ups=3.04, wpb=350.4, bsz=8, num_updates=18210, lr=8.26529e-05, gnorm=2.837, clip=0, loss_scale=512, train_wall=3, gb_free=14.8, wall=6253
2023-03-15 15:43:58 - progress_bar.py[line:272] - INFO: epoch 010:    305 / 2004 loss=0.495, loss_v1=0, loss_v2=0, nll_loss=0.495, ntokens=352.5, nsentences=8, sample_size=352.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=1139.5, ups=3.23, wpb=352.5, bsz=8, num_updates=18220, lr=8.26428e-05, gnorm=2.982, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=6256
2023-03-15 15:44:01 - progress_bar.py[line:272] - INFO: epoch 010:    315 / 2004 loss=0.486, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=354.3, nsentences=8, sample_size=354.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=1125, ups=3.18, wpb=354.3, bsz=8, num_updates=18230, lr=8.26327e-05, gnorm=3.057, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=6259
2023-03-15 15:44:04 - progress_bar.py[line:272] - INFO: epoch 010:    325 / 2004 loss=0.463, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=325.8, nsentences=8, sample_size=325.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=1084.3, ups=3.33, wpb=325.8, bsz=8, num_updates=18240, lr=8.26226e-05, gnorm=2.931, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=6262
2023-03-15 15:44:07 - progress_bar.py[line:272] - INFO: epoch 010:    335 / 2004 loss=0.477, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=323.6, nsentences=8, sample_size=323.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=1045.8, ups=3.23, wpb=323.6, bsz=8, num_updates=18250, lr=8.26126e-05, gnorm=3.103, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=6265
2023-03-15 15:44:11 - progress_bar.py[line:272] - INFO: epoch 010:    345 / 2004 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.572, ntokens=379.6, nsentences=8, sample_size=379.6, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=1176.6, ups=3.1, wpb=379.6, bsz=8, num_updates=18260, lr=8.26025e-05, gnorm=3.211, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=6268
2023-03-15 15:44:14 - progress_bar.py[line:272] - INFO: epoch 010:    355 / 2004 loss=0.483, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=349.4, nsentences=8, sample_size=349.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=1095.4, ups=3.13, wpb=349.4, bsz=8, num_updates=18270, lr=8.25924e-05, gnorm=3.221, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=6271
2023-03-15 15:44:17 - progress_bar.py[line:272] - INFO: epoch 010:    365 / 2004 loss=0.486, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=356.6, nsentences=8, sample_size=356.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=1145.2, ups=3.21, wpb=356.6, bsz=8, num_updates=18280, lr=8.25823e-05, gnorm=3.045, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=6274
2023-03-15 15:44:20 - progress_bar.py[line:272] - INFO: epoch 010:    375 / 2004 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=314.5, nsentences=8, sample_size=314.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=1026.7, ups=3.26, wpb=314.5, bsz=8, num_updates=18290, lr=8.25722e-05, gnorm=2.971, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=6277
2023-03-15 15:44:23 - progress_bar.py[line:272] - INFO: epoch 010:    385 / 2004 loss=0.477, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=324.8, nsentences=8, sample_size=324.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=1052.2, ups=3.24, wpb=324.8, bsz=8, num_updates=18300, lr=8.25621e-05, gnorm=3.089, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=6281
2023-03-15 15:44:26 - progress_bar.py[line:272] - INFO: epoch 010:    395 / 2004 loss=0.475, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=359.4, nsentences=8, sample_size=359.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=1169.4, ups=3.25, wpb=359.4, bsz=8, num_updates=18310, lr=8.25521e-05, gnorm=2.947, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=6284
2023-03-15 15:44:29 - progress_bar.py[line:272] - INFO: epoch 010:    405 / 2004 loss=0.49, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=364.9, nsentences=8, sample_size=364.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=1185.2, ups=3.25, wpb=364.9, bsz=8, num_updates=18320, lr=8.2542e-05, gnorm=3, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=6287
2023-03-15 15:44:32 - progress_bar.py[line:272] - INFO: epoch 010:    415 / 2004 loss=0.476, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=351.2, nsentences=8, sample_size=351.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=1131.4, ups=3.22, wpb=351.2, bsz=8, num_updates=18330, lr=8.25319e-05, gnorm=2.984, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=6290
2023-03-15 15:44:35 - progress_bar.py[line:272] - INFO: epoch 010:    425 / 2004 loss=0.468, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=327.2, nsentences=8, sample_size=327.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=1062.2, ups=3.25, wpb=327.2, bsz=8, num_updates=18340, lr=8.25218e-05, gnorm=3.044, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=6293
2023-03-15 15:44:37 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 15:44:39 - progress_bar.py[line:272] - INFO: epoch 010:    436 / 2004 loss=0.501, loss_v1=0, loss_v2=0, nll_loss=0.501, ntokens=352.5, nsentences=8, sample_size=352.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=1035.5, ups=2.94, wpb=352.5, bsz=8, num_updates=18350, lr=8.25117e-05, gnorm=3.131, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=6296
2023-03-15 15:44:42 - progress_bar.py[line:272] - INFO: epoch 010:    446 / 2004 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.524, ntokens=370.2, nsentences=8, sample_size=370.2, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=1181.6, ups=3.19, wpb=370.2, bsz=8, num_updates=18360, lr=8.25017e-05, gnorm=2.978, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=6299
2023-03-15 15:44:45 - progress_bar.py[line:272] - INFO: epoch 010:    456 / 2004 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.541, ntokens=374.7, nsentences=8, sample_size=374.7, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=1195.4, ups=3.19, wpb=374.7, bsz=8, num_updates=18370, lr=8.24916e-05, gnorm=3.064, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=6303
2023-03-15 15:44:48 - progress_bar.py[line:272] - INFO: epoch 010:    466 / 2004 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.572, ntokens=353.1, nsentences=8, sample_size=353.1, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=1130.7, ups=3.2, wpb=353.1, bsz=8, num_updates=18380, lr=8.24815e-05, gnorm=3.209, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=6306
2023-03-15 15:44:51 - progress_bar.py[line:272] - INFO: epoch 010:    476 / 2004 loss=0.493, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=361.6, nsentences=8, sample_size=361.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=1123.5, ups=3.11, wpb=361.6, bsz=8, num_updates=18390, lr=8.24714e-05, gnorm=2.822, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=6309
2023-03-15 15:44:54 - progress_bar.py[line:272] - INFO: epoch 010:    486 / 2004 loss=0.484, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=374.1, nsentences=8, sample_size=374.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=1231.6, ups=3.29, wpb=374.1, bsz=8, num_updates=18400, lr=8.24613e-05, gnorm=3.04, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=6312
2023-03-15 15:44:57 - progress_bar.py[line:272] - INFO: epoch 010:    496 / 2004 loss=0.486, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=360.7, nsentences=8, sample_size=360.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=1222.9, ups=3.39, wpb=360.7, bsz=8, num_updates=18410, lr=8.24513e-05, gnorm=2.941, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=6315
2023-03-15 15:45:00 - progress_bar.py[line:272] - INFO: epoch 010:    506 / 2004 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.526, ntokens=356.7, nsentences=8, sample_size=356.7, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=1171.2, ups=3.28, wpb=356.7, bsz=8, num_updates=18420, lr=8.24412e-05, gnorm=3.191, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=6318
2023-03-15 15:45:04 - progress_bar.py[line:272] - INFO: epoch 010:    516 / 2004 loss=0.499, loss_v1=0, loss_v2=0, nll_loss=0.499, ntokens=358.1, nsentences=8, sample_size=358.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=1117.5, ups=3.12, wpb=358.1, bsz=8, num_updates=18430, lr=8.24311e-05, gnorm=3.06, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=6321
2023-03-15 15:45:07 - progress_bar.py[line:272] - INFO: epoch 010:    526 / 2004 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.531, ntokens=386.6, nsentences=8, sample_size=386.6, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=1180.4, ups=3.05, wpb=386.6, bsz=8, num_updates=18440, lr=8.2421e-05, gnorm=2.989, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=6324
2023-03-15 15:45:10 - progress_bar.py[line:272] - INFO: epoch 010:    536 / 2004 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.51, ntokens=384.6, nsentences=8, sample_size=384.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=1157.6, ups=3.01, wpb=384.6, bsz=8, num_updates=18450, lr=8.24109e-05, gnorm=2.919, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=6328
2023-03-15 15:45:14 - progress_bar.py[line:272] - INFO: epoch 010:    546 / 2004 loss=0.485, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=363.8, nsentences=8, sample_size=363.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=1046.5, ups=2.88, wpb=363.8, bsz=8, num_updates=18460, lr=8.24009e-05, gnorm=2.94, clip=0, loss_scale=1024, train_wall=3, gb_free=13.9, wall=6331
2023-03-15 15:45:17 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-03-15 15:45:17 - progress_bar.py[line:272] - INFO: epoch 010:    557 / 2004 loss=0.488, loss_v1=0, loss_v2=0, nll_loss=0.488, ntokens=376.8, nsentences=8, sample_size=376.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=1072.6, ups=2.85, wpb=376.8, bsz=8, num_updates=18470, lr=8.23908e-05, gnorm=2.945, clip=0, loss_scale=512, train_wall=3, gb_free=14.9, wall=6335
2023-03-15 15:45:20 - progress_bar.py[line:272] - INFO: epoch 010:    567 / 2004 loss=0.5, loss_v1=0, loss_v2=0, nll_loss=0.5, ntokens=374.8, nsentences=8, sample_size=374.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=1202.8, ups=3.21, wpb=374.8, bsz=8, num_updates=18480, lr=8.23807e-05, gnorm=2.947, clip=0, loss_scale=512, train_wall=3, gb_free=14.7, wall=6338
2023-03-15 15:45:23 - progress_bar.py[line:272] - INFO: epoch 010:    577 / 2004 loss=0.479, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=337.8, nsentences=8, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=1095.5, ups=3.24, wpb=337.8, bsz=8, num_updates=18490, lr=8.23706e-05, gnorm=2.905, clip=0, loss_scale=512, train_wall=3, gb_free=15.3, wall=6341
2023-03-15 15:45:27 - progress_bar.py[line:272] - INFO: epoch 010:    587 / 2004 loss=0.497, loss_v1=0, loss_v2=0, nll_loss=0.497, ntokens=352.1, nsentences=8, sample_size=352.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=1116.5, ups=3.17, wpb=352.1, bsz=8, num_updates=18500, lr=8.23605e-05, gnorm=2.893, clip=0, loss_scale=512, train_wall=3, gb_free=15.1, wall=6344
2023-03-15 15:45:30 - progress_bar.py[line:272] - INFO: epoch 010:    597 / 2004 loss=0.469, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=343.9, nsentences=8, sample_size=343.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=1116, ups=3.24, wpb=343.9, bsz=8, num_updates=18510, lr=8.23505e-05, gnorm=2.945, clip=0, loss_scale=512, train_wall=3, gb_free=15.3, wall=6347
2023-03-15 15:45:33 - progress_bar.py[line:272] - INFO: epoch 010:    607 / 2004 loss=0.495, loss_v1=0, loss_v2=0, nll_loss=0.495, ntokens=355.3, nsentences=8, sample_size=355.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=1101.2, ups=3.1, wpb=355.3, bsz=8, num_updates=18520, lr=8.23404e-05, gnorm=2.945, clip=0, loss_scale=512, train_wall=3, gb_free=13.9, wall=6350
2023-03-15 15:45:36 - progress_bar.py[line:272] - INFO: epoch 010:    617 / 2004 loss=0.435, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=348.8, nsentences=8, sample_size=348.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=1075.7, ups=3.08, wpb=348.8, bsz=8, num_updates=18530, lr=8.23303e-05, gnorm=2.751, clip=0, loss_scale=512, train_wall=3, gb_free=13.4, wall=6354
2023-03-15 15:45:39 - progress_bar.py[line:272] - INFO: epoch 010:    627 / 2004 loss=0.471, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=374.8, nsentences=8, sample_size=374.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=1129.2, ups=3.01, wpb=374.8, bsz=8, num_updates=18540, lr=8.23202e-05, gnorm=2.79, clip=0, loss_scale=512, train_wall=3, gb_free=14.3, wall=6357
2023-03-15 15:45:43 - progress_bar.py[line:272] - INFO: epoch 010:    637 / 2004 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=331.8, nsentences=8, sample_size=331.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=960.7, ups=2.9, wpb=331.8, bsz=8, num_updates=18550, lr=8.23101e-05, gnorm=2.986, clip=0, loss_scale=512, train_wall=3, gb_free=15.5, wall=6360
2023-03-15 15:45:46 - progress_bar.py[line:272] - INFO: epoch 010:    647 / 2004 loss=0.441, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=327.6, nsentences=8, sample_size=327.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=924.5, ups=2.82, wpb=327.6, bsz=8, num_updates=18560, lr=8.23e-05, gnorm=2.933, clip=0, loss_scale=512, train_wall=3, gb_free=14.4, wall=6364
2023-03-15 15:45:50 - progress_bar.py[line:272] - INFO: epoch 010:    657 / 2004 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=355.4, nsentences=8, sample_size=355.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=1033.8, ups=2.91, wpb=355.4, bsz=8, num_updates=18570, lr=8.229e-05, gnorm=3.11, clip=0, loss_scale=512, train_wall=3, gb_free=15.1, wall=6367
2023-03-15 15:45:53 - progress_bar.py[line:272] - INFO: epoch 010:    667 / 2004 loss=0.435, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=301, nsentences=8, sample_size=301, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=883.3, ups=2.93, wpb=301, bsz=8, num_updates=18580, lr=8.22799e-05, gnorm=2.944, clip=0, loss_scale=512, train_wall=3, gb_free=13.9, wall=6371
2023-03-15 15:45:57 - progress_bar.py[line:272] - INFO: epoch 010:    677 / 2004 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=336.4, nsentences=8, sample_size=336.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=961.4, ups=2.86, wpb=336.4, bsz=8, num_updates=18590, lr=8.22698e-05, gnorm=2.819, clip=0, loss_scale=512, train_wall=3, gb_free=14.4, wall=6374
2023-03-15 15:46:00 - progress_bar.py[line:272] - INFO: epoch 010:    687 / 2004 loss=0.458, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=351.4, nsentences=8, sample_size=351.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=1020.1, ups=2.9, wpb=351.4, bsz=8, num_updates=18600, lr=8.22597e-05, gnorm=3.032, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=6378
2023-03-15 15:46:04 - progress_bar.py[line:272] - INFO: epoch 010:    697 / 2004 loss=0.482, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=357.5, nsentences=8, sample_size=357.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=1037.8, ups=2.9, wpb=357.5, bsz=8, num_updates=18610, lr=8.22496e-05, gnorm=3.042, clip=0, loss_scale=1024, train_wall=3, gb_free=14, wall=6381
2023-03-15 15:46:07 - progress_bar.py[line:272] - INFO: epoch 010:    707 / 2004 loss=0.481, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=349.6, nsentences=8, sample_size=349.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=998.1, ups=2.85, wpb=349.6, bsz=8, num_updates=18620, lr=8.22396e-05, gnorm=3.019, clip=0, loss_scale=1024, train_wall=3, gb_free=14.1, wall=6385
2023-03-15 15:46:10 - progress_bar.py[line:272] - INFO: epoch 010:    717 / 2004 loss=0.453, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=310.8, nsentences=8, sample_size=310.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=918.5, ups=2.96, wpb=310.8, bsz=8, num_updates=18630, lr=8.22295e-05, gnorm=3.014, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=6388
2023-03-15 15:46:14 - progress_bar.py[line:272] - INFO: epoch 010:    727 / 2004 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.519, ntokens=369.1, nsentences=8, sample_size=369.1, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=1073, ups=2.91, wpb=369.1, bsz=8, num_updates=18640, lr=8.22194e-05, gnorm=3.177, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=6392
2023-03-15 15:46:17 - progress_bar.py[line:272] - INFO: epoch 010:    737 / 2004 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=344.2, nsentences=8, sample_size=344.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=1006.5, ups=2.92, wpb=344.2, bsz=8, num_updates=18650, lr=8.22093e-05, gnorm=2.892, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=6395
2023-03-15 15:46:21 - progress_bar.py[line:272] - INFO: epoch 010:    747 / 2004 loss=0.491, loss_v1=0, loss_v2=0, nll_loss=0.491, ntokens=352.4, nsentences=8, sample_size=352.4, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=1028.2, ups=2.92, wpb=352.4, bsz=8, num_updates=18660, lr=8.21992e-05, gnorm=3.035, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=6398
2023-03-15 15:46:24 - progress_bar.py[line:272] - INFO: epoch 010:    757 / 2004 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=311.3, nsentences=8, sample_size=311.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=909.6, ups=2.92, wpb=311.3, bsz=8, num_updates=18670, lr=8.21892e-05, gnorm=2.95, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=6402
2023-03-15 15:46:28 - progress_bar.py[line:272] - INFO: epoch 010:    767 / 2004 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.51, ntokens=390.2, nsentences=8, sample_size=390.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=1121.1, ups=2.87, wpb=390.2, bsz=8, num_updates=18680, lr=8.21791e-05, gnorm=2.991, clip=0, loss_scale=1024, train_wall=3, gb_free=14.2, wall=6405
2023-03-15 15:46:31 - progress_bar.py[line:272] - INFO: epoch 010:    777 / 2004 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.529, ntokens=368.2, nsentences=8, sample_size=368.2, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=1044.8, ups=2.84, wpb=368.2, bsz=8, num_updates=18690, lr=8.2169e-05, gnorm=3.063, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=6409
2023-03-15 15:46:35 - progress_bar.py[line:272] - INFO: epoch 010:    787 / 2004 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=338.8, nsentences=8, sample_size=338.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=986.1, ups=2.91, wpb=338.8, bsz=8, num_updates=18700, lr=8.21589e-05, gnorm=2.953, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=6412
2023-03-15 15:46:38 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-03-15 15:46:38 - progress_bar.py[line:272] - INFO: epoch 010:    798 / 2004 loss=0.468, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=326.9, nsentences=8, sample_size=326.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=862.5, ups=2.64, wpb=326.9, bsz=8, num_updates=18710, lr=8.21488e-05, gnorm=3.106, clip=0, loss_scale=512, train_wall=4, gb_free=14.7, wall=6416
2023-03-15 15:46:42 - progress_bar.py[line:272] - INFO: epoch 010:    808 / 2004 loss=0.455, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=340, nsentences=8, sample_size=340, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=997.2, ups=2.93, wpb=340, bsz=8, num_updates=18720, lr=8.21388e-05, gnorm=3.076, clip=0, loss_scale=512, train_wall=3, gb_free=15.4, wall=6419
2023-03-15 15:46:45 - progress_bar.py[line:272] - INFO: epoch 010:    818 / 2004 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=322.2, nsentences=8, sample_size=322.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=1004.4, ups=3.12, wpb=322.2, bsz=8, num_updates=18730, lr=8.21287e-05, gnorm=2.878, clip=0, loss_scale=512, train_wall=3, gb_free=15.7, wall=6423
2023-03-15 15:46:48 - progress_bar.py[line:272] - INFO: epoch 010:    828 / 2004 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=383.7, nsentences=8, sample_size=383.7, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=1206.8, ups=3.15, wpb=383.7, bsz=8, num_updates=18740, lr=8.21186e-05, gnorm=3.163, clip=0, loss_scale=512, train_wall=3, gb_free=14.6, wall=6426
2023-03-15 15:46:51 - progress_bar.py[line:272] - INFO: epoch 010:    838 / 2004 loss=0.453, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=323.7, nsentences=8, sample_size=323.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=1038.9, ups=3.21, wpb=323.7, bsz=8, num_updates=18750, lr=8.21085e-05, gnorm=2.996, clip=0, loss_scale=512, train_wall=3, gb_free=14.5, wall=6429
2023-03-15 15:46:54 - progress_bar.py[line:272] - INFO: epoch 010:    848 / 2004 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=358.4, nsentences=8, sample_size=358.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=1143, ups=3.19, wpb=358.4, bsz=8, num_updates=18760, lr=8.20984e-05, gnorm=2.944, clip=0, loss_scale=512, train_wall=3, gb_free=14.7, wall=6432
2023-03-15 15:46:58 - progress_bar.py[line:272] - INFO: epoch 010:    858 / 2004 loss=0.495, loss_v1=0, loss_v2=0, nll_loss=0.495, ntokens=358, nsentences=8, sample_size=358, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=1130.7, ups=3.16, wpb=358, bsz=8, num_updates=18770, lr=8.20883e-05, gnorm=2.948, clip=0, loss_scale=512, train_wall=3, gb_free=14.7, wall=6435
2023-03-15 15:47:01 - progress_bar.py[line:272] - INFO: epoch 010:    868 / 2004 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=368.4, nsentences=8, sample_size=368.4, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=1173.7, ups=3.19, wpb=368.4, bsz=8, num_updates=18780, lr=8.20783e-05, gnorm=3.175, clip=0, loss_scale=512, train_wall=3, gb_free=14.8, wall=6438
2023-03-15 15:47:04 - progress_bar.py[line:272] - INFO: epoch 010:    878 / 2004 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=327.8, nsentences=8, sample_size=327.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=1076.5, ups=3.28, wpb=327.8, bsz=8, num_updates=18790, lr=8.20682e-05, gnorm=2.81, clip=0, loss_scale=512, train_wall=3, gb_free=15.3, wall=6441
2023-03-15 15:47:07 - progress_bar.py[line:272] - INFO: epoch 010:    888 / 2004 loss=0.463, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=321.3, nsentences=8, sample_size=321.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=1028.7, ups=3.2, wpb=321.3, bsz=8, num_updates=18800, lr=8.20581e-05, gnorm=3.204, clip=0, loss_scale=512, train_wall=3, gb_free=15.3, wall=6445
2023-03-15 15:47:10 - progress_bar.py[line:272] - INFO: epoch 010:    898 / 2004 loss=0.492, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=341.8, nsentences=8, sample_size=341.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=1109.8, ups=3.25, wpb=341.8, bsz=8, num_updates=18810, lr=8.2048e-05, gnorm=3.066, clip=0, loss_scale=512, train_wall=3, gb_free=15, wall=6448
2023-03-15 15:47:13 - progress_bar.py[line:272] - INFO: epoch 010:    908 / 2004 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=363.1, nsentences=8, sample_size=363.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=1163.4, ups=3.2, wpb=363.1, bsz=8, num_updates=18820, lr=8.20379e-05, gnorm=2.773, clip=0, loss_scale=512, train_wall=3, gb_free=14.7, wall=6451
2023-03-15 15:47:16 - progress_bar.py[line:272] - INFO: epoch 010:    918 / 2004 loss=0.489, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=358.3, nsentences=8, sample_size=358.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=1128.3, ups=3.15, wpb=358.3, bsz=8, num_updates=18830, lr=8.20279e-05, gnorm=3.012, clip=0, loss_scale=512, train_wall=3, gb_free=15.1, wall=6454
2023-03-15 15:47:19 - progress_bar.py[line:272] - INFO: epoch 010:    928 / 2004 loss=0.455, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=333, nsentences=8, sample_size=333, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=1082.8, ups=3.25, wpb=333, bsz=8, num_updates=18840, lr=8.20178e-05, gnorm=2.932, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=6457
2023-03-15 15:47:23 - progress_bar.py[line:272] - INFO: epoch 010:    938 / 2004 loss=0.458, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=358.9, nsentences=8, sample_size=358.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=1143.2, ups=3.19, wpb=358.9, bsz=8, num_updates=18850, lr=8.20077e-05, gnorm=3.061, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=6460
2023-03-15 15:47:26 - progress_bar.py[line:272] - INFO: epoch 010:    948 / 2004 loss=0.474, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=355.3, nsentences=8, sample_size=355.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=1121.6, ups=3.16, wpb=355.3, bsz=8, num_updates=18860, lr=8.19976e-05, gnorm=3.157, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=6463
2023-03-15 15:47:29 - progress_bar.py[line:272] - INFO: epoch 010:    958 / 2004 loss=0.483, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=346.5, nsentences=8, sample_size=346.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=1125.3, ups=3.25, wpb=346.5, bsz=8, num_updates=18870, lr=8.19875e-05, gnorm=2.923, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=6466
2023-03-15 15:47:32 - progress_bar.py[line:272] - INFO: epoch 010:    968 / 2004 loss=0.494, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=357.7, nsentences=8, sample_size=357.7, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=1144.9, ups=3.2, wpb=357.7, bsz=8, num_updates=18880, lr=8.19775e-05, gnorm=2.944, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=6470
2023-03-15 15:47:35 - progress_bar.py[line:272] - INFO: epoch 010:    978 / 2004 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=341.3, nsentences=8, sample_size=341.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=1074.1, ups=3.15, wpb=341.3, bsz=8, num_updates=18890, lr=8.19674e-05, gnorm=2.925, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=6473
2023-03-15 15:47:37 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-03-15 15:47:39 - progress_bar.py[line:272] - INFO: epoch 010:    989 / 2004 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=355.5, nsentences=8, sample_size=355.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=951.8, ups=2.68, wpb=355.5, bsz=8, num_updates=18900, lr=8.19573e-05, gnorm=3.224, clip=0, loss_scale=512, train_wall=4, gb_free=14.5, wall=6476
2023-03-15 15:47:42 - progress_bar.py[line:272] - INFO: epoch 010:    999 / 2004 loss=0.465, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=359.1, nsentences=8, sample_size=359.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=1128.8, ups=3.14, wpb=359.1, bsz=8, num_updates=18910, lr=8.19472e-05, gnorm=2.982, clip=0, loss_scale=512, train_wall=3, gb_free=15, wall=6480
2023-03-15 15:47:45 - progress_bar.py[line:272] - INFO: epoch 010:   1009 / 2004 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=298, nsentences=8, sample_size=298, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=958.2, ups=3.22, wpb=298, bsz=8, num_updates=18920, lr=8.19371e-05, gnorm=2.992, clip=0, loss_scale=512, train_wall=3, gb_free=14.7, wall=6483
2023-03-15 15:47:48 - progress_bar.py[line:272] - INFO: epoch 010:   1019 / 2004 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=342.6, nsentences=8, sample_size=342.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=1094.5, ups=3.19, wpb=342.6, bsz=8, num_updates=18930, lr=8.19271e-05, gnorm=2.861, clip=0, loss_scale=512, train_wall=3, gb_free=15.2, wall=6486
2023-03-15 15:47:51 - progress_bar.py[line:272] - INFO: epoch 010:   1029 / 2004 loss=0.454, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=324, nsentences=8, sample_size=324, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=1036.6, ups=3.2, wpb=324, bsz=8, num_updates=18940, lr=8.1917e-05, gnorm=3.01, clip=0, loss_scale=512, train_wall=3, gb_free=14.5, wall=6489
2023-03-15 15:47:54 - progress_bar.py[line:272] - INFO: epoch 010:   1039 / 2004 loss=0.453, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=319.1, nsentences=8, sample_size=319.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=1042.6, ups=3.27, wpb=319.1, bsz=8, num_updates=18950, lr=8.19069e-05, gnorm=3.071, clip=0, loss_scale=512, train_wall=3, gb_free=15, wall=6492
2023-03-15 15:47:58 - progress_bar.py[line:272] - INFO: epoch 010:   1049 / 2004 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.534, ntokens=392.2, nsentences=8, sample_size=392.2, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=1222.2, ups=3.12, wpb=392.2, bsz=8, num_updates=18960, lr=8.18968e-05, gnorm=3.163, clip=0, loss_scale=512, train_wall=3, gb_free=14.7, wall=6495
2023-03-15 15:48:01 - progress_bar.py[line:272] - INFO: epoch 010:   1059 / 2004 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=337.6, nsentences=8, sample_size=337.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=1066, ups=3.16, wpb=337.6, bsz=8, num_updates=18970, lr=8.18867e-05, gnorm=2.879, clip=0, loss_scale=512, train_wall=3, gb_free=15.1, wall=6498
2023-03-15 15:48:04 - progress_bar.py[line:272] - INFO: epoch 010:   1069 / 2004 loss=0.479, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=340.7, nsentences=8, sample_size=340.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=1100.5, ups=3.23, wpb=340.7, bsz=8, num_updates=18980, lr=8.18767e-05, gnorm=3.138, clip=0, loss_scale=512, train_wall=3, gb_free=14.5, wall=6502
2023-03-15 15:48:07 - progress_bar.py[line:272] - INFO: epoch 010:   1079 / 2004 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=361.7, nsentences=8, sample_size=361.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=1147.7, ups=3.17, wpb=361.7, bsz=8, num_updates=18990, lr=8.18666e-05, gnorm=2.983, clip=0, loss_scale=512, train_wall=3, gb_free=14.7, wall=6505
2023-03-15 15:48:10 - progress_bar.py[line:272] - INFO: epoch 010:   1089 / 2004 loss=0.494, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=368.6, nsentences=8, sample_size=368.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=1165.8, ups=3.16, wpb=368.6, bsz=8, num_updates=19000, lr=8.18565e-05, gnorm=3, clip=0, loss_scale=512, train_wall=3, gb_free=14.8, wall=6508
2023-03-15 15:48:13 - progress_bar.py[line:272] - INFO: epoch 010:   1099 / 2004 loss=0.501, loss_v1=0, loss_v2=0, nll_loss=0.501, ntokens=332.7, nsentences=8, sample_size=332.7, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=1057.5, ups=3.18, wpb=332.7, bsz=8, num_updates=19010, lr=8.18464e-05, gnorm=3.125, clip=0, loss_scale=512, train_wall=3, gb_free=14.1, wall=6511
2023-03-15 15:48:17 - progress_bar.py[line:272] - INFO: epoch 010:   1109 / 2004 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.509, ntokens=371.1, nsentences=8, sample_size=371.1, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=1129.5, ups=3.04, wpb=371.1, bsz=8, num_updates=19020, lr=8.18363e-05, gnorm=3.078, clip=0, loss_scale=512, train_wall=3, gb_free=14.8, wall=6514
2023-03-15 15:48:20 - progress_bar.py[line:272] - INFO: epoch 010:   1119 / 2004 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=327.8, nsentences=8, sample_size=327.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=942.5, ups=2.88, wpb=327.8, bsz=8, num_updates=19030, lr=8.18262e-05, gnorm=2.806, clip=0, loss_scale=1024, train_wall=3, gb_free=14.1, wall=6518
2023-03-15 15:48:23 - progress_bar.py[line:272] - INFO: epoch 010:   1129 / 2004 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=343.2, nsentences=8, sample_size=343.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=1025.5, ups=2.99, wpb=343.2, bsz=8, num_updates=19040, lr=8.18162e-05, gnorm=2.943, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=6521
2023-03-15 15:48:27 - progress_bar.py[line:272] - INFO: epoch 010:   1139 / 2004 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=379, nsentences=8, sample_size=379, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=1197, ups=3.16, wpb=379, bsz=8, num_updates=19050, lr=8.18061e-05, gnorm=2.977, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=6524
2023-03-15 15:48:30 - progress_bar.py[line:272] - INFO: epoch 010:   1149 / 2004 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=352.7, nsentences=8, sample_size=352.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=1134.5, ups=3.22, wpb=352.7, bsz=8, num_updates=19060, lr=8.1796e-05, gnorm=2.769, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=6527
2023-03-15 15:48:33 - progress_bar.py[line:272] - INFO: epoch 010:   1159 / 2004 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.515, ntokens=407.1, nsentences=8, sample_size=407.1, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=1277, ups=3.14, wpb=407.1, bsz=8, num_updates=19070, lr=8.17859e-05, gnorm=3.117, clip=0, loss_scale=1024, train_wall=3, gb_free=14.2, wall=6531
2023-03-15 15:48:36 - progress_bar.py[line:272] - INFO: epoch 010:   1169 / 2004 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=320.5, nsentences=8, sample_size=320.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=1020.2, ups=3.18, wpb=320.5, bsz=8, num_updates=19080, lr=8.17758e-05, gnorm=3.044, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=6534
2023-03-15 15:48:39 - progress_bar.py[line:272] - INFO: epoch 010:   1179 / 2004 loss=0.456, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=355.8, nsentences=8, sample_size=355.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=1135.9, ups=3.19, wpb=355.8, bsz=8, num_updates=19090, lr=8.17658e-05, gnorm=2.959, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=6537
2023-03-15 15:48:42 - progress_bar.py[line:272] - INFO: epoch 010:   1189 / 2004 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=339.9, nsentences=8, sample_size=339.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=1097.5, ups=3.23, wpb=339.9, bsz=8, num_updates=19100, lr=8.17557e-05, gnorm=2.948, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=6540
2023-03-15 15:48:45 - progress_bar.py[line:272] - INFO: epoch 010:   1199 / 2004 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=354.4, nsentences=8, sample_size=354.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=1131, ups=3.19, wpb=354.4, bsz=8, num_updates=19110, lr=8.17456e-05, gnorm=2.884, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=6543
2023-03-15 15:48:49 - progress_bar.py[line:272] - INFO: epoch 010:   1209 / 2004 loss=0.44, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=286.6, nsentences=8, sample_size=286.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=913.6, ups=3.19, wpb=286.6, bsz=8, num_updates=19120, lr=8.17355e-05, gnorm=3.059, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=6546
2023-03-15 15:48:52 - progress_bar.py[line:272] - INFO: epoch 010:   1219 / 2004 loss=0.479, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=333.3, nsentences=8, sample_size=333.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=1062.7, ups=3.19, wpb=333.3, bsz=8, num_updates=19130, lr=8.17254e-05, gnorm=3.206, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=6549
2023-03-15 15:48:55 - progress_bar.py[line:272] - INFO: epoch 010:   1229 / 2004 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=307, nsentences=8, sample_size=307, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=977.1, ups=3.18, wpb=307, bsz=8, num_updates=19140, lr=8.17154e-05, gnorm=2.975, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=6552
2023-03-15 15:48:58 - progress_bar.py[line:272] - INFO: epoch 010:   1239 / 2004 loss=0.494, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=382.6, nsentences=8, sample_size=382.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=1198.2, ups=3.13, wpb=382.6, bsz=8, num_updates=19150, lr=8.17053e-05, gnorm=3.028, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=6556
2023-03-15 15:49:01 - progress_bar.py[line:272] - INFO: epoch 010:   1249 / 2004 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=338.6, nsentences=8, sample_size=338.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=1090.8, ups=3.22, wpb=338.6, bsz=8, num_updates=19160, lr=8.16952e-05, gnorm=3.074, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=6559
2023-03-15 15:49:04 - progress_bar.py[line:272] - INFO: epoch 010:   1259 / 2004 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=348.2, nsentences=8, sample_size=348.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=1117.6, ups=3.21, wpb=348.2, bsz=8, num_updates=19170, lr=8.16851e-05, gnorm=3.139, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=6562
2023-03-15 15:49:05 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 15:49:08 - progress_bar.py[line:272] - INFO: epoch 010:   1270 / 2004 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=355.9, nsentences=8, sample_size=355.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=1026.4, ups=2.88, wpb=355.9, bsz=8, num_updates=19180, lr=8.1675e-05, gnorm=2.917, clip=0, loss_scale=1024, train_wall=3, gb_free=13.7, wall=6565
2023-03-15 15:49:11 - progress_bar.py[line:272] - INFO: epoch 010:   1280 / 2004 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=328.2, nsentences=8, sample_size=328.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=1047.1, ups=3.19, wpb=328.2, bsz=8, num_updates=19190, lr=8.1665e-05, gnorm=2.941, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=6569
2023-03-15 15:49:14 - progress_bar.py[line:272] - INFO: epoch 010:   1290 / 2004 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=311.6, nsentences=8, sample_size=311.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=1010.4, ups=3.24, wpb=311.6, bsz=8, num_updates=19200, lr=8.16549e-05, gnorm=2.693, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=6572
2023-03-15 15:49:17 - progress_bar.py[line:272] - INFO: epoch 010:   1300 / 2004 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=302.5, nsentences=8, sample_size=302.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=990.2, ups=3.27, wpb=302.5, bsz=8, num_updates=19210, lr=8.16448e-05, gnorm=3.001, clip=0, loss_scale=1024, train_wall=3, gb_free=15.7, wall=6575
2023-03-15 15:49:20 - progress_bar.py[line:272] - INFO: epoch 010:   1310 / 2004 loss=0.454, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=349.7, nsentences=8, sample_size=349.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=1040, ups=2.97, wpb=349.7, bsz=8, num_updates=19220, lr=8.16347e-05, gnorm=2.956, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=6578
2023-03-15 15:49:22 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-03-15 15:49:24 - progress_bar.py[line:272] - INFO: epoch 010:   1321 / 2004 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=326.7, nsentences=8, sample_size=326.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=878.7, ups=2.69, wpb=326.7, bsz=8, num_updates=19230, lr=8.16246e-05, gnorm=3.031, clip=0, loss_scale=512, train_wall=4, gb_free=15.4, wall=6582
2023-03-15 15:49:28 - progress_bar.py[line:272] - INFO: epoch 010:   1331 / 2004 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=316.8, nsentences=8, sample_size=316.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=892.6, ups=2.82, wpb=316.8, bsz=8, num_updates=19240, lr=8.16145e-05, gnorm=2.955, clip=0, loss_scale=512, train_wall=3, gb_free=14.6, wall=6585
2023-03-15 15:49:31 - progress_bar.py[line:272] - INFO: epoch 010:   1341 / 2004 loss=0.501, loss_v1=0, loss_v2=0, nll_loss=0.501, ntokens=335.9, nsentences=8, sample_size=335.9, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=976.5, ups=2.91, wpb=335.9, bsz=8, num_updates=19250, lr=8.16045e-05, gnorm=3.209, clip=0, loss_scale=512, train_wall=3, gb_free=15.1, wall=6589
2023-03-15 15:49:34 - progress_bar.py[line:272] - INFO: epoch 010:   1351 / 2004 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=317.1, nsentences=8, sample_size=317.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=942.6, ups=2.97, wpb=317.1, bsz=8, num_updates=19260, lr=8.15944e-05, gnorm=2.929, clip=0, loss_scale=512, train_wall=3, gb_free=15.6, wall=6592
2023-03-15 15:49:38 - progress_bar.py[line:272] - INFO: epoch 010:   1361 / 2004 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=308.8, nsentences=8, sample_size=308.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=936.8, ups=3.03, wpb=308.8, bsz=8, num_updates=19270, lr=8.15843e-05, gnorm=3.093, clip=0, loss_scale=512, train_wall=3, gb_free=15.2, wall=6595
2023-03-15 15:49:41 - progress_bar.py[line:272] - INFO: epoch 010:   1371 / 2004 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=317.2, nsentences=8, sample_size=317.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=930.5, ups=2.93, wpb=317.2, bsz=8, num_updates=19280, lr=8.15742e-05, gnorm=3.11, clip=0, loss_scale=512, train_wall=3, gb_free=15.3, wall=6599
2023-03-15 15:49:45 - progress_bar.py[line:272] - INFO: epoch 010:   1381 / 2004 loss=0.476, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=367.9, nsentences=8, sample_size=367.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=1056.3, ups=2.87, wpb=367.9, bsz=8, num_updates=19290, lr=8.15641e-05, gnorm=3.075, clip=0, loss_scale=512, train_wall=3, gb_free=13.9, wall=6602
2023-03-15 15:49:48 - progress_bar.py[line:272] - INFO: epoch 010:   1391 / 2004 loss=0.492, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=372, nsentences=8, sample_size=372, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=1089, ups=2.93, wpb=372, bsz=8, num_updates=19300, lr=8.15541e-05, gnorm=3.027, clip=0, loss_scale=512, train_wall=3, gb_free=14.7, wall=6606
2023-03-15 15:49:51 - progress_bar.py[line:272] - INFO: epoch 010:   1401 / 2004 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=334.7, nsentences=8, sample_size=334.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=987.6, ups=2.95, wpb=334.7, bsz=8, num_updates=19310, lr=8.1544e-05, gnorm=2.753, clip=0, loss_scale=512, train_wall=3, gb_free=15.4, wall=6609
2023-03-15 15:49:55 - progress_bar.py[line:272] - INFO: epoch 010:   1411 / 2004 loss=0.5, loss_v1=0, loss_v2=0, nll_loss=0.5, ntokens=376.8, nsentences=8, sample_size=376.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=1090.6, ups=2.89, wpb=376.8, bsz=8, num_updates=19320, lr=8.15339e-05, gnorm=3.181, clip=0, loss_scale=512, train_wall=3, gb_free=14.3, wall=6613
2023-03-15 15:49:58 - progress_bar.py[line:272] - INFO: epoch 010:   1421 / 2004 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=342.3, nsentences=8, sample_size=342.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=995.3, ups=2.91, wpb=342.3, bsz=8, num_updates=19330, lr=8.15238e-05, gnorm=2.94, clip=0, loss_scale=512, train_wall=3, gb_free=14.7, wall=6616
2023-03-15 15:50:02 - progress_bar.py[line:272] - INFO: epoch 010:   1431 / 2004 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=323.8, nsentences=8, sample_size=323.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=938.6, ups=2.9, wpb=323.8, bsz=8, num_updates=19340, lr=8.15137e-05, gnorm=2.902, clip=0, loss_scale=512, train_wall=3, gb_free=15.3, wall=6619
2023-03-15 15:50:05 - progress_bar.py[line:272] - INFO: epoch 010:   1441 / 2004 loss=0.485, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=354.6, nsentences=8, sample_size=354.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=1047.9, ups=2.96, wpb=354.6, bsz=8, num_updates=19350, lr=8.15037e-05, gnorm=3.193, clip=0, loss_scale=512, train_wall=3, gb_free=14.7, wall=6623
2023-03-15 15:50:09 - progress_bar.py[line:272] - INFO: epoch 010:   1451 / 2004 loss=0.463, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=325.6, nsentences=8, sample_size=325.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=967.6, ups=2.97, wpb=325.6, bsz=8, num_updates=19360, lr=8.14936e-05, gnorm=3.066, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=6626
2023-03-15 15:50:12 - progress_bar.py[line:272] - INFO: epoch 010:   1461 / 2004 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.511, ntokens=381.5, nsentences=8, sample_size=381.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=1106.9, ups=2.9, wpb=381.5, bsz=8, num_updates=19370, lr=8.14835e-05, gnorm=3.119, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=6630
2023-03-15 15:50:15 - progress_bar.py[line:272] - INFO: epoch 010:   1471 / 2004 loss=0.452, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=390.4, nsentences=8, sample_size=390.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=1205.8, ups=3.09, wpb=390.4, bsz=8, num_updates=19380, lr=8.14734e-05, gnorm=2.857, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=6633
2023-03-15 15:50:18 - progress_bar.py[line:272] - INFO: epoch 010:   1481 / 2004 loss=0.489, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=397.4, nsentences=8, sample_size=397.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=1267.7, ups=3.19, wpb=397.4, bsz=8, num_updates=19390, lr=8.14633e-05, gnorm=3.062, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=6636
2023-03-15 15:50:22 - progress_bar.py[line:272] - INFO: epoch 010:   1491 / 2004 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=310.2, nsentences=8, sample_size=310.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=995, ups=3.21, wpb=310.2, bsz=8, num_updates=19400, lr=8.14533e-05, gnorm=3.073, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=6639
2023-03-15 15:50:25 - progress_bar.py[line:272] - INFO: epoch 010:   1501 / 2004 loss=0.498, loss_v1=0, loss_v2=0, nll_loss=0.498, ntokens=350.3, nsentences=8, sample_size=350.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=1058.4, ups=3.02, wpb=350.3, bsz=8, num_updates=19410, lr=8.14432e-05, gnorm=3.048, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=6642
2023-03-15 15:50:28 - progress_bar.py[line:272] - INFO: epoch 010:   1511 / 2004 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=330.1, nsentences=8, sample_size=330.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=959.3, ups=2.91, wpb=330.1, bsz=8, num_updates=19420, lr=8.14331e-05, gnorm=2.939, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=6646
2023-03-15 15:50:31 - progress_bar.py[line:272] - INFO: epoch 010:   1521 / 2004 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=332.1, nsentences=8, sample_size=332.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=1081.1, ups=3.26, wpb=332.1, bsz=8, num_updates=19430, lr=8.1423e-05, gnorm=3.088, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=6649
2023-03-15 15:50:34 - progress_bar.py[line:272] - INFO: epoch 010:   1531 / 2004 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=343.2, nsentences=8, sample_size=343.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=1083.9, ups=3.16, wpb=343.2, bsz=8, num_updates=19440, lr=8.14129e-05, gnorm=2.988, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=6652
2023-03-15 15:50:38 - progress_bar.py[line:272] - INFO: epoch 010:   1541 / 2004 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=316.3, nsentences=8, sample_size=316.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=1032.4, ups=3.26, wpb=316.3, bsz=8, num_updates=19450, lr=8.14029e-05, gnorm=3.204, clip=0, loss_scale=1024, train_wall=3, gb_free=15.7, wall=6655
2023-03-15 15:50:41 - progress_bar.py[line:272] - INFO: epoch 010:   1551 / 2004 loss=0.467, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=338.2, nsentences=8, sample_size=338.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=1067.6, ups=3.16, wpb=338.2, bsz=8, num_updates=19460, lr=8.13928e-05, gnorm=3.073, clip=0, loss_scale=1024, train_wall=3, gb_free=13.9, wall=6658
2023-03-15 15:50:44 - progress_bar.py[line:272] - INFO: epoch 010:   1561 / 2004 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=350.8, nsentences=8, sample_size=350.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=1101.9, ups=3.14, wpb=350.8, bsz=8, num_updates=19470, lr=8.13827e-05, gnorm=2.929, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=6662
2023-03-15 15:50:47 - progress_bar.py[line:272] - INFO: epoch 010:   1571 / 2004 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=319.7, nsentences=8, sample_size=319.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=968.3, ups=3.03, wpb=319.7, bsz=8, num_updates=19480, lr=8.13726e-05, gnorm=3.07, clip=0, loss_scale=2048, train_wall=3, gb_free=15.9, wall=6665
2023-03-15 15:50:50 - progress_bar.py[line:272] - INFO: epoch 010:   1581 / 2004 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=361, nsentences=8, sample_size=361, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=1150.4, ups=3.19, wpb=361, bsz=8, num_updates=19490, lr=8.13625e-05, gnorm=2.871, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=6668
2023-03-15 15:50:53 - progress_bar.py[line:272] - INFO: epoch 010:   1591 / 2004 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=331.4, nsentences=8, sample_size=331.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=1086.8, ups=3.28, wpb=331.4, bsz=8, num_updates=19500, lr=8.13524e-05, gnorm=2.889, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=6671
2023-03-15 15:50:56 - progress_bar.py[line:272] - INFO: epoch 010:   1601 / 2004 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=345.8, nsentences=8, sample_size=345.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=1135.2, ups=3.28, wpb=345.8, bsz=8, num_updates=19510, lr=8.13424e-05, gnorm=2.992, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=6674
2023-03-15 15:51:00 - progress_bar.py[line:272] - INFO: epoch 010:   1611 / 2004 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=358.2, nsentences=8, sample_size=358.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=1084.2, ups=3.03, wpb=358.2, bsz=8, num_updates=19520, lr=8.13323e-05, gnorm=2.917, clip=0, loss_scale=2048, train_wall=3, gb_free=13.9, wall=6677
2023-03-15 15:51:02 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 15:51:03 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-03-15 15:51:04 - progress_bar.py[line:272] - INFO: epoch 010:   1623 / 2004 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=331.6, nsentences=8, sample_size=331.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=837.6, ups=2.53, wpb=331.6, bsz=8, num_updates=19530, lr=8.13222e-05, gnorm=3.047, clip=0, loss_scale=512, train_wall=4, gb_free=14.9, wall=6681
2023-03-15 15:51:04 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-03-15 15:51:07 - progress_bar.py[line:272] - INFO: epoch 010:   1634 / 2004 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=338.9, nsentences=8, sample_size=338.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=998.2, ups=2.95, wpb=338.9, bsz=8, num_updates=19540, lr=8.13121e-05, gnorm=3.009, clip=0, loss_scale=256, train_wall=3, gb_free=14.8, wall=6685
2023-03-15 15:51:10 - progress_bar.py[line:272] - INFO: epoch 010:   1644 / 2004 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=309.4, nsentences=8, sample_size=309.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=1014.9, ups=3.28, wpb=309.4, bsz=8, num_updates=19550, lr=8.1302e-05, gnorm=2.977, clip=0, loss_scale=256, train_wall=3, gb_free=15.1, wall=6688
2023-03-15 15:51:13 - progress_bar.py[line:272] - INFO: epoch 010:   1654 / 2004 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=338.6, nsentences=8, sample_size=338.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=1079.6, ups=3.19, wpb=338.6, bsz=8, num_updates=19560, lr=8.1292e-05, gnorm=3.019, clip=0, loss_scale=256, train_wall=3, gb_free=15, wall=6691
2023-03-15 15:51:16 - progress_bar.py[line:272] - INFO: epoch 010:   1664 / 2004 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=358.4, nsentences=8, sample_size=358.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=1169.8, ups=3.26, wpb=358.4, bsz=8, num_updates=19570, lr=8.12819e-05, gnorm=2.909, clip=0, loss_scale=256, train_wall=3, gb_free=14.4, wall=6694
2023-03-15 15:51:19 - progress_bar.py[line:272] - INFO: epoch 010:   1674 / 2004 loss=0.441, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=316.3, nsentences=8, sample_size=316.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=1042.7, ups=3.3, wpb=316.3, bsz=8, num_updates=19580, lr=8.12718e-05, gnorm=3.163, clip=0, loss_scale=256, train_wall=3, gb_free=15.9, wall=6697
2023-03-15 15:51:23 - progress_bar.py[line:272] - INFO: epoch 010:   1684 / 2004 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=349.4, nsentences=8, sample_size=349.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=1118.1, ups=3.2, wpb=349.4, bsz=8, num_updates=19590, lr=8.12617e-05, gnorm=2.931, clip=0, loss_scale=256, train_wall=3, gb_free=14.8, wall=6700
2023-03-15 15:51:26 - progress_bar.py[line:272] - INFO: epoch 010:   1694 / 2004 loss=0.462, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=338.3, nsentences=8, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=1087, ups=3.21, wpb=338.3, bsz=8, num_updates=19600, lr=8.12516e-05, gnorm=3.154, clip=0, loss_scale=256, train_wall=3, gb_free=14.5, wall=6703
2023-03-15 15:51:29 - progress_bar.py[line:272] - INFO: epoch 010:   1704 / 2004 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=334.7, nsentences=8, sample_size=334.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=1101.3, ups=3.29, wpb=334.7, bsz=8, num_updates=19610, lr=8.12416e-05, gnorm=2.841, clip=0, loss_scale=256, train_wall=3, gb_free=14.3, wall=6706
2023-03-15 15:51:32 - progress_bar.py[line:272] - INFO: epoch 010:   1714 / 2004 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.522, ntokens=364, nsentences=8, sample_size=364, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=1106.9, ups=3.04, wpb=364, bsz=8, num_updates=19620, lr=8.12315e-05, gnorm=3.391, clip=0, loss_scale=256, train_wall=3, gb_free=14.2, wall=6710
2023-03-15 15:51:35 - progress_bar.py[line:272] - INFO: epoch 010:   1724 / 2004 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=380.9, nsentences=8, sample_size=380.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=1131.3, ups=2.97, wpb=380.9, bsz=8, num_updates=19630, lr=8.12214e-05, gnorm=2.888, clip=0, loss_scale=256, train_wall=3, gb_free=14.5, wall=6713
2023-03-15 15:51:38 - progress_bar.py[line:272] - INFO: epoch 010:   1734 / 2004 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=350.8, nsentences=8, sample_size=350.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=1137.8, ups=3.24, wpb=350.8, bsz=8, num_updates=19640, lr=8.12113e-05, gnorm=3.057, clip=0, loss_scale=256, train_wall=3, gb_free=14.9, wall=6716
2023-03-15 15:51:42 - progress_bar.py[line:272] - INFO: epoch 010:   1744 / 2004 loss=0.475, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=346.2, nsentences=8, sample_size=346.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=1117.1, ups=3.23, wpb=346.2, bsz=8, num_updates=19650, lr=8.12012e-05, gnorm=3.235, clip=0, loss_scale=256, train_wall=3, gb_free=14.9, wall=6719
2023-03-15 15:51:45 - progress_bar.py[line:272] - INFO: epoch 010:   1754 / 2004 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=347.7, nsentences=8, sample_size=347.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=1121.4, ups=3.23, wpb=347.7, bsz=8, num_updates=19660, lr=8.11912e-05, gnorm=3.003, clip=0, loss_scale=512, train_wall=3, gb_free=14.8, wall=6722
2023-03-15 15:51:48 - progress_bar.py[line:272] - INFO: epoch 010:   1764 / 2004 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=303.9, nsentences=8, sample_size=303.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=989.6, ups=3.26, wpb=303.9, bsz=8, num_updates=19670, lr=8.11811e-05, gnorm=2.957, clip=0, loss_scale=512, train_wall=3, gb_free=15.1, wall=6725
2023-03-15 15:51:51 - progress_bar.py[line:272] - INFO: epoch 010:   1774 / 2004 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=346.8, nsentences=8, sample_size=346.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=1111.5, ups=3.2, wpb=346.8, bsz=8, num_updates=19680, lr=8.1171e-05, gnorm=3.06, clip=0, loss_scale=512, train_wall=3, gb_free=14.5, wall=6728
2023-03-15 15:51:54 - progress_bar.py[line:272] - INFO: epoch 010:   1784 / 2004 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=323.6, nsentences=8, sample_size=323.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=972.4, ups=3.01, wpb=323.6, bsz=8, num_updates=19690, lr=8.11609e-05, gnorm=2.901, clip=0, loss_scale=512, train_wall=3, gb_free=14.8, wall=6732
2023-03-15 15:51:57 - progress_bar.py[line:272] - INFO: epoch 010:   1794 / 2004 loss=0.438, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=324.6, nsentences=8, sample_size=324.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=985.2, ups=3.04, wpb=324.6, bsz=8, num_updates=19700, lr=8.11508e-05, gnorm=2.992, clip=0, loss_scale=512, train_wall=3, gb_free=15, wall=6735
2023-03-15 15:52:01 - progress_bar.py[line:272] - INFO: epoch 010:   1804 / 2004 loss=0.449, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=335.3, nsentences=8, sample_size=335.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=1088.9, ups=3.25, wpb=335.3, bsz=8, num_updates=19710, lr=8.11407e-05, gnorm=3.098, clip=0, loss_scale=512, train_wall=3, gb_free=15.4, wall=6738
2023-03-15 15:52:04 - progress_bar.py[line:272] - INFO: epoch 010:   1814 / 2004 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=364.4, nsentences=8, sample_size=364.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=1181.9, ups=3.24, wpb=364.4, bsz=8, num_updates=19720, lr=8.11307e-05, gnorm=3.006, clip=0, loss_scale=512, train_wall=3, gb_free=15.4, wall=6741
2023-03-15 15:52:07 - progress_bar.py[line:272] - INFO: epoch 010:   1824 / 2004 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=357.5, nsentences=8, sample_size=357.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=1181.9, ups=3.31, wpb=357.5, bsz=8, num_updates=19730, lr=8.11206e-05, gnorm=2.726, clip=0, loss_scale=512, train_wall=3, gb_free=14.4, wall=6744
2023-03-15 15:52:10 - progress_bar.py[line:272] - INFO: epoch 010:   1834 / 2004 loss=0.461, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=345.3, nsentences=8, sample_size=345.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=1088.5, ups=3.15, wpb=345.3, bsz=8, num_updates=19740, lr=8.11105e-05, gnorm=3.095, clip=0, loss_scale=512, train_wall=3, gb_free=14.8, wall=6747
2023-03-15 15:52:13 - progress_bar.py[line:272] - INFO: epoch 010:   1844 / 2004 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=333.3, nsentences=8, sample_size=333.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=1084.7, ups=3.25, wpb=333.3, bsz=8, num_updates=19750, lr=8.11004e-05, gnorm=2.994, clip=0, loss_scale=512, train_wall=3, gb_free=15, wall=6750
2023-03-15 15:52:16 - progress_bar.py[line:272] - INFO: epoch 010:   1854 / 2004 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=331.8, nsentences=8, sample_size=331.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=1117.2, ups=3.37, wpb=331.8, bsz=8, num_updates=19760, lr=8.10903e-05, gnorm=2.81, clip=0, loss_scale=512, train_wall=3, gb_free=15.6, wall=6753
2023-03-15 15:52:19 - progress_bar.py[line:272] - INFO: epoch 010:   1864 / 2004 loss=0.441, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=347.7, nsentences=8, sample_size=347.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=1126.8, ups=3.24, wpb=347.7, bsz=8, num_updates=19770, lr=8.10803e-05, gnorm=2.866, clip=0, loss_scale=512, train_wall=3, gb_free=15, wall=6757
2023-03-15 15:52:20 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-03-15 15:52:22 - progress_bar.py[line:272] - INFO: epoch 010:   1875 / 2004 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=330.7, nsentences=8, sample_size=330.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=991.9, ups=3, wpb=330.7, bsz=8, num_updates=19780, lr=8.10702e-05, gnorm=2.967, clip=0, loss_scale=256, train_wall=3, gb_free=14.7, wall=6760
2023-03-15 15:52:25 - progress_bar.py[line:272] - INFO: epoch 010:   1885 / 2004 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=323.1, nsentences=8, sample_size=323.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=1029.7, ups=3.19, wpb=323.1, bsz=8, num_updates=19790, lr=8.10601e-05, gnorm=2.938, clip=0, loss_scale=256, train_wall=3, gb_free=15.2, wall=6763
2023-03-15 15:52:29 - progress_bar.py[line:272] - INFO: epoch 010:   1895 / 2004 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=338.2, nsentences=8, sample_size=338.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=1071.4, ups=3.17, wpb=338.2, bsz=8, num_updates=19800, lr=8.105e-05, gnorm=2.947, clip=0, loss_scale=256, train_wall=3, gb_free=15.2, wall=6766
2023-03-15 15:52:32 - progress_bar.py[line:272] - INFO: epoch 010:   1905 / 2004 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=352.6, nsentences=8, sample_size=352.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=1116.7, ups=3.17, wpb=352.6, bsz=8, num_updates=19810, lr=8.10399e-05, gnorm=2.873, clip=0, loss_scale=256, train_wall=3, gb_free=14.8, wall=6769
2023-03-15 15:52:35 - progress_bar.py[line:272] - INFO: epoch 010:   1915 / 2004 loss=0.388, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=306.6, nsentences=8, sample_size=306.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=998.6, ups=3.26, wpb=306.6, bsz=8, num_updates=19820, lr=8.10299e-05, gnorm=2.809, clip=0, loss_scale=256, train_wall=3, gb_free=14.7, wall=6772
2023-03-15 15:52:38 - progress_bar.py[line:272] - INFO: epoch 010:   1925 / 2004 loss=0.409, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=340.3, nsentences=8, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=1120.2, ups=3.29, wpb=340.3, bsz=8, num_updates=19830, lr=8.10198e-05, gnorm=2.861, clip=0, loss_scale=256, train_wall=3, gb_free=14.9, wall=6775
2023-03-15 15:52:41 - progress_bar.py[line:272] - INFO: epoch 010:   1935 / 2004 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=327.9, nsentences=8, sample_size=327.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=1067.7, ups=3.26, wpb=327.9, bsz=8, num_updates=19840, lr=8.10097e-05, gnorm=2.98, clip=0, loss_scale=256, train_wall=3, gb_free=14.3, wall=6778
2023-03-15 15:52:44 - progress_bar.py[line:272] - INFO: epoch 010:   1945 / 2004 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=355.2, nsentences=8, sample_size=355.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=1152.6, ups=3.24, wpb=355.2, bsz=8, num_updates=19850, lr=8.09996e-05, gnorm=2.903, clip=0, loss_scale=256, train_wall=3, gb_free=14.6, wall=6782
2023-03-15 15:52:47 - progress_bar.py[line:272] - INFO: epoch 010:   1955 / 2004 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=355, nsentences=8, sample_size=355, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=1091, ups=3.07, wpb=355, bsz=8, num_updates=19860, lr=8.09895e-05, gnorm=2.905, clip=0, loss_scale=256, train_wall=3, gb_free=14.3, wall=6785
2023-03-15 15:52:51 - progress_bar.py[line:272] - INFO: epoch 010:   1965 / 2004 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=349.1, nsentences=8, sample_size=349.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=1055.8, ups=3.02, wpb=349.1, bsz=8, num_updates=19870, lr=8.09795e-05, gnorm=3.01, clip=0, loss_scale=256, train_wall=3, gb_free=14.6, wall=6788
2023-03-15 15:52:54 - progress_bar.py[line:272] - INFO: epoch 010:   1975 / 2004 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=344.5, nsentences=8, sample_size=344.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=1083, ups=3.14, wpb=344.5, bsz=8, num_updates=19880, lr=8.09694e-05, gnorm=3.023, clip=0, loss_scale=256, train_wall=3, gb_free=14.6, wall=6791
2023-03-15 15:52:57 - progress_bar.py[line:272] - INFO: epoch 010:   1985 / 2004 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=307.7, nsentences=8, sample_size=307.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=921.4, ups=2.99, wpb=307.7, bsz=8, num_updates=19890, lr=8.09593e-05, gnorm=2.797, clip=0, loss_scale=256, train_wall=3, gb_free=15.5, wall=6795
2023-03-15 15:53:00 - progress_bar.py[line:272] - INFO: epoch 010:   1995 / 2004 loss=0.508, loss_v1=0, loss_v2=0, nll_loss=0.508, ntokens=396.1, nsentences=8, sample_size=396.1, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=1263.2, ups=3.19, wpb=396.1, bsz=8, num_updates=19900, lr=8.09492e-05, gnorm=3.162, clip=0, loss_scale=512, train_wall=3, gb_free=14.3, wall=6798
2023-03-15 15:53:03 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 10 @ 19909 updates
2023-03-15 15:53:03 - trainer.py[line:431] - INFO: Saving checkpoint to ./checkpoints/checkpoint10.pt
2023-03-15 15:53:09 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./checkpoints/checkpoint10.pt
2023-03-15 15:53:12 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./checkpoints/checkpoint10.pt (epoch 10 @ 19909 updates, score None) (writing took 9.07592598721385 seconds)
2023-03-15 15:53:12 - train.py[line:332] - INFO: end of epoch 10 (average epoch stats below)
2023-03-15 15:53:12 - progress_bar.py[line:282] - INFO: epoch 010 | loss 0.464 | loss_v1 0 | loss_v2 0 | nll_loss 0.464 | ntokens 345.495 | nsentences 7.999 | sample_size 345.495 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.38 | wps 1035.2 | ups 3 | wpb 345.5 | bsz 8 | num_updates 19909 | lr 8.09401e-05 | gnorm 2.994 | clip 0 | loss_scale 512 | train_wall 633 | gb_free 13.9 | wall 6810
2023-03-15 15:53:12 - trainer.py[line:639] - INFO: loading train data for epoch 11
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 row count 8015 total row count 8015
slice_id 0 seek offset 0
2023-03-15 15:53:13 - trainer.py[line:703] - INFO: begin training epoch 11
2023-03-15 15:53:13 - train.py[line:305] - INFO: Start iterating over samples
2023-03-15 15:53:13 - progress_bar.py[line:272] - INFO: epoch 011:      1 / 2004 loss=0.468, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=378.7, nsentences=8, sample_size=378.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=293.1, ups=0.77, wpb=378.7, bsz=8, num_updates=19910, lr=8.09391e-05, gnorm=3.04, clip=0, loss_scale=512, train_wall=3, gb_free=15, wall=6811
2023-03-15 15:53:16 - progress_bar.py[line:272] - INFO: epoch 011:     11 / 2004 loss=0.457, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=347, nsentences=8, sample_size=347, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=1072.6, ups=3.09, wpb=347, bsz=8, num_updates=19920, lr=8.09291e-05, gnorm=3.079, clip=0, loss_scale=512, train_wall=3, gb_free=16, wall=6814
2023-03-15 15:53:20 - progress_bar.py[line:272] - INFO: epoch 011:     21 / 2004 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=347.2, nsentences=8, sample_size=347.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=1066.1, ups=3.07, wpb=347.2, bsz=8, num_updates=19930, lr=8.0919e-05, gnorm=2.998, clip=0, loss_scale=512, train_wall=3, gb_free=14.8, wall=6817
2023-03-15 15:53:23 - progress_bar.py[line:272] - INFO: epoch 011:     31 / 2004 loss=0.439, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=342, nsentences=8, sample_size=342, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=1024.4, ups=3, wpb=342, bsz=8, num_updates=19940, lr=8.09089e-05, gnorm=3.012, clip=0, loss_scale=512, train_wall=3, gb_free=15.2, wall=6821
2023-03-15 15:53:27 - progress_bar.py[line:272] - INFO: epoch 011:     41 / 2004 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=348.6, nsentences=8, sample_size=348.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=795, ups=2.28, wpb=348.6, bsz=8, num_updates=19950, lr=8.08988e-05, gnorm=2.876, clip=0, loss_scale=512, train_wall=4, gb_free=15.5, wall=6825
2023-03-15 15:53:31 - progress_bar.py[line:272] - INFO: epoch 011:     51 / 2004 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=360.5, nsentences=8, sample_size=360.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=1031.5, ups=2.86, wpb=360.5, bsz=8, num_updates=19960, lr=8.08887e-05, gnorm=3.068, clip=0, loss_scale=512, train_wall=3, gb_free=13.1, wall=6828
2023-03-15 15:53:34 - progress_bar.py[line:272] - INFO: epoch 011:     61 / 2004 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=332.3, nsentences=8, sample_size=332.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=989, ups=2.98, wpb=332.3, bsz=8, num_updates=19970, lr=8.08786e-05, gnorm=2.954, clip=0, loss_scale=512, train_wall=3, gb_free=15.2, wall=6832
2023-03-15 15:53:37 - progress_bar.py[line:272] - INFO: epoch 011:     71 / 2004 loss=0.467, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=340.5, nsentences=8, sample_size=340.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=1043.6, ups=3.06, wpb=340.5, bsz=8, num_updates=19980, lr=8.08686e-05, gnorm=3.087, clip=0, loss_scale=512, train_wall=3, gb_free=14.8, wall=6835
2023-03-15 15:53:41 - progress_bar.py[line:272] - INFO: epoch 011:     81 / 2004 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=340, nsentences=8, sample_size=340, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=1076.9, ups=3.17, wpb=340, bsz=8, num_updates=19990, lr=8.08585e-05, gnorm=2.93, clip=0, loss_scale=512, train_wall=3, gb_free=14.1, wall=6838
2023-03-15 15:53:44 - progress_bar.py[line:272] - INFO: epoch 011:     91 / 2004 loss=0.409, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=354.9, nsentences=8, sample_size=354.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=1143.7, ups=3.22, wpb=354.9, bsz=8, num_updates=20000, lr=8.08484e-05, gnorm=2.965, clip=0, loss_scale=512, train_wall=3, gb_free=15, wall=6841
2023-03-15 15:53:47 - progress_bar.py[line:272] - INFO: epoch 011:    101 / 2004 loss=0.5, loss_v1=0, loss_v2=0, nll_loss=0.5, ntokens=381.7, nsentences=8, sample_size=381.7, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=1206.9, ups=3.16, wpb=381.7, bsz=8, num_updates=20010, lr=8.08383e-05, gnorm=3.289, clip=0, loss_scale=512, train_wall=3, gb_free=15.4, wall=6844
2023-03-15 15:53:50 - progress_bar.py[line:272] - INFO: epoch 011:    111 / 2004 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=330.7, nsentences=8, sample_size=330.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=1054, ups=3.19, wpb=330.7, bsz=8, num_updates=20020, lr=8.08282e-05, gnorm=2.885, clip=0, loss_scale=512, train_wall=3, gb_free=15.6, wall=6848
2023-03-15 15:53:53 - progress_bar.py[line:272] - INFO: epoch 011:    121 / 2004 loss=0.452, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=364.2, nsentences=8, sample_size=364.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=1144.3, ups=3.14, wpb=364.2, bsz=8, num_updates=20030, lr=8.08182e-05, gnorm=2.94, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=6851
2023-03-15 15:53:56 - progress_bar.py[line:272] - INFO: epoch 011:    131 / 2004 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=307.2, nsentences=8, sample_size=307.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=996.6, ups=3.24, wpb=307.2, bsz=8, num_updates=20040, lr=8.08081e-05, gnorm=2.912, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=6854
2023-03-15 15:53:59 - progress_bar.py[line:272] - INFO: epoch 011:    141 / 2004 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=357.4, nsentences=8, sample_size=357.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=1140.9, ups=3.19, wpb=357.4, bsz=8, num_updates=20050, lr=8.0798e-05, gnorm=3.013, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=6857
2023-03-15 15:54:03 - progress_bar.py[line:272] - INFO: epoch 011:    151 / 2004 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=324.3, nsentences=8, sample_size=324.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=1031.8, ups=3.18, wpb=324.3, bsz=8, num_updates=20060, lr=8.07879e-05, gnorm=2.926, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=6860
2023-03-15 15:54:06 - progress_bar.py[line:272] - INFO: epoch 011:    161 / 2004 loss=0.494, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=355.1, nsentences=8, sample_size=355.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=1076, ups=3.03, wpb=355.1, bsz=8, num_updates=20070, lr=8.07778e-05, gnorm=3.143, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=6863
2023-03-15 15:54:09 - progress_bar.py[line:272] - INFO: epoch 011:    171 / 2004 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=336.1, nsentences=8, sample_size=336.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=1033.4, ups=3.07, wpb=336.1, bsz=8, num_updates=20080, lr=8.07678e-05, gnorm=2.876, clip=0, loss_scale=1024, train_wall=3, gb_free=16, wall=6867
2023-03-15 15:54:12 - progress_bar.py[line:272] - INFO: epoch 011:    181 / 2004 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=336.1, nsentences=8, sample_size=336.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=1021, ups=3.04, wpb=336.1, bsz=8, num_updates=20090, lr=8.07577e-05, gnorm=2.932, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=6870
2023-03-15 15:54:16 - progress_bar.py[line:272] - INFO: epoch 011:    191 / 2004 loss=0.37, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=322.6, nsentences=8, sample_size=322.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=976.5, ups=3.03, wpb=322.6, bsz=8, num_updates=20100, lr=8.07476e-05, gnorm=2.847, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=6873
2023-03-15 15:54:19 - progress_bar.py[line:272] - INFO: epoch 011:    201 / 2004 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=345.5, nsentences=8, sample_size=345.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=1055.7, ups=3.06, wpb=345.5, bsz=8, num_updates=20110, lr=8.07375e-05, gnorm=3.121, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=6877
2023-03-15 15:54:22 - progress_bar.py[line:272] - INFO: epoch 011:    211 / 2004 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=324.4, nsentences=8, sample_size=324.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=1053.2, ups=3.25, wpb=324.4, bsz=8, num_updates=20120, lr=8.07274e-05, gnorm=3.01, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=6880
2023-03-15 15:54:25 - progress_bar.py[line:272] - INFO: epoch 011:    221 / 2004 loss=0.38, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=329.2, nsentences=8, sample_size=329.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=1088.9, ups=3.31, wpb=329.2, bsz=8, num_updates=20130, lr=8.07174e-05, gnorm=2.925, clip=0, loss_scale=1024, train_wall=3, gb_free=15.7, wall=6883
2023-03-15 15:54:28 - progress_bar.py[line:272] - INFO: epoch 011:    231 / 2004 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=348.8, nsentences=8, sample_size=348.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=1131.5, ups=3.24, wpb=348.8, bsz=8, num_updates=20140, lr=8.07073e-05, gnorm=3.124, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=6886
2023-03-15 15:54:31 - progress_bar.py[line:272] - INFO: epoch 011:    241 / 2004 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=375.9, nsentences=8, sample_size=375.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=1212, ups=3.22, wpb=375.9, bsz=8, num_updates=20150, lr=8.06972e-05, gnorm=3.193, clip=0, loss_scale=1024, train_wall=3, gb_free=15.7, wall=6889
2023-03-15 15:54:34 - progress_bar.py[line:272] - INFO: epoch 011:    251 / 2004 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=344.3, nsentences=8, sample_size=344.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=1070.9, ups=3.11, wpb=344.3, bsz=8, num_updates=20160, lr=8.06871e-05, gnorm=3.045, clip=0, loss_scale=2048, train_wall=3, gb_free=15.8, wall=6892
2023-03-15 15:54:38 - progress_bar.py[line:272] - INFO: epoch 011:    261 / 2004 loss=0.438, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=348.2, nsentences=8, sample_size=348.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=1118.3, ups=3.21, wpb=348.2, bsz=8, num_updates=20170, lr=8.0677e-05, gnorm=3.106, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=6895
2023-03-15 15:54:41 - progress_bar.py[line:272] - INFO: epoch 011:    271 / 2004 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=342, nsentences=8, sample_size=342, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=1110.4, ups=3.25, wpb=342, bsz=8, num_updates=20180, lr=8.06669e-05, gnorm=3.059, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=6898
2023-03-15 15:54:44 - progress_bar.py[line:272] - INFO: epoch 011:    281 / 2004 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=328.4, nsentences=8, sample_size=328.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=1070.2, ups=3.26, wpb=328.4, bsz=8, num_updates=20190, lr=8.06569e-05, gnorm=2.943, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=6901
2023-03-15 15:54:47 - progress_bar.py[line:272] - INFO: epoch 011:    291 / 2004 loss=0.48, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=396.7, nsentences=8, sample_size=396.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=1222.9, ups=3.08, wpb=396.7, bsz=8, num_updates=20200, lr=8.06468e-05, gnorm=3.085, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=6905
2023-03-15 15:54:50 - progress_bar.py[line:272] - INFO: epoch 011:    301 / 2004 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=346.9, nsentences=8, sample_size=346.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=1054.2, ups=3.04, wpb=346.9, bsz=8, num_updates=20210, lr=8.06367e-05, gnorm=2.779, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=6908
2023-03-15 15:54:54 - progress_bar.py[line:272] - INFO: epoch 011:    311 / 2004 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=352.9, nsentences=8, sample_size=352.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=1031.2, ups=2.92, wpb=352.9, bsz=8, num_updates=20220, lr=8.06266e-05, gnorm=3.346, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=6911
2023-03-15 15:54:57 - progress_bar.py[line:272] - INFO: epoch 011:    321 / 2004 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=330, nsentences=8, sample_size=330, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=997.1, ups=3.02, wpb=330, bsz=8, num_updates=20230, lr=8.06165e-05, gnorm=2.879, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=6915
2023-03-15 15:55:00 - progress_bar.py[line:272] - INFO: epoch 011:    331 / 2004 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=337.6, nsentences=8, sample_size=337.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=1016, ups=3.01, wpb=337.6, bsz=8, num_updates=20240, lr=8.06065e-05, gnorm=2.977, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=6918
2023-03-15 15:55:04 - progress_bar.py[line:272] - INFO: epoch 011:    341 / 2004 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=349.5, nsentences=8, sample_size=349.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=999.9, ups=2.86, wpb=349.5, bsz=8, num_updates=20250, lr=8.05964e-05, gnorm=3.012, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=6921
2023-03-15 15:55:07 - progress_bar.py[line:272] - INFO: epoch 011:    351 / 2004 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=359.7, nsentences=8, sample_size=359.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=1031.2, ups=2.87, wpb=359.7, bsz=8, num_updates=20260, lr=8.05863e-05, gnorm=3.328, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=6925
2023-03-15 15:55:11 - progress_bar.py[line:272] - INFO: epoch 011:    361 / 2004 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=355.6, nsentences=8, sample_size=355.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=1053.1, ups=2.96, wpb=355.6, bsz=8, num_updates=20270, lr=8.05762e-05, gnorm=2.983, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=6928
2023-03-15 15:55:14 - progress_bar.py[line:272] - INFO: epoch 011:    371 / 2004 loss=0.392, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=330.2, nsentences=8, sample_size=330.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=975.2, ups=2.95, wpb=330.2, bsz=8, num_updates=20280, lr=8.05661e-05, gnorm=2.913, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=6932
2023-03-15 15:55:16 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 15:55:18 - progress_bar.py[line:272] - INFO: epoch 011:    382 / 2004 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=319.6, nsentences=8, sample_size=319.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=860.3, ups=2.69, wpb=319.6, bsz=8, num_updates=20290, lr=8.05561e-05, gnorm=3.177, clip=0, loss_scale=2048, train_wall=4, gb_free=15, wall=6935
2023-03-15 15:55:21 - progress_bar.py[line:272] - INFO: epoch 011:    392 / 2004 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=352.6, nsentences=8, sample_size=352.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=1052.6, ups=2.99, wpb=352.6, bsz=8, num_updates=20300, lr=8.0546e-05, gnorm=3.113, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=6939
2023-03-15 15:55:25 - progress_bar.py[line:272] - INFO: epoch 011:    402 / 2004 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=376.4, nsentences=8, sample_size=376.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=1102.3, ups=2.93, wpb=376.4, bsz=8, num_updates=20310, lr=8.05359e-05, gnorm=3.018, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=6942
2023-03-15 15:55:28 - progress_bar.py[line:272] - INFO: epoch 011:    412 / 2004 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=342.2, nsentences=8, sample_size=342.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=1023.7, ups=2.99, wpb=342.2, bsz=8, num_updates=20320, lr=8.05258e-05, gnorm=2.899, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=6946
2023-03-15 15:55:31 - progress_bar.py[line:272] - INFO: epoch 011:    422 / 2004 loss=0.453, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=338.9, nsentences=8, sample_size=338.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=1006, ups=2.97, wpb=338.9, bsz=8, num_updates=20330, lr=8.05157e-05, gnorm=3.219, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=6949
2023-03-15 15:55:35 - progress_bar.py[line:272] - INFO: epoch 011:    432 / 2004 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=345, nsentences=8, sample_size=345, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=989.8, ups=2.87, wpb=345, bsz=8, num_updates=20340, lr=8.05057e-05, gnorm=3.085, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=6952
2023-03-15 15:55:38 - progress_bar.py[line:272] - INFO: epoch 011:    442 / 2004 loss=0.461, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=372.3, nsentences=8, sample_size=372.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=1094.2, ups=2.94, wpb=372.3, bsz=8, num_updates=20350, lr=8.04956e-05, gnorm=3.139, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=6956
2023-03-15 15:55:42 - progress_bar.py[line:272] - INFO: epoch 011:    452 / 2004 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=349, nsentences=8, sample_size=349, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=1021.4, ups=2.93, wpb=349, bsz=8, num_updates=20360, lr=8.04855e-05, gnorm=2.88, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=6959
2023-03-15 15:55:45 - progress_bar.py[line:272] - INFO: epoch 011:    462 / 2004 loss=0.492, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=390.3, nsentences=8, sample_size=390.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=1119.4, ups=2.87, wpb=390.3, bsz=8, num_updates=20370, lr=8.04754e-05, gnorm=3.035, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=6963
2023-03-15 15:55:48 - progress_bar.py[line:272] - INFO: epoch 011:    472 / 2004 loss=0.5, loss_v1=0, loss_v2=0, nll_loss=0.5, ntokens=348.9, nsentences=8, sample_size=348.9, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=1030.9, ups=2.95, wpb=348.9, bsz=8, num_updates=20380, lr=8.04653e-05, gnorm=3.195, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=6966
2023-03-15 15:55:52 - progress_bar.py[line:272] - INFO: epoch 011:    482 / 2004 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=364.5, nsentences=8, sample_size=364.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=1091.4, ups=2.99, wpb=364.5, bsz=8, num_updates=20390, lr=8.04553e-05, gnorm=2.831, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=6969
2023-03-15 15:55:55 - progress_bar.py[line:272] - INFO: epoch 011:    492 / 2004 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=376.1, nsentences=8, sample_size=376.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=1146.8, ups=3.05, wpb=376.1, bsz=8, num_updates=20400, lr=8.04452e-05, gnorm=2.98, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=6973
2023-03-15 15:55:58 - progress_bar.py[line:272] - INFO: epoch 011:    502 / 2004 loss=0.457, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=362.2, nsentences=8, sample_size=362.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=1193.8, ups=3.3, wpb=362.2, bsz=8, num_updates=20410, lr=8.04351e-05, gnorm=3.086, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=6976
2023-03-15 15:55:59 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 15:56:01 - progress_bar.py[line:272] - INFO: epoch 011:    513 / 2004 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=348.7, nsentences=8, sample_size=348.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=1030.3, ups=2.95, wpb=348.7, bsz=8, num_updates=20420, lr=8.0425e-05, gnorm=3.251, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=6979
2023-03-15 15:56:05 - progress_bar.py[line:272] - INFO: epoch 011:    523 / 2004 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=371.1, nsentences=8, sample_size=371.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=1197, ups=3.23, wpb=371.1, bsz=8, num_updates=20430, lr=8.04149e-05, gnorm=2.943, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=6982
2023-03-15 15:56:08 - progress_bar.py[line:272] - INFO: epoch 011:    533 / 2004 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=386.9, nsentences=8, sample_size=386.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=1269.7, ups=3.28, wpb=386.9, bsz=8, num_updates=20440, lr=8.04048e-05, gnorm=2.902, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=6985
2023-03-15 15:56:11 - progress_bar.py[line:272] - INFO: epoch 011:    543 / 2004 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=371.9, nsentences=8, sample_size=371.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=1207.9, ups=3.25, wpb=371.9, bsz=8, num_updates=20450, lr=8.03948e-05, gnorm=3.123, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=6988
2023-03-15 15:56:14 - progress_bar.py[line:272] - INFO: epoch 011:    553 / 2004 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=372.5, nsentences=8, sample_size=372.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=1197.2, ups=3.21, wpb=372.5, bsz=8, num_updates=20460, lr=8.03847e-05, gnorm=3.179, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=6991
2023-03-15 15:56:17 - progress_bar.py[line:272] - INFO: epoch 011:    563 / 2004 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=367.4, nsentences=8, sample_size=367.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=1143.6, ups=3.11, wpb=367.4, bsz=8, num_updates=20470, lr=8.03746e-05, gnorm=3.186, clip=0, loss_scale=2048, train_wall=3, gb_free=13.6, wall=6995
2023-03-15 15:56:20 - progress_bar.py[line:272] - INFO: epoch 011:    573 / 2004 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=366.6, nsentences=8, sample_size=366.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=1101.3, ups=3, wpb=366.6, bsz=8, num_updates=20480, lr=8.03645e-05, gnorm=3.069, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=6998
2023-03-15 15:56:23 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 15:56:24 - progress_bar.py[line:272] - INFO: epoch 011:    584 / 2004 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=313.1, nsentences=8, sample_size=313.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=849, ups=2.71, wpb=313.1, bsz=8, num_updates=20490, lr=8.03544e-05, gnorm=3.047, clip=0, loss_scale=1024, train_wall=4, gb_free=14.5, wall=7002
2023-03-15 15:56:27 - progress_bar.py[line:272] - INFO: epoch 011:    594 / 2004 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=349.5, nsentences=8, sample_size=349.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=1137.9, ups=3.26, wpb=349.5, bsz=8, num_updates=20500, lr=8.03444e-05, gnorm=3.041, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=7005
2023-03-15 15:56:30 - progress_bar.py[line:272] - INFO: epoch 011:    604 / 2004 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=355.8, nsentences=8, sample_size=355.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=1163.9, ups=3.27, wpb=355.8, bsz=8, num_updates=20510, lr=8.03343e-05, gnorm=3.011, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=7008
2023-03-15 15:56:33 - progress_bar.py[line:272] - INFO: epoch 011:    614 / 2004 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=346.6, nsentences=8, sample_size=346.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=1115.6, ups=3.22, wpb=346.6, bsz=8, num_updates=20520, lr=8.03242e-05, gnorm=3.037, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=7011
2023-03-15 15:56:36 - progress_bar.py[line:272] - INFO: epoch 011:    624 / 2004 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=362.5, nsentences=8, sample_size=362.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=1180.1, ups=3.26, wpb=362.5, bsz=8, num_updates=20530, lr=8.03141e-05, gnorm=2.898, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=7014
2023-03-15 15:56:39 - progress_bar.py[line:272] - INFO: epoch 011:    634 / 2004 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=347.2, nsentences=8, sample_size=347.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=1139.8, ups=3.28, wpb=347.2, bsz=8, num_updates=20540, lr=8.0304e-05, gnorm=2.935, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=7017
2023-03-15 15:56:42 - progress_bar.py[line:272] - INFO: epoch 011:    644 / 2004 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=340, nsentences=8, sample_size=340, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=1122.7, ups=3.3, wpb=340, bsz=8, num_updates=20550, lr=8.0294e-05, gnorm=3.077, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=7020
2023-03-15 15:56:45 - progress_bar.py[line:272] - INFO: epoch 011:    654 / 2004 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=348.4, nsentences=8, sample_size=348.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=1174.6, ups=3.37, wpb=348.4, bsz=8, num_updates=20560, lr=8.02839e-05, gnorm=3.132, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=7023
2023-03-15 15:56:48 - progress_bar.py[line:272] - INFO: epoch 011:    664 / 2004 loss=0.386, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=292.1, nsentences=8, sample_size=292.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=970, ups=3.32, wpb=292.1, bsz=8, num_updates=20570, lr=8.02738e-05, gnorm=2.928, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=7026
2023-03-15 15:56:51 - progress_bar.py[line:272] - INFO: epoch 011:    674 / 2004 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=330.9, nsentences=8, sample_size=330.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=1078.7, ups=3.26, wpb=330.9, bsz=8, num_updates=20580, lr=8.02637e-05, gnorm=2.969, clip=0, loss_scale=1024, train_wall=3, gb_free=15.9, wall=7029
2023-03-15 15:56:55 - progress_bar.py[line:272] - INFO: epoch 011:    684 / 2004 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=357, nsentences=8, sample_size=357, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=1140.3, ups=3.19, wpb=357, bsz=8, num_updates=20590, lr=8.02536e-05, gnorm=3.004, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=7032
2023-03-15 15:56:58 - progress_bar.py[line:272] - INFO: epoch 011:    694 / 2004 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=354.2, nsentences=8, sample_size=354.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=1139.6, ups=3.22, wpb=354.2, bsz=8, num_updates=20600, lr=8.02436e-05, gnorm=3.069, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=7035
2023-03-15 15:57:01 - progress_bar.py[line:272] - INFO: epoch 011:    704 / 2004 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=321, nsentences=8, sample_size=321, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=1048, ups=3.26, wpb=321, bsz=8, num_updates=20610, lr=8.02335e-05, gnorm=2.725, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=7038
2023-03-15 15:57:04 - progress_bar.py[line:272] - INFO: epoch 011:    714 / 2004 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=331.7, nsentences=8, sample_size=331.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=1029.9, ups=3.1, wpb=331.7, bsz=8, num_updates=20620, lr=8.02234e-05, gnorm=3.058, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=7042
2023-03-15 15:57:07 - progress_bar.py[line:272] - INFO: epoch 011:    724 / 2004 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=364.1, nsentences=8, sample_size=364.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=1127.9, ups=3.1, wpb=364.1, bsz=8, num_updates=20630, lr=8.02133e-05, gnorm=3.126, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=7045
2023-03-15 15:57:10 - progress_bar.py[line:272] - INFO: epoch 011:    734 / 2004 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=352.1, nsentences=8, sample_size=352.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=1133.5, ups=3.22, wpb=352.1, bsz=8, num_updates=20640, lr=8.02032e-05, gnorm=3.088, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=7048
2023-03-15 15:57:13 - progress_bar.py[line:272] - INFO: epoch 011:    744 / 2004 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=346.6, nsentences=8, sample_size=346.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=1152.9, ups=3.33, wpb=346.6, bsz=8, num_updates=20650, lr=8.01931e-05, gnorm=3.092, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=7051
2023-03-15 15:57:16 - progress_bar.py[line:272] - INFO: epoch 011:    754 / 2004 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=344.4, nsentences=8, sample_size=344.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=1128.3, ups=3.28, wpb=344.4, bsz=8, num_updates=20660, lr=8.01831e-05, gnorm=3.169, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=7054
2023-03-15 15:57:20 - progress_bar.py[line:272] - INFO: epoch 011:    764 / 2004 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=359.2, nsentences=8, sample_size=359.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=1104.5, ups=3.07, wpb=359.2, bsz=8, num_updates=20670, lr=8.0173e-05, gnorm=3, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=7057
2023-03-15 15:57:23 - progress_bar.py[line:272] - INFO: epoch 011:    774 / 2004 loss=0.468, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=380.6, nsentences=8, sample_size=380.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=1157, ups=3.04, wpb=380.6, bsz=8, num_updates=20680, lr=8.01629e-05, gnorm=3.207, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=7061
2023-03-15 15:57:26 - progress_bar.py[line:272] - INFO: epoch 011:    784 / 2004 loss=0.386, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=335.1, nsentences=8, sample_size=335.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=1022.2, ups=3.05, wpb=335.1, bsz=8, num_updates=20690, lr=8.01528e-05, gnorm=3.05, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=7064
2023-03-15 15:57:30 - progress_bar.py[line:272] - INFO: epoch 011:    794 / 2004 loss=0.369, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=334.2, nsentences=8, sample_size=334.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=994.3, ups=2.98, wpb=334.2, bsz=8, num_updates=20700, lr=8.01427e-05, gnorm=2.662, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=7067
2023-03-15 15:57:33 - progress_bar.py[line:272] - INFO: epoch 011:    804 / 2004 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=320.2, nsentences=8, sample_size=320.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=974.5, ups=3.04, wpb=320.2, bsz=8, num_updates=20710, lr=8.01327e-05, gnorm=3.2, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=7070
2023-03-15 15:57:36 - progress_bar.py[line:272] - INFO: epoch 011:    814 / 2004 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=343.8, nsentences=8, sample_size=343.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=1010.2, ups=2.94, wpb=343.8, bsz=8, num_updates=20720, lr=8.01226e-05, gnorm=2.898, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=7074
2023-03-15 15:57:40 - progress_bar.py[line:272] - INFO: epoch 011:    824 / 2004 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=355.7, nsentences=8, sample_size=355.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=1047, ups=2.94, wpb=355.7, bsz=8, num_updates=20730, lr=8.01125e-05, gnorm=3.108, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=7077
2023-03-15 15:57:43 - progress_bar.py[line:272] - INFO: epoch 011:    834 / 2004 loss=0.38, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=341.1, nsentences=8, sample_size=341.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=1021.9, ups=3, wpb=341.1, bsz=8, num_updates=20740, lr=8.01024e-05, gnorm=3.163, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=7081
2023-03-15 15:57:44 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 15:57:47 - progress_bar.py[line:272] - INFO: epoch 011:    845 / 2004 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=348.6, nsentences=8, sample_size=348.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=945.2, ups=2.71, wpb=348.6, bsz=8, num_updates=20750, lr=8.00923e-05, gnorm=2.932, clip=0, loss_scale=2048, train_wall=4, gb_free=14.9, wall=7084
2023-03-15 15:57:50 - progress_bar.py[line:272] - INFO: epoch 011:    855 / 2004 loss=0.438, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=348.9, nsentences=8, sample_size=348.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=1030.1, ups=2.95, wpb=348.9, bsz=8, num_updates=20760, lr=8.00823e-05, gnorm=3.073, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=7088
2023-03-15 15:57:53 - progress_bar.py[line:272] - INFO: epoch 011:    865 / 2004 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=375.2, nsentences=8, sample_size=375.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=1103.8, ups=2.94, wpb=375.2, bsz=8, num_updates=20770, lr=8.00722e-05, gnorm=3.031, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=7091
2023-03-15 15:57:57 - progress_bar.py[line:272] - INFO: epoch 011:    875 / 2004 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=339.5, nsentences=8, sample_size=339.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=1086.8, ups=3.2, wpb=339.5, bsz=8, num_updates=20780, lr=8.00621e-05, gnorm=2.946, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=7094
2023-03-15 15:58:00 - progress_bar.py[line:272] - INFO: epoch 011:    885 / 2004 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=317.6, nsentences=8, sample_size=317.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=1017.9, ups=3.21, wpb=317.6, bsz=8, num_updates=20790, lr=8.0052e-05, gnorm=3.096, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=7097
2023-03-15 15:58:03 - progress_bar.py[line:272] - INFO: epoch 011:    895 / 2004 loss=0.435, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=337.2, nsentences=8, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=1081.5, ups=3.21, wpb=337.2, bsz=8, num_updates=20800, lr=8.00419e-05, gnorm=3.286, clip=0, loss_scale=2048, train_wall=3, gb_free=14, wall=7100
2023-03-15 15:58:06 - progress_bar.py[line:272] - INFO: epoch 011:    905 / 2004 loss=0.372, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=352.4, nsentences=8, sample_size=352.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=1117.6, ups=3.17, wpb=352.4, bsz=8, num_updates=20810, lr=8.00319e-05, gnorm=2.883, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=7104
2023-03-15 15:58:09 - progress_bar.py[line:272] - INFO: epoch 011:    915 / 2004 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=371.7, nsentences=8, sample_size=371.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=1101.1, ups=2.96, wpb=371.7, bsz=8, num_updates=20820, lr=8.00218e-05, gnorm=3.263, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=7107
2023-03-15 15:58:12 - progress_bar.py[line:272] - INFO: epoch 011:    925 / 2004 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=338.7, nsentences=8, sample_size=338.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=1112.1, ups=3.28, wpb=338.7, bsz=8, num_updates=20830, lr=8.00117e-05, gnorm=3.104, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=7110
2023-03-15 15:58:16 - progress_bar.py[line:272] - INFO: epoch 011:    935 / 2004 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=342, nsentences=8, sample_size=342, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=1112.5, ups=3.25, wpb=342, bsz=8, num_updates=20840, lr=8.00016e-05, gnorm=3.008, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=7113
2023-03-15 15:58:19 - progress_bar.py[line:272] - INFO: epoch 011:    945 / 2004 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=357.1, nsentences=8, sample_size=357.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=1156, ups=3.24, wpb=357.1, bsz=8, num_updates=20850, lr=7.99915e-05, gnorm=2.924, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=7116
2023-03-15 15:58:22 - progress_bar.py[line:272] - INFO: epoch 011:    955 / 2004 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=345.1, nsentences=8, sample_size=345.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=1115.4, ups=3.23, wpb=345.1, bsz=8, num_updates=20860, lr=7.99815e-05, gnorm=3.095, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=7119
2023-03-15 15:58:24 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 15:58:25 - progress_bar.py[line:272] - INFO: epoch 011:    966 / 2004 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=353.5, nsentences=8, sample_size=353.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=1044.8, ups=2.96, wpb=353.5, bsz=8, num_updates=20870, lr=7.99714e-05, gnorm=2.908, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=7123
2023-03-15 15:58:28 - progress_bar.py[line:272] - INFO: epoch 011:    976 / 2004 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=328.8, nsentences=8, sample_size=328.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=1072.3, ups=3.26, wpb=328.8, bsz=8, num_updates=20880, lr=7.99613e-05, gnorm=3.183, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=7126
2023-03-15 15:58:31 - progress_bar.py[line:272] - INFO: epoch 011:    986 / 2004 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=332.6, nsentences=8, sample_size=332.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=1079.8, ups=3.25, wpb=332.6, bsz=8, num_updates=20890, lr=7.99512e-05, gnorm=3.035, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=7129
2023-03-15 15:58:34 - progress_bar.py[line:272] - INFO: epoch 011:    996 / 2004 loss=0.46, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=379.9, nsentences=8, sample_size=379.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=1267.4, ups=3.34, wpb=379.9, bsz=8, num_updates=20900, lr=7.99411e-05, gnorm=3.092, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=7132
2023-03-15 15:58:37 - progress_bar.py[line:272] - INFO: epoch 011:   1006 / 2004 loss=0.381, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=300.6, nsentences=8, sample_size=300.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=990.2, ups=3.29, wpb=300.6, bsz=8, num_updates=20910, lr=7.9931e-05, gnorm=3.157, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=7135
2023-03-15 15:58:40 - progress_bar.py[line:272] - INFO: epoch 011:   1016 / 2004 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=347.9, nsentences=8, sample_size=347.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=1166.5, ups=3.35, wpb=347.9, bsz=8, num_updates=20920, lr=7.9921e-05, gnorm=3.03, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=7138
2023-03-15 15:58:43 - progress_bar.py[line:272] - INFO: epoch 011:   1026 / 2004 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=325, nsentences=8, sample_size=325, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=1079.3, ups=3.32, wpb=325, bsz=8, num_updates=20930, lr=7.99109e-05, gnorm=3.098, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=7141
2023-03-15 15:58:46 - progress_bar.py[line:272] - INFO: epoch 011:   1036 / 2004 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=320.9, nsentences=8, sample_size=320.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=1050.2, ups=3.27, wpb=320.9, bsz=8, num_updates=20940, lr=7.99008e-05, gnorm=3.144, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=7144
2023-03-15 15:58:49 - progress_bar.py[line:272] - INFO: epoch 011:   1046 / 2004 loss=0.479, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=376.6, nsentences=8, sample_size=376.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=1208.4, ups=3.21, wpb=376.6, bsz=8, num_updates=20950, lr=7.98907e-05, gnorm=3.27, clip=0, loss_scale=1024, train_wall=3, gb_free=14.2, wall=7147
2023-03-15 15:58:53 - progress_bar.py[line:272] - INFO: epoch 011:   1056 / 2004 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=349.8, nsentences=8, sample_size=349.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=1114.1, ups=3.18, wpb=349.8, bsz=8, num_updates=20960, lr=7.98806e-05, gnorm=2.92, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=7150
2023-03-15 15:58:56 - progress_bar.py[line:272] - INFO: epoch 011:   1066 / 2004 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=341.4, nsentences=8, sample_size=341.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=1034.4, ups=3.03, wpb=341.4, bsz=8, num_updates=20970, lr=7.98706e-05, gnorm=3.156, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=7153
2023-03-15 15:58:59 - progress_bar.py[line:272] - INFO: epoch 011:   1076 / 2004 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=359.1, nsentences=8, sample_size=359.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=1070.3, ups=2.98, wpb=359.1, bsz=8, num_updates=20980, lr=7.98605e-05, gnorm=3.047, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=7157
2023-03-15 15:59:03 - progress_bar.py[line:272] - INFO: epoch 011:   1086 / 2004 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=372.6, nsentences=8, sample_size=372.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=1111.5, ups=2.98, wpb=372.6, bsz=8, num_updates=20990, lr=7.98504e-05, gnorm=3.142, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=7160
2023-03-15 15:59:06 - progress_bar.py[line:272] - INFO: epoch 011:   1096 / 2004 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=326.1, nsentences=8, sample_size=326.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=987.6, ups=3.03, wpb=326.1, bsz=8, num_updates=21000, lr=7.98403e-05, gnorm=3.098, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=7163
2023-03-15 15:59:09 - progress_bar.py[line:272] - INFO: epoch 011:   1106 / 2004 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=379.3, nsentences=8, sample_size=379.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=1205.7, ups=3.18, wpb=379.3, bsz=8, num_updates=21010, lr=7.98302e-05, gnorm=2.974, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=7167
2023-03-15 15:59:12 - progress_bar.py[line:272] - INFO: epoch 011:   1116 / 2004 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=326.9, nsentences=7.8, sample_size=326.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=991.9, ups=3.03, wpb=326.9, bsz=7.8, num_updates=21020, lr=7.98202e-05, gnorm=3.051, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=7170
2023-03-15 15:59:16 - progress_bar.py[line:272] - INFO: epoch 011:   1126 / 2004 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=321.6, nsentences=8, sample_size=321.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=974, ups=3.03, wpb=321.6, bsz=8, num_updates=21030, lr=7.98101e-05, gnorm=3.009, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=7173
2023-03-15 15:59:19 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 15:59:19 - progress_bar.py[line:272] - INFO: epoch 011:   1137 / 2004 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=388.8, nsentences=8, sample_size=388.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=1040.2, ups=2.68, wpb=388.8, bsz=8, num_updates=21040, lr=7.98e-05, gnorm=2.96, clip=0, loss_scale=1024, train_wall=4, gb_free=14.1, wall=7177
2023-03-15 15:59:23 - progress_bar.py[line:272] - INFO: epoch 011:   1147 / 2004 loss=0.369, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=343.7, nsentences=8, sample_size=343.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=992.8, ups=2.89, wpb=343.7, bsz=8, num_updates=21050, lr=7.97899e-05, gnorm=3.009, clip=0, loss_scale=1024, train_wall=3, gb_free=13.8, wall=7180
2023-03-15 15:59:26 - progress_bar.py[line:272] - INFO: epoch 011:   1157 / 2004 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=401.4, nsentences=8, sample_size=401.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=1208.3, ups=3.01, wpb=401.4, bsz=8, num_updates=21060, lr=7.97798e-05, gnorm=2.99, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=7184
2023-03-15 15:59:30 - progress_bar.py[line:272] - INFO: epoch 011:   1167 / 2004 loss=0.386, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=332.3, nsentences=8, sample_size=332.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=983.4, ups=2.96, wpb=332.3, bsz=8, num_updates=21070, lr=7.97698e-05, gnorm=3.023, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=7187
2023-03-15 15:59:33 - progress_bar.py[line:272] - INFO: epoch 011:   1177 / 2004 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=370.3, nsentences=8, sample_size=370.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=1099.9, ups=2.97, wpb=370.3, bsz=8, num_updates=21080, lr=7.97597e-05, gnorm=2.891, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=7190
2023-03-15 15:59:36 - progress_bar.py[line:272] - INFO: epoch 011:   1187 / 2004 loss=0.392, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=327.9, nsentences=8, sample_size=327.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=972.8, ups=2.97, wpb=327.9, bsz=8, num_updates=21090, lr=7.97496e-05, gnorm=2.883, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=7194
2023-03-15 15:59:39 - progress_bar.py[line:272] - INFO: epoch 011:   1197 / 2004 loss=0.38, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=364.3, nsentences=8, sample_size=364.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=1137, ups=3.12, wpb=364.3, bsz=8, num_updates=21100, lr=7.97395e-05, gnorm=2.76, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=7197
2023-03-15 15:59:43 - progress_bar.py[line:272] - INFO: epoch 011:   1207 / 2004 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=289.7, nsentences=8, sample_size=289.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=894.6, ups=3.09, wpb=289.7, bsz=8, num_updates=21110, lr=7.97294e-05, gnorm=2.87, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=7200
2023-03-15 15:59:46 - progress_bar.py[line:272] - INFO: epoch 011:   1217 / 2004 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=312.2, nsentences=8, sample_size=312.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=941.9, ups=3.02, wpb=312.2, bsz=8, num_updates=21120, lr=7.97193e-05, gnorm=3.033, clip=0, loss_scale=1024, train_wall=3, gb_free=15.9, wall=7204
2023-03-15 15:59:49 - progress_bar.py[line:272] - INFO: epoch 011:   1227 / 2004 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=321.7, nsentences=8, sample_size=321.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=950.6, ups=2.95, wpb=321.7, bsz=8, num_updates=21130, lr=7.97093e-05, gnorm=2.69, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=7207
2023-03-15 15:59:53 - progress_bar.py[line:272] - INFO: epoch 011:   1237 / 2004 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=368.6, nsentences=8, sample_size=368.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=1086.7, ups=2.95, wpb=368.6, bsz=8, num_updates=21140, lr=7.96992e-05, gnorm=2.969, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=7210
2023-03-15 15:59:56 - progress_bar.py[line:272] - INFO: epoch 011:   1247 / 2004 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=340.3, nsentences=8, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=1003.7, ups=2.95, wpb=340.3, bsz=8, num_updates=21150, lr=7.96891e-05, gnorm=3.002, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=7214
2023-03-15 16:00:00 - progress_bar.py[line:272] - INFO: epoch 011:   1257 / 2004 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=354.3, nsentences=8, sample_size=354.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=1055.1, ups=2.98, wpb=354.3, bsz=8, num_updates=21160, lr=7.9679e-05, gnorm=3.033, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=7217
2023-03-15 16:00:03 - progress_bar.py[line:272] - INFO: epoch 011:   1267 / 2004 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=335.2, nsentences=8, sample_size=335.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=994.6, ups=2.97, wpb=335.2, bsz=8, num_updates=21170, lr=7.96689e-05, gnorm=2.957, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=7221
2023-03-15 16:00:06 - progress_bar.py[line:272] - INFO: epoch 011:   1277 / 2004 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=354.9, nsentences=8, sample_size=354.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=1037.8, ups=2.92, wpb=354.9, bsz=8, num_updates=21180, lr=7.96589e-05, gnorm=3.107, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=7224
2023-03-15 16:00:10 - progress_bar.py[line:272] - INFO: epoch 011:   1287 / 2004 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=321, nsentences=8, sample_size=321, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=943.2, ups=2.94, wpb=321, bsz=8, num_updates=21190, lr=7.96488e-05, gnorm=2.909, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=7227
2023-03-15 16:00:13 - progress_bar.py[line:272] - INFO: epoch 011:   1297 / 2004 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=306.7, nsentences=8, sample_size=306.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=928.6, ups=3.03, wpb=306.7, bsz=8, num_updates=21200, lr=7.96387e-05, gnorm=2.965, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=7231
2023-03-15 16:00:16 - progress_bar.py[line:272] - INFO: epoch 011:   1307 / 2004 loss=0.392, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=320.1, nsentences=8, sample_size=320.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=968.2, ups=3.02, wpb=320.1, bsz=8, num_updates=21210, lr=7.96286e-05, gnorm=3.038, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=7234
2023-03-15 16:00:19 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 16:00:20 - progress_bar.py[line:272] - INFO: epoch 011:   1318 / 2004 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=354.9, nsentences=8, sample_size=354.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=976.1, ups=2.75, wpb=354.9, bsz=8, num_updates=21220, lr=7.96185e-05, gnorm=2.997, clip=0, loss_scale=1024, train_wall=4, gb_free=15.4, wall=7238
2023-03-15 16:00:23 - progress_bar.py[line:272] - INFO: epoch 011:   1328 / 2004 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=292.4, nsentences=8, sample_size=292.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=881.7, ups=3.02, wpb=292.4, bsz=8, num_updates=21230, lr=7.96085e-05, gnorm=3.171, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=7241
2023-03-15 16:00:26 - progress_bar.py[line:272] - INFO: epoch 011:   1338 / 2004 loss=0.435, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=365.9, nsentences=8, sample_size=365.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=1143.4, ups=3.12, wpb=365.9, bsz=8, num_updates=21240, lr=7.95984e-05, gnorm=3.158, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=7244
2023-03-15 16:00:30 - progress_bar.py[line:272] - INFO: epoch 011:   1348 / 2004 loss=0.38, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=302.1, nsentences=8, sample_size=302.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=1001.3, ups=3.31, wpb=302.1, bsz=8, num_updates=21250, lr=7.95883e-05, gnorm=3.133, clip=0, loss_scale=1024, train_wall=3, gb_free=15.7, wall=7247
2023-03-15 16:00:33 - progress_bar.py[line:272] - INFO: epoch 011:   1358 / 2004 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=317.5, nsentences=8, sample_size=317.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=1048.9, ups=3.3, wpb=317.5, bsz=8, num_updates=21260, lr=7.95782e-05, gnorm=3.029, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=7250
2023-03-15 16:00:36 - progress_bar.py[line:272] - INFO: epoch 011:   1368 / 2004 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=319.2, nsentences=8, sample_size=319.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=1043.1, ups=3.27, wpb=319.2, bsz=8, num_updates=21270, lr=7.95681e-05, gnorm=3.144, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=7253
2023-03-15 16:00:39 - progress_bar.py[line:272] - INFO: epoch 011:   1378 / 2004 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=328, nsentences=8, sample_size=328, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=1053.3, ups=3.21, wpb=328, bsz=8, num_updates=21280, lr=7.95581e-05, gnorm=2.947, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=7256
2023-03-15 16:00:42 - progress_bar.py[line:272] - INFO: epoch 011:   1388 / 2004 loss=0.454, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=394.4, nsentences=8, sample_size=394.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=1253.6, ups=3.18, wpb=394.4, bsz=8, num_updates=21290, lr=7.9548e-05, gnorm=3.337, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=7259
2023-03-15 16:00:45 - progress_bar.py[line:272] - INFO: epoch 011:   1398 / 2004 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=348.6, nsentences=8, sample_size=348.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=1127.2, ups=3.23, wpb=348.6, bsz=8, num_updates=21300, lr=7.95379e-05, gnorm=2.731, clip=0, loss_scale=1024, train_wall=3, gb_free=13.6, wall=7263
2023-03-15 16:00:48 - progress_bar.py[line:272] - INFO: epoch 011:   1408 / 2004 loss=0.409, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=346, nsentences=8, sample_size=346, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=1131, ups=3.27, wpb=346, bsz=8, num_updates=21310, lr=7.95278e-05, gnorm=3.052, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=7266
2023-03-15 16:00:51 - progress_bar.py[line:272] - INFO: epoch 011:   1418 / 2004 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=372.2, nsentences=8, sample_size=372.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=1178.7, ups=3.17, wpb=372.2, bsz=8, num_updates=21320, lr=7.95177e-05, gnorm=2.974, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=7269
2023-03-15 16:00:54 - progress_bar.py[line:272] - INFO: epoch 011:   1428 / 2004 loss=0.386, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=309.5, nsentences=8, sample_size=309.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=936.1, ups=3.02, wpb=309.5, bsz=8, num_updates=21330, lr=7.95077e-05, gnorm=2.79, clip=0, loss_scale=1024, train_wall=3, gb_free=13.8, wall=7272
2023-03-15 16:00:58 - progress_bar.py[line:272] - INFO: epoch 011:   1438 / 2004 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=359.9, nsentences=8, sample_size=359.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=1071.3, ups=2.98, wpb=359.9, bsz=8, num_updates=21340, lr=7.94976e-05, gnorm=3.033, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=7275
2023-03-15 16:01:01 - progress_bar.py[line:272] - INFO: epoch 011:   1448 / 2004 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=317.7, nsentences=8, sample_size=317.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=954.4, ups=3, wpb=317.7, bsz=8, num_updates=21350, lr=7.94875e-05, gnorm=2.961, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=7279
2023-03-15 16:01:05 - progress_bar.py[line:272] - INFO: epoch 011:   1458 / 2004 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=382.4, nsentences=8, sample_size=382.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=1099.2, ups=2.87, wpb=382.4, bsz=8, num_updates=21360, lr=7.94774e-05, gnorm=3.286, clip=0, loss_scale=2048, train_wall=3, gb_free=14, wall=7282
2023-03-15 16:01:08 - progress_bar.py[line:272] - INFO: epoch 011:   1468 / 2004 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=394.2, nsentences=8, sample_size=394.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=1183, ups=3, wpb=394.2, bsz=8, num_updates=21370, lr=7.94673e-05, gnorm=2.836, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=7286
2023-03-15 16:01:09 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 16:01:12 - progress_bar.py[line:272] - INFO: epoch 011:   1479 / 2004 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=394.5, nsentences=8, sample_size=394.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=1047.3, ups=2.65, wpb=394.5, bsz=8, num_updates=21380, lr=7.94572e-05, gnorm=3.083, clip=0, loss_scale=1024, train_wall=4, gb_free=13.8, wall=7289
2023-03-15 16:01:15 - progress_bar.py[line:272] - INFO: epoch 011:   1489 / 2004 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=309.1, nsentences=8, sample_size=309.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=908.5, ups=2.94, wpb=309.1, bsz=8, num_updates=21390, lr=7.94472e-05, gnorm=2.909, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=7293
2023-03-15 16:01:19 - progress_bar.py[line:272] - INFO: epoch 011:   1499 / 2004 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=344.8, nsentences=8, sample_size=344.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=1021.6, ups=2.96, wpb=344.8, bsz=8, num_updates=21400, lr=7.94371e-05, gnorm=3.359, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=7296
2023-03-15 16:01:22 - progress_bar.py[line:272] - INFO: epoch 011:   1509 / 2004 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=328.7, nsentences=8, sample_size=328.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=974.5, ups=2.96, wpb=328.7, bsz=8, num_updates=21410, lr=7.9427e-05, gnorm=2.943, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=7300
2023-03-15 16:01:25 - progress_bar.py[line:272] - INFO: epoch 011:   1519 / 2004 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=327.1, nsentences=8, sample_size=327.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=968.8, ups=2.96, wpb=327.1, bsz=8, num_updates=21420, lr=7.94169e-05, gnorm=3.054, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=7303
2023-03-15 16:01:29 - progress_bar.py[line:272] - INFO: epoch 011:   1529 / 2004 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=335.7, nsentences=8, sample_size=335.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=998.3, ups=2.97, wpb=335.7, bsz=8, num_updates=21430, lr=7.94068e-05, gnorm=3.144, clip=0, loss_scale=1024, train_wall=3, gb_free=13.9, wall=7306
2023-03-15 16:01:32 - progress_bar.py[line:272] - INFO: epoch 011:   1539 / 2004 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=346.3, nsentences=8, sample_size=346.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=1048.7, ups=3.03, wpb=346.3, bsz=8, num_updates=21440, lr=7.93968e-05, gnorm=2.99, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=7310
2023-03-15 16:01:35 - progress_bar.py[line:272] - INFO: epoch 011:   1549 / 2004 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=317.1, nsentences=8, sample_size=317.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=952.2, ups=3, wpb=317.1, bsz=8, num_updates=21450, lr=7.93867e-05, gnorm=3.004, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=7313
2023-03-15 16:01:39 - progress_bar.py[line:272] - INFO: epoch 011:   1559 / 2004 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=353.3, nsentences=8, sample_size=353.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=1042.4, ups=2.95, wpb=353.3, bsz=8, num_updates=21460, lr=7.93766e-05, gnorm=2.79, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=7316
2023-03-15 16:01:42 - progress_bar.py[line:272] - INFO: epoch 011:   1569 / 2004 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=325.9, nsentences=8, sample_size=325.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=983.6, ups=3.02, wpb=325.9, bsz=8, num_updates=21470, lr=7.93665e-05, gnorm=3.106, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=7320
2023-03-15 16:01:45 - progress_bar.py[line:272] - INFO: epoch 011:   1579 / 2004 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=354, nsentences=8, sample_size=354, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=1103, ups=3.12, wpb=354, bsz=8, num_updates=21480, lr=7.93564e-05, gnorm=2.899, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=7323
2023-03-15 16:01:48 - progress_bar.py[line:272] - INFO: epoch 011:   1589 / 2004 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=328.2, nsentences=8, sample_size=328.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=1050.9, ups=3.2, wpb=328.2, bsz=8, num_updates=21490, lr=7.93464e-05, gnorm=2.915, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=7326
2023-03-15 16:01:51 - progress_bar.py[line:272] - INFO: epoch 011:   1599 / 2004 loss=0.38, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=345.9, nsentences=8, sample_size=345.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=1157.5, ups=3.35, wpb=345.9, bsz=8, num_updates=21500, lr=7.93363e-05, gnorm=2.93, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=7329
2023-03-15 16:01:54 - progress_bar.py[line:272] - INFO: epoch 011:   1609 / 2004 loss=0.388, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=336.5, nsentences=8, sample_size=336.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=1110, ups=3.3, wpb=336.5, bsz=8, num_updates=21510, lr=7.93262e-05, gnorm=3.154, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=7332
2023-03-15 16:01:57 - progress_bar.py[line:272] - INFO: epoch 011:   1619 / 2004 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=342.5, nsentences=8, sample_size=342.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=1151.2, ups=3.36, wpb=342.5, bsz=8, num_updates=21520, lr=7.93161e-05, gnorm=3.186, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=7335
2023-03-15 16:01:58 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 16:02:01 - progress_bar.py[line:272] - INFO: epoch 011:   1630 / 2004 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=351.8, nsentences=8, sample_size=351.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=985, ups=2.8, wpb=351.8, bsz=8, num_updates=21530, lr=7.9306e-05, gnorm=3.108, clip=0, loss_scale=1024, train_wall=4, gb_free=14.9, wall=7338
2023-03-15 16:02:04 - progress_bar.py[line:272] - INFO: epoch 011:   1640 / 2004 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=321.7, nsentences=8, sample_size=321.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=1046.7, ups=3.25, wpb=321.7, bsz=8, num_updates=21540, lr=7.9296e-05, gnorm=2.892, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=7342
2023-03-15 16:02:07 - progress_bar.py[line:272] - INFO: epoch 011:   1650 / 2004 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=327.5, nsentences=8, sample_size=327.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=992.4, ups=3.03, wpb=327.5, bsz=8, num_updates=21550, lr=7.92859e-05, gnorm=3.211, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=7345
2023-03-15 16:02:11 - progress_bar.py[line:272] - INFO: epoch 011:   1660 / 2004 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=346.7, nsentences=8, sample_size=346.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=1002.6, ups=2.89, wpb=346.7, bsz=8, num_updates=21560, lr=7.92758e-05, gnorm=3.079, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=7348
2023-03-15 16:02:14 - progress_bar.py[line:272] - INFO: epoch 011:   1670 / 2004 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=352.2, nsentences=8, sample_size=352.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=1022.9, ups=2.9, wpb=352.2, bsz=8, num_updates=21570, lr=7.92657e-05, gnorm=3.158, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=7352
2023-03-15 16:02:18 - progress_bar.py[line:272] - INFO: epoch 011:   1680 / 2004 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=314, nsentences=8, sample_size=314, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=926.5, ups=2.95, wpb=314, bsz=8, num_updates=21580, lr=7.92556e-05, gnorm=2.853, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=7355
2023-03-15 16:02:21 - progress_bar.py[line:272] - INFO: epoch 011:   1690 / 2004 loss=0.388, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=347.7, nsentences=8, sample_size=347.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=1035.9, ups=2.98, wpb=347.7, bsz=8, num_updates=21590, lr=7.92455e-05, gnorm=3.089, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=7359
2023-03-15 16:02:24 - progress_bar.py[line:272] - INFO: epoch 011:   1700 / 2004 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=335.8, nsentences=8, sample_size=335.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=1002.4, ups=2.99, wpb=335.8, bsz=8, num_updates=21600, lr=7.92355e-05, gnorm=2.94, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=7362
2023-03-15 16:02:28 - progress_bar.py[line:272] - INFO: epoch 011:   1710 / 2004 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=346.6, nsentences=8, sample_size=346.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=1049.5, ups=3.03, wpb=346.6, bsz=8, num_updates=21610, lr=7.92254e-05, gnorm=3.094, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=7365
2023-03-15 16:02:31 - progress_bar.py[line:272] - INFO: epoch 011:   1720 / 2004 loss=0.389, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=379, nsentences=8, sample_size=379, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=1104.5, ups=2.91, wpb=379, bsz=8, num_updates=21620, lr=7.92153e-05, gnorm=3.105, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=7369
2023-03-15 16:02:34 - progress_bar.py[line:272] - INFO: epoch 011:   1730 / 2004 loss=0.38, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=379.3, nsentences=8, sample_size=379.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=1101.1, ups=2.9, wpb=379.3, bsz=8, num_updates=21630, lr=7.92052e-05, gnorm=2.957, clip=0, loss_scale=1024, train_wall=3, gb_free=14, wall=7372
2023-03-15 16:02:38 - progress_bar.py[line:272] - INFO: epoch 011:   1740 / 2004 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=314.8, nsentences=8, sample_size=314.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=929.6, ups=2.95, wpb=314.8, bsz=8, num_updates=21640, lr=7.91951e-05, gnorm=3.097, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=7375
2023-03-15 16:02:41 - progress_bar.py[line:272] - INFO: epoch 011:   1750 / 2004 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=357.9, nsentences=8, sample_size=357.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=1056.9, ups=2.95, wpb=357.9, bsz=8, num_updates=21650, lr=7.91851e-05, gnorm=3.117, clip=0, loss_scale=2048, train_wall=3, gb_free=15.8, wall=7379
2023-03-15 16:02:45 - progress_bar.py[line:272] - INFO: epoch 011:   1760 / 2004 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=325.3, nsentences=8, sample_size=325.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=977.7, ups=3.01, wpb=325.3, bsz=8, num_updates=21660, lr=7.9175e-05, gnorm=3.188, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=7382
2023-03-15 16:02:48 - progress_bar.py[line:272] - INFO: epoch 011:   1770 / 2004 loss=0.386, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=339.2, nsentences=8, sample_size=339.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=998.2, ups=2.94, wpb=339.2, bsz=8, num_updates=21670, lr=7.91649e-05, gnorm=3.112, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=7386
2023-03-15 16:02:51 - progress_bar.py[line:272] - INFO: epoch 011:   1780 / 2004 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=330.8, nsentences=8, sample_size=330.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=985.1, ups=2.98, wpb=330.8, bsz=8, num_updates=21680, lr=7.91548e-05, gnorm=2.84, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=7389
2023-03-15 16:02:55 - progress_bar.py[line:272] - INFO: epoch 011:   1790 / 2004 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=306.4, nsentences=8, sample_size=306.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=916, ups=2.99, wpb=306.4, bsz=8, num_updates=21690, lr=7.91447e-05, gnorm=3.035, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=7392
2023-03-15 16:02:58 - progress_bar.py[line:272] - INFO: epoch 011:   1800 / 2004 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=355.2, nsentences=8, sample_size=355.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=1047.3, ups=2.95, wpb=355.2, bsz=8, num_updates=21700, lr=7.91347e-05, gnorm=3.097, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=7396
2023-03-15 16:03:01 - progress_bar.py[line:272] - INFO: epoch 011:   1810 / 2004 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=343.4, nsentences=8, sample_size=343.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=1001.4, ups=2.92, wpb=343.4, bsz=8, num_updates=21710, lr=7.91246e-05, gnorm=2.971, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=7399
2023-03-15 16:03:05 - progress_bar.py[line:272] - INFO: epoch 011:   1820 / 2004 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=350.1, nsentences=8, sample_size=350.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=1032.7, ups=2.95, wpb=350.1, bsz=8, num_updates=21720, lr=7.91145e-05, gnorm=2.948, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=7402
2023-03-15 16:03:08 - progress_bar.py[line:272] - INFO: epoch 011:   1830 / 2004 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=347.9, nsentences=8, sample_size=347.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=1045.1, ups=3, wpb=347.9, bsz=8, num_updates=21730, lr=7.91044e-05, gnorm=2.838, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=7406
2023-03-15 16:03:12 - progress_bar.py[line:272] - INFO: epoch 011:   1840 / 2004 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=348.1, nsentences=8, sample_size=348.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=1012.6, ups=2.91, wpb=348.1, bsz=8, num_updates=21740, lr=7.90943e-05, gnorm=3.209, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=7409
2023-03-15 16:03:15 - progress_bar.py[line:272] - INFO: epoch 011:   1850 / 2004 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=338.2, nsentences=8, sample_size=338.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=988.4, ups=2.92, wpb=338.2, bsz=8, num_updates=21750, lr=7.90843e-05, gnorm=2.86, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=7413
2023-03-15 16:03:18 - progress_bar.py[line:272] - INFO: epoch 011:   1860 / 2004 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=326.2, nsentences=8, sample_size=326.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=962.1, ups=2.95, wpb=326.2, bsz=8, num_updates=21760, lr=7.90742e-05, gnorm=3.127, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=7416
2023-03-15 16:03:22 - progress_bar.py[line:272] - INFO: epoch 011:   1870 / 2004 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=343.6, nsentences=8, sample_size=343.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=1008.2, ups=2.93, wpb=343.6, bsz=8, num_updates=21770, lr=7.90641e-05, gnorm=3.042, clip=0, loss_scale=2048, train_wall=3, gb_free=13.9, wall=7419
2023-03-15 16:03:25 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 16:03:26 - progress_bar.py[line:272] - INFO: epoch 011:   1881 / 2004 loss=0.363, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=327.9, nsentences=8, sample_size=327.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=894.3, ups=2.73, wpb=327.9, bsz=8, num_updates=21780, lr=7.9054e-05, gnorm=2.942, clip=0, loss_scale=2048, train_wall=4, gb_free=15.3, wall=7423
2023-03-15 16:03:29 - progress_bar.py[line:272] - INFO: epoch 011:   1891 / 2004 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=337.8, nsentences=8, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=1007.8, ups=2.98, wpb=337.8, bsz=8, num_updates=21790, lr=7.90439e-05, gnorm=3.109, clip=0, loss_scale=2048, train_wall=3, gb_free=13.8, wall=7426
2023-03-15 16:03:32 - progress_bar.py[line:272] - INFO: epoch 011:   1901 / 2004 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=346.1, nsentences=8, sample_size=346.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=1026.9, ups=2.97, wpb=346.1, bsz=8, num_updates=21800, lr=7.90339e-05, gnorm=2.875, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=7430
2023-03-15 16:03:36 - progress_bar.py[line:272] - INFO: epoch 011:   1911 / 2004 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=334.7, nsentences=8, sample_size=334.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=985.6, ups=2.94, wpb=334.7, bsz=8, num_updates=21810, lr=7.90238e-05, gnorm=2.865, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=7433
2023-03-15 16:03:39 - progress_bar.py[line:272] - INFO: epoch 011:   1921 / 2004 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=323.1, nsentences=8, sample_size=323.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=1039.6, ups=3.22, wpb=323.1, bsz=8, num_updates=21820, lr=7.90137e-05, gnorm=2.821, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=7436
2023-03-15 16:03:42 - progress_bar.py[line:272] - INFO: epoch 011:   1931 / 2004 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=326.7, nsentences=8, sample_size=326.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=1075.6, ups=3.29, wpb=326.7, bsz=8, num_updates=21830, lr=7.90036e-05, gnorm=3.139, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=7439
2023-03-15 16:03:45 - progress_bar.py[line:272] - INFO: epoch 011:   1941 / 2004 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=341.3, nsentences=8, sample_size=341.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=1084.3, ups=3.18, wpb=341.3, bsz=8, num_updates=21840, lr=7.89935e-05, gnorm=2.883, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=7443
2023-03-15 16:03:48 - progress_bar.py[line:272] - INFO: epoch 011:   1951 / 2004 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=340.2, nsentences=8, sample_size=340.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=1094.5, ups=3.22, wpb=340.2, bsz=8, num_updates=21850, lr=7.89834e-05, gnorm=3.194, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=7446
2023-03-15 16:03:51 - progress_bar.py[line:272] - INFO: epoch 011:   1961 / 2004 loss=0.372, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=363.8, nsentences=8, sample_size=363.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=1114.5, ups=3.06, wpb=363.8, bsz=8, num_updates=21860, lr=7.89734e-05, gnorm=3.06, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=7449
2023-03-15 16:03:55 - progress_bar.py[line:272] - INFO: epoch 011:   1971 / 2004 loss=0.387, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=357.7, nsentences=8, sample_size=357.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=1052.2, ups=2.94, wpb=357.7, bsz=8, num_updates=21870, lr=7.89633e-05, gnorm=2.951, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=7452
2023-03-15 16:03:58 - progress_bar.py[line:272] - INFO: epoch 011:   1981 / 2004 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=321.6, nsentences=8, sample_size=321.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=950.8, ups=2.96, wpb=321.6, bsz=8, num_updates=21880, lr=7.89532e-05, gnorm=3, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=7456
2023-03-15 16:04:01 - progress_bar.py[line:272] - INFO: epoch 011:   1991 / 2004 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=360.9, nsentences=8, sample_size=360.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=1068.7, ups=2.96, wpb=360.9, bsz=8, num_updates=21890, lr=7.89431e-05, gnorm=3.02, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=7459
2023-03-15 16:04:05 - progress_bar.py[line:272] - INFO: epoch 011:   2001 / 2004 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=370.4, nsentences=8, sample_size=370.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=1135.3, ups=3.07, wpb=370.4, bsz=8, num_updates=21900, lr=7.8933e-05, gnorm=3.09, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=7462
2023-03-15 16:04:06 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 11 @ 21903 updates
2023-03-15 16:04:06 - trainer.py[line:431] - INFO: Saving checkpoint to ./checkpoints/checkpoint11.pt
2023-03-15 16:04:12 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./checkpoints/checkpoint11.pt
2023-03-15 16:04:14 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./checkpoints/checkpoint11.pt (epoch 11 @ 21903 updates, score None) (writing took 8.424878757447004 seconds)
2023-03-15 16:04:14 - train.py[line:332] - INFO: end of epoch 11 (average epoch stats below)
2023-03-15 16:04:14 - progress_bar.py[line:282] - INFO: epoch 011 | loss 0.407 | loss_v1 0 | loss_v2 0 | nll_loss 0.407 | ntokens 345.219 | nsentences 7.999 | sample_size 345.219 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.33 | wps 1039.4 | ups 3.01 | wpb 345.2 | bsz 8 | num_updates 21903 | lr 7.893e-05 | gnorm 3.028 | clip 0 | loss_scale 2048 | train_wall 642 | gb_free 13.9 | wall 7472
2023-03-15 16:04:14 - trainer.py[line:639] - INFO: loading train data for epoch 12
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 row count 8015 total row count 8015
slice_id 0 seek offset 0
2023-03-15 16:04:15 - trainer.py[line:703] - INFO: begin training epoch 12
2023-03-15 16:04:15 - train.py[line:305] - INFO: Start iterating over samples
2023-03-15 16:04:16 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 16:04:18 - progress_bar.py[line:272] - INFO: epoch 012:      8 / 2004 loss=0.438, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=375.9, nsentences=8, sample_size=375.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=286.1, ups=0.76, wpb=375.9, bsz=8, num_updates=21910, lr=7.8923e-05, gnorm=3.233, clip=0, loss_scale=2048, train_wall=4, gb_free=15, wall=7475
2023-03-15 16:04:21 - progress_bar.py[line:272] - INFO: epoch 012:     18 / 2004 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=330.2, nsentences=8, sample_size=330.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=1006, ups=3.05, wpb=330.2, bsz=8, num_updates=21920, lr=7.89129e-05, gnorm=3.049, clip=0, loss_scale=2048, train_wall=3, gb_free=13.9, wall=7479
2023-03-15 16:04:24 - progress_bar.py[line:272] - INFO: epoch 012:     28 / 2004 loss=0.409, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=347.2, nsentences=8, sample_size=347.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=1110.8, ups=3.2, wpb=347.2, bsz=8, num_updates=21930, lr=7.89028e-05, gnorm=3.209, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=7482
2023-03-15 16:04:27 - progress_bar.py[line:272] - INFO: epoch 012:     38 / 2004 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=348.1, nsentences=8, sample_size=348.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=1144.6, ups=3.29, wpb=348.1, bsz=8, num_updates=21940, lr=7.88927e-05, gnorm=3.058, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=7485
2023-03-15 16:04:30 - progress_bar.py[line:272] - INFO: epoch 012:     48 / 2004 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=348.2, nsentences=8, sample_size=348.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=1111.7, ups=3.19, wpb=348.2, bsz=8, num_updates=21950, lr=7.88826e-05, gnorm=3.037, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=7488
2023-03-15 16:04:34 - progress_bar.py[line:272] - INFO: epoch 012:     58 / 2004 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=359, nsentences=8, sample_size=359, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=1152, ups=3.21, wpb=359, bsz=8, num_updates=21960, lr=7.88726e-05, gnorm=3.051, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=7491
2023-03-15 16:04:37 - progress_bar.py[line:272] - INFO: epoch 012:     68 / 2004 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=334, nsentences=8, sample_size=334, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=1052.9, ups=3.15, wpb=334, bsz=8, num_updates=21970, lr=7.88625e-05, gnorm=3.045, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=7494
2023-03-15 16:04:40 - progress_bar.py[line:272] - INFO: epoch 012:     78 / 2004 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=334.8, nsentences=8, sample_size=334.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=996.3, ups=2.98, wpb=334.8, bsz=8, num_updates=21980, lr=7.88524e-05, gnorm=2.968, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=7498
2023-03-15 16:04:41 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 16:04:44 - progress_bar.py[line:272] - INFO: epoch 012:     89 / 2004 loss=0.384, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=350, nsentences=8, sample_size=350, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=955.9, ups=2.73, wpb=350, bsz=8, num_updates=21990, lr=7.88423e-05, gnorm=3.031, clip=0, loss_scale=1024, train_wall=4, gb_free=14.7, wall=7501
2023-03-15 16:04:47 - progress_bar.py[line:272] - INFO: epoch 012:     99 / 2004 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=380.8, nsentences=8, sample_size=380.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=1132.1, ups=2.97, wpb=380.8, bsz=8, num_updates=22000, lr=7.88322e-05, gnorm=3.148, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=7505
2023-03-15 16:04:51 - progress_bar.py[line:272] - INFO: epoch 012:    109 / 2004 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=341.4, nsentences=8, sample_size=341.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=1006.2, ups=2.95, wpb=341.4, bsz=8, num_updates=22010, lr=7.88222e-05, gnorm=2.988, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=7508
2023-03-15 16:04:54 - progress_bar.py[line:272] - INFO: epoch 012:    119 / 2004 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=347.4, nsentences=8, sample_size=347.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=1018.1, ups=2.93, wpb=347.4, bsz=8, num_updates=22020, lr=7.88121e-05, gnorm=3.074, clip=0, loss_scale=1024, train_wall=3, gb_free=13.8, wall=7512
2023-03-15 16:04:57 - progress_bar.py[line:272] - INFO: epoch 012:    129 / 2004 loss=0.387, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=333.8, nsentences=8, sample_size=333.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=981.3, ups=2.94, wpb=333.8, bsz=8, num_updates=22030, lr=7.8802e-05, gnorm=3.175, clip=0, loss_scale=1024, train_wall=3, gb_free=14, wall=7515
2023-03-15 16:05:01 - progress_bar.py[line:272] - INFO: epoch 012:    139 / 2004 loss=0.389, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=329.9, nsentences=8, sample_size=329.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=969.1, ups=2.94, wpb=329.9, bsz=8, num_updates=22040, lr=7.87919e-05, gnorm=3.046, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=7518
2023-03-15 16:05:04 - progress_bar.py[line:272] - INFO: epoch 012:    149 / 2004 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=322.7, nsentences=8, sample_size=322.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=941.5, ups=2.92, wpb=322.7, bsz=8, num_updates=22050, lr=7.87818e-05, gnorm=3.058, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=7522
2023-03-15 16:05:08 - progress_bar.py[line:272] - INFO: epoch 012:    159 / 2004 loss=0.438, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=377.6, nsentences=8, sample_size=377.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=1077.6, ups=2.85, wpb=377.6, bsz=8, num_updates=22060, lr=7.87717e-05, gnorm=3.178, clip=0, loss_scale=1024, train_wall=3, gb_free=14.1, wall=7525
2023-03-15 16:05:11 - progress_bar.py[line:272] - INFO: epoch 012:    169 / 2004 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=326.8, nsentences=8, sample_size=326.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=961.7, ups=2.94, wpb=326.8, bsz=8, num_updates=22070, lr=7.87617e-05, gnorm=3.094, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=7529
2023-03-15 16:05:14 - progress_bar.py[line:272] - INFO: epoch 012:    179 / 2004 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=323.9, nsentences=8, sample_size=323.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=958.4, ups=2.96, wpb=323.9, bsz=8, num_updates=22080, lr=7.87516e-05, gnorm=3.128, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=7532
2023-03-15 16:05:18 - progress_bar.py[line:272] - INFO: epoch 012:    189 / 2004 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=338.3, nsentences=8, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=992.4, ups=2.93, wpb=338.3, bsz=8, num_updates=22090, lr=7.87415e-05, gnorm=2.807, clip=0, loss_scale=1024, train_wall=3, gb_free=13.9, wall=7535
2023-03-15 16:05:21 - progress_bar.py[line:272] - INFO: epoch 012:    199 / 2004 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=328.9, nsentences=8, sample_size=328.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=982.8, ups=2.99, wpb=328.9, bsz=8, num_updates=22100, lr=7.87314e-05, gnorm=2.84, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=7539
2023-03-15 16:05:25 - progress_bar.py[line:272] - INFO: epoch 012:    209 / 2004 loss=0.37, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=344, nsentences=8, sample_size=344, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=985.5, ups=2.86, wpb=344, bsz=8, num_updates=22110, lr=7.87213e-05, gnorm=2.995, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=7542
2023-03-15 16:05:28 - progress_bar.py[line:272] - INFO: epoch 012:    219 / 2004 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=327.8, nsentences=8, sample_size=327.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=953.5, ups=2.91, wpb=327.8, bsz=8, num_updates=22120, lr=7.87113e-05, gnorm=2.903, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=7546
2023-03-15 16:05:32 - progress_bar.py[line:272] - INFO: epoch 012:    229 / 2004 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=337.7, nsentences=8, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=969.2, ups=2.87, wpb=337.7, bsz=8, num_updates=22130, lr=7.87012e-05, gnorm=2.813, clip=0, loss_scale=2048, train_wall=3, gb_free=13.5, wall=7549
2023-03-15 16:05:35 - progress_bar.py[line:272] - INFO: epoch 012:    239 / 2004 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=384.6, nsentences=8, sample_size=384.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=1132, ups=2.94, wpb=384.6, bsz=8, num_updates=22140, lr=7.86911e-05, gnorm=2.861, clip=0, loss_scale=2048, train_wall=3, gb_free=13.8, wall=7553
2023-03-15 16:05:38 - progress_bar.py[line:272] - INFO: epoch 012:    249 / 2004 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=346.2, nsentences=8, sample_size=346.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=1015.1, ups=2.93, wpb=346.2, bsz=8, num_updates=22150, lr=7.8681e-05, gnorm=2.958, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=7556
2023-03-15 16:05:42 - progress_bar.py[line:272] - INFO: epoch 012:    259 / 2004 loss=0.38, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=339.1, nsentences=8, sample_size=339.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=993.5, ups=2.93, wpb=339.1, bsz=8, num_updates=22160, lr=7.86709e-05, gnorm=3.07, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=7559
2023-03-15 16:05:45 - progress_bar.py[line:272] - INFO: epoch 012:    269 / 2004 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=344.2, nsentences=8, sample_size=344.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=1021, ups=2.97, wpb=344.2, bsz=8, num_updates=22170, lr=7.86609e-05, gnorm=3.192, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=7563
2023-03-15 16:05:48 - progress_bar.py[line:272] - INFO: epoch 012:    279 / 2004 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=341.6, nsentences=8, sample_size=341.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=1079.6, ups=3.16, wpb=341.6, bsz=8, num_updates=22180, lr=7.86508e-05, gnorm=3.109, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=7566
2023-03-15 16:05:52 - progress_bar.py[line:272] - INFO: epoch 012:    289 / 2004 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=345.9, nsentences=8, sample_size=345.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=1029.8, ups=2.98, wpb=345.9, bsz=8, num_updates=22190, lr=7.86407e-05, gnorm=2.947, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=7569
2023-03-15 16:05:55 - progress_bar.py[line:272] - INFO: epoch 012:    299 / 2004 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=380.7, nsentences=8, sample_size=380.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=1101.8, ups=2.89, wpb=380.7, bsz=8, num_updates=22200, lr=7.86306e-05, gnorm=2.949, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=7573
2023-03-15 16:05:59 - progress_bar.py[line:272] - INFO: epoch 012:    309 / 2004 loss=0.37, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=344.3, nsentences=8, sample_size=344.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=1009, ups=2.93, wpb=344.3, bsz=8, num_updates=22210, lr=7.86205e-05, gnorm=3.042, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=7576
2023-03-15 16:06:02 - progress_bar.py[line:272] - INFO: epoch 012:    319 / 2004 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=344.9, nsentences=8, sample_size=344.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=1044.3, ups=3.03, wpb=344.9, bsz=8, num_updates=22220, lr=7.86105e-05, gnorm=2.992, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=7580
2023-03-15 16:06:05 - progress_bar.py[line:272] - INFO: epoch 012:    329 / 2004 loss=0.375, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=331.9, nsentences=8, sample_size=331.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=1045.9, ups=3.15, wpb=331.9, bsz=8, num_updates=22230, lr=7.86004e-05, gnorm=2.993, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=7583
2023-03-15 16:06:08 - progress_bar.py[line:272] - INFO: epoch 012:    339 / 2004 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=355.8, nsentences=8, sample_size=355.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=1100.5, ups=3.09, wpb=355.8, bsz=8, num_updates=22240, lr=7.85903e-05, gnorm=3, clip=0, loss_scale=4096, train_wall=3, gb_free=13.6, wall=7586
2023-03-15 16:06:09 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 16:06:12 - progress_bar.py[line:272] - INFO: epoch 012:    350 / 2004 loss=0.375, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=347.1, nsentences=8, sample_size=347.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=968.3, ups=2.79, wpb=347.1, bsz=8, num_updates=22250, lr=7.85802e-05, gnorm=3.09, clip=0, loss_scale=2048, train_wall=4, gb_free=15.1, wall=7590
2023-03-15 16:06:15 - progress_bar.py[line:272] - INFO: epoch 012:    360 / 2004 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=349.9, nsentences=8, sample_size=349.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=1018.8, ups=2.91, wpb=349.9, bsz=8, num_updates=22260, lr=7.85701e-05, gnorm=3.362, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=7593
2023-03-15 16:06:19 - progress_bar.py[line:272] - INFO: epoch 012:    370 / 2004 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=337.5, nsentences=8, sample_size=337.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=971.7, ups=2.88, wpb=337.5, bsz=8, num_updates=22270, lr=7.85601e-05, gnorm=2.943, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=7596
2023-03-15 16:06:22 - progress_bar.py[line:272] - INFO: epoch 012:    380 / 2004 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=316.2, nsentences=8, sample_size=316.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=927.1, ups=2.93, wpb=316.2, bsz=8, num_updates=22280, lr=7.855e-05, gnorm=3.237, clip=0, loss_scale=2048, train_wall=3, gb_free=14, wall=7600
2023-03-15 16:06:26 - progress_bar.py[line:272] - INFO: epoch 012:    390 / 2004 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=354.3, nsentences=8, sample_size=354.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=1016.2, ups=2.87, wpb=354.3, bsz=8, num_updates=22290, lr=7.85399e-05, gnorm=3.079, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=7603
2023-03-15 16:06:29 - progress_bar.py[line:272] - INFO: epoch 012:    400 / 2004 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=358.4, nsentences=8, sample_size=358.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=1057, ups=2.95, wpb=358.4, bsz=8, num_updates=22300, lr=7.85298e-05, gnorm=2.975, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=7607
2023-03-15 16:06:33 - progress_bar.py[line:272] - INFO: epoch 012:    410 / 2004 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=356, nsentences=8, sample_size=356, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=1029.6, ups=2.89, wpb=356, bsz=8, num_updates=22310, lr=7.85197e-05, gnorm=3.013, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=7610
2023-03-15 16:06:36 - progress_bar.py[line:272] - INFO: epoch 012:    420 / 2004 loss=0.384, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=337.1, nsentences=8, sample_size=337.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=977.1, ups=2.9, wpb=337.1, bsz=8, num_updates=22320, lr=7.85096e-05, gnorm=3.164, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=7614
2023-03-15 16:06:39 - progress_bar.py[line:272] - INFO: epoch 012:    430 / 2004 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=335.9, nsentences=8, sample_size=335.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=988.2, ups=2.94, wpb=335.9, bsz=8, num_updates=22330, lr=7.84996e-05, gnorm=2.807, clip=0, loss_scale=2048, train_wall=3, gb_free=13.9, wall=7617
2023-03-15 16:06:43 - progress_bar.py[line:272] - INFO: epoch 012:    440 / 2004 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=364.4, nsentences=8, sample_size=364.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=1085.9, ups=2.98, wpb=364.4, bsz=8, num_updates=22340, lr=7.84895e-05, gnorm=3.179, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=7620
2023-03-15 16:06:46 - progress_bar.py[line:272] - INFO: epoch 012:    450 / 2004 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=364.6, nsentences=8, sample_size=364.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=1134.1, ups=3.11, wpb=364.6, bsz=8, num_updates=22350, lr=7.84794e-05, gnorm=3.2, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=7624
2023-03-15 16:06:49 - progress_bar.py[line:272] - INFO: epoch 012:    460 / 2004 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=392.3, nsentences=8, sample_size=392.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=1244.9, ups=3.17, wpb=392.3, bsz=8, num_updates=22360, lr=7.84693e-05, gnorm=3.175, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=7627
2023-03-15 16:06:52 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 16:06:53 - progress_bar.py[line:272] - INFO: epoch 012:    471 / 2004 loss=0.463, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=354.1, nsentences=8, sample_size=354.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=1016.4, ups=2.87, wpb=354.1, bsz=8, num_updates=22370, lr=7.84592e-05, gnorm=3.421, clip=10, loss_scale=2048, train_wall=3, gb_free=14.5, wall=7630
2023-03-15 16:06:53 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 16:06:56 - progress_bar.py[line:272] - INFO: epoch 012:    482 / 2004 loss=0.369, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=341.9, nsentences=8, sample_size=341.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=931.9, ups=2.73, wpb=341.9, bsz=8, num_updates=22380, lr=7.84492e-05, gnorm=3.056, clip=0, loss_scale=1024, train_wall=4, gb_free=15, wall=7634
2023-03-15 16:07:00 - progress_bar.py[line:272] - INFO: epoch 012:    492 / 2004 loss=0.369, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=376.1, nsentences=8, sample_size=376.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=1098.5, ups=2.92, wpb=376.1, bsz=8, num_updates=22390, lr=7.84391e-05, gnorm=3.093, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=7637
2023-03-15 16:07:03 - progress_bar.py[line:272] - INFO: epoch 012:    502 / 2004 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=362.2, nsentences=8, sample_size=362.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=1052, ups=2.9, wpb=362.2, bsz=8, num_updates=22400, lr=7.8429e-05, gnorm=2.978, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=7641
2023-03-15 16:07:07 - progress_bar.py[line:272] - INFO: epoch 012:    512 / 2004 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=347.2, nsentences=8, sample_size=347.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=1018.7, ups=2.93, wpb=347.2, bsz=8, num_updates=22410, lr=7.84189e-05, gnorm=3.262, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=7644
2023-03-15 16:07:10 - progress_bar.py[line:272] - INFO: epoch 012:    522 / 2004 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=377.6, nsentences=8, sample_size=377.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=1111.7, ups=2.94, wpb=377.6, bsz=8, num_updates=22420, lr=7.84088e-05, gnorm=3.068, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=7648
2023-03-15 16:07:13 - progress_bar.py[line:272] - INFO: epoch 012:    532 / 2004 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=385.3, nsentences=8, sample_size=385.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=1123.3, ups=2.92, wpb=385.3, bsz=8, num_updates=22430, lr=7.83988e-05, gnorm=3.119, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=7651
2023-03-15 16:07:17 - progress_bar.py[line:272] - INFO: epoch 012:    542 / 2004 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=374.1, nsentences=8, sample_size=374.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=1056.3, ups=2.82, wpb=374.1, bsz=8, num_updates=22440, lr=7.83887e-05, gnorm=2.873, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=7655
2023-03-15 16:07:20 - progress_bar.py[line:272] - INFO: epoch 012:    552 / 2004 loss=0.38, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=362.2, nsentences=8, sample_size=362.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=1023.3, ups=2.83, wpb=362.2, bsz=8, num_updates=22450, lr=7.83786e-05, gnorm=3.048, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=7658
2023-03-15 16:07:24 - progress_bar.py[line:272] - INFO: epoch 012:    562 / 2004 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=370.4, nsentences=8, sample_size=370.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=1064.2, ups=2.87, wpb=370.4, bsz=8, num_updates=22460, lr=7.83685e-05, gnorm=3.055, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=7662
2023-03-15 16:07:27 - progress_bar.py[line:272] - INFO: epoch 012:    572 / 2004 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=367.1, nsentences=8, sample_size=367.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=1062.3, ups=2.89, wpb=367.1, bsz=8, num_updates=22470, lr=7.83584e-05, gnorm=2.828, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=7665
2023-03-15 16:07:31 - progress_bar.py[line:272] - INFO: epoch 012:    582 / 2004 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=355.9, nsentences=8, sample_size=355.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=1012.3, ups=2.84, wpb=355.9, bsz=8, num_updates=22480, lr=7.83484e-05, gnorm=2.968, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=7669
2023-03-15 16:07:34 - progress_bar.py[line:272] - INFO: epoch 012:    592 / 2004 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=338.3, nsentences=8, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=993.5, ups=2.94, wpb=338.3, bsz=8, num_updates=22490, lr=7.83383e-05, gnorm=2.834, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=7672
2023-03-15 16:07:38 - progress_bar.py[line:272] - INFO: epoch 012:    602 / 2004 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=358.5, nsentences=8, sample_size=358.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=1032.6, ups=2.88, wpb=358.5, bsz=8, num_updates=22500, lr=7.83282e-05, gnorm=2.862, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=7675
2023-03-15 16:07:41 - progress_bar.py[line:272] - INFO: epoch 012:    612 / 2004 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=356.4, nsentences=8, sample_size=356.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=1006.9, ups=2.83, wpb=356.4, bsz=8, num_updates=22510, lr=7.83181e-05, gnorm=3.06, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=7679
2023-03-15 16:07:45 - progress_bar.py[line:272] - INFO: epoch 012:    622 / 2004 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=357.3, nsentences=8, sample_size=357.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=1040, ups=2.91, wpb=357.3, bsz=8, num_updates=22520, lr=7.8308e-05, gnorm=2.964, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=7682
2023-03-15 16:07:48 - progress_bar.py[line:272] - INFO: epoch 012:    632 / 2004 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=342.4, nsentences=8, sample_size=342.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=986.7, ups=2.88, wpb=342.4, bsz=8, num_updates=22530, lr=7.82979e-05, gnorm=2.985, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=7686
2023-03-15 16:07:52 - progress_bar.py[line:272] - INFO: epoch 012:    642 / 2004 loss=0.38, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=340.3, nsentences=8, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=1001.6, ups=2.94, wpb=340.3, bsz=8, num_updates=22540, lr=7.82879e-05, gnorm=3.269, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=7689
2023-03-15 16:07:55 - progress_bar.py[line:272] - INFO: epoch 012:    652 / 2004 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=330.2, nsentences=8, sample_size=330.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=986.5, ups=2.99, wpb=330.2, bsz=8, num_updates=22550, lr=7.82778e-05, gnorm=2.898, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=7693
2023-03-15 16:07:58 - progress_bar.py[line:272] - INFO: epoch 012:    662 / 2004 loss=0.363, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=322.9, nsentences=8, sample_size=322.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=963.8, ups=2.98, wpb=322.9, bsz=8, num_updates=22560, lr=7.82677e-05, gnorm=3.213, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=7696
2023-03-15 16:08:02 - progress_bar.py[line:272] - INFO: epoch 012:    672 / 2004 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=335.3, nsentences=8, sample_size=335.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=979.5, ups=2.92, wpb=335.3, bsz=8, num_updates=22570, lr=7.82576e-05, gnorm=2.86, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=7699
2023-03-15 16:08:05 - progress_bar.py[line:272] - INFO: epoch 012:    682 / 2004 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=346.4, nsentences=8, sample_size=346.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=1017.5, ups=2.94, wpb=346.4, bsz=8, num_updates=22580, lr=7.82475e-05, gnorm=2.902, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=7703
2023-03-15 16:08:09 - progress_bar.py[line:272] - INFO: epoch 012:    692 / 2004 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=353.3, nsentences=8, sample_size=353.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=1033.2, ups=2.92, wpb=353.3, bsz=8, num_updates=22590, lr=7.82375e-05, gnorm=3.022, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=7706
2023-03-15 16:08:12 - progress_bar.py[line:272] - INFO: epoch 012:    702 / 2004 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=335, nsentences=8, sample_size=335, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=982.3, ups=2.93, wpb=335, bsz=8, num_updates=22600, lr=7.82274e-05, gnorm=2.951, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=7710
2023-03-15 16:08:15 - progress_bar.py[line:272] - INFO: epoch 012:    712 / 2004 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=318.9, nsentences=8, sample_size=318.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=937.6, ups=2.94, wpb=318.9, bsz=8, num_updates=22610, lr=7.82173e-05, gnorm=2.947, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=7713
2023-03-15 16:08:19 - progress_bar.py[line:272] - INFO: epoch 012:    722 / 2004 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=368.8, nsentences=8, sample_size=368.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=1070.7, ups=2.9, wpb=368.8, bsz=8, num_updates=22620, lr=7.82072e-05, gnorm=3.046, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=7716
2023-03-15 16:08:22 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 16:08:23 - progress_bar.py[line:272] - INFO: epoch 012:    733 / 2004 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=342, nsentences=8, sample_size=342, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=910.4, ups=2.66, wpb=342, bsz=8, num_updates=22630, lr=7.81971e-05, gnorm=2.972, clip=0, loss_scale=2048, train_wall=4, gb_free=15.3, wall=7720
2023-03-15 16:08:26 - progress_bar.py[line:272] - INFO: epoch 012:    743 / 2004 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=348.7, nsentences=8, sample_size=348.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=1002.8, ups=2.88, wpb=348.7, bsz=8, num_updates=22640, lr=7.81871e-05, gnorm=3.071, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=7724
2023-03-15 16:08:30 - progress_bar.py[line:272] - INFO: epoch 012:    753 / 2004 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=338.2, nsentences=8, sample_size=338.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=975.1, ups=2.88, wpb=338.2, bsz=8, num_updates=22650, lr=7.8177e-05, gnorm=3.203, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=7727
2023-03-15 16:08:33 - progress_bar.py[line:272] - INFO: epoch 012:    763 / 2004 loss=0.392, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=353.4, nsentences=8, sample_size=353.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=1015.6, ups=2.87, wpb=353.4, bsz=8, num_updates=22660, lr=7.81669e-05, gnorm=3.101, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=7731
2023-03-15 16:08:37 - progress_bar.py[line:272] - INFO: epoch 012:    773 / 2004 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=398.9, nsentences=8, sample_size=398.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=1136.1, ups=2.85, wpb=398.9, bsz=8, num_updates=22670, lr=7.81568e-05, gnorm=3.064, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=7734
2023-03-15 16:08:41 - progress_bar.py[line:272] - INFO: epoch 012:    783 / 2004 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=330.3, nsentences=8, sample_size=330.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=734.5, ups=2.22, wpb=330.3, bsz=8, num_updates=22680, lr=7.81467e-05, gnorm=3.061, clip=0, loss_scale=2048, train_wall=4, gb_free=14.5, wall=7739
2023-03-15 16:08:44 - progress_bar.py[line:272] - INFO: epoch 012:    793 / 2004 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=319.8, nsentences=8, sample_size=319.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=946.6, ups=2.96, wpb=319.8, bsz=8, num_updates=22690, lr=7.81367e-05, gnorm=2.835, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=7742
2023-03-15 16:08:48 - progress_bar.py[line:272] - INFO: epoch 012:    803 / 2004 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=336, nsentences=8, sample_size=336, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=980.4, ups=2.92, wpb=336, bsz=8, num_updates=22700, lr=7.81266e-05, gnorm=3.256, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=7745
2023-03-15 16:08:51 - progress_bar.py[line:272] - INFO: epoch 012:    813 / 2004 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=341.4, nsentences=8, sample_size=341.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=992, ups=2.91, wpb=341.4, bsz=8, num_updates=22710, lr=7.81165e-05, gnorm=3.097, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=7749
2023-03-15 16:08:52 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 16:08:55 - progress_bar.py[line:272] - INFO: epoch 012:    824 / 2004 loss=0.372, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=355.7, nsentences=8, sample_size=355.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=938.8, ups=2.64, wpb=355.7, bsz=8, num_updates=22720, lr=7.81064e-05, gnorm=3.233, clip=0, loss_scale=1024, train_wall=4, gb_free=15.3, wall=7753
2023-03-15 16:08:58 - progress_bar.py[line:272] - INFO: epoch 012:    834 / 2004 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=341.1, nsentences=8, sample_size=341.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=1006.7, ups=2.95, wpb=341.1, bsz=8, num_updates=22730, lr=7.80963e-05, gnorm=2.977, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=7756
2023-03-15 16:09:02 - progress_bar.py[line:272] - INFO: epoch 012:    844 / 2004 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=358.9, nsentences=8, sample_size=358.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=1055, ups=2.94, wpb=358.9, bsz=8, num_updates=22740, lr=7.80863e-05, gnorm=3.069, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=7759
2023-03-15 16:09:05 - progress_bar.py[line:272] - INFO: epoch 012:    854 / 2004 loss=0.387, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=359.8, nsentences=8, sample_size=359.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=1045.9, ups=2.91, wpb=359.8, bsz=8, num_updates=22750, lr=7.80762e-05, gnorm=3.331, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=7763
2023-03-15 16:09:09 - progress_bar.py[line:272] - INFO: epoch 012:    864 / 2004 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=350.1, nsentences=8, sample_size=350.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=1005.2, ups=2.87, wpb=350.1, bsz=8, num_updates=22760, lr=7.80661e-05, gnorm=2.984, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=7766
2023-03-15 16:09:12 - progress_bar.py[line:272] - INFO: epoch 012:    874 / 2004 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=355.6, nsentences=8, sample_size=355.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=1042.9, ups=2.93, wpb=355.6, bsz=8, num_updates=22770, lr=7.8056e-05, gnorm=3.128, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=7770
2023-03-15 16:09:16 - progress_bar.py[line:272] - INFO: epoch 012:    884 / 2004 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=316.2, nsentences=8, sample_size=316.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=930.9, ups=2.94, wpb=316.2, bsz=8, num_updates=22780, lr=7.80459e-05, gnorm=2.927, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=7773
2023-03-15 16:09:19 - progress_bar.py[line:272] - INFO: epoch 012:    894 / 2004 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=312, nsentences=8, sample_size=312, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=914.4, ups=2.93, wpb=312, bsz=8, num_updates=22790, lr=7.80358e-05, gnorm=2.97, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=7777
2023-03-15 16:09:23 - progress_bar.py[line:272] - INFO: epoch 012:    904 / 2004 loss=0.389, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=377.7, nsentences=8, sample_size=377.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=1073.4, ups=2.84, wpb=377.7, bsz=8, num_updates=22800, lr=7.80258e-05, gnorm=3.149, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=7780
2023-03-15 16:09:26 - progress_bar.py[line:272] - INFO: epoch 012:    914 / 2004 loss=0.384, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=374.9, nsentences=8, sample_size=374.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=1089.2, ups=2.91, wpb=374.9, bsz=8, num_updates=22810, lr=7.80157e-05, gnorm=3.16, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=7784
2023-03-15 16:09:29 - progress_bar.py[line:272] - INFO: epoch 012:    924 / 2004 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=325.9, nsentences=8, sample_size=325.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=960.4, ups=2.95, wpb=325.9, bsz=8, num_updates=22820, lr=7.80056e-05, gnorm=3.2, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=7787
2023-03-15 16:09:33 - progress_bar.py[line:272] - INFO: epoch 012:    934 / 2004 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=340.5, nsentences=8, sample_size=340.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=995.5, ups=2.92, wpb=340.5, bsz=8, num_updates=22830, lr=7.79955e-05, gnorm=2.935, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=7790
2023-03-15 16:09:36 - progress_bar.py[line:272] - INFO: epoch 012:    944 / 2004 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=370, nsentences=8, sample_size=370, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=1081.2, ups=2.92, wpb=370, bsz=8, num_updates=22840, lr=7.79854e-05, gnorm=3.007, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=7794
2023-03-15 16:09:40 - progress_bar.py[line:272] - INFO: epoch 012:    954 / 2004 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=335, nsentences=8, sample_size=335, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=986.1, ups=2.94, wpb=335, bsz=8, num_updates=22850, lr=7.79754e-05, gnorm=2.996, clip=0, loss_scale=2048, train_wall=3, gb_free=13.8, wall=7797
2023-03-15 16:09:43 - progress_bar.py[line:272] - INFO: epoch 012:    964 / 2004 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=382.1, nsentences=8, sample_size=382.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=1119.7, ups=2.93, wpb=382.1, bsz=8, num_updates=22860, lr=7.79653e-05, gnorm=3.219, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=7801
2023-03-15 16:09:46 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 16:09:47 - progress_bar.py[line:272] - INFO: epoch 012:    975 / 2004 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=330.8, nsentences=8, sample_size=330.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=879.3, ups=2.66, wpb=330.8, bsz=8, num_updates=22870, lr=7.79552e-05, gnorm=3.049, clip=0, loss_scale=1024, train_wall=4, gb_free=15.1, wall=7804
2023-03-15 16:09:50 - progress_bar.py[line:272] - INFO: epoch 012:    985 / 2004 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=321.4, nsentences=8, sample_size=321.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=951.7, ups=2.96, wpb=321.4, bsz=8, num_updates=22880, lr=7.79451e-05, gnorm=3.155, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=7808
2023-03-15 16:09:54 - progress_bar.py[line:272] - INFO: epoch 012:    995 / 2004 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=393.7, nsentences=8, sample_size=393.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=1152.8, ups=2.93, wpb=393.7, bsz=8, num_updates=22890, lr=7.7935e-05, gnorm=3.202, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=7811
2023-03-15 16:09:57 - progress_bar.py[line:272] - INFO: epoch 012:   1005 / 2004 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=308.6, nsentences=8, sample_size=308.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=893.5, ups=2.9, wpb=308.6, bsz=8, num_updates=22900, lr=7.7925e-05, gnorm=2.929, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=7815
2023-03-15 16:10:00 - progress_bar.py[line:272] - INFO: epoch 012:   1015 / 2004 loss=0.372, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=339.8, nsentences=8, sample_size=339.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=994.5, ups=2.93, wpb=339.8, bsz=8, num_updates=22910, lr=7.79149e-05, gnorm=3.035, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=7818
2023-03-15 16:10:04 - progress_bar.py[line:272] - INFO: epoch 012:   1025 / 2004 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=329.4, nsentences=8, sample_size=329.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=969.5, ups=2.94, wpb=329.4, bsz=8, num_updates=22920, lr=7.79048e-05, gnorm=2.961, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=7821
2023-03-15 16:10:07 - progress_bar.py[line:272] - INFO: epoch 012:   1035 / 2004 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=315, nsentences=8, sample_size=315, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=910.4, ups=2.89, wpb=315, bsz=8, num_updates=22930, lr=7.78947e-05, gnorm=3.193, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=7825
2023-03-15 16:10:11 - progress_bar.py[line:272] - INFO: epoch 012:   1045 / 2004 loss=0.38, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=366.9, nsentences=8, sample_size=366.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=1033.9, ups=2.82, wpb=366.9, bsz=8, num_updates=22940, lr=7.78846e-05, gnorm=3.118, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=7828
2023-03-15 16:10:14 - progress_bar.py[line:272] - INFO: epoch 012:   1055 / 2004 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=365.4, nsentences=8, sample_size=365.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=1057.1, ups=2.89, wpb=365.4, bsz=8, num_updates=22950, lr=7.78746e-05, gnorm=3.203, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=7832
2023-03-15 16:10:18 - progress_bar.py[line:272] - INFO: epoch 012:   1065 / 2004 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=322.7, nsentences=7.8, sample_size=322.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=958.2, ups=2.97, wpb=322.7, bsz=7.8, num_updates=22960, lr=7.78645e-05, gnorm=3.482, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=7835
2023-03-15 16:10:21 - progress_bar.py[line:272] - INFO: epoch 012:   1075 / 2004 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=361.8, nsentences=8, sample_size=361.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=1050.3, ups=2.9, wpb=361.8, bsz=8, num_updates=22970, lr=7.78544e-05, gnorm=3.08, clip=0, loss_scale=1024, train_wall=3, gb_free=14.1, wall=7839
2023-03-15 16:10:25 - progress_bar.py[line:272] - INFO: epoch 012:   1085 / 2004 loss=0.375, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=369, nsentences=8, sample_size=369, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=1076.5, ups=2.92, wpb=369, bsz=8, num_updates=22980, lr=7.78443e-05, gnorm=3.07, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=7842
2023-03-15 16:10:28 - progress_bar.py[line:272] - INFO: epoch 012:   1095 / 2004 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=323.9, nsentences=8, sample_size=323.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=942.1, ups=2.91, wpb=323.9, bsz=8, num_updates=22990, lr=7.78342e-05, gnorm=3.19, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=7846
2023-03-15 16:10:31 - progress_bar.py[line:272] - INFO: epoch 012:   1105 / 2004 loss=0.372, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=375, nsentences=8, sample_size=375, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=1078.1, ups=2.87, wpb=375, bsz=8, num_updates=23000, lr=7.78241e-05, gnorm=3.067, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=7849
2023-03-15 16:10:35 - progress_bar.py[line:272] - INFO: epoch 012:   1115 / 2004 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=341.2, nsentences=8, sample_size=341.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=992.2, ups=2.91, wpb=341.2, bsz=8, num_updates=23010, lr=7.78141e-05, gnorm=2.918, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=7853
2023-03-15 16:10:38 - progress_bar.py[line:272] - INFO: epoch 012:   1125 / 2004 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=321, nsentences=8, sample_size=321, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=926.9, ups=2.89, wpb=321, bsz=8, num_updates=23020, lr=7.7804e-05, gnorm=2.957, clip=0, loss_scale=2048, train_wall=3, gb_free=13.8, wall=7856
2023-03-15 16:10:42 - progress_bar.py[line:272] - INFO: epoch 012:   1135 / 2004 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=388.3, nsentences=8, sample_size=388.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=1091.8, ups=2.81, wpb=388.3, bsz=8, num_updates=23030, lr=7.77939e-05, gnorm=3.14, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=7860
2023-03-15 16:10:45 - progress_bar.py[line:272] - INFO: epoch 012:   1145 / 2004 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=335.4, nsentences=8, sample_size=335.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=978.8, ups=2.92, wpb=335.4, bsz=8, num_updates=23040, lr=7.77838e-05, gnorm=3.057, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=7863
2023-03-15 16:10:49 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 16:10:49 - progress_bar.py[line:272] - INFO: epoch 012:   1156 / 2004 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=400, nsentences=8, sample_size=400, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=1047.6, ups=2.62, wpb=400, bsz=8, num_updates=23050, lr=7.77737e-05, gnorm=3.031, clip=0, loss_scale=1024, train_wall=4, gb_free=14.5, wall=7867
2023-03-15 16:10:53 - progress_bar.py[line:272] - INFO: epoch 012:   1166 / 2004 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=351.7, nsentences=8, sample_size=351.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=1012.9, ups=2.88, wpb=351.7, bsz=8, num_updates=23060, lr=7.77637e-05, gnorm=2.993, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=7870
2023-03-15 16:10:56 - progress_bar.py[line:272] - INFO: epoch 012:   1176 / 2004 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=363.7, nsentences=8, sample_size=363.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=1042.9, ups=2.87, wpb=363.7, bsz=8, num_updates=23070, lr=7.77536e-05, gnorm=2.976, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=7874
2023-03-15 16:10:59 - progress_bar.py[line:272] - INFO: epoch 012:   1186 / 2004 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=333.3, nsentences=8, sample_size=333.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=1004.6, ups=3.01, wpb=333.3, bsz=8, num_updates=23080, lr=7.77435e-05, gnorm=3.02, clip=0, loss_scale=1024, train_wall=3, gb_free=15.7, wall=7877
2023-03-15 16:11:03 - progress_bar.py[line:272] - INFO: epoch 012:   1196 / 2004 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=362.6, nsentences=8, sample_size=362.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=1052.3, ups=2.9, wpb=362.6, bsz=8, num_updates=23090, lr=7.77334e-05, gnorm=2.825, clip=0, loss_scale=1024, train_wall=3, gb_free=14, wall=7881
2023-03-15 16:11:06 - progress_bar.py[line:272] - INFO: epoch 012:   1206 / 2004 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=291.8, nsentences=8, sample_size=291.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=872.5, ups=2.99, wpb=291.8, bsz=8, num_updates=23100, lr=7.77233e-05, gnorm=2.906, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=7884
2023-03-15 16:11:10 - progress_bar.py[line:272] - INFO: epoch 012:   1216 / 2004 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=322.4, nsentences=8, sample_size=322.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=936, ups=2.9, wpb=322.4, bsz=8, num_updates=23110, lr=7.77133e-05, gnorm=2.999, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=7887
2023-03-15 16:11:13 - progress_bar.py[line:272] - INFO: epoch 012:   1226 / 2004 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=306.6, nsentences=8, sample_size=306.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=900.9, ups=2.94, wpb=306.6, bsz=8, num_updates=23120, lr=7.77032e-05, gnorm=2.777, clip=0, loss_scale=1024, train_wall=3, gb_free=15.9, wall=7891
2023-03-15 16:11:17 - progress_bar.py[line:272] - INFO: epoch 012:   1236 / 2004 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=357.7, nsentences=8, sample_size=357.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=1047.3, ups=2.93, wpb=357.7, bsz=8, num_updates=23130, lr=7.76931e-05, gnorm=2.933, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=7894
2023-03-15 16:11:20 - progress_bar.py[line:272] - INFO: epoch 012:   1246 / 2004 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=355.5, nsentences=8, sample_size=355.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=1031.4, ups=2.9, wpb=355.5, bsz=8, num_updates=23140, lr=7.7683e-05, gnorm=3.153, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=7898
2023-03-15 16:11:23 - progress_bar.py[line:272] - INFO: epoch 012:   1256 / 2004 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=353.5, nsentences=8, sample_size=353.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=1029.9, ups=2.91, wpb=353.5, bsz=8, num_updates=23150, lr=7.76729e-05, gnorm=3.06, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=7901
2023-03-15 16:11:27 - progress_bar.py[line:272] - INFO: epoch 012:   1266 / 2004 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=337.8, nsentences=8, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=969.1, ups=2.87, wpb=337.8, bsz=8, num_updates=23160, lr=7.76629e-05, gnorm=2.946, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=7904
2023-03-15 16:11:30 - progress_bar.py[line:272] - INFO: epoch 012:   1276 / 2004 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=348.6, nsentences=8, sample_size=348.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=991.1, ups=2.84, wpb=348.6, bsz=8, num_updates=23170, lr=7.76528e-05, gnorm=2.889, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=7908
2023-03-15 16:11:34 - progress_bar.py[line:272] - INFO: epoch 012:   1286 / 2004 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=320.2, nsentences=8, sample_size=320.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=954.4, ups=2.98, wpb=320.2, bsz=8, num_updates=23180, lr=7.76427e-05, gnorm=2.915, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=7911
2023-03-15 16:11:37 - progress_bar.py[line:272] - INFO: epoch 012:   1296 / 2004 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=317.6, nsentences=8, sample_size=317.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=902.4, ups=2.84, wpb=317.6, bsz=8, num_updates=23190, lr=7.76326e-05, gnorm=2.965, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=7915
2023-03-15 16:11:41 - progress_bar.py[line:272] - INFO: epoch 012:   1306 / 2004 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=306.1, nsentences=8, sample_size=306.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=898.4, ups=2.94, wpb=306.1, bsz=8, num_updates=23200, lr=7.76225e-05, gnorm=2.813, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=7918
2023-03-15 16:11:44 - progress_bar.py[line:272] - INFO: epoch 012:   1316 / 2004 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=349.7, nsentences=8, sample_size=349.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=1027.1, ups=2.94, wpb=349.7, bsz=8, num_updates=23210, lr=7.76125e-05, gnorm=3.151, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=7922
2023-03-15 16:11:47 - progress_bar.py[line:272] - INFO: epoch 012:   1326 / 2004 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=296, nsentences=8, sample_size=296, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=868.7, ups=2.93, wpb=296, bsz=8, num_updates=23220, lr=7.76024e-05, gnorm=2.986, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=7925
2023-03-15 16:11:51 - progress_bar.py[line:272] - INFO: epoch 012:   1336 / 2004 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=361.4, nsentences=8, sample_size=361.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=1028.4, ups=2.85, wpb=361.4, bsz=8, num_updates=23230, lr=7.75923e-05, gnorm=3.015, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=7929
2023-03-15 16:11:54 - progress_bar.py[line:272] - INFO: epoch 012:   1346 / 2004 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=297.5, nsentences=8, sample_size=297.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=880.3, ups=2.96, wpb=297.5, bsz=8, num_updates=23240, lr=7.75822e-05, gnorm=2.993, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=7932
2023-03-15 16:11:58 - progress_bar.py[line:272] - INFO: epoch 012:   1356 / 2004 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=327.6, nsentences=8, sample_size=327.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=957.9, ups=2.92, wpb=327.6, bsz=8, num_updates=23250, lr=7.75721e-05, gnorm=2.928, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=7935
2023-03-15 16:12:01 - progress_bar.py[line:272] - INFO: epoch 012:   1366 / 2004 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=310.3, nsentences=8, sample_size=310.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=908, ups=2.93, wpb=310.3, bsz=8, num_updates=23260, lr=7.7562e-05, gnorm=3.082, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=7939
2023-03-15 16:12:05 - progress_bar.py[line:272] - INFO: epoch 012:   1376 / 2004 loss=0.37, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=329.6, nsentences=8, sample_size=329.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=963, ups=2.92, wpb=329.6, bsz=8, num_updates=23270, lr=7.7552e-05, gnorm=3.226, clip=0, loss_scale=2048, train_wall=3, gb_free=12.7, wall=7942
2023-03-15 16:12:08 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 16:12:08 - progress_bar.py[line:272] - INFO: epoch 012:   1387 / 2004 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=399.7, nsentences=8, sample_size=399.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=1065.5, ups=2.67, wpb=399.7, bsz=8, num_updates=23280, lr=7.75419e-05, gnorm=3.081, clip=0, loss_scale=1024, train_wall=4, gb_free=14.9, wall=7946
2023-03-15 16:12:12 - progress_bar.py[line:272] - INFO: epoch 012:   1397 / 2004 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=339.6, nsentences=8, sample_size=339.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=1003.3, ups=2.95, wpb=339.6, bsz=8, num_updates=23290, lr=7.75318e-05, gnorm=2.696, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=7949
2023-03-15 16:12:15 - progress_bar.py[line:272] - INFO: epoch 012:   1407 / 2004 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=348.2, nsentences=8, sample_size=348.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=1005.3, ups=2.89, wpb=348.2, bsz=8, num_updates=23300, lr=7.75217e-05, gnorm=3.105, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=7953
2023-03-15 16:12:19 - progress_bar.py[line:272] - INFO: epoch 012:   1417 / 2004 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=382.3, nsentences=8, sample_size=382.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=1096.3, ups=2.87, wpb=382.3, bsz=8, num_updates=23310, lr=7.75116e-05, gnorm=3.183, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=7956
2023-03-15 16:12:22 - progress_bar.py[line:272] - INFO: epoch 012:   1427 / 2004 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=289.4, nsentences=8, sample_size=289.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=858.7, ups=2.97, wpb=289.4, bsz=8, num_updates=23320, lr=7.75016e-05, gnorm=2.874, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=7960
2023-03-15 16:12:26 - progress_bar.py[line:272] - INFO: epoch 012:   1437 / 2004 loss=0.375, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=366.3, nsentences=8, sample_size=366.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=1061.8, ups=2.9, wpb=366.3, bsz=8, num_updates=23330, lr=7.74915e-05, gnorm=3.098, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=7963
2023-03-15 16:12:29 - progress_bar.py[line:272] - INFO: epoch 012:   1447 / 2004 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=329.8, nsentences=8, sample_size=329.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=969.5, ups=2.94, wpb=329.8, bsz=8, num_updates=23340, lr=7.74814e-05, gnorm=2.871, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=7967
2023-03-15 16:12:32 - progress_bar.py[line:272] - INFO: epoch 012:   1457 / 2004 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=358.2, nsentences=8, sample_size=358.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=1023.1, ups=2.86, wpb=358.2, bsz=8, num_updates=23350, lr=7.74713e-05, gnorm=3.215, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=7970
2023-03-15 16:12:36 - progress_bar.py[line:272] - INFO: epoch 012:   1467 / 2004 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=409.2, nsentences=8, sample_size=409.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=1176.6, ups=2.88, wpb=409.2, bsz=8, num_updates=23360, lr=7.74612e-05, gnorm=3.076, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=7974
2023-03-15 16:12:39 - progress_bar.py[line:272] - INFO: epoch 012:   1477 / 2004 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=400.9, nsentences=8, sample_size=400.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=1186.8, ups=2.96, wpb=400.9, bsz=8, num_updates=23370, lr=7.74512e-05, gnorm=3.236, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=7977
2023-03-15 16:12:43 - progress_bar.py[line:272] - INFO: epoch 012:   1487 / 2004 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=332, nsentences=8, sample_size=332, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=978.2, ups=2.95, wpb=332, bsz=8, num_updates=23380, lr=7.74411e-05, gnorm=2.865, clip=0, loss_scale=1024, train_wall=3, gb_free=15.7, wall=7980
2023-03-15 16:12:46 - progress_bar.py[line:272] - INFO: epoch 012:   1497 / 2004 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=342.2, nsentences=8, sample_size=342.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=984.8, ups=2.88, wpb=342.2, bsz=8, num_updates=23390, lr=7.7431e-05, gnorm=2.948, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=7984
2023-03-15 16:12:50 - progress_bar.py[line:272] - INFO: epoch 012:   1507 / 2004 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=323.1, nsentences=8, sample_size=323.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=938.8, ups=2.91, wpb=323.1, bsz=8, num_updates=23400, lr=7.74209e-05, gnorm=2.923, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=7987
2023-03-15 16:12:53 - progress_bar.py[line:272] - INFO: epoch 012:   1517 / 2004 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=330.4, nsentences=8, sample_size=330.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=967.3, ups=2.93, wpb=330.4, bsz=8, num_updates=23410, lr=7.74108e-05, gnorm=2.783, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=7991
2023-03-15 16:12:56 - progress_bar.py[line:272] - INFO: epoch 012:   1527 / 2004 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=321, nsentences=8, sample_size=321, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=931.7, ups=2.9, wpb=321, bsz=8, num_updates=23420, lr=7.74008e-05, gnorm=2.997, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=7994
2023-03-15 16:13:00 - progress_bar.py[line:272] - INFO: epoch 012:   1537 / 2004 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=353.2, nsentences=8, sample_size=353.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=1027.2, ups=2.91, wpb=353.2, bsz=8, num_updates=23430, lr=7.73907e-05, gnorm=2.91, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=7998
2023-03-15 16:13:03 - progress_bar.py[line:272] - INFO: epoch 012:   1547 / 2004 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=318.7, nsentences=8, sample_size=318.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=923.1, ups=2.9, wpb=318.7, bsz=8, num_updates=23440, lr=7.73806e-05, gnorm=3.086, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=8001
2023-03-15 16:13:07 - progress_bar.py[line:272] - INFO: epoch 012:   1557 / 2004 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=349.2, nsentences=8, sample_size=349.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=1003.6, ups=2.87, wpb=349.2, bsz=8, num_updates=23450, lr=7.73705e-05, gnorm=3.145, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=8004
2023-03-15 16:13:10 - progress_bar.py[line:272] - INFO: epoch 012:   1567 / 2004 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=334.5, nsentences=8, sample_size=334.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=979.9, ups=2.93, wpb=334.5, bsz=8, num_updates=23460, lr=7.73604e-05, gnorm=2.897, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=8008
2023-03-15 16:13:14 - progress_bar.py[line:272] - INFO: epoch 012:   1577 / 2004 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=357.8, nsentences=8, sample_size=357.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=1054.5, ups=2.95, wpb=357.8, bsz=8, num_updates=23470, lr=7.73503e-05, gnorm=2.888, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=8011
2023-03-15 16:13:17 - progress_bar.py[line:272] - INFO: epoch 012:   1587 / 2004 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=308.2, nsentences=8, sample_size=308.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=894.3, ups=2.9, wpb=308.2, bsz=8, num_updates=23480, lr=7.73403e-05, gnorm=2.805, clip=0, loss_scale=2048, train_wall=3, gb_free=15.9, wall=8015
2023-03-15 16:13:21 - progress_bar.py[line:272] - INFO: epoch 012:   1597 / 2004 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=358.6, nsentences=8, sample_size=358.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=1032.2, ups=2.88, wpb=358.6, bsz=8, num_updates=23490, lr=7.73302e-05, gnorm=2.956, clip=0, loss_scale=2048, train_wall=3, gb_free=15.8, wall=8018
2023-03-15 16:13:24 - progress_bar.py[line:272] - INFO: epoch 012:   1607 / 2004 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=341.3, nsentences=8, sample_size=341.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=977.3, ups=2.86, wpb=341.3, bsz=8, num_updates=23500, lr=7.73201e-05, gnorm=2.93, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=8022
2023-03-15 16:13:28 - progress_bar.py[line:272] - INFO: epoch 012:   1617 / 2004 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=336.2, nsentences=8, sample_size=336.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=978.2, ups=2.91, wpb=336.2, bsz=8, num_updates=23510, lr=7.731e-05, gnorm=3.209, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=8025
2023-03-15 16:13:31 - progress_bar.py[line:272] - INFO: epoch 012:   1627 / 2004 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=375.1, nsentences=8, sample_size=375.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=1084.7, ups=2.89, wpb=375.1, bsz=8, num_updates=23520, lr=7.72999e-05, gnorm=3.298, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=8029
2023-03-15 16:13:34 - progress_bar.py[line:272] - INFO: epoch 012:   1637 / 2004 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=328.2, nsentences=8, sample_size=328.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=951.1, ups=2.9, wpb=328.2, bsz=8, num_updates=23530, lr=7.72899e-05, gnorm=2.962, clip=0, loss_scale=2048, train_wall=3, gb_free=13.4, wall=8032
2023-03-15 16:13:37 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 16:13:38 - progress_bar.py[line:272] - INFO: epoch 012:   1648 / 2004 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=308.1, nsentences=8, sample_size=308.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=810.3, ups=2.63, wpb=308.1, bsz=8, num_updates=23540, lr=7.72798e-05, gnorm=2.876, clip=0, loss_scale=2048, train_wall=4, gb_free=14.2, wall=8036
2023-03-15 16:13:42 - progress_bar.py[line:272] - INFO: epoch 012:   1658 / 2004 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=343.7, nsentences=8, sample_size=343.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=992, ups=2.89, wpb=343.7, bsz=8, num_updates=23550, lr=7.72697e-05, gnorm=2.997, clip=0, loss_scale=2048, train_wall=3, gb_free=15.8, wall=8039
2023-03-15 16:13:45 - progress_bar.py[line:272] - INFO: epoch 012:   1668 / 2004 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=355, nsentences=8, sample_size=355, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=1029.7, ups=2.9, wpb=355, bsz=8, num_updates=23560, lr=7.72596e-05, gnorm=3.125, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=8043
2023-03-15 16:13:49 - progress_bar.py[line:272] - INFO: epoch 012:   1678 / 2004 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=321.1, nsentences=8, sample_size=321.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=945.9, ups=2.95, wpb=321.1, bsz=8, num_updates=23570, lr=7.72495e-05, gnorm=3.136, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=8046
2023-03-15 16:13:52 - progress_bar.py[line:272] - INFO: epoch 012:   1688 / 2004 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=341.6, nsentences=8, sample_size=341.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=1010.4, ups=2.96, wpb=341.6, bsz=8, num_updates=23580, lr=7.72395e-05, gnorm=3.103, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=8050
2023-03-15 16:13:55 - progress_bar.py[line:272] - INFO: epoch 012:   1698 / 2004 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=336.2, nsentences=8, sample_size=336.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=969, ups=2.88, wpb=336.2, bsz=8, num_updates=23590, lr=7.72294e-05, gnorm=2.894, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=8053
2023-03-15 16:13:59 - progress_bar.py[line:272] - INFO: epoch 012:   1708 / 2004 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=343.8, nsentences=8, sample_size=343.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=984, ups=2.86, wpb=343.8, bsz=8, num_updates=23600, lr=7.72193e-05, gnorm=3.051, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=8057
2023-03-15 16:14:02 - progress_bar.py[line:272] - INFO: epoch 012:   1718 / 2004 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=379.9, nsentences=8, sample_size=379.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=1069.9, ups=2.82, wpb=379.9, bsz=8, num_updates=23610, lr=7.72092e-05, gnorm=3.208, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=8060
2023-03-15 16:14:06 - progress_bar.py[line:272] - INFO: epoch 012:   1728 / 2004 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=390.8, nsentences=8, sample_size=390.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=1108.9, ups=2.84, wpb=390.8, bsz=8, num_updates=23620, lr=7.71991e-05, gnorm=3.11, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=8064
2023-03-15 16:14:09 - progress_bar.py[line:272] - INFO: epoch 012:   1738 / 2004 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=326.8, nsentences=8, sample_size=326.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=957.3, ups=2.93, wpb=326.8, bsz=8, num_updates=23630, lr=7.71891e-05, gnorm=3.01, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=8067
2023-03-15 16:14:13 - progress_bar.py[line:272] - INFO: epoch 012:   1748 / 2004 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=348.9, nsentences=8, sample_size=348.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=1044.7, ups=2.99, wpb=348.9, bsz=8, num_updates=23640, lr=7.7179e-05, gnorm=2.927, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=8070
2023-03-15 16:14:16 - progress_bar.py[line:272] - INFO: epoch 012:   1758 / 2004 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=328, nsentences=8, sample_size=328, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=954.3, ups=2.91, wpb=328, bsz=8, num_updates=23650, lr=7.71689e-05, gnorm=3.003, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=8074
2023-03-15 16:14:20 - progress_bar.py[line:272] - INFO: epoch 012:   1768 / 2004 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=323.1, nsentences=8, sample_size=323.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=945, ups=2.92, wpb=323.1, bsz=8, num_updates=23660, lr=7.71588e-05, gnorm=3.047, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=8077
2023-03-15 16:14:21 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 16:14:23 - progress_bar.py[line:272] - INFO: epoch 012:   1779 / 2004 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=353, nsentences=8, sample_size=353, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=944.5, ups=2.68, wpb=353, bsz=8, num_updates=23670, lr=7.71487e-05, gnorm=2.824, clip=0, loss_scale=2048, train_wall=4, gb_free=15.1, wall=8081
2023-03-15 16:14:27 - progress_bar.py[line:272] - INFO: epoch 012:   1789 / 2004 loss=0.3, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=301.3, nsentences=8, sample_size=301.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=886.5, ups=2.94, wpb=301.3, bsz=8, num_updates=23680, lr=7.71387e-05, gnorm=2.829, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=8084
2023-03-15 16:14:30 - progress_bar.py[line:272] - INFO: epoch 012:   1799 / 2004 loss=0.363, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=347.4, nsentences=8, sample_size=347.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=1010.3, ups=2.91, wpb=347.4, bsz=8, num_updates=23690, lr=7.71286e-05, gnorm=2.976, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=8088
2023-03-15 16:14:34 - progress_bar.py[line:272] - INFO: epoch 012:   1809 / 2004 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=347.7, nsentences=8, sample_size=347.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=1013, ups=2.91, wpb=347.7, bsz=8, num_updates=23700, lr=7.71185e-05, gnorm=3.296, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=8091
2023-03-15 16:14:37 - progress_bar.py[line:272] - INFO: epoch 012:   1819 / 2004 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=357.9, nsentences=8, sample_size=357.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=1025.2, ups=2.86, wpb=357.9, bsz=8, num_updates=23710, lr=7.71084e-05, gnorm=2.92, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=8095
2023-03-15 16:14:41 - progress_bar.py[line:272] - INFO: epoch 012:   1829 / 2004 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=339.4, nsentences=8, sample_size=339.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=979.4, ups=2.89, wpb=339.4, bsz=8, num_updates=23720, lr=7.70983e-05, gnorm=3, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=8098
2023-03-15 16:14:44 - progress_bar.py[line:272] - INFO: epoch 012:   1839 / 2004 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=341.2, nsentences=8, sample_size=341.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=1003.2, ups=2.94, wpb=341.2, bsz=8, num_updates=23730, lr=7.70882e-05, gnorm=2.988, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=8102
2023-03-15 16:14:47 - progress_bar.py[line:272] - INFO: epoch 012:   1849 / 2004 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=351.7, nsentences=8, sample_size=351.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=1029, ups=2.93, wpb=351.7, bsz=8, num_updates=23740, lr=7.70782e-05, gnorm=2.814, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=8105
2023-03-15 16:14:51 - progress_bar.py[line:272] - INFO: epoch 012:   1859 / 2004 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=330.7, nsentences=8, sample_size=330.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=945, ups=2.86, wpb=330.7, bsz=8, num_updates=23750, lr=7.70681e-05, gnorm=2.954, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=8108
2023-03-15 16:14:54 - progress_bar.py[line:272] - INFO: epoch 012:   1869 / 2004 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=335.2, nsentences=8, sample_size=335.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=982.9, ups=2.93, wpb=335.2, bsz=8, num_updates=23760, lr=7.7058e-05, gnorm=3.057, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=8112
2023-03-15 16:14:58 - progress_bar.py[line:272] - INFO: epoch 012:   1879 / 2004 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=333.8, nsentences=8, sample_size=333.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=998.8, ups=2.99, wpb=333.8, bsz=8, num_updates=23770, lr=7.70479e-05, gnorm=2.841, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=8115
2023-03-15 16:15:01 - progress_bar.py[line:272] - INFO: epoch 012:   1889 / 2004 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=317, nsentences=8, sample_size=317, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=943.9, ups=2.98, wpb=317, bsz=8, num_updates=23780, lr=7.70378e-05, gnorm=2.963, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=8119
2023-03-15 16:15:04 - progress_bar.py[line:272] - INFO: epoch 012:   1899 / 2004 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=351, nsentences=8, sample_size=351, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=1026.8, ups=2.93, wpb=351, bsz=8, num_updates=23790, lr=7.70278e-05, gnorm=2.947, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=8122
2023-03-15 16:15:05 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 16:15:08 - progress_bar.py[line:272] - INFO: epoch 012:   1910 / 2004 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=332.1, nsentences=8, sample_size=332.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=892.8, ups=2.69, wpb=332.1, bsz=8, num_updates=23800, lr=7.70177e-05, gnorm=2.872, clip=0, loss_scale=2048, train_wall=4, gb_free=14.6, wall=8126
2023-03-15 16:15:11 - progress_bar.py[line:272] - INFO: epoch 012:   1920 / 2004 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=330.2, nsentences=8, sample_size=330.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=984.1, ups=2.98, wpb=330.2, bsz=8, num_updates=23810, lr=7.70076e-05, gnorm=2.966, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=8129
2023-03-15 16:15:15 - progress_bar.py[line:272] - INFO: epoch 012:   1930 / 2004 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=316.2, nsentences=8, sample_size=316.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=915.4, ups=2.9, wpb=316.2, bsz=8, num_updates=23820, lr=7.69975e-05, gnorm=3.049, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=8133
2023-03-15 16:15:18 - progress_bar.py[line:272] - INFO: epoch 012:   1940 / 2004 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=349.9, nsentences=8, sample_size=349.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=1017.3, ups=2.91, wpb=349.9, bsz=8, num_updates=23830, lr=7.69874e-05, gnorm=2.995, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=8136
2023-03-15 16:15:22 - progress_bar.py[line:272] - INFO: epoch 012:   1950 / 2004 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=337.9, nsentences=8, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=983.5, ups=2.91, wpb=337.9, bsz=8, num_updates=23840, lr=7.69774e-05, gnorm=2.836, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=8139
2023-03-15 16:15:25 - progress_bar.py[line:272] - INFO: epoch 012:   1960 / 2004 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=365.6, nsentences=8, sample_size=365.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=1052.9, ups=2.88, wpb=365.6, bsz=8, num_updates=23850, lr=7.69673e-05, gnorm=3.2, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=8143
2023-03-15 16:15:29 - progress_bar.py[line:272] - INFO: epoch 012:   1970 / 2004 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=336.8, nsentences=8, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=979.6, ups=2.91, wpb=336.8, bsz=8, num_updates=23860, lr=7.69572e-05, gnorm=2.845, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=8146
2023-03-15 16:15:32 - progress_bar.py[line:272] - INFO: epoch 012:   1980 / 2004 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=343.1, nsentences=8, sample_size=343.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=1028.9, ups=3, wpb=343.1, bsz=8, num_updates=23870, lr=7.69471e-05, gnorm=2.973, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=8150
2023-03-15 16:15:35 - progress_bar.py[line:272] - INFO: epoch 012:   1990 / 2004 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=355.1, nsentences=8, sample_size=355.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=1125.1, ups=3.17, wpb=355.1, bsz=8, num_updates=23880, lr=7.6937e-05, gnorm=2.835, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=8153
2023-03-15 16:15:38 - progress_bar.py[line:272] - INFO: epoch 012:   2000 / 2004 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=377.8, nsentences=8, sample_size=377.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=1235, ups=3.27, wpb=377.8, bsz=8, num_updates=23890, lr=7.6927e-05, gnorm=2.995, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=8156
2023-03-15 16:15:39 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 12 @ 23894 updates
2023-03-15 16:15:39 - trainer.py[line:431] - INFO: Saving checkpoint to ./checkpoints/checkpoint12.pt
2023-03-15 16:15:45 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./checkpoints/checkpoint12.pt
2023-03-15 16:15:47 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./checkpoints/checkpoint12.pt (epoch 12 @ 23894 updates, score None) (writing took 7.871109344065189 seconds)
2023-03-15 16:15:47 - train.py[line:332] - INFO: end of epoch 12 (average epoch stats below)
2023-03-15 16:15:47 - progress_bar.py[line:282] - INFO: epoch 012 | loss 0.362 | loss_v1 0 | loss_v2 0 | nll_loss 0.362 | ntokens 345.423 | nsentences 7.999 | sample_size 345.423 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.29 | wps 992.1 | ups 2.87 | wpb 345.4 | bsz 8 | num_updates 23894 | lr 7.69229e-05 | gnorm 3.028 | clip 0.1 | loss_scale 2048 | train_wall 672 | gb_free 13.9 | wall 8165
2023-03-15 16:15:47 - trainer.py[line:639] - INFO: loading train data for epoch 13
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 row count 8015 total row count 8015
slice_id 0 seek offset 0
2023-03-15 16:15:48 - trainer.py[line:703] - INFO: begin training epoch 13
2023-03-15 16:15:48 - train.py[line:305] - INFO: Start iterating over samples
2023-03-15 16:15:50 - progress_bar.py[line:272] - INFO: epoch 013:      6 / 2004 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=382.1, nsentences=8, sample_size=382.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=321.5, ups=0.84, wpb=382.1, bsz=8, num_updates=23900, lr=7.69169e-05, gnorm=3.157, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=8168
2023-03-15 16:15:53 - progress_bar.py[line:272] - INFO: epoch 013:     16 / 2004 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=311.6, nsentences=8, sample_size=311.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=1016.7, ups=3.26, wpb=311.6, bsz=8, num_updates=23910, lr=7.69068e-05, gnorm=2.816, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=8171
2023-03-15 16:15:56 - progress_bar.py[line:272] - INFO: epoch 013:     26 / 2004 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=366.9, nsentences=8, sample_size=366.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=1164.3, ups=3.17, wpb=366.9, bsz=8, num_updates=23920, lr=7.68967e-05, gnorm=3.111, clip=0, loss_scale=4096, train_wall=3, gb_free=14.5, wall=8174
2023-03-15 16:15:57 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 16:16:00 - progress_bar.py[line:272] - INFO: epoch 013:     37 / 2004 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=343.7, nsentences=8, sample_size=343.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=1011.4, ups=2.94, wpb=343.7, bsz=8, num_updates=23930, lr=7.68866e-05, gnorm=2.949, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=8177
2023-03-15 16:16:03 - progress_bar.py[line:272] - INFO: epoch 013:     47 / 2004 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=350.5, nsentences=8, sample_size=350.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=1118.8, ups=3.19, wpb=350.5, bsz=8, num_updates=23940, lr=7.68765e-05, gnorm=2.807, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=8181
2023-03-15 16:16:06 - progress_bar.py[line:272] - INFO: epoch 013:     57 / 2004 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=360.4, nsentences=8, sample_size=360.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=1104.8, ups=3.07, wpb=360.4, bsz=8, num_updates=23950, lr=7.68665e-05, gnorm=2.841, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=8184
2023-03-15 16:16:10 - progress_bar.py[line:272] - INFO: epoch 013:     67 / 2004 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=328.9, nsentences=8, sample_size=328.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=968.9, ups=2.95, wpb=328.9, bsz=8, num_updates=23960, lr=7.68564e-05, gnorm=2.787, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=8187
2023-03-15 16:16:13 - progress_bar.py[line:272] - INFO: epoch 013:     77 / 2004 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=336.2, nsentences=8, sample_size=336.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=987.9, ups=2.94, wpb=336.2, bsz=8, num_updates=23970, lr=7.68463e-05, gnorm=3.046, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=8191
2023-03-15 16:16:16 - progress_bar.py[line:272] - INFO: epoch 013:     87 / 2004 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=353.6, nsentences=8, sample_size=353.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=1025, ups=2.9, wpb=353.6, bsz=8, num_updates=23980, lr=7.68362e-05, gnorm=3.02, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=8194
2023-03-15 16:16:18 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 16:16:20 - progress_bar.py[line:272] - INFO: epoch 013:     98 / 2004 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=367.7, nsentences=8, sample_size=367.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=993.5, ups=2.7, wpb=367.7, bsz=8, num_updates=23990, lr=7.68261e-05, gnorm=3.16, clip=0, loss_scale=1024, train_wall=4, gb_free=14.2, wall=8198
2023-03-15 16:16:23 - progress_bar.py[line:272] - INFO: epoch 013:    108 / 2004 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=351.3, nsentences=8, sample_size=351.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=1045.2, ups=2.98, wpb=351.3, bsz=8, num_updates=24000, lr=7.68161e-05, gnorm=2.958, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=8201
2023-03-15 16:16:23 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 13 @ 24000 updates
2023-03-15 16:16:23 - trainer.py[line:431] - INFO: Saving checkpoint to ./checkpoints/checkpoint_13_24000.pt
2023-03-15 16:16:31 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./checkpoints/checkpoint_13_24000.pt
2023-03-15 16:16:33 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./checkpoints/checkpoint_13_24000.pt (epoch 13 @ 24000 updates, score None) (writing took 9.747054839506745 seconds)
2023-03-15 16:16:36 - progress_bar.py[line:272] - INFO: epoch 013:    118 / 2004 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=329.3, nsentences=8, sample_size=329.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=255.5, ups=0.78, wpb=329.3, bsz=8, num_updates=24010, lr=7.6806e-05, gnorm=2.822, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=8214
2023-03-15 16:16:40 - progress_bar.py[line:272] - INFO: epoch 013:    128 / 2004 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=342.9, nsentences=8, sample_size=342.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=1085.4, ups=3.17, wpb=342.9, bsz=8, num_updates=24020, lr=7.67959e-05, gnorm=3.07, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=8217
2023-03-15 16:16:43 - progress_bar.py[line:272] - INFO: epoch 013:    138 / 2004 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=337.7, nsentences=8, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=1086, ups=3.22, wpb=337.7, bsz=8, num_updates=24030, lr=7.67858e-05, gnorm=2.98, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=8220
2023-03-15 16:16:46 - progress_bar.py[line:272] - INFO: epoch 013:    148 / 2004 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=320.5, nsentences=8, sample_size=320.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=1042, ups=3.25, wpb=320.5, bsz=8, num_updates=24040, lr=7.67757e-05, gnorm=2.97, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=8223
2023-03-15 16:16:49 - progress_bar.py[line:272] - INFO: epoch 013:    158 / 2004 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=355, nsentences=8, sample_size=355, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=1117.5, ups=3.15, wpb=355, bsz=8, num_updates=24050, lr=7.67657e-05, gnorm=3.095, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=8226
2023-03-15 16:16:52 - progress_bar.py[line:272] - INFO: epoch 013:    168 / 2004 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=338, nsentences=8, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=1080.9, ups=3.2, wpb=338, bsz=8, num_updates=24060, lr=7.67556e-05, gnorm=2.815, clip=0, loss_scale=1024, train_wall=3, gb_free=15.9, wall=8230
2023-03-15 16:16:55 - progress_bar.py[line:272] - INFO: epoch 013:    178 / 2004 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=338.5, nsentences=8, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=1077.3, ups=3.18, wpb=338.5, bsz=8, num_updates=24070, lr=7.67455e-05, gnorm=2.958, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=8233
2023-03-15 16:16:58 - progress_bar.py[line:272] - INFO: epoch 013:    188 / 2004 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=331.9, nsentences=8, sample_size=331.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=1080, ups=3.25, wpb=331.9, bsz=8, num_updates=24080, lr=7.67354e-05, gnorm=2.824, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=8236
2023-03-15 16:17:01 - progress_bar.py[line:272] - INFO: epoch 013:    198 / 2004 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=330.2, nsentences=8, sample_size=330.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=1054.8, ups=3.19, wpb=330.2, bsz=8, num_updates=24090, lr=7.67253e-05, gnorm=2.814, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=8239
2023-03-15 16:17:04 - progress_bar.py[line:272] - INFO: epoch 013:    208 / 2004 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=341.9, nsentences=8, sample_size=341.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=1091.4, ups=3.19, wpb=341.9, bsz=8, num_updates=24100, lr=7.67153e-05, gnorm=2.993, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=8242
2023-03-15 16:17:08 - progress_bar.py[line:272] - INFO: epoch 013:    218 / 2004 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=322.5, nsentences=8, sample_size=322.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=959.5, ups=2.98, wpb=322.5, bsz=8, num_updates=24110, lr=7.67052e-05, gnorm=2.887, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=8245
2023-03-15 16:17:11 - progress_bar.py[line:272] - INFO: epoch 013:    228 / 2004 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=341.6, nsentences=8, sample_size=341.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=1014.5, ups=2.97, wpb=341.6, bsz=8, num_updates=24120, lr=7.66951e-05, gnorm=3.035, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=8249
2023-03-15 16:17:15 - progress_bar.py[line:272] - INFO: epoch 013:    238 / 2004 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=377.6, nsentences=8, sample_size=377.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=1111.2, ups=2.94, wpb=377.6, bsz=8, num_updates=24130, lr=7.6685e-05, gnorm=2.815, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=8252
2023-03-15 16:17:18 - progress_bar.py[line:272] - INFO: epoch 013:    248 / 2004 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=349.8, nsentences=8, sample_size=349.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=1021.7, ups=2.92, wpb=349.8, bsz=8, num_updates=24140, lr=7.66749e-05, gnorm=2.974, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=8256
2023-03-15 16:17:21 - progress_bar.py[line:272] - INFO: epoch 013:    258 / 2004 loss=0.297, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=336.9, nsentences=8, sample_size=336.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=981.8, ups=2.91, wpb=336.9, bsz=8, num_updates=24150, lr=7.66649e-05, gnorm=2.858, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=8259
2023-03-15 16:17:25 - progress_bar.py[line:272] - INFO: epoch 013:    268 / 2004 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=350.4, nsentences=8, sample_size=350.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=1023.8, ups=2.92, wpb=350.4, bsz=8, num_updates=24160, lr=7.66548e-05, gnorm=3.047, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=8263
2023-03-15 16:17:28 - progress_bar.py[line:272] - INFO: epoch 013:    278 / 2004 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=340.4, nsentences=8, sample_size=340.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=992.4, ups=2.92, wpb=340.4, bsz=8, num_updates=24170, lr=7.66447e-05, gnorm=2.854, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=8266
2023-03-15 16:17:32 - progress_bar.py[line:272] - INFO: epoch 013:    288 / 2004 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=361.1, nsentences=8, sample_size=361.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=1053.5, ups=2.92, wpb=361.1, bsz=8, num_updates=24180, lr=7.66346e-05, gnorm=2.986, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=8269
2023-03-15 16:17:35 - progress_bar.py[line:272] - INFO: epoch 013:    298 / 2004 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=377.3, nsentences=8, sample_size=377.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=1121.9, ups=2.97, wpb=377.3, bsz=8, num_updates=24190, lr=7.66245e-05, gnorm=3.012, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=8273
2023-03-15 16:17:38 - progress_bar.py[line:272] - INFO: epoch 013:    308 / 2004 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=342.5, nsentences=8, sample_size=342.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=1058.8, ups=3.09, wpb=342.5, bsz=8, num_updates=24200, lr=7.66144e-05, gnorm=3.097, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=8276
2023-03-15 16:17:41 - progress_bar.py[line:272] - INFO: epoch 013:    318 / 2004 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=330.4, nsentences=7.8, sample_size=330.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=1077.3, ups=3.26, wpb=330.4, bsz=7.8, num_updates=24210, lr=7.66044e-05, gnorm=2.911, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=8279
2023-03-15 16:17:44 - progress_bar.py[line:272] - INFO: epoch 013:    328 / 2004 loss=0.289, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=330.5, nsentences=8, sample_size=330.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1074.5, ups=3.25, wpb=330.5, bsz=8, num_updates=24220, lr=7.65943e-05, gnorm=2.84, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=8282
2023-03-15 16:17:48 - progress_bar.py[line:272] - INFO: epoch 013:    338 / 2004 loss=0.363, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=343.6, nsentences=8, sample_size=343.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=1080.8, ups=3.15, wpb=343.6, bsz=8, num_updates=24230, lr=7.65842e-05, gnorm=3.106, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=8285
2023-03-15 16:17:51 - progress_bar.py[line:272] - INFO: epoch 013:    348 / 2004 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=370.8, nsentences=8, sample_size=370.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=1154.1, ups=3.11, wpb=370.8, bsz=8, num_updates=24240, lr=7.65741e-05, gnorm=3.004, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=8289
2023-03-15 16:17:52 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 16:17:54 - progress_bar.py[line:272] - INFO: epoch 013:    359 / 2004 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=351.5, nsentences=8, sample_size=351.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=1026.8, ups=2.92, wpb=351.5, bsz=8, num_updates=24250, lr=7.6564e-05, gnorm=2.935, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=8292
2023-03-15 16:17:58 - progress_bar.py[line:272] - INFO: epoch 013:    369 / 2004 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=354.4, nsentences=8, sample_size=354.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=1059.4, ups=2.99, wpb=354.4, bsz=8, num_updates=24260, lr=7.6554e-05, gnorm=3, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=8295
2023-03-15 16:18:01 - progress_bar.py[line:272] - INFO: epoch 013:    379 / 2004 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=300.5, nsentences=8, sample_size=300.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=972.9, ups=3.24, wpb=300.5, bsz=8, num_updates=24270, lr=7.65439e-05, gnorm=3.188, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=8298
2023-03-15 16:18:04 - progress_bar.py[line:272] - INFO: epoch 013:    389 / 2004 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=349, nsentences=8, sample_size=349, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=1013.4, ups=2.9, wpb=349, bsz=8, num_updates=24280, lr=7.65338e-05, gnorm=3.096, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=8302
2023-03-15 16:18:07 - progress_bar.py[line:272] - INFO: epoch 013:    399 / 2004 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=355.7, nsentences=8, sample_size=355.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=1100, ups=3.09, wpb=355.7, bsz=8, num_updates=24290, lr=7.65237e-05, gnorm=3.079, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=8305
2023-03-15 16:18:11 - progress_bar.py[line:272] - INFO: epoch 013:    409 / 2004 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=358.9, nsentences=8, sample_size=358.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=1049.5, ups=2.92, wpb=358.9, bsz=8, num_updates=24300, lr=7.65136e-05, gnorm=2.986, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=8308
2023-03-15 16:18:14 - progress_bar.py[line:272] - INFO: epoch 013:    419 / 2004 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=356.7, nsentences=8, sample_size=356.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=1008, ups=2.83, wpb=356.7, bsz=8, num_updates=24310, lr=7.65036e-05, gnorm=2.962, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=8312
2023-03-15 16:18:18 - progress_bar.py[line:272] - INFO: epoch 013:    429 / 2004 loss=0.292, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=322.7, nsentences=8, sample_size=322.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=932.2, ups=2.89, wpb=322.7, bsz=8, num_updates=24320, lr=7.64935e-05, gnorm=2.866, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=8315
2023-03-15 16:18:21 - progress_bar.py[line:272] - INFO: epoch 013:    439 / 2004 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=364.3, nsentences=8, sample_size=364.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=1046.4, ups=2.87, wpb=364.3, bsz=8, num_updates=24330, lr=7.64834e-05, gnorm=3.025, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=8319
2023-03-15 16:18:25 - progress_bar.py[line:272] - INFO: epoch 013:    449 / 2004 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=370.7, nsentences=8, sample_size=370.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=1078.5, ups=2.91, wpb=370.7, bsz=8, num_updates=24340, lr=7.64733e-05, gnorm=3.091, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=8322
2023-03-15 16:18:28 - progress_bar.py[line:272] - INFO: epoch 013:    459 / 2004 loss=0.363, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=391.5, nsentences=8, sample_size=391.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=1111, ups=2.84, wpb=391.5, bsz=8, num_updates=24350, lr=7.64632e-05, gnorm=3.076, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=8326
2023-03-15 16:18:32 - progress_bar.py[line:272] - INFO: epoch 013:    469 / 2004 loss=0.389, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=362.4, nsentences=8, sample_size=362.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=1055.7, ups=2.91, wpb=362.4, bsz=8, num_updates=24360, lr=7.64532e-05, gnorm=3.317, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=8329
2023-03-15 16:18:35 - progress_bar.py[line:272] - INFO: epoch 013:    479 / 2004 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=342.7, nsentences=8, sample_size=342.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=997.9, ups=2.91, wpb=342.7, bsz=8, num_updates=24370, lr=7.64431e-05, gnorm=2.974, clip=0, loss_scale=4096, train_wall=3, gb_free=15.1, wall=8333
2023-03-15 16:18:35 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 16:18:39 - progress_bar.py[line:272] - INFO: epoch 013:    490 / 2004 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=373.2, nsentences=8, sample_size=373.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=993.4, ups=2.66, wpb=373.2, bsz=8, num_updates=24380, lr=7.6433e-05, gnorm=2.972, clip=0, loss_scale=2048, train_wall=4, gb_free=15.2, wall=8337
2023-03-15 16:18:42 - progress_bar.py[line:272] - INFO: epoch 013:    500 / 2004 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=355, nsentences=8, sample_size=355, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=1030.5, ups=2.9, wpb=355, bsz=8, num_updates=24390, lr=7.64229e-05, gnorm=2.858, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=8340
2023-03-15 16:18:46 - progress_bar.py[line:272] - INFO: epoch 013:    510 / 2004 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=365.3, nsentences=8, sample_size=365.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=1041.8, ups=2.85, wpb=365.3, bsz=8, num_updates=24400, lr=7.64128e-05, gnorm=3.125, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=8343
2023-03-15 16:18:49 - progress_bar.py[line:272] - INFO: epoch 013:    520 / 2004 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=348, nsentences=8, sample_size=348, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=999.7, ups=2.87, wpb=348, bsz=8, num_updates=24410, lr=7.64028e-05, gnorm=2.987, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=8347
2023-03-15 16:18:53 - progress_bar.py[line:272] - INFO: epoch 013:    530 / 2004 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=408.2, nsentences=8, sample_size=408.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=1174.8, ups=2.88, wpb=408.2, bsz=8, num_updates=24420, lr=7.63927e-05, gnorm=2.976, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=8350
2023-03-15 16:18:56 - progress_bar.py[line:272] - INFO: epoch 013:    540 / 2004 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=392.2, nsentences=8, sample_size=392.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=1121.8, ups=2.86, wpb=392.2, bsz=8, num_updates=24430, lr=7.63826e-05, gnorm=3.114, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=8354
2023-03-15 16:19:00 - progress_bar.py[line:272] - INFO: epoch 013:    550 / 2004 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=346.1, nsentences=8, sample_size=346.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=1008.5, ups=2.91, wpb=346.1, bsz=8, num_updates=24440, lr=7.63725e-05, gnorm=3.125, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=8357
2023-03-15 16:19:03 - progress_bar.py[line:272] - INFO: epoch 013:    560 / 2004 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=361.8, nsentences=8, sample_size=361.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=1050.5, ups=2.9, wpb=361.8, bsz=8, num_updates=24450, lr=7.63624e-05, gnorm=3.019, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=8361
2023-03-15 16:19:07 - progress_bar.py[line:272] - INFO: epoch 013:    570 / 2004 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=383, nsentences=8, sample_size=383, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=1092.7, ups=2.85, wpb=383, bsz=8, num_updates=24460, lr=7.63523e-05, gnorm=2.983, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=8364
2023-03-15 16:19:10 - progress_bar.py[line:272] - INFO: epoch 013:    580 / 2004 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=320.9, nsentences=8, sample_size=320.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=942.9, ups=2.94, wpb=320.9, bsz=8, num_updates=24470, lr=7.63423e-05, gnorm=2.934, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=8368
2023-03-15 16:19:14 - progress_bar.py[line:272] - INFO: epoch 013:    590 / 2004 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=376.7, nsentences=8, sample_size=376.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=1101.9, ups=2.93, wpb=376.7, bsz=8, num_updates=24480, lr=7.63322e-05, gnorm=2.94, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=8371
2023-03-15 16:19:17 - progress_bar.py[line:272] - INFO: epoch 013:    600 / 2004 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=354.5, nsentences=8, sample_size=354.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=1036.3, ups=2.92, wpb=354.5, bsz=8, num_updates=24490, lr=7.63221e-05, gnorm=2.971, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=8375
2023-03-15 16:19:20 - progress_bar.py[line:272] - INFO: epoch 013:    610 / 2004 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=332.8, nsentences=8, sample_size=332.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=979, ups=2.94, wpb=332.8, bsz=8, num_updates=24500, lr=7.6312e-05, gnorm=2.837, clip=0, loss_scale=4096, train_wall=3, gb_free=15.1, wall=8378
2023-03-15 16:19:21 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 16:19:24 - progress_bar.py[line:272] - INFO: epoch 013:    621 / 2004 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=362.6, nsentences=8, sample_size=362.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=965, ups=2.66, wpb=362.6, bsz=8, num_updates=24510, lr=7.63019e-05, gnorm=2.877, clip=0, loss_scale=2048, train_wall=4, gb_free=15.1, wall=8382
2023-03-15 16:19:28 - progress_bar.py[line:272] - INFO: epoch 013:    631 / 2004 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=347, nsentences=8, sample_size=347, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=1003.5, ups=2.89, wpb=347, bsz=8, num_updates=24520, lr=7.62919e-05, gnorm=2.924, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=8385
2023-03-15 16:19:31 - progress_bar.py[line:272] - INFO: epoch 013:    641 / 2004 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=355.2, nsentences=8, sample_size=355.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=1020.1, ups=2.87, wpb=355.2, bsz=8, num_updates=24530, lr=7.62818e-05, gnorm=3.065, clip=0, loss_scale=2048, train_wall=3, gb_free=14, wall=8389
2023-03-15 16:19:34 - progress_bar.py[line:272] - INFO: epoch 013:    651 / 2004 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=305, nsentences=8, sample_size=305, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=907.1, ups=2.97, wpb=305, bsz=8, num_updates=24540, lr=7.62717e-05, gnorm=2.753, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=8392
2023-03-15 16:19:38 - progress_bar.py[line:272] - INFO: epoch 013:    661 / 2004 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=339.1, nsentences=8, sample_size=339.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=994, ups=2.93, wpb=339.1, bsz=8, num_updates=24550, lr=7.62616e-05, gnorm=3.008, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=8395
2023-03-15 16:19:41 - progress_bar.py[line:272] - INFO: epoch 013:    671 / 2004 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=324.7, nsentences=8, sample_size=324.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=928.9, ups=2.86, wpb=324.7, bsz=8, num_updates=24560, lr=7.62515e-05, gnorm=3.066, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=8399
2023-03-15 16:19:45 - progress_bar.py[line:272] - INFO: epoch 013:    681 / 2004 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=344.2, nsentences=8, sample_size=344.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=1006.4, ups=2.92, wpb=344.2, bsz=8, num_updates=24570, lr=7.62415e-05, gnorm=3.06, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=8402
2023-03-15 16:19:48 - progress_bar.py[line:272] - INFO: epoch 013:    691 / 2004 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=347.9, nsentences=8, sample_size=347.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=1013.9, ups=2.91, wpb=347.9, bsz=8, num_updates=24580, lr=7.62314e-05, gnorm=3.014, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=8406
2023-03-15 16:19:52 - progress_bar.py[line:272] - INFO: epoch 013:    701 / 2004 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=342.9, nsentences=8, sample_size=342.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=989.9, ups=2.89, wpb=342.9, bsz=8, num_updates=24590, lr=7.62213e-05, gnorm=3.063, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=8409
2023-03-15 16:19:55 - progress_bar.py[line:272] - INFO: epoch 013:    711 / 2004 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=331.5, nsentences=8, sample_size=331.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=960.8, ups=2.9, wpb=331.5, bsz=8, num_updates=24600, lr=7.62112e-05, gnorm=2.916, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=8413
2023-03-15 16:19:58 - progress_bar.py[line:272] - INFO: epoch 013:    721 / 2004 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=356.9, nsentences=8, sample_size=356.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=1049.4, ups=2.94, wpb=356.9, bsz=8, num_updates=24610, lr=7.62011e-05, gnorm=3.015, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=8416
2023-03-15 16:20:02 - progress_bar.py[line:272] - INFO: epoch 013:    731 / 2004 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=353.1, nsentences=8, sample_size=353.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=1020.9, ups=2.89, wpb=353.1, bsz=8, num_updates=24620, lr=7.61911e-05, gnorm=3.093, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=8420
2023-03-15 16:20:05 - progress_bar.py[line:272] - INFO: epoch 013:    741 / 2004 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=330.9, nsentences=8, sample_size=330.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=980, ups=2.96, wpb=330.9, bsz=8, num_updates=24630, lr=7.6181e-05, gnorm=3.022, clip=0, loss_scale=4096, train_wall=3, gb_free=14.9, wall=8423
2023-03-15 16:20:06 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 16:20:09 - progress_bar.py[line:272] - INFO: epoch 013:    752 / 2004 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=347.8, nsentences=8, sample_size=347.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=930.4, ups=2.68, wpb=347.8, bsz=8, num_updates=24640, lr=7.61709e-05, gnorm=3.038, clip=0, loss_scale=2048, train_wall=4, gb_free=14.6, wall=8427
2023-03-15 16:20:12 - progress_bar.py[line:272] - INFO: epoch 013:    762 / 2004 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=337.7, nsentences=8, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=984.5, ups=2.92, wpb=337.7, bsz=8, num_updates=24650, lr=7.61608e-05, gnorm=2.95, clip=0, loss_scale=2048, train_wall=3, gb_free=13.2, wall=8430
2023-03-15 16:20:16 - progress_bar.py[line:272] - INFO: epoch 013:    772 / 2004 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=385.8, nsentences=8, sample_size=385.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=1106.1, ups=2.87, wpb=385.8, bsz=8, num_updates=24660, lr=7.61507e-05, gnorm=3.162, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=8434
2023-03-15 16:20:19 - progress_bar.py[line:272] - INFO: epoch 013:    782 / 2004 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=336, nsentences=8, sample_size=336, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=989.3, ups=2.94, wpb=336, bsz=8, num_updates=24670, lr=7.61406e-05, gnorm=3.062, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=8437
2023-03-15 16:20:23 - progress_bar.py[line:272] - INFO: epoch 013:    792 / 2004 loss=0.294, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=343.1, nsentences=8, sample_size=343.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=1000.5, ups=2.92, wpb=343.1, bsz=8, num_updates=24680, lr=7.61306e-05, gnorm=2.774, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=8440
2023-03-15 16:20:26 - progress_bar.py[line:272] - INFO: epoch 013:    802 / 2004 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=332.5, nsentences=8, sample_size=332.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=995.1, ups=2.99, wpb=332.5, bsz=8, num_updates=24690, lr=7.61205e-05, gnorm=2.904, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=8444
2023-03-15 16:20:30 - progress_bar.py[line:272] - INFO: epoch 013:    812 / 2004 loss=0.294, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=338.1, nsentences=8, sample_size=338.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=1009, ups=2.98, wpb=338.1, bsz=8, num_updates=24700, lr=7.61104e-05, gnorm=2.884, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=8447
2023-03-15 16:20:33 - progress_bar.py[line:272] - INFO: epoch 013:    822 / 2004 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=333.3, nsentences=8, sample_size=333.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=965.5, ups=2.9, wpb=333.3, bsz=8, num_updates=24710, lr=7.61003e-05, gnorm=3.036, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=8451
2023-03-15 16:20:36 - progress_bar.py[line:272] - INFO: epoch 013:    832 / 2004 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=353.1, nsentences=8, sample_size=353.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=1020.6, ups=2.89, wpb=353.1, bsz=8, num_updates=24720, lr=7.60902e-05, gnorm=3.005, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=8454
2023-03-15 16:20:40 - progress_bar.py[line:272] - INFO: epoch 013:    842 / 2004 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=363.1, nsentences=8, sample_size=363.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=1070.6, ups=2.95, wpb=363.1, bsz=8, num_updates=24730, lr=7.60802e-05, gnorm=2.966, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=8457
2023-03-15 16:20:43 - progress_bar.py[line:272] - INFO: epoch 013:    852 / 2004 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=357.9, nsentences=8, sample_size=357.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=1059.4, ups=2.96, wpb=357.9, bsz=8, num_updates=24740, lr=7.60701e-05, gnorm=3.011, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=8461
2023-03-15 16:20:47 - progress_bar.py[line:272] - INFO: epoch 013:    862 / 2004 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=337.9, nsentences=8, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=990.7, ups=2.93, wpb=337.9, bsz=8, num_updates=24750, lr=7.606e-05, gnorm=3.025, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=8464
2023-03-15 16:20:50 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 16:20:50 - progress_bar.py[line:272] - INFO: epoch 013:    873 / 2004 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=362.7, nsentences=8, sample_size=362.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=975.1, ups=2.69, wpb=362.7, bsz=8, num_updates=24760, lr=7.60499e-05, gnorm=2.925, clip=0, loss_scale=2048, train_wall=4, gb_free=15.3, wall=8468
2023-03-15 16:20:54 - progress_bar.py[line:272] - INFO: epoch 013:    883 / 2004 loss=0.288, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=324.1, nsentences=8, sample_size=324.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=940.7, ups=2.9, wpb=324.1, bsz=8, num_updates=24770, lr=7.60398e-05, gnorm=2.895, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=8471
2023-03-15 16:20:57 - progress_bar.py[line:272] - INFO: epoch 013:    893 / 2004 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=306, nsentences=8, sample_size=306, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=885.7, ups=2.89, wpb=306, bsz=8, num_updates=24780, lr=7.60298e-05, gnorm=3.07, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=8475
2023-03-15 16:21:01 - progress_bar.py[line:272] - INFO: epoch 013:    903 / 2004 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=366, nsentences=8, sample_size=366, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=1039.6, ups=2.84, wpb=366, bsz=8, num_updates=24790, lr=7.60197e-05, gnorm=3.13, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=8478
2023-03-15 16:21:04 - progress_bar.py[line:272] - INFO: epoch 013:    913 / 2004 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=380.4, nsentences=8, sample_size=380.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=1099.3, ups=2.89, wpb=380.4, bsz=8, num_updates=24800, lr=7.60096e-05, gnorm=3.03, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=8482
2023-03-15 16:21:08 - progress_bar.py[line:272] - INFO: epoch 013:    923 / 2004 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=318.2, nsentences=8, sample_size=318.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=922.6, ups=2.9, wpb=318.2, bsz=8, num_updates=24810, lr=7.59995e-05, gnorm=3.19, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=8485
2023-03-15 16:21:11 - progress_bar.py[line:272] - INFO: epoch 013:    933 / 2004 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=347.3, nsentences=8, sample_size=347.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=1043.6, ups=3, wpb=347.3, bsz=8, num_updates=24820, lr=7.59894e-05, gnorm=3.01, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=8489
2023-03-15 16:21:14 - progress_bar.py[line:272] - INFO: epoch 013:    943 / 2004 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=373.6, nsentences=8, sample_size=373.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=1098.1, ups=2.94, wpb=373.6, bsz=8, num_updates=24830, lr=7.59794e-05, gnorm=2.882, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=8492
2023-03-15 16:21:18 - progress_bar.py[line:272] - INFO: epoch 013:    953 / 2004 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=326.6, nsentences=8, sample_size=326.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=944.3, ups=2.89, wpb=326.6, bsz=8, num_updates=24840, lr=7.59693e-05, gnorm=3.194, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=8495
2023-03-15 16:21:21 - progress_bar.py[line:272] - INFO: epoch 013:    963 / 2004 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=399.1, nsentences=8, sample_size=399.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=1147.6, ups=2.88, wpb=399.1, bsz=8, num_updates=24850, lr=7.59592e-05, gnorm=3.109, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=8499
2023-03-15 16:21:25 - progress_bar.py[line:272] - INFO: epoch 013:    973 / 2004 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=323, nsentences=8, sample_size=323, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=967.2, ups=2.99, wpb=323, bsz=8, num_updates=24860, lr=7.59491e-05, gnorm=2.978, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=8502
2023-03-15 16:21:28 - progress_bar.py[line:272] - INFO: epoch 013:    983 / 2004 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=321.3, nsentences=8, sample_size=321.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=960.2, ups=2.99, wpb=321.3, bsz=8, num_updates=24870, lr=7.5939e-05, gnorm=3.126, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=8506
2023-03-15 16:21:31 - progress_bar.py[line:272] - INFO: epoch 013:    993 / 2004 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=381.2, nsentences=8, sample_size=381.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=1123.8, ups=2.95, wpb=381.2, bsz=8, num_updates=24880, lr=7.5929e-05, gnorm=2.944, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=8509
2023-03-15 16:21:34 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 16:21:35 - progress_bar.py[line:272] - INFO: epoch 013:   1004 / 2004 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=341, nsentences=8, sample_size=341, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=917.7, ups=2.69, wpb=341, bsz=8, num_updates=24890, lr=7.59189e-05, gnorm=2.971, clip=0, loss_scale=2048, train_wall=4, gb_free=15.3, wall=8513
2023-03-15 16:21:38 - progress_bar.py[line:272] - INFO: epoch 013:   1014 / 2004 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=337.4, nsentences=8, sample_size=337.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=997.2, ups=2.96, wpb=337.4, bsz=8, num_updates=24900, lr=7.59088e-05, gnorm=3.252, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=8516
2023-03-15 16:21:42 - progress_bar.py[line:272] - INFO: epoch 013:   1024 / 2004 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=327.4, nsentences=8, sample_size=327.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=964.2, ups=2.94, wpb=327.4, bsz=8, num_updates=24910, lr=7.58987e-05, gnorm=3.106, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=8520
2023-03-15 16:21:45 - progress_bar.py[line:272] - INFO: epoch 013:   1034 / 2004 loss=0.29, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=305.6, nsentences=8, sample_size=305.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=892.7, ups=2.92, wpb=305.6, bsz=8, num_updates=24920, lr=7.58886e-05, gnorm=2.894, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=8523
2023-03-15 16:21:49 - progress_bar.py[line:272] - INFO: epoch 013:   1044 / 2004 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=362.4, nsentences=8, sample_size=362.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=1074.8, ups=2.97, wpb=362.4, bsz=8, num_updates=24930, lr=7.58785e-05, gnorm=3.162, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=8526
2023-03-15 16:21:51 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 16:21:52 - progress_bar.py[line:272] - INFO: epoch 013:   1055 / 2004 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=372, nsentences=8, sample_size=372, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=990.7, ups=2.66, wpb=372, bsz=8, num_updates=24940, lr=7.58685e-05, gnorm=2.947, clip=0, loss_scale=1024, train_wall=4, gb_free=15.2, wall=8530
2023-03-15 16:21:56 - progress_bar.py[line:272] - INFO: epoch 013:   1065 / 2004 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=329.5, nsentences=8, sample_size=329.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=961.2, ups=2.92, wpb=329.5, bsz=8, num_updates=24950, lr=7.58584e-05, gnorm=3.114, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=8533
2023-03-15 16:21:59 - progress_bar.py[line:272] - INFO: epoch 013:   1075 / 2004 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=361.8, nsentences=8, sample_size=361.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=1063, ups=2.94, wpb=361.8, bsz=8, num_updates=24960, lr=7.58483e-05, gnorm=2.952, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=8537
2023-03-15 16:22:03 - progress_bar.py[line:272] - INFO: epoch 013:   1085 / 2004 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=369, nsentences=8, sample_size=369, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=1080.7, ups=2.93, wpb=369, bsz=8, num_updates=24970, lr=7.58382e-05, gnorm=3.171, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=8540
2023-03-15 16:22:06 - progress_bar.py[line:272] - INFO: epoch 013:   1095 / 2004 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=323.9, nsentences=8, sample_size=323.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=954.7, ups=2.95, wpb=323.9, bsz=8, num_updates=24980, lr=7.58281e-05, gnorm=3.069, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=8544
2023-03-15 16:22:09 - progress_bar.py[line:272] - INFO: epoch 013:   1105 / 2004 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=375, nsentences=8, sample_size=375, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=1106.8, ups=2.95, wpb=375, bsz=8, num_updates=24990, lr=7.58181e-05, gnorm=3.044, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=8547
2023-03-15 16:22:13 - progress_bar.py[line:272] - INFO: epoch 013:   1115 / 2004 loss=0.296, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=341.2, nsentences=8, sample_size=341.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=972.1, ups=2.85, wpb=341.2, bsz=8, num_updates=25000, lr=7.5808e-05, gnorm=2.785, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=8551
2023-03-15 16:22:16 - progress_bar.py[line:272] - INFO: epoch 013:   1125 / 2004 loss=0.289, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=321, nsentences=8, sample_size=321, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=942.6, ups=2.94, wpb=321, bsz=8, num_updates=25010, lr=7.57979e-05, gnorm=2.636, clip=0, loss_scale=1024, train_wall=3, gb_free=13.8, wall=8554
2023-03-15 16:22:20 - progress_bar.py[line:272] - INFO: epoch 013:   1135 / 2004 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=388.3, nsentences=8, sample_size=388.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=1159.6, ups=2.99, wpb=388.3, bsz=8, num_updates=25020, lr=7.57878e-05, gnorm=2.838, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=8557
2023-03-15 16:22:23 - progress_bar.py[line:272] - INFO: epoch 013:   1145 / 2004 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=335.4, nsentences=8, sample_size=335.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=976.8, ups=2.91, wpb=335.4, bsz=8, num_updates=25030, lr=7.57777e-05, gnorm=2.981, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=8561
2023-03-15 16:22:27 - progress_bar.py[line:272] - INFO: epoch 013:   1155 / 2004 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=395.1, nsentences=8, sample_size=395.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=1123.8, ups=2.84, wpb=395.1, bsz=8, num_updates=25040, lr=7.57677e-05, gnorm=3.111, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=8564
2023-03-15 16:22:30 - progress_bar.py[line:272] - INFO: epoch 013:   1165 / 2004 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=358.4, nsentences=8, sample_size=358.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=1033.8, ups=2.88, wpb=358.4, bsz=8, num_updates=25050, lr=7.57576e-05, gnorm=2.961, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=8568
2023-03-15 16:22:34 - progress_bar.py[line:272] - INFO: epoch 013:   1175 / 2004 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=364.5, nsentences=8, sample_size=364.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=1054.8, ups=2.89, wpb=364.5, bsz=8, num_updates=25060, lr=7.57475e-05, gnorm=2.915, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=8571
2023-03-15 16:22:37 - progress_bar.py[line:272] - INFO: epoch 013:   1185 / 2004 loss=0.297, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=339.9, nsentences=8, sample_size=339.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=987.3, ups=2.9, wpb=339.9, bsz=8, num_updates=25070, lr=7.57374e-05, gnorm=2.722, clip=0, loss_scale=2048, train_wall=3, gb_free=13.6, wall=8575
2023-03-15 16:22:40 - progress_bar.py[line:272] - INFO: epoch 013:   1195 / 2004 loss=0.293, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=341.9, nsentences=8, sample_size=341.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1016, ups=2.97, wpb=341.9, bsz=8, num_updates=25080, lr=7.57273e-05, gnorm=2.846, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=8578
2023-03-15 16:22:44 - progress_bar.py[line:272] - INFO: epoch 013:   1205 / 2004 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=308.6, nsentences=8, sample_size=308.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=893.9, ups=2.9, wpb=308.6, bsz=8, num_updates=25090, lr=7.57173e-05, gnorm=2.969, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=8581
2023-03-15 16:22:47 - progress_bar.py[line:272] - INFO: epoch 013:   1215 / 2004 loss=0.292, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=317, nsentences=8, sample_size=317, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=931.2, ups=2.94, wpb=317, bsz=8, num_updates=25100, lr=7.57072e-05, gnorm=2.81, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=8585
2023-03-15 16:22:51 - progress_bar.py[line:272] - INFO: epoch 013:   1225 / 2004 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=322.5, nsentences=8, sample_size=322.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=926.3, ups=2.87, wpb=322.5, bsz=8, num_updates=25110, lr=7.56971e-05, gnorm=2.801, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=8588
2023-03-15 16:22:54 - progress_bar.py[line:272] - INFO: epoch 013:   1235 / 2004 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=344.5, nsentences=8, sample_size=344.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=1009.5, ups=2.93, wpb=344.5, bsz=8, num_updates=25120, lr=7.5687e-05, gnorm=2.785, clip=0, loss_scale=2048, train_wall=3, gb_free=13.6, wall=8592
2023-03-15 16:22:58 - progress_bar.py[line:272] - INFO: epoch 013:   1245 / 2004 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=359.4, nsentences=8, sample_size=359.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=1053.5, ups=2.93, wpb=359.4, bsz=8, num_updates=25130, lr=7.56769e-05, gnorm=2.984, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=8595
2023-03-15 16:23:01 - progress_bar.py[line:272] - INFO: epoch 013:   1255 / 2004 loss=0.286, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=347.9, nsentences=8, sample_size=347.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1004.7, ups=2.89, wpb=347.9, bsz=8, num_updates=25140, lr=7.56668e-05, gnorm=2.871, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=8599
2023-03-15 16:23:04 - progress_bar.py[line:272] - INFO: epoch 013:   1265 / 2004 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=331.6, nsentences=8, sample_size=331.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=965.8, ups=2.91, wpb=331.6, bsz=8, num_updates=25150, lr=7.56568e-05, gnorm=2.923, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=8602
2023-03-15 16:23:08 - progress_bar.py[line:272] - INFO: epoch 013:   1275 / 2004 loss=0.292, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=356.3, nsentences=8, sample_size=356.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1059.4, ups=2.97, wpb=356.3, bsz=8, num_updates=25160, lr=7.56467e-05, gnorm=2.929, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=8605
2023-03-15 16:23:11 - progress_bar.py[line:272] - INFO: epoch 013:   1285 / 2004 loss=0.286, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=321.5, nsentences=8, sample_size=321.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=951.9, ups=2.96, wpb=321.5, bsz=8, num_updates=25170, lr=7.56366e-05, gnorm=2.939, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=8609
2023-03-15 16:23:15 - progress_bar.py[line:272] - INFO: epoch 013:   1295 / 2004 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=318.4, nsentences=8, sample_size=318.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=954, ups=3, wpb=318.4, bsz=8, num_updates=25180, lr=7.56265e-05, gnorm=2.979, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=8612
2023-03-15 16:23:18 - progress_bar.py[line:272] - INFO: epoch 013:   1305 / 2004 loss=0.293, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=311.2, nsentences=8, sample_size=311.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=917.3, ups=2.95, wpb=311.2, bsz=8, num_updates=25190, lr=7.56164e-05, gnorm=2.917, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=8616
2023-03-15 16:23:19 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 16:23:22 - progress_bar.py[line:272] - INFO: epoch 013:   1316 / 2004 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=343.1, nsentences=8, sample_size=343.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=926.3, ups=2.7, wpb=343.1, bsz=8, num_updates=25200, lr=7.56064e-05, gnorm=3.081, clip=0, loss_scale=2048, train_wall=4, gb_free=14.7, wall=8619
2023-03-15 16:23:25 - progress_bar.py[line:272] - INFO: epoch 013:   1326 / 2004 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=296, nsentences=8, sample_size=296, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=864.1, ups=2.92, wpb=296, bsz=8, num_updates=25210, lr=7.55963e-05, gnorm=3.068, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=8623
2023-03-15 16:23:29 - progress_bar.py[line:272] - INFO: epoch 013:   1336 / 2004 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=361.4, nsentences=8, sample_size=361.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=1050.7, ups=2.91, wpb=361.4, bsz=8, num_updates=25220, lr=7.55862e-05, gnorm=3.249, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=8626
2023-03-15 16:23:32 - progress_bar.py[line:272] - INFO: epoch 013:   1346 / 2004 loss=0.289, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=297.5, nsentences=8, sample_size=297.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=872.3, ups=2.93, wpb=297.5, bsz=8, num_updates=25230, lr=7.55761e-05, gnorm=2.95, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=8630
2023-03-15 16:23:35 - progress_bar.py[line:272] - INFO: epoch 013:   1356 / 2004 loss=0.299, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=327.6, nsentences=8, sample_size=327.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=977.5, ups=2.98, wpb=327.6, bsz=8, num_updates=25240, lr=7.5566e-05, gnorm=2.948, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=8633
2023-03-15 16:23:36 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 16:23:39 - progress_bar.py[line:272] - INFO: epoch 013:   1367 / 2004 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=319, nsentences=8, sample_size=319, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=877.8, ups=2.75, wpb=319, bsz=8, num_updates=25250, lr=7.5556e-05, gnorm=2.95, clip=0, loss_scale=1024, train_wall=4, gb_free=14.5, wall=8637
2023-03-15 16:23:42 - progress_bar.py[line:272] - INFO: epoch 013:   1377 / 2004 loss=0.293, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=326, nsentences=8, sample_size=326, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=976.9, ups=3, wpb=326, bsz=8, num_updates=25260, lr=7.55459e-05, gnorm=2.9, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=8640
2023-03-15 16:23:46 - progress_bar.py[line:272] - INFO: epoch 013:   1387 / 2004 loss=0.386, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=400.3, nsentences=8, sample_size=400.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=1160.7, ups=2.9, wpb=400.3, bsz=8, num_updates=25270, lr=7.55358e-05, gnorm=3.367, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=8643
2023-03-15 16:23:49 - progress_bar.py[line:272] - INFO: epoch 013:   1397 / 2004 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=339.6, nsentences=8, sample_size=339.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=995.7, ups=2.93, wpb=339.6, bsz=8, num_updates=25280, lr=7.55257e-05, gnorm=2.945, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=8647
2023-03-15 16:23:53 - progress_bar.py[line:272] - INFO: epoch 013:   1407 / 2004 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=348.2, nsentences=8, sample_size=348.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=1005.7, ups=2.89, wpb=348.2, bsz=8, num_updates=25290, lr=7.55156e-05, gnorm=3.051, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=8650
2023-03-15 16:23:56 - progress_bar.py[line:272] - INFO: epoch 013:   1417 / 2004 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=382.3, nsentences=8, sample_size=382.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=1122, ups=2.93, wpb=382.3, bsz=8, num_updates=25300, lr=7.55056e-05, gnorm=3.123, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=8654
2023-03-15 16:23:59 - progress_bar.py[line:272] - INFO: epoch 013:   1427 / 2004 loss=0.299, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=289.4, nsentences=8, sample_size=289.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=864.3, ups=2.99, wpb=289.4, bsz=8, num_updates=25310, lr=7.54955e-05, gnorm=2.911, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=8657
2023-03-15 16:24:03 - progress_bar.py[line:272] - INFO: epoch 013:   1437 / 2004 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=366.3, nsentences=8, sample_size=366.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=1065.5, ups=2.91, wpb=366.3, bsz=8, num_updates=25320, lr=7.54854e-05, gnorm=3.096, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=8660
2023-03-15 16:24:07 - progress_bar.py[line:272] - INFO: epoch 013:   1447 / 2004 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=329.8, nsentences=8, sample_size=329.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=752, ups=2.28, wpb=329.8, bsz=8, num_updates=25330, lr=7.54753e-05, gnorm=2.934, clip=0, loss_scale=1024, train_wall=4, gb_free=14.9, wall=8665
2023-03-15 16:24:11 - progress_bar.py[line:272] - INFO: epoch 013:   1457 / 2004 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=358.2, nsentences=8, sample_size=358.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=1032.7, ups=2.88, wpb=358.2, bsz=8, num_updates=25340, lr=7.54652e-05, gnorm=3.078, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=8668
2023-03-15 16:24:14 - progress_bar.py[line:272] - INFO: epoch 013:   1467 / 2004 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=409.2, nsentences=8, sample_size=409.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=1154.5, ups=2.82, wpb=409.2, bsz=8, num_updates=25350, lr=7.54552e-05, gnorm=2.998, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=8672
2023-03-15 16:24:18 - progress_bar.py[line:272] - INFO: epoch 013:   1477 / 2004 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=400.9, nsentences=8, sample_size=400.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=1162.9, ups=2.9, wpb=400.9, bsz=8, num_updates=25360, lr=7.54451e-05, gnorm=3.159, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=8675
2023-03-15 16:24:21 - progress_bar.py[line:272] - INFO: epoch 013:   1487 / 2004 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=332, nsentences=8, sample_size=332, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=978.8, ups=2.95, wpb=332, bsz=8, num_updates=25370, lr=7.5435e-05, gnorm=3.026, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=8679
2023-03-15 16:24:24 - progress_bar.py[line:272] - INFO: epoch 013:   1497 / 2004 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=342.2, nsentences=8, sample_size=342.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=1002, ups=2.93, wpb=342.2, bsz=8, num_updates=25380, lr=7.54249e-05, gnorm=3.321, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=8682
2023-03-15 16:24:28 - progress_bar.py[line:272] - INFO: epoch 013:   1507 / 2004 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=323.1, nsentences=8, sample_size=323.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=940.4, ups=2.91, wpb=323.1, bsz=8, num_updates=25390, lr=7.54148e-05, gnorm=2.864, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=8685
2023-03-15 16:24:31 - progress_bar.py[line:272] - INFO: epoch 013:   1517 / 2004 loss=0.28, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=330.4, nsentences=8, sample_size=330.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=997.5, ups=3.02, wpb=330.4, bsz=8, num_updates=25400, lr=7.54047e-05, gnorm=2.825, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=8689
2023-03-15 16:24:35 - progress_bar.py[line:272] - INFO: epoch 013:   1527 / 2004 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=321, nsentences=8, sample_size=321, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=961.1, ups=2.99, wpb=321, bsz=8, num_updates=25410, lr=7.53947e-05, gnorm=2.9, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=8692
2023-03-15 16:24:38 - progress_bar.py[line:272] - INFO: epoch 013:   1537 / 2004 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=353.2, nsentences=8, sample_size=353.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=1027.1, ups=2.91, wpb=353.2, bsz=8, num_updates=25420, lr=7.53846e-05, gnorm=3.114, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=8696
2023-03-15 16:24:41 - progress_bar.py[line:272] - INFO: epoch 013:   1547 / 2004 loss=0.265, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=318.7, nsentences=8, sample_size=318.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=961.1, ups=3.02, wpb=318.7, bsz=8, num_updates=25430, lr=7.53745e-05, gnorm=2.741, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=8699
2023-03-15 16:24:45 - progress_bar.py[line:272] - INFO: epoch 013:   1557 / 2004 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=349.2, nsentences=8, sample_size=349.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=1034.4, ups=2.96, wpb=349.2, bsz=8, num_updates=25440, lr=7.53644e-05, gnorm=3.103, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=8702
2023-03-15 16:24:48 - progress_bar.py[line:272] - INFO: epoch 013:   1567 / 2004 loss=0.289, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=334.5, nsentences=8, sample_size=334.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=990.9, ups=2.96, wpb=334.5, bsz=8, num_updates=25450, lr=7.53543e-05, gnorm=2.807, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=8706
2023-03-15 16:24:51 - progress_bar.py[line:272] - INFO: epoch 013:   1577 / 2004 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=357.8, nsentences=8, sample_size=357.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=1042.3, ups=2.91, wpb=357.8, bsz=8, num_updates=25460, lr=7.53443e-05, gnorm=3.119, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=8709
2023-03-15 16:24:55 - progress_bar.py[line:272] - INFO: epoch 013:   1587 / 2004 loss=0.27, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=308.2, nsentences=8, sample_size=308.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=898.8, ups=2.92, wpb=308.2, bsz=8, num_updates=25470, lr=7.53342e-05, gnorm=2.798, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=8713
2023-03-15 16:24:58 - progress_bar.py[line:272] - INFO: epoch 013:   1597 / 2004 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=358.6, nsentences=8, sample_size=358.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=1036.6, ups=2.89, wpb=358.6, bsz=8, num_updates=25480, lr=7.53241e-05, gnorm=3.047, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=8716
2023-03-15 16:25:02 - progress_bar.py[line:272] - INFO: epoch 013:   1607 / 2004 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=341.3, nsentences=8, sample_size=341.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=1002.1, ups=2.94, wpb=341.3, bsz=8, num_updates=25490, lr=7.5314e-05, gnorm=2.897, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=8719
2023-03-15 16:25:05 - progress_bar.py[line:272] - INFO: epoch 013:   1617 / 2004 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=336.2, nsentences=8, sample_size=336.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=974.2, ups=2.9, wpb=336.2, bsz=8, num_updates=25500, lr=7.53039e-05, gnorm=3.109, clip=0, loss_scale=4096, train_wall=3, gb_free=15.3, wall=8723
2023-03-15 16:25:06 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 16:25:09 - progress_bar.py[line:272] - INFO: epoch 013:   1628 / 2004 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=369.5, nsentences=8, sample_size=369.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=983.9, ups=2.66, wpb=369.5, bsz=8, num_updates=25510, lr=7.52939e-05, gnorm=3.097, clip=0, loss_scale=2048, train_wall=4, gb_free=14.9, wall=8727
2023-03-15 16:25:12 - progress_bar.py[line:272] - INFO: epoch 013:   1638 / 2004 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=319, nsentences=8, sample_size=319, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=936.3, ups=2.94, wpb=319, bsz=8, num_updates=25520, lr=7.52838e-05, gnorm=3.093, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=8730
2023-03-15 16:25:16 - progress_bar.py[line:272] - INFO: epoch 013:   1648 / 2004 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=315.7, nsentences=8, sample_size=315.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=927.1, ups=2.94, wpb=315.7, bsz=8, num_updates=25530, lr=7.52737e-05, gnorm=2.993, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=8733
2023-03-15 16:25:19 - progress_bar.py[line:272] - INFO: epoch 013:   1658 / 2004 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=343.7, nsentences=8, sample_size=343.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=1023.7, ups=2.98, wpb=343.7, bsz=8, num_updates=25540, lr=7.52636e-05, gnorm=3.036, clip=0, loss_scale=2048, train_wall=3, gb_free=15.9, wall=8737
2023-03-15 16:25:22 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 16:25:23 - progress_bar.py[line:272] - INFO: epoch 013:   1669 / 2004 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=369.2, nsentences=8, sample_size=369.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=968.9, ups=2.62, wpb=369.2, bsz=8, num_updates=25550, lr=7.52535e-05, gnorm=2.928, clip=0, loss_scale=1024, train_wall=4, gb_free=14.5, wall=8741
2023-03-15 16:25:26 - progress_bar.py[line:272] - INFO: epoch 013:   1679 / 2004 loss=0.291, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=315.7, nsentences=8, sample_size=315.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=940.1, ups=2.98, wpb=315.7, bsz=8, num_updates=25560, lr=7.52435e-05, gnorm=2.911, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=8744
2023-03-15 16:25:30 - progress_bar.py[line:272] - INFO: epoch 013:   1689 / 2004 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=349.9, nsentences=8, sample_size=349.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=1037.3, ups=2.96, wpb=349.9, bsz=8, num_updates=25570, lr=7.52334e-05, gnorm=3.109, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=8747
2023-03-15 16:25:33 - progress_bar.py[line:272] - INFO: epoch 013:   1699 / 2004 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=331.1, nsentences=8, sample_size=331.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=963.8, ups=2.91, wpb=331.1, bsz=8, num_updates=25580, lr=7.52233e-05, gnorm=2.988, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=8751
2023-03-15 16:25:37 - progress_bar.py[line:272] - INFO: epoch 013:   1709 / 2004 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=346, nsentences=8, sample_size=346, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=1011, ups=2.92, wpb=346, bsz=8, num_updates=25590, lr=7.52132e-05, gnorm=2.924, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=8754
2023-03-15 16:25:40 - progress_bar.py[line:272] - INFO: epoch 013:   1719 / 2004 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=370.1, nsentences=8, sample_size=370.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=1029.3, ups=2.78, wpb=370.1, bsz=8, num_updates=25600, lr=7.52031e-05, gnorm=3.066, clip=0, loss_scale=1024, train_wall=4, gb_free=15.6, wall=8758
2023-03-15 16:25:44 - progress_bar.py[line:272] - INFO: epoch 013:   1729 / 2004 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=386.1, nsentences=8, sample_size=386.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=1147.7, ups=2.97, wpb=386.1, bsz=8, num_updates=25610, lr=7.5193e-05, gnorm=2.772, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=8761
2023-03-15 16:25:47 - progress_bar.py[line:272] - INFO: epoch 013:   1739 / 2004 loss=0.296, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=326.4, nsentences=8, sample_size=326.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=961.9, ups=2.95, wpb=326.4, bsz=8, num_updates=25620, lr=7.5183e-05, gnorm=2.91, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=8765
2023-03-15 16:25:50 - progress_bar.py[line:272] - INFO: epoch 013:   1749 / 2004 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=363.3, nsentences=8, sample_size=363.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=1073.6, ups=2.96, wpb=363.3, bsz=8, num_updates=25630, lr=7.51729e-05, gnorm=2.828, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=8768
2023-03-15 16:25:54 - progress_bar.py[line:272] - INFO: epoch 013:   1759 / 2004 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=313.7, nsentences=8, sample_size=313.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=927.9, ups=2.96, wpb=313.7, bsz=8, num_updates=25640, lr=7.51628e-05, gnorm=2.905, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=8771
2023-03-15 16:25:57 - progress_bar.py[line:272] - INFO: epoch 013:   1769 / 2004 loss=0.287, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=338.7, nsentences=8, sample_size=338.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1006.8, ups=2.97, wpb=338.7, bsz=8, num_updates=25650, lr=7.51527e-05, gnorm=2.799, clip=0, loss_scale=1024, train_wall=3, gb_free=14.2, wall=8775
2023-03-15 16:26:00 - progress_bar.py[line:272] - INFO: epoch 013:   1779 / 2004 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=339.3, nsentences=8, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=1003.2, ups=2.96, wpb=339.3, bsz=8, num_updates=25660, lr=7.51426e-05, gnorm=3.054, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=8778
2023-03-15 16:26:04 - progress_bar.py[line:272] - INFO: epoch 013:   1789 / 2004 loss=0.29, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=301.3, nsentences=8, sample_size=301.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=874, ups=2.9, wpb=301.3, bsz=8, num_updates=25670, lr=7.51326e-05, gnorm=2.887, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=8781
2023-03-15 16:26:07 - progress_bar.py[line:272] - INFO: epoch 013:   1799 / 2004 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=347.4, nsentences=8, sample_size=347.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=1013.5, ups=2.92, wpb=347.4, bsz=8, num_updates=25680, lr=7.51225e-05, gnorm=3.077, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=8785
2023-03-15 16:26:11 - progress_bar.py[line:272] - INFO: epoch 013:   1809 / 2004 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=347.7, nsentences=8, sample_size=347.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=1012.3, ups=2.91, wpb=347.7, bsz=8, num_updates=25690, lr=7.51124e-05, gnorm=3.132, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=8788
2023-03-15 16:26:12 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 16:26:14 - progress_bar.py[line:272] - INFO: epoch 013:   1820 / 2004 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=344.7, nsentences=8, sample_size=344.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=937.6, ups=2.72, wpb=344.7, bsz=8, num_updates=25700, lr=7.51023e-05, gnorm=2.904, clip=0, loss_scale=1024, train_wall=4, gb_free=15.6, wall=8792
2023-03-15 16:26:18 - progress_bar.py[line:272] - INFO: epoch 013:   1830 / 2004 loss=0.296, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=347.9, nsentences=8, sample_size=347.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=1008.1, ups=2.9, wpb=347.9, bsz=8, num_updates=25710, lr=7.50922e-05, gnorm=2.846, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=8795
2023-03-15 16:26:21 - progress_bar.py[line:272] - INFO: epoch 013:   1840 / 2004 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=348.1, nsentences=8, sample_size=348.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=1013.8, ups=2.91, wpb=348.1, bsz=8, num_updates=25720, lr=7.50822e-05, gnorm=2.975, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=8799
2023-03-15 16:26:25 - progress_bar.py[line:272] - INFO: epoch 013:   1850 / 2004 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=338.2, nsentences=8, sample_size=338.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=995.9, ups=2.94, wpb=338.2, bsz=8, num_updates=25730, lr=7.50721e-05, gnorm=3.02, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=8802
2023-03-15 16:26:28 - progress_bar.py[line:272] - INFO: epoch 013:   1860 / 2004 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=326.2, nsentences=8, sample_size=326.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=947.6, ups=2.91, wpb=326.2, bsz=8, num_updates=25740, lr=7.5062e-05, gnorm=3.238, clip=10, loss_scale=1024, train_wall=3, gb_free=14.3, wall=8806
2023-03-15 16:26:32 - progress_bar.py[line:272] - INFO: epoch 013:   1870 / 2004 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=343.6, nsentences=8, sample_size=343.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=1011.8, ups=2.94, wpb=343.6, bsz=8, num_updates=25750, lr=7.50519e-05, gnorm=2.855, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=8809
2023-03-15 16:26:35 - progress_bar.py[line:272] - INFO: epoch 013:   1880 / 2004 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=332, nsentences=8, sample_size=332, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=992.1, ups=2.99, wpb=332, bsz=8, num_updates=25760, lr=7.50418e-05, gnorm=3.165, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=8812
2023-03-15 16:26:38 - progress_bar.py[line:272] - INFO: epoch 013:   1890 / 2004 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=323, nsentences=8, sample_size=323, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=969.7, ups=3, wpb=323, bsz=8, num_updates=25770, lr=7.50318e-05, gnorm=2.888, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=8816
2023-03-15 16:26:42 - progress_bar.py[line:272] - INFO: epoch 013:   1900 / 2004 loss=0.281, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=352.6, nsentences=8, sample_size=352.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1007.6, ups=2.86, wpb=352.6, bsz=8, num_updates=25780, lr=7.50217e-05, gnorm=2.802, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=8819
2023-03-15 16:26:45 - progress_bar.py[line:272] - INFO: epoch 013:   1910 / 2004 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=339.3, nsentences=8, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=991.7, ups=2.92, wpb=339.3, bsz=8, num_updates=25790, lr=7.50116e-05, gnorm=3.031, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=8823
2023-03-15 16:26:49 - progress_bar.py[line:272] - INFO: epoch 013:   1920 / 2004 loss=0.285, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=330.2, nsentences=8, sample_size=330.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=931, ups=2.82, wpb=330.2, bsz=8, num_updates=25800, lr=7.50015e-05, gnorm=2.766, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=8826
2023-03-15 16:26:52 - progress_bar.py[line:272] - INFO: epoch 013:   1930 / 2004 loss=0.29, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=316.2, nsentences=8, sample_size=316.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=929.3, ups=2.94, wpb=316.2, bsz=8, num_updates=25810, lr=7.49914e-05, gnorm=2.877, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=8830
2023-03-15 16:26:55 - progress_bar.py[line:272] - INFO: epoch 013:   1940 / 2004 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=349.9, nsentences=8, sample_size=349.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=1020.6, ups=2.92, wpb=349.9, bsz=8, num_updates=25820, lr=7.49814e-05, gnorm=3.034, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=8833
2023-03-15 16:26:59 - progress_bar.py[line:272] - INFO: epoch 013:   1950 / 2004 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=337.9, nsentences=8, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=982.7, ups=2.91, wpb=337.9, bsz=8, num_updates=25830, lr=7.49713e-05, gnorm=3.012, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=8837
2023-03-15 16:27:02 - progress_bar.py[line:272] - INFO: epoch 013:   1960 / 2004 loss=0.276, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=365.6, nsentences=8, sample_size=365.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1049.2, ups=2.87, wpb=365.6, bsz=8, num_updates=25840, lr=7.49612e-05, gnorm=2.762, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=8840
2023-03-15 16:27:06 - progress_bar.py[line:272] - INFO: epoch 013:   1970 / 2004 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=336.8, nsentences=8, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=993.6, ups=2.95, wpb=336.8, bsz=8, num_updates=25850, lr=7.49511e-05, gnorm=3.004, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=8843
2023-03-15 16:27:09 - progress_bar.py[line:272] - INFO: epoch 013:   1980 / 2004 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=343.1, nsentences=8, sample_size=343.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=999.2, ups=2.91, wpb=343.1, bsz=8, num_updates=25860, lr=7.4941e-05, gnorm=3.06, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=8847
2023-03-15 16:27:13 - progress_bar.py[line:272] - INFO: epoch 013:   1990 / 2004 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=355.1, nsentences=8, sample_size=355.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=1036.8, ups=2.92, wpb=355.1, bsz=8, num_updates=25870, lr=7.49309e-05, gnorm=3.014, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=8850
2023-03-15 16:27:16 - progress_bar.py[line:272] - INFO: epoch 013:   2000 / 2004 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=377.8, nsentences=8, sample_size=377.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=1173.4, ups=3.11, wpb=377.8, bsz=8, num_updates=25880, lr=7.49209e-05, gnorm=2.909, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=8854
2023-03-15 16:27:17 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 13 @ 25884 updates
2023-03-15 16:27:17 - trainer.py[line:431] - INFO: Saving checkpoint to ./checkpoints/checkpoint13.pt
2023-03-15 16:27:24 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./checkpoints/checkpoint13.pt
2023-03-15 16:27:26 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./checkpoints/checkpoint13.pt (epoch 13 @ 25884 updates, score None) (writing took 9.02707340568304 seconds)
2023-03-15 16:27:26 - train.py[line:332] - INFO: end of epoch 13 (average epoch stats below)
2023-03-15 16:27:26 - progress_bar.py[line:282] - INFO: epoch 013 | loss 0.322 | loss_v1 0 | loss_v2 0 | nll_loss 0.322 | ntokens 345.54 | nsentences 7.999 | sample_size 345.54 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.25 | wps 984 | ups 2.85 | wpb 345.5 | bsz 8 | num_updates 25884 | lr 7.49168e-05 | gnorm 2.983 | clip 0.1 | loss_scale 2048 | train_wall 667 | gb_free 14.5 | wall 8864
2023-03-15 16:27:26 - trainer.py[line:639] - INFO: loading train data for epoch 14
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 row count 8015 total row count 8015
slice_id 0 seek offset 0
2023-03-15 16:27:27 - trainer.py[line:703] - INFO: begin training epoch 14
2023-03-15 16:27:27 - train.py[line:305] - INFO: Start iterating over samples
2023-03-15 16:27:29 - progress_bar.py[line:272] - INFO: epoch 014:      6 / 2004 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=382.1, nsentences=8, sample_size=382.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=288.6, ups=0.76, wpb=382.1, bsz=8, num_updates=25890, lr=7.49108e-05, gnorm=3.095, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=8867
2023-03-15 16:27:32 - progress_bar.py[line:272] - INFO: epoch 014:     16 / 2004 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=311.6, nsentences=8, sample_size=311.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=931.1, ups=2.99, wpb=311.6, bsz=8, num_updates=25900, lr=7.49007e-05, gnorm=3.061, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=8870
2023-03-15 16:27:36 - progress_bar.py[line:272] - INFO: epoch 014:     26 / 2004 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=366.9, nsentences=8, sample_size=366.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=1046.1, ups=2.85, wpb=366.9, bsz=8, num_updates=25910, lr=7.48906e-05, gnorm=2.932, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=8874
2023-03-15 16:27:39 - progress_bar.py[line:272] - INFO: epoch 014:     36 / 2004 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=337.9, nsentences=8, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=996.2, ups=2.95, wpb=337.9, bsz=8, num_updates=25920, lr=7.48805e-05, gnorm=3.317, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=8877
2023-03-15 16:27:43 - progress_bar.py[line:272] - INFO: epoch 014:     46 / 2004 loss=0.291, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=362.6, nsentences=8, sample_size=362.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1052.9, ups=2.9, wpb=362.6, bsz=8, num_updates=25930, lr=7.48705e-05, gnorm=2.859, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=8880
2023-03-15 16:27:46 - progress_bar.py[line:272] - INFO: epoch 014:     56 / 2004 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=343, nsentences=8, sample_size=343, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=1006.1, ups=2.93, wpb=343, bsz=8, num_updates=25940, lr=7.48604e-05, gnorm=2.908, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=8884
2023-03-15 16:27:50 - progress_bar.py[line:272] - INFO: epoch 014:     66 / 2004 loss=0.28, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=337.6, nsentences=8, sample_size=337.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=990.3, ups=2.93, wpb=337.6, bsz=8, num_updates=25950, lr=7.48503e-05, gnorm=2.914, clip=0, loss_scale=4096, train_wall=3, gb_free=14.9, wall=8887
2023-03-15 16:27:50 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 16:27:53 - progress_bar.py[line:272] - INFO: epoch 014:     77 / 2004 loss=0.276, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=336.2, nsentences=8, sample_size=336.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=903.7, ups=2.69, wpb=336.2, bsz=8, num_updates=25960, lr=7.48402e-05, gnorm=2.705, clip=0, loss_scale=2048, train_wall=4, gb_free=15, wall=8891
2023-03-15 16:27:54 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 16:27:57 - progress_bar.py[line:272] - INFO: epoch 014:     88 / 2004 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=349.5, nsentences=8, sample_size=349.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=931.6, ups=2.67, wpb=349.5, bsz=8, num_updates=25970, lr=7.48301e-05, gnorm=3.088, clip=0, loss_scale=1024, train_wall=4, gb_free=14.7, wall=8895
2023-03-15 16:28:01 - progress_bar.py[line:272] - INFO: epoch 014:     98 / 2004 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=381.1, nsentences=8, sample_size=381.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=1095.2, ups=2.87, wpb=381.1, bsz=8, num_updates=25980, lr=7.48201e-05, gnorm=3.117, clip=0, loss_scale=1024, train_wall=3, gb_free=14.1, wall=8898
2023-03-15 16:28:04 - progress_bar.py[line:272] - INFO: epoch 014:    108 / 2004 loss=0.271, loss_v1=0, loss_v2=0, nll_loss=0.271, ntokens=351.3, nsentences=8, sample_size=351.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1017.2, ups=2.9, wpb=351.3, bsz=8, num_updates=25990, lr=7.481e-05, gnorm=2.83, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=8902
2023-03-15 16:28:07 - progress_bar.py[line:272] - INFO: epoch 014:    118 / 2004 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=329.3, nsentences=8, sample_size=329.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=972.2, ups=2.95, wpb=329.3, bsz=8, num_updates=26000, lr=7.47999e-05, gnorm=2.996, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=8905
2023-03-15 16:28:11 - progress_bar.py[line:272] - INFO: epoch 014:    128 / 2004 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=342.9, nsentences=8, sample_size=342.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=989.4, ups=2.89, wpb=342.9, bsz=8, num_updates=26010, lr=7.47898e-05, gnorm=2.887, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=8909
2023-03-15 16:28:14 - progress_bar.py[line:272] - INFO: epoch 014:    138 / 2004 loss=0.279, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=337.7, nsentences=8, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=990.3, ups=2.93, wpb=337.7, bsz=8, num_updates=26020, lr=7.47797e-05, gnorm=2.806, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=8912
2023-03-15 16:28:18 - progress_bar.py[line:272] - INFO: epoch 014:    148 / 2004 loss=0.283, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=320.5, nsentences=8, sample_size=320.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=960.4, ups=3, wpb=320.5, bsz=8, num_updates=26030, lr=7.47697e-05, gnorm=2.822, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=8915
2023-03-15 16:28:21 - progress_bar.py[line:272] - INFO: epoch 014:    158 / 2004 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=355, nsentences=8, sample_size=355, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=1032.1, ups=2.91, wpb=355, bsz=8, num_updates=26040, lr=7.47596e-05, gnorm=3.07, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=8919
2023-03-15 16:28:25 - progress_bar.py[line:272] - INFO: epoch 014:    168 / 2004 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=338, nsentences=8, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=981.5, ups=2.9, wpb=338, bsz=8, num_updates=26050, lr=7.47495e-05, gnorm=2.848, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=8922
2023-03-15 16:28:28 - progress_bar.py[line:272] - INFO: epoch 014:    178 / 2004 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=338.5, nsentences=8, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=997.4, ups=2.95, wpb=338.5, bsz=8, num_updates=26060, lr=7.47394e-05, gnorm=3.003, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=8926
2023-03-15 16:28:31 - progress_bar.py[line:272] - INFO: epoch 014:    188 / 2004 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=331.9, nsentences=8, sample_size=331.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=985.3, ups=2.97, wpb=331.9, bsz=8, num_updates=26070, lr=7.47293e-05, gnorm=2.995, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=8929
2023-03-15 16:28:35 - progress_bar.py[line:272] - INFO: epoch 014:    198 / 2004 loss=0.285, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=330.2, nsentences=8, sample_size=330.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=968.7, ups=2.93, wpb=330.2, bsz=8, num_updates=26080, lr=7.47192e-05, gnorm=2.836, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=8932
2023-03-15 16:28:38 - progress_bar.py[line:272] - INFO: epoch 014:    208 / 2004 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=341.9, nsentences=8, sample_size=341.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=998, ups=2.92, wpb=341.9, bsz=8, num_updates=26090, lr=7.47092e-05, gnorm=2.815, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=8936
2023-03-15 16:28:42 - progress_bar.py[line:272] - INFO: epoch 014:    218 / 2004 loss=0.279, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=322.5, nsentences=8, sample_size=322.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=935.2, ups=2.9, wpb=322.5, bsz=8, num_updates=26100, lr=7.46991e-05, gnorm=2.787, clip=0, loss_scale=2048, train_wall=3, gb_free=13.8, wall=8939
2023-03-15 16:28:45 - progress_bar.py[line:272] - INFO: epoch 014:    228 / 2004 loss=0.271, loss_v1=0, loss_v2=0, nll_loss=0.271, ntokens=341.6, nsentences=8, sample_size=341.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1018.3, ups=2.98, wpb=341.6, bsz=8, num_updates=26110, lr=7.4689e-05, gnorm=2.767, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=8943
2023-03-15 16:28:48 - progress_bar.py[line:272] - INFO: epoch 014:    238 / 2004 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=377.6, nsentences=8, sample_size=377.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=1099.3, ups=2.91, wpb=377.6, bsz=8, num_updates=26120, lr=7.46789e-05, gnorm=2.965, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=8946
2023-03-15 16:28:52 - progress_bar.py[line:272] - INFO: epoch 014:    248 / 2004 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=349.8, nsentences=8, sample_size=349.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=1012.9, ups=2.9, wpb=349.8, bsz=8, num_updates=26130, lr=7.46688e-05, gnorm=3.139, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=8949
2023-03-15 16:28:55 - progress_bar.py[line:272] - INFO: epoch 014:    258 / 2004 loss=0.291, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=336.9, nsentences=8, sample_size=336.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=982.6, ups=2.92, wpb=336.9, bsz=8, num_updates=26140, lr=7.46588e-05, gnorm=2.83, clip=0, loss_scale=2048, train_wall=3, gb_free=13.2, wall=8953
2023-03-15 16:28:56 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 16:28:59 - progress_bar.py[line:272] - INFO: epoch 014:    269 / 2004 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=351.2, nsentences=8, sample_size=351.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=942.2, ups=2.68, wpb=351.2, bsz=8, num_updates=26150, lr=7.46487e-05, gnorm=3.013, clip=0, loss_scale=1024, train_wall=4, gb_free=15.1, wall=8957
2023-03-15 16:29:02 - progress_bar.py[line:272] - INFO: epoch 014:    279 / 2004 loss=0.299, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=341.6, nsentences=8, sample_size=341.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=1016.8, ups=2.98, wpb=341.6, bsz=8, num_updates=26160, lr=7.46386e-05, gnorm=2.953, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=8960
2023-03-15 16:29:06 - progress_bar.py[line:272] - INFO: epoch 014:    289 / 2004 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=345.9, nsentences=8, sample_size=345.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=1016.9, ups=2.94, wpb=345.9, bsz=8, num_updates=26170, lr=7.46285e-05, gnorm=2.934, clip=0, loss_scale=1024, train_wall=3, gb_free=15.7, wall=8963
2023-03-15 16:29:09 - progress_bar.py[line:272] - INFO: epoch 014:    299 / 2004 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=380.7, nsentences=8, sample_size=380.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=1112.4, ups=2.92, wpb=380.7, bsz=8, num_updates=26180, lr=7.46184e-05, gnorm=2.909, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=8967
2023-03-15 16:29:13 - progress_bar.py[line:272] - INFO: epoch 014:    309 / 2004 loss=0.284, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=344.3, nsentences=8, sample_size=344.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1013.1, ups=2.94, wpb=344.3, bsz=8, num_updates=26190, lr=7.46084e-05, gnorm=2.885, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=8970
2023-03-15 16:29:16 - progress_bar.py[line:272] - INFO: epoch 014:    319 / 2004 loss=0.284, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=344.9, nsentences=8, sample_size=344.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1010.2, ups=2.93, wpb=344.9, bsz=8, num_updates=26200, lr=7.45983e-05, gnorm=2.951, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=8974
2023-03-15 16:29:19 - progress_bar.py[line:272] - INFO: epoch 014:    329 / 2004 loss=0.277, loss_v1=0, loss_v2=0, nll_loss=0.277, ntokens=331.9, nsentences=8, sample_size=331.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=988.5, ups=2.98, wpb=331.9, bsz=8, num_updates=26210, lr=7.45882e-05, gnorm=2.687, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=8977
2023-03-15 16:29:23 - progress_bar.py[line:272] - INFO: epoch 014:    339 / 2004 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=355.8, nsentences=8, sample_size=355.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=1040.8, ups=2.93, wpb=355.8, bsz=8, num_updates=26220, lr=7.45781e-05, gnorm=3.077, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=8980
2023-03-15 16:29:26 - progress_bar.py[line:272] - INFO: epoch 014:    349 / 2004 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=363, nsentences=8, sample_size=363, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=1057.6, ups=2.91, wpb=363, bsz=8, num_updates=26230, lr=7.4568e-05, gnorm=3.071, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=8984
2023-03-15 16:29:30 - progress_bar.py[line:272] - INFO: epoch 014:    359 / 2004 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=330.9, nsentences=8, sample_size=330.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=975.4, ups=2.95, wpb=330.9, bsz=8, num_updates=26240, lr=7.4558e-05, gnorm=3.016, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=8987
2023-03-15 16:29:33 - progress_bar.py[line:272] - INFO: epoch 014:    369 / 2004 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=354.7, nsentences=8, sample_size=354.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=1044.2, ups=2.94, wpb=354.7, bsz=8, num_updates=26250, lr=7.45479e-05, gnorm=3.147, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=8991
2023-03-15 16:29:36 - progress_bar.py[line:272] - INFO: epoch 014:    379 / 2004 loss=0.278, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=303.7, nsentences=8, sample_size=303.7, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=901.8, ups=2.97, wpb=303.7, bsz=8, num_updates=26260, lr=7.45378e-05, gnorm=2.909, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=8994
2023-03-15 16:29:40 - progress_bar.py[line:272] - INFO: epoch 014:    389 / 2004 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=356.9, nsentences=8, sample_size=356.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=1023.6, ups=2.87, wpb=356.9, bsz=8, num_updates=26270, lr=7.45277e-05, gnorm=2.887, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=8997
2023-03-15 16:29:43 - progress_bar.py[line:272] - INFO: epoch 014:    399 / 2004 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=352.8, nsentences=8, sample_size=352.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=1051.5, ups=2.98, wpb=352.8, bsz=8, num_updates=26280, lr=7.45176e-05, gnorm=2.783, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=9001
2023-03-15 16:29:47 - progress_bar.py[line:272] - INFO: epoch 014:    409 / 2004 loss=0.294, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=351.5, nsentences=8, sample_size=351.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=1037.4, ups=2.95, wpb=351.5, bsz=8, num_updates=26290, lr=7.45076e-05, gnorm=2.96, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=9004
2023-03-15 16:29:50 - progress_bar.py[line:272] - INFO: epoch 014:    419 / 2004 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=361.7, nsentences=8, sample_size=361.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=1060.8, ups=2.93, wpb=361.7, bsz=8, num_updates=26300, lr=7.44975e-05, gnorm=3.125, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=9008
2023-03-15 16:29:53 - progress_bar.py[line:272] - INFO: epoch 014:    429 / 2004 loss=0.289, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=316.8, nsentences=8, sample_size=316.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=952.1, ups=3.01, wpb=316.8, bsz=8, num_updates=26310, lr=7.44874e-05, gnorm=2.956, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=9011
2023-03-15 16:29:57 - progress_bar.py[line:272] - INFO: epoch 014:    439 / 2004 loss=0.3, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=368.1, nsentences=8, sample_size=368.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=1078.4, ups=2.93, wpb=368.1, bsz=8, num_updates=26320, lr=7.44773e-05, gnorm=2.94, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=9014
2023-03-15 16:30:00 - progress_bar.py[line:272] - INFO: epoch 014:    449 / 2004 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=377.3, nsentences=8, sample_size=377.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=1085.6, ups=2.88, wpb=377.3, bsz=8, num_updates=26330, lr=7.44672e-05, gnorm=3.134, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=9018
2023-03-15 16:30:04 - progress_bar.py[line:272] - INFO: epoch 014:    459 / 2004 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=389.4, nsentences=8, sample_size=389.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=1123.3, ups=2.88, wpb=389.4, bsz=8, num_updates=26340, lr=7.44571e-05, gnorm=3.007, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=9021
2023-03-15 16:30:07 - progress_bar.py[line:272] - INFO: epoch 014:    469 / 2004 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=356, nsentences=8, sample_size=356, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=1026.2, ups=2.88, wpb=356, bsz=8, num_updates=26350, lr=7.44471e-05, gnorm=2.937, clip=0, loss_scale=2048, train_wall=3, gb_free=13.9, wall=9025
2023-03-15 16:30:09 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 16:30:11 - progress_bar.py[line:272] - INFO: epoch 014:    480 / 2004 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=331.7, nsentences=8, sample_size=331.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=881.8, ups=2.66, wpb=331.7, bsz=8, num_updates=26360, lr=7.4437e-05, gnorm=2.986, clip=0, loss_scale=1024, train_wall=4, gb_free=15, wall=9029
2023-03-15 16:30:14 - progress_bar.py[line:272] - INFO: epoch 014:    490 / 2004 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=370.7, nsentences=8, sample_size=370.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=1052.2, ups=2.84, wpb=370.7, bsz=8, num_updates=26370, lr=7.44269e-05, gnorm=3.061, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=9032
2023-03-15 16:30:18 - progress_bar.py[line:272] - INFO: epoch 014:    500 / 2004 loss=0.3, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=356.4, nsentences=8, sample_size=356.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=1001.2, ups=2.81, wpb=356.4, bsz=8, num_updates=26380, lr=7.44168e-05, gnorm=2.988, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=9036
2023-03-15 16:30:22 - progress_bar.py[line:272] - INFO: epoch 014:    510 / 2004 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=363.2, nsentences=8, sample_size=363.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=1005.3, ups=2.77, wpb=363.2, bsz=8, num_updates=26390, lr=7.44067e-05, gnorm=3.166, clip=0, loss_scale=1024, train_wall=4, gb_free=14.1, wall=9039
2023-03-15 16:30:25 - progress_bar.py[line:272] - INFO: epoch 014:    520 / 2004 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=352.6, nsentences=8, sample_size=352.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=972.8, ups=2.76, wpb=352.6, bsz=8, num_updates=26400, lr=7.43967e-05, gnorm=3.087, clip=0, loss_scale=1024, train_wall=4, gb_free=15.4, wall=9043
2023-03-15 16:30:29 - progress_bar.py[line:272] - INFO: epoch 014:    530 / 2004 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=402.7, nsentences=8, sample_size=402.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=1171, ups=2.91, wpb=402.7, bsz=8, num_updates=26410, lr=7.43866e-05, gnorm=2.97, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=9046
2023-03-15 16:30:32 - progress_bar.py[line:272] - INFO: epoch 014:    540 / 2004 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=391.4, nsentences=8, sample_size=391.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=1170.3, ups=2.99, wpb=391.4, bsz=8, num_updates=26420, lr=7.43765e-05, gnorm=2.981, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=9050
2023-03-15 16:30:35 - progress_bar.py[line:272] - INFO: epoch 014:    550 / 2004 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=350.7, nsentences=8, sample_size=350.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=1018.7, ups=2.9, wpb=350.7, bsz=8, num_updates=26430, lr=7.43664e-05, gnorm=2.97, clip=0, loss_scale=1024, train_wall=3, gb_free=14.2, wall=9053
2023-03-15 16:30:39 - progress_bar.py[line:272] - INFO: epoch 014:    560 / 2004 loss=0.289, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=362.5, nsentences=8, sample_size=362.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1080.2, ups=2.98, wpb=362.5, bsz=8, num_updates=26440, lr=7.43563e-05, gnorm=2.894, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=9056
2023-03-15 16:30:42 - progress_bar.py[line:272] - INFO: epoch 014:    570 / 2004 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=382, nsentences=8, sample_size=382, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=1094.3, ups=2.86, wpb=382, bsz=8, num_updates=26450, lr=7.43463e-05, gnorm=3.086, clip=0, loss_scale=1024, train_wall=3, gb_free=14.1, wall=9060
2023-03-15 16:30:46 - progress_bar.py[line:272] - INFO: epoch 014:    580 / 2004 loss=0.288, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=317.6, nsentences=8, sample_size=317.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=943.4, ups=2.97, wpb=317.6, bsz=8, num_updates=26460, lr=7.43362e-05, gnorm=2.81, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=9063
2023-03-15 16:30:49 - progress_bar.py[line:272] - INFO: epoch 014:    590 / 2004 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=383, nsentences=8, sample_size=383, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=1108, ups=2.89, wpb=383, bsz=8, num_updates=26470, lr=7.43261e-05, gnorm=3.056, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=9067
2023-03-15 16:30:53 - progress_bar.py[line:272] - INFO: epoch 014:    600 / 2004 loss=0.299, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=349.1, nsentences=8, sample_size=349.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=1021.9, ups=2.93, wpb=349.1, bsz=8, num_updates=26480, lr=7.4316e-05, gnorm=2.879, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=9070
2023-03-15 16:30:56 - progress_bar.py[line:272] - INFO: epoch 014:    610 / 2004 loss=0.293, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=335.9, nsentences=8, sample_size=335.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=980.5, ups=2.92, wpb=335.9, bsz=8, num_updates=26490, lr=7.43059e-05, gnorm=2.806, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=9074
2023-03-15 16:30:59 - progress_bar.py[line:272] - INFO: epoch 014:    620 / 2004 loss=0.282, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=370.2, nsentences=8, sample_size=370.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1079.4, ups=2.92, wpb=370.2, bsz=8, num_updates=26500, lr=7.42959e-05, gnorm=2.784, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=9077
2023-03-15 16:31:03 - progress_bar.py[line:272] - INFO: epoch 014:    630 / 2004 loss=0.267, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=347.8, nsentences=8, sample_size=347.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1025.3, ups=2.95, wpb=347.8, bsz=8, num_updates=26510, lr=7.42858e-05, gnorm=2.703, clip=0, loss_scale=2048, train_wall=3, gb_free=15.8, wall=9080
2023-03-15 16:31:06 - progress_bar.py[line:272] - INFO: epoch 014:    640 / 2004 loss=0.28, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=347.1, nsentences=8, sample_size=347.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1013.3, ups=2.92, wpb=347.1, bsz=8, num_updates=26520, lr=7.42757e-05, gnorm=2.957, clip=0, loss_scale=2048, train_wall=3, gb_free=13.5, wall=9084
2023-03-15 16:31:10 - progress_bar.py[line:272] - INFO: epoch 014:    650 / 2004 loss=0.288, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=321.3, nsentences=8, sample_size=321.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=958.6, ups=2.98, wpb=321.3, bsz=8, num_updates=26530, lr=7.42656e-05, gnorm=2.835, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=9087
2023-03-15 16:31:13 - progress_bar.py[line:272] - INFO: epoch 014:    660 / 2004 loss=0.296, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=341.3, nsentences=8, sample_size=341.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=978.5, ups=2.87, wpb=341.3, bsz=8, num_updates=26540, lr=7.42555e-05, gnorm=2.839, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=9091
2023-03-15 16:31:16 - progress_bar.py[line:272] - INFO: epoch 014:    670 / 2004 loss=0.286, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=323.1, nsentences=8, sample_size=323.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=963.3, ups=2.98, wpb=323.1, bsz=8, num_updates=26550, lr=7.42454e-05, gnorm=2.959, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=9094
2023-03-15 16:31:20 - progress_bar.py[line:272] - INFO: epoch 014:    680 / 2004 loss=0.287, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=332.9, nsentences=8, sample_size=332.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=988.7, ups=2.97, wpb=332.9, bsz=8, num_updates=26560, lr=7.42354e-05, gnorm=2.777, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=9097
2023-03-15 16:31:23 - progress_bar.py[line:272] - INFO: epoch 014:    690 / 2004 loss=0.293, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=355.4, nsentences=8, sample_size=355.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=1042.5, ups=2.93, wpb=355.4, bsz=8, num_updates=26570, lr=7.42253e-05, gnorm=2.965, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=9101
2023-03-15 16:31:27 - progress_bar.py[line:272] - INFO: epoch 014:    700 / 2004 loss=0.277, loss_v1=0, loss_v2=0, nll_loss=0.277, ntokens=341, nsentences=8, sample_size=341, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=989.4, ups=2.9, wpb=341, bsz=8, num_updates=26580, lr=7.42152e-05, gnorm=2.86, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=9104
2023-03-15 16:31:28 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 16:31:30 - progress_bar.py[line:272] - INFO: epoch 014:    711 / 2004 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=320.9, nsentences=8, sample_size=320.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=854.7, ups=2.66, wpb=320.9, bsz=8, num_updates=26590, lr=7.42051e-05, gnorm=3.005, clip=0, loss_scale=1024, train_wall=4, gb_free=14.9, wall=9108
2023-03-15 16:31:34 - progress_bar.py[line:272] - INFO: epoch 014:    721 / 2004 loss=0.289, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=351.6, nsentences=8, sample_size=351.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1036.3, ups=2.95, wpb=351.6, bsz=8, num_updates=26600, lr=7.4195e-05, gnorm=2.982, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=9111
2023-03-15 16:31:37 - progress_bar.py[line:272] - INFO: epoch 014:    731 / 2004 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=356.9, nsentences=8, sample_size=356.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=1067.9, ups=2.99, wpb=356.9, bsz=8, num_updates=26610, lr=7.4185e-05, gnorm=3.204, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=9115
2023-03-15 16:31:41 - progress_bar.py[line:272] - INFO: epoch 014:    741 / 2004 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=332.4, nsentences=8, sample_size=332.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=960.2, ups=2.89, wpb=332.4, bsz=8, num_updates=26620, lr=7.41749e-05, gnorm=3.047, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=9118
2023-03-15 16:31:44 - progress_bar.py[line:272] - INFO: epoch 014:    751 / 2004 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=354.2, nsentences=8, sample_size=354.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=1034.2, ups=2.92, wpb=354.2, bsz=8, num_updates=26630, lr=7.41648e-05, gnorm=3.19, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=9122
2023-03-15 16:31:47 - progress_bar.py[line:272] - INFO: epoch 014:    761 / 2004 loss=0.297, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=329.7, nsentences=8, sample_size=329.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=959.6, ups=2.91, wpb=329.7, bsz=8, num_updates=26640, lr=7.41547e-05, gnorm=2.94, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=9125
2023-03-15 16:31:51 - progress_bar.py[line:272] - INFO: epoch 014:    771 / 2004 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=394.1, nsentences=8, sample_size=394.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=1123.5, ups=2.85, wpb=394.1, bsz=8, num_updates=26650, lr=7.41446e-05, gnorm=3.026, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=9129
2023-03-15 16:31:54 - progress_bar.py[line:272] - INFO: epoch 014:    781 / 2004 loss=0.28, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=338.5, nsentences=8, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1017.7, ups=3.01, wpb=338.5, bsz=8, num_updates=26660, lr=7.41346e-05, gnorm=2.827, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=9132
2023-03-15 16:31:58 - progress_bar.py[line:272] - INFO: epoch 014:    791 / 2004 loss=0.283, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=346.9, nsentences=8, sample_size=346.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1013.6, ups=2.92, wpb=346.9, bsz=8, num_updates=26670, lr=7.41245e-05, gnorm=2.889, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=9135
2023-03-15 16:32:01 - progress_bar.py[line:272] - INFO: epoch 014:    801 / 2004 loss=0.275, loss_v1=0, loss_v2=0, nll_loss=0.275, ntokens=323.7, nsentences=8, sample_size=323.7, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=957.7, ups=2.96, wpb=323.7, bsz=8, num_updates=26680, lr=7.41144e-05, gnorm=2.891, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=9139
2023-03-15 16:32:04 - progress_bar.py[line:272] - INFO: epoch 014:    811 / 2004 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=350.3, nsentences=8, sample_size=350.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=1044.1, ups=2.98, wpb=350.3, bsz=8, num_updates=26690, lr=7.41043e-05, gnorm=3.094, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=9142
2023-03-15 16:32:08 - progress_bar.py[line:272] - INFO: epoch 014:    821 / 2004 loss=0.287, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=324.2, nsentences=8, sample_size=324.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=975.2, ups=3.01, wpb=324.2, bsz=8, num_updates=26700, lr=7.40942e-05, gnorm=3.053, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=9145
2023-03-15 16:32:11 - progress_bar.py[line:272] - INFO: epoch 014:    831 / 2004 loss=0.279, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=356.2, nsentences=8, sample_size=356.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1038.1, ups=2.91, wpb=356.2, bsz=8, num_updates=26710, lr=7.40842e-05, gnorm=2.832, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=9149
2023-03-15 16:32:15 - progress_bar.py[line:272] - INFO: epoch 014:    841 / 2004 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=352.8, nsentences=8, sample_size=352.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=1022.7, ups=2.9, wpb=352.8, bsz=8, num_updates=26720, lr=7.40741e-05, gnorm=3.139, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=9152
2023-03-15 16:32:18 - progress_bar.py[line:272] - INFO: epoch 014:    851 / 2004 loss=0.278, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=361.9, nsentences=8, sample_size=361.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1065.9, ups=2.95, wpb=361.9, bsz=8, num_updates=26730, lr=7.4064e-05, gnorm=2.908, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=9156
2023-03-15 16:32:21 - progress_bar.py[line:272] - INFO: epoch 014:    861 / 2004 loss=0.287, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=345, nsentences=8, sample_size=345, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1011.9, ups=2.93, wpb=345, bsz=8, num_updates=26740, lr=7.40539e-05, gnorm=2.959, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=9159
2023-03-15 16:32:25 - progress_bar.py[line:272] - INFO: epoch 014:    871 / 2004 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=373.7, nsentences=8, sample_size=373.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=1074, ups=2.87, wpb=373.7, bsz=8, num_updates=26750, lr=7.40438e-05, gnorm=3.203, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=9163
2023-03-15 16:32:28 - progress_bar.py[line:272] - INFO: epoch 014:    881 / 2004 loss=0.265, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=313.5, nsentences=8, sample_size=313.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=935.5, ups=2.98, wpb=313.5, bsz=8, num_updates=26760, lr=7.40338e-05, gnorm=2.866, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=9166
2023-03-15 16:32:32 - progress_bar.py[line:272] - INFO: epoch 014:    891 / 2004 loss=0.265, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=320.9, nsentences=8, sample_size=320.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=917.8, ups=2.86, wpb=320.9, bsz=8, num_updates=26770, lr=7.40237e-05, gnorm=3.08, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=9169
2023-03-15 16:32:35 - progress_bar.py[line:272] - INFO: epoch 014:    901 / 2004 loss=0.292, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=364.7, nsentences=8, sample_size=364.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1056.3, ups=2.9, wpb=364.7, bsz=8, num_updates=26780, lr=7.40136e-05, gnorm=2.862, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=9173
2023-03-15 16:32:39 - progress_bar.py[line:272] - INFO: epoch 014:    911 / 2004 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=354, nsentences=8, sample_size=354, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=1035.4, ups=2.92, wpb=354, bsz=8, num_updates=26790, lr=7.40035e-05, gnorm=2.975, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=9176
2023-03-15 16:32:42 - progress_bar.py[line:272] - INFO: epoch 014:    921 / 2004 loss=0.274, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=345.4, nsentences=8, sample_size=345.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1010.8, ups=2.93, wpb=345.4, bsz=8, num_updates=26800, lr=7.39934e-05, gnorm=2.879, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=9180
2023-03-15 16:32:46 - progress_bar.py[line:272] - INFO: epoch 014:    931 / 2004 loss=0.294, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=333, nsentences=8, sample_size=333, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=964.8, ups=2.9, wpb=333, bsz=8, num_updates=26810, lr=7.39833e-05, gnorm=2.945, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=9183
2023-03-15 16:32:49 - progress_bar.py[line:272] - INFO: epoch 014:    941 / 2004 loss=0.278, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=368.6, nsentences=8, sample_size=368.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1060.9, ups=2.88, wpb=368.6, bsz=8, num_updates=26820, lr=7.39733e-05, gnorm=3.012, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=9187
2023-03-15 16:32:51 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 16:32:53 - progress_bar.py[line:272] - INFO: epoch 014:    952 / 2004 loss=0.29, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=348.1, nsentences=8, sample_size=348.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=925.8, ups=2.66, wpb=348.1, bsz=8, num_updates=26830, lr=7.39632e-05, gnorm=3.016, clip=0, loss_scale=1024, train_wall=4, gb_free=15.3, wall=9190
2023-03-15 16:32:56 - progress_bar.py[line:272] - INFO: epoch 014:    962 / 2004 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=383.1, nsentences=8, sample_size=383.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=1115.7, ups=2.91, wpb=383.1, bsz=8, num_updates=26840, lr=7.39531e-05, gnorm=3.106, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=9194
2023-03-15 16:33:00 - progress_bar.py[line:272] - INFO: epoch 014:    972 / 2004 loss=0.292, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=337.4, nsentences=8, sample_size=337.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=967.6, ups=2.87, wpb=337.4, bsz=8, num_updates=26850, lr=7.3943e-05, gnorm=2.895, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=9197
2023-03-15 16:33:03 - progress_bar.py[line:272] - INFO: epoch 014:    982 / 2004 loss=0.282, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=316.7, nsentences=8, sample_size=316.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=943.6, ups=2.98, wpb=316.7, bsz=8, num_updates=26860, lr=7.39329e-05, gnorm=2.907, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=9201
2023-03-15 16:33:06 - progress_bar.py[line:272] - INFO: epoch 014:    992 / 2004 loss=0.3, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=380.5, nsentences=8, sample_size=380.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=1109.9, ups=2.92, wpb=380.5, bsz=8, num_updates=26870, lr=7.39229e-05, gnorm=2.952, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=9204
2023-03-15 16:33:10 - progress_bar.py[line:272] - INFO: epoch 014:   1002 / 2004 loss=0.275, loss_v1=0, loss_v2=0, nll_loss=0.275, ntokens=334.7, nsentences=8, sample_size=334.7, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=995.8, ups=2.98, wpb=334.7, bsz=8, num_updates=26880, lr=7.39128e-05, gnorm=2.919, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=9207
2023-03-15 16:33:13 - progress_bar.py[line:272] - INFO: epoch 014:   1012 / 2004 loss=0.285, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=329.9, nsentences=8, sample_size=329.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=954.9, ups=2.89, wpb=329.9, bsz=8, num_updates=26890, lr=7.39027e-05, gnorm=2.944, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=9211
2023-03-15 16:33:17 - progress_bar.py[line:272] - INFO: epoch 014:   1022 / 2004 loss=0.291, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=319.8, nsentences=8, sample_size=319.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=956.5, ups=2.99, wpb=319.8, bsz=8, num_updates=26900, lr=7.38926e-05, gnorm=2.831, clip=0, loss_scale=1024, train_wall=3, gb_free=15.8, wall=9214
2023-03-15 16:33:20 - progress_bar.py[line:272] - INFO: epoch 014:   1032 / 2004 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.25, ntokens=331, nsentences=8, sample_size=331, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=984.5, ups=2.97, wpb=331, bsz=8, num_updates=26910, lr=7.38825e-05, gnorm=2.894, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=9218
2023-03-15 16:33:23 - progress_bar.py[line:272] - INFO: epoch 014:   1042 / 2004 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=338.7, nsentences=8, sample_size=338.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=993.1, ups=2.93, wpb=338.7, bsz=8, num_updates=26920, lr=7.38725e-05, gnorm=2.985, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=9221
2023-03-15 16:33:27 - progress_bar.py[line:272] - INFO: epoch 014:   1052 / 2004 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=368, nsentences=8, sample_size=368, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=1073.8, ups=2.92, wpb=368, bsz=8, num_updates=26930, lr=7.38624e-05, gnorm=3.02, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=9224
2023-03-15 16:33:30 - progress_bar.py[line:272] - INFO: epoch 014:   1062 / 2004 loss=0.283, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=338.8, nsentences=8, sample_size=338.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1010.1, ups=2.98, wpb=338.8, bsz=8, num_updates=26940, lr=7.38523e-05, gnorm=3.054, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=9228
2023-03-15 16:33:34 - progress_bar.py[line:272] - INFO: epoch 014:   1072 / 2004 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=355.7, nsentences=8, sample_size=355.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=1067.6, ups=3, wpb=355.7, bsz=8, num_updates=26950, lr=7.38422e-05, gnorm=3.077, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=9231
2023-03-15 16:33:37 - progress_bar.py[line:272] - INFO: epoch 014:   1082 / 2004 loss=0.283, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=368.8, nsentences=8, sample_size=368.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1045.7, ups=2.84, wpb=368.8, bsz=8, num_updates=26960, lr=7.38321e-05, gnorm=2.907, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=9235
2023-03-15 16:33:40 - progress_bar.py[line:272] - INFO: epoch 014:   1092 / 2004 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=329.3, nsentences=8, sample_size=329.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=966.3, ups=2.93, wpb=329.3, bsz=8, num_updates=26970, lr=7.38221e-05, gnorm=3.167, clip=10, loss_scale=2048, train_wall=3, gb_free=14.9, wall=9238
2023-03-15 16:33:44 - progress_bar.py[line:272] - INFO: epoch 014:   1102 / 2004 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=362, nsentences=8, sample_size=362, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=1045.1, ups=2.89, wpb=362, bsz=8, num_updates=26980, lr=7.3812e-05, gnorm=3.11, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=9242
2023-03-15 16:33:47 - progress_bar.py[line:272] - INFO: epoch 014:   1112 / 2004 loss=0.275, loss_v1=0, loss_v2=0, nll_loss=0.275, ntokens=360.1, nsentences=8, sample_size=360.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1064.6, ups=2.96, wpb=360.1, bsz=8, num_updates=26990, lr=7.38019e-05, gnorm=2.717, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=9245
2023-03-15 16:33:51 - progress_bar.py[line:272] - INFO: epoch 014:   1122 / 2004 loss=0.258, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=307.3, nsentences=8, sample_size=307.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=902.3, ups=2.94, wpb=307.3, bsz=8, num_updates=27000, lr=7.37918e-05, gnorm=2.775, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=9248
2023-03-15 16:33:54 - progress_bar.py[line:272] - INFO: epoch 014:   1132 / 2004 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=378.4, nsentences=8, sample_size=378.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=1101.6, ups=2.91, wpb=378.4, bsz=8, num_updates=27010, lr=7.37817e-05, gnorm=2.977, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=9252
2023-03-15 16:33:57 - progress_bar.py[line:272] - INFO: epoch 014:   1142 / 2004 loss=0.289, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=361.2, nsentences=8, sample_size=361.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1078.5, ups=2.99, wpb=361.2, bsz=8, num_updates=27020, lr=7.37716e-05, gnorm=2.978, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=9255
2023-03-15 16:34:01 - progress_bar.py[line:272] - INFO: epoch 014:   1152 / 2004 loss=0.283, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=377.5, nsentences=8, sample_size=377.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1097.5, ups=2.91, wpb=377.5, bsz=8, num_updates=27030, lr=7.37616e-05, gnorm=2.913, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=9259
2023-03-15 16:34:04 - progress_bar.py[line:272] - INFO: epoch 014:   1162 / 2004 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=376.5, nsentences=8, sample_size=376.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=1107.8, ups=2.94, wpb=376.5, bsz=8, num_updates=27040, lr=7.37515e-05, gnorm=3.164, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=9262
2023-03-15 16:34:08 - progress_bar.py[line:272] - INFO: epoch 014:   1172 / 2004 loss=0.276, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=344.4, nsentences=8, sample_size=344.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1033.8, ups=3, wpb=344.4, bsz=8, num_updates=27050, lr=7.37414e-05, gnorm=2.903, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=9265
2023-03-15 16:34:11 - progress_bar.py[line:272] - INFO: epoch 014:   1182 / 2004 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=348.5, nsentences=8, sample_size=348.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=1027.5, ups=2.95, wpb=348.5, bsz=8, num_updates=27060, lr=7.37313e-05, gnorm=3.204, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=9269
2023-03-15 16:34:14 - progress_bar.py[line:272] - INFO: epoch 014:   1192 / 2004 loss=0.274, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=346.6, nsentences=8, sample_size=346.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1014.9, ups=2.93, wpb=346.6, bsz=8, num_updates=27070, lr=7.37212e-05, gnorm=2.8, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=9272
2023-03-15 16:34:18 - progress_bar.py[line:272] - INFO: epoch 014:   1202 / 2004 loss=0.274, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=343.5, nsentences=8, sample_size=343.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1003.2, ups=2.92, wpb=343.5, bsz=8, num_updates=27080, lr=7.37112e-05, gnorm=2.963, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=9276
2023-03-15 16:34:21 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 16:34:22 - progress_bar.py[line:272] - INFO: epoch 014:   1213 / 2004 loss=0.276, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=271.8, nsentences=8, sample_size=271.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=752.1, ups=2.77, wpb=271.8, bsz=8, num_updates=27090, lr=7.37011e-05, gnorm=2.945, clip=0, loss_scale=2048, train_wall=4, gb_free=14, wall=9279
2023-03-15 16:34:25 - progress_bar.py[line:272] - INFO: epoch 014:   1223 / 2004 loss=0.3, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=341.2, nsentences=8, sample_size=341.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=1036.8, ups=3.04, wpb=341.2, bsz=8, num_updates=27100, lr=7.3691e-05, gnorm=2.952, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=9282
2023-03-15 16:34:28 - progress_bar.py[line:272] - INFO: epoch 014:   1233 / 2004 loss=0.266, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=304.3, nsentences=8, sample_size=304.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=887.2, ups=2.92, wpb=304.3, bsz=8, num_updates=27110, lr=7.36809e-05, gnorm=2.736, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=9286
2023-03-15 16:34:32 - progress_bar.py[line:272] - INFO: epoch 014:   1243 / 2004 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=392.9, nsentences=8, sample_size=392.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=1127.5, ups=2.87, wpb=392.9, bsz=8, num_updates=27120, lr=7.36708e-05, gnorm=3.01, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=9289
2023-03-15 16:34:35 - progress_bar.py[line:272] - INFO: epoch 014:   1253 / 2004 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=347.9, nsentences=8, sample_size=347.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=1014.1, ups=2.92, wpb=347.9, bsz=8, num_updates=27130, lr=7.36608e-05, gnorm=3.279, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=9293
2023-03-15 16:34:39 - progress_bar.py[line:272] - INFO: epoch 014:   1263 / 2004 loss=0.279, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=340.3, nsentences=8, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=997.7, ups=2.93, wpb=340.3, bsz=8, num_updates=27140, lr=7.36507e-05, gnorm=2.939, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=9296
2023-03-15 16:34:42 - progress_bar.py[line:272] - INFO: epoch 014:   1273 / 2004 loss=0.299, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=342.2, nsentences=8, sample_size=342.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=999.9, ups=2.92, wpb=342.2, bsz=8, num_updates=27150, lr=7.36406e-05, gnorm=3.175, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=9300
2023-03-15 16:34:45 - progress_bar.py[line:272] - INFO: epoch 014:   1283 / 2004 loss=0.285, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=337.5, nsentences=8, sample_size=337.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=994.9, ups=2.95, wpb=337.5, bsz=8, num_updates=27160, lr=7.36305e-05, gnorm=2.993, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=9303
2023-03-15 16:34:49 - progress_bar.py[line:272] - INFO: epoch 014:   1293 / 2004 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=300.3, nsentences=8, sample_size=300.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=879.1, ups=2.93, wpb=300.3, bsz=8, num_updates=27170, lr=7.36204e-05, gnorm=2.714, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=9306
2023-03-15 16:34:52 - progress_bar.py[line:272] - INFO: epoch 014:   1303 / 2004 loss=0.288, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=337.6, nsentences=8, sample_size=337.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=979.3, ups=2.9, wpb=337.6, bsz=8, num_updates=27180, lr=7.36104e-05, gnorm=2.868, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=9310
2023-03-15 16:34:56 - progress_bar.py[line:272] - INFO: epoch 014:   1313 / 2004 loss=0.286, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=318.6, nsentences=8, sample_size=318.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=934.7, ups=2.93, wpb=318.6, bsz=8, num_updates=27190, lr=7.36003e-05, gnorm=2.792, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=9313
2023-03-15 16:34:59 - progress_bar.py[line:272] - INFO: epoch 014:   1323 / 2004 loss=0.274, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=317.3, nsentences=8, sample_size=317.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=945.3, ups=2.98, wpb=317.3, bsz=8, num_updates=27200, lr=7.35902e-05, gnorm=3.065, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=9317
2023-03-15 16:35:02 - progress_bar.py[line:272] - INFO: epoch 014:   1333 / 2004 loss=0.286, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=341.2, nsentences=8, sample_size=341.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1025.1, ups=3, wpb=341.2, bsz=8, num_updates=27210, lr=7.35801e-05, gnorm=2.961, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=9320
2023-03-15 16:35:06 - progress_bar.py[line:272] - INFO: epoch 014:   1343 / 2004 loss=0.286, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=315.7, nsentences=8, sample_size=315.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=925.8, ups=2.93, wpb=315.7, bsz=8, num_updates=27220, lr=7.357e-05, gnorm=2.885, clip=0, loss_scale=4096, train_wall=3, gb_free=14.2, wall=9323
2023-03-15 16:35:07 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 16:35:09 - progress_bar.py[line:272] - INFO: epoch 014:   1354 / 2004 loss=0.264, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=306.7, nsentences=8, sample_size=306.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=837.5, ups=2.73, wpb=306.7, bsz=8, num_updates=27230, lr=7.356e-05, gnorm=2.943, clip=0, loss_scale=2048, train_wall=4, gb_free=15.2, wall=9327
2023-03-15 16:35:13 - progress_bar.py[line:272] - INFO: epoch 014:   1364 / 2004 loss=0.294, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=312.3, nsentences=8, sample_size=312.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=913.2, ups=2.92, wpb=312.3, bsz=8, num_updates=27240, lr=7.35499e-05, gnorm=3.048, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=9330
2023-03-15 16:35:13 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 16:35:17 - progress_bar.py[line:272] - INFO: epoch 014:   1375 / 2004 loss=0.268, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=322.4, nsentences=8, sample_size=322.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=852.1, ups=2.64, wpb=322.4, bsz=8, num_updates=27250, lr=7.35398e-05, gnorm=2.878, clip=0, loss_scale=1024, train_wall=4, gb_free=13.9, wall=9334
2023-03-15 16:35:20 - progress_bar.py[line:272] - INFO: epoch 014:   1385 / 2004 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=384.2, nsentences=8, sample_size=384.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=1101.8, ups=2.87, wpb=384.2, bsz=8, num_updates=27260, lr=7.35297e-05, gnorm=3.298, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=9338
2023-03-15 16:35:24 - progress_bar.py[line:272] - INFO: epoch 014:   1395 / 2004 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=358.4, nsentences=8, sample_size=358.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=1043, ups=2.91, wpb=358.4, bsz=8, num_updates=27270, lr=7.35196e-05, gnorm=3.19, clip=0, loss_scale=1024, train_wall=3, gb_free=13.6, wall=9341
2023-03-15 16:35:27 - progress_bar.py[line:272] - INFO: epoch 014:   1405 / 2004 loss=0.299, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=330, nsentences=8, sample_size=330, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=980.1, ups=2.97, wpb=330, bsz=8, num_updates=27280, lr=7.35095e-05, gnorm=3.026, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=9345
2023-03-15 16:35:30 - progress_bar.py[line:272] - INFO: epoch 014:   1415 / 2004 loss=0.29, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=402.8, nsentences=8, sample_size=402.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1153.4, ups=2.86, wpb=402.8, bsz=8, num_updates=27290, lr=7.34995e-05, gnorm=2.873, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=9348
2023-03-15 16:35:34 - progress_bar.py[line:272] - INFO: epoch 014:   1425 / 2004 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=286.3, nsentences=8, sample_size=286.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=843.1, ups=2.94, wpb=286.3, bsz=8, num_updates=27300, lr=7.34894e-05, gnorm=2.698, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=9351
2023-03-15 16:35:37 - progress_bar.py[line:272] - INFO: epoch 014:   1435 / 2004 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=354.5, nsentences=8, sample_size=354.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=1028.1, ups=2.9, wpb=354.5, bsz=8, num_updates=27310, lr=7.34793e-05, gnorm=3.222, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=9355
2023-03-15 16:35:41 - progress_bar.py[line:272] - INFO: epoch 014:   1445 / 2004 loss=0.278, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=330.5, nsentences=8, sample_size=330.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=978.2, ups=2.96, wpb=330.5, bsz=8, num_updates=27320, lr=7.34692e-05, gnorm=2.807, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=9358
2023-03-15 16:35:44 - progress_bar.py[line:272] - INFO: epoch 014:   1455 / 2004 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=369.9, nsentences=8, sample_size=369.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=1088, ups=2.94, wpb=369.9, bsz=8, num_updates=27330, lr=7.34591e-05, gnorm=3.162, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=9362
2023-03-15 16:35:48 - progress_bar.py[line:272] - INFO: epoch 014:   1465 / 2004 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=395.3, nsentences=8, sample_size=395.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=1136.2, ups=2.87, wpb=395.3, bsz=8, num_updates=27340, lr=7.34491e-05, gnorm=2.978, clip=0, loss_scale=1024, train_wall=3, gb_free=14.1, wall=9365
2023-03-15 16:35:51 - progress_bar.py[line:272] - INFO: epoch 014:   1475 / 2004 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=403.8, nsentences=8, sample_size=403.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=1164.1, ups=2.88, wpb=403.8, bsz=8, num_updates=27350, lr=7.3439e-05, gnorm=3.033, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=9369
2023-03-15 16:35:54 - progress_bar.py[line:272] - INFO: epoch 014:   1485 / 2004 loss=0.275, loss_v1=0, loss_v2=0, nll_loss=0.275, ntokens=357.2, nsentences=8, sample_size=357.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1053.4, ups=2.95, wpb=357.2, bsz=8, num_updates=27360, lr=7.34289e-05, gnorm=2.813, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=9372
2023-03-15 16:35:58 - progress_bar.py[line:272] - INFO: epoch 014:   1495 / 2004 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=321, nsentences=8, sample_size=321, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=933.6, ups=2.91, wpb=321, bsz=8, num_updates=27370, lr=7.34188e-05, gnorm=3.232, clip=0, loss_scale=2048, train_wall=3, gb_free=13.9, wall=9375
2023-03-15 16:36:01 - progress_bar.py[line:272] - INFO: epoch 014:   1505 / 2004 loss=0.262, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=325.8, nsentences=8, sample_size=325.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=954.2, ups=2.93, wpb=325.8, bsz=8, num_updates=27380, lr=7.34087e-05, gnorm=2.811, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=9379
2023-03-15 16:36:05 - progress_bar.py[line:272] - INFO: epoch 014:   1515 / 2004 loss=0.268, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=322.9, nsentences=8, sample_size=322.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=928.7, ups=2.88, wpb=322.9, bsz=8, num_updates=27390, lr=7.33987e-05, gnorm=2.948, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=9382
2023-03-15 16:36:08 - progress_bar.py[line:272] - INFO: epoch 014:   1525 / 2004 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=333, nsentences=8, sample_size=333, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=975.4, ups=2.93, wpb=333, bsz=8, num_updates=27400, lr=7.33886e-05, gnorm=3.207, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=9386
2023-03-15 16:36:11 - progress_bar.py[line:272] - INFO: epoch 014:   1535 / 2004 loss=0.282, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=347.4, nsentences=7.8, sample_size=347.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1040.4, ups=2.99, wpb=347.4, bsz=7.8, num_updates=27410, lr=7.33785e-05, gnorm=2.978, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=9389
2023-03-15 16:36:15 - progress_bar.py[line:272] - INFO: epoch 014:   1545 / 2004 loss=0.261, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=309.5, nsentences=8, sample_size=309.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=924.2, ups=2.99, wpb=309.5, bsz=8, num_updates=27420, lr=7.33684e-05, gnorm=2.862, clip=0, loss_scale=2048, train_wall=3, gb_free=15.8, wall=9392
2023-03-15 16:36:18 - progress_bar.py[line:272] - INFO: epoch 014:   1555 / 2004 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=355.3, nsentences=8, sample_size=355.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=1029.1, ups=2.9, wpb=355.3, bsz=8, num_updates=27430, lr=7.33583e-05, gnorm=3.04, clip=0, loss_scale=2048, train_wall=3, gb_free=13.5, wall=9396
2023-03-15 16:36:22 - progress_bar.py[line:272] - INFO: epoch 014:   1565 / 2004 loss=0.27, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=347, nsentences=8, sample_size=347, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=999.7, ups=2.88, wpb=347, bsz=8, num_updates=27440, lr=7.33483e-05, gnorm=2.986, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=9399
2023-03-15 16:36:25 - progress_bar.py[line:272] - INFO: epoch 014:   1575 / 2004 loss=0.29, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=336.5, nsentences=8, sample_size=336.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1002.1, ups=2.98, wpb=336.5, bsz=8, num_updates=27450, lr=7.33382e-05, gnorm=2.894, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=9403
2023-03-15 16:36:28 - progress_bar.py[line:272] - INFO: epoch 014:   1585 / 2004 loss=0.261, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=321.1, nsentences=8, sample_size=321.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=946.3, ups=2.95, wpb=321.1, bsz=8, num_updates=27460, lr=7.33281e-05, gnorm=2.724, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=9406
2023-03-15 16:36:32 - progress_bar.py[line:272] - INFO: epoch 014:   1595 / 2004 loss=0.294, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=362.8, nsentences=8, sample_size=362.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=1040.5, ups=2.87, wpb=362.8, bsz=8, num_updates=27470, lr=7.3318e-05, gnorm=2.896, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=9410
2023-03-15 16:36:35 - progress_bar.py[line:272] - INFO: epoch 014:   1605 / 2004 loss=0.271, loss_v1=0, loss_v2=0, nll_loss=0.271, ntokens=337.9, nsentences=8, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=998.3, ups=2.95, wpb=337.9, bsz=8, num_updates=27480, lr=7.33079e-05, gnorm=2.948, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=9413
2023-03-15 16:36:39 - progress_bar.py[line:272] - INFO: epoch 014:   1615 / 2004 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=341.2, nsentences=8, sample_size=341.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=1004.2, ups=2.94, wpb=341.2, bsz=8, num_updates=27490, lr=7.32978e-05, gnorm=3.27, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=9416
2023-03-15 16:36:40 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 16:36:43 - progress_bar.py[line:272] - INFO: epoch 014:   1626 / 2004 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=338.2, nsentences=8, sample_size=338.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=892.4, ups=2.64, wpb=338.2, bsz=8, num_updates=27500, lr=7.32878e-05, gnorm=3.14, clip=0, loss_scale=1024, train_wall=4, gb_free=14.6, wall=9420
2023-03-15 16:36:46 - progress_bar.py[line:272] - INFO: epoch 014:   1636 / 2004 loss=0.271, loss_v1=0, loss_v2=0, nll_loss=0.271, ntokens=324, nsentences=8, sample_size=324, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=952.7, ups=2.94, wpb=324, bsz=8, num_updates=27510, lr=7.32777e-05, gnorm=2.871, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=9424
2023-03-15 16:36:49 - progress_bar.py[line:272] - INFO: epoch 014:   1646 / 2004 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=318.5, nsentences=8, sample_size=318.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=930.4, ups=2.92, wpb=318.5, bsz=8, num_updates=27520, lr=7.32676e-05, gnorm=3.078, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=9427
2023-03-15 16:36:53 - progress_bar.py[line:272] - INFO: epoch 014:   1656 / 2004 loss=0.29, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=358.1, nsentences=8, sample_size=358.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1022.1, ups=2.85, wpb=358.1, bsz=8, num_updates=27530, lr=7.32575e-05, gnorm=2.957, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=9430
2023-03-15 16:36:56 - progress_bar.py[line:272] - INFO: epoch 014:   1666 / 2004 loss=0.283, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=345.7, nsentences=8, sample_size=345.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1009.6, ups=2.92, wpb=345.7, bsz=8, num_updates=27540, lr=7.32474e-05, gnorm=2.968, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=9434
2023-03-15 16:37:00 - progress_bar.py[line:272] - INFO: epoch 014:   1676 / 2004 loss=0.277, loss_v1=0, loss_v2=0, nll_loss=0.277, ntokens=320.2, nsentences=8, sample_size=320.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=963.9, ups=3.01, wpb=320.2, bsz=8, num_updates=27550, lr=7.32374e-05, gnorm=2.945, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=9437
2023-03-15 16:37:03 - progress_bar.py[line:272] - INFO: epoch 014:   1686 / 2004 loss=0.273, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=334, nsentences=8, sample_size=334, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=981, ups=2.94, wpb=334, bsz=8, num_updates=27560, lr=7.32273e-05, gnorm=2.821, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=9441
2023-03-15 16:37:06 - progress_bar.py[line:272] - INFO: epoch 014:   1696 / 2004 loss=0.275, loss_v1=0, loss_v2=0, nll_loss=0.275, ntokens=337.7, nsentences=8, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1008, ups=2.98, wpb=337.7, bsz=8, num_updates=27570, lr=7.32172e-05, gnorm=2.864, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=9444
2023-03-15 16:37:10 - progress_bar.py[line:272] - INFO: epoch 014:   1706 / 2004 loss=0.282, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=348.9, nsentences=8, sample_size=348.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1020.4, ups=2.92, wpb=348.9, bsz=8, num_updates=27580, lr=7.32071e-05, gnorm=2.946, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=9447
2023-03-15 16:37:13 - progress_bar.py[line:272] - INFO: epoch 014:   1716 / 2004 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=356.2, nsentences=8, sample_size=356.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=1049.2, ups=2.95, wpb=356.2, bsz=8, num_updates=27590, lr=7.3197e-05, gnorm=3.234, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=9451
2023-03-15 16:37:17 - progress_bar.py[line:272] - INFO: epoch 014:   1726 / 2004 loss=0.284, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=396.6, nsentences=8, sample_size=396.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1146.1, ups=2.89, wpb=396.6, bsz=8, num_updates=27600, lr=7.3187e-05, gnorm=2.873, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=9454
2023-03-15 16:37:20 - progress_bar.py[line:272] - INFO: epoch 014:   1736 / 2004 loss=0.27, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=347.5, nsentences=8, sample_size=347.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1012.9, ups=2.91, wpb=347.5, bsz=8, num_updates=27610, lr=7.31769e-05, gnorm=2.819, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=9458
2023-03-15 16:37:23 - progress_bar.py[line:272] - INFO: epoch 014:   1746 / 2004 loss=0.276, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=341.3, nsentences=8, sample_size=341.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1004, ups=2.94, wpb=341.3, bsz=8, num_updates=27620, lr=7.31668e-05, gnorm=2.838, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=9461
2023-03-15 16:37:27 - progress_bar.py[line:272] - INFO: epoch 014:   1756 / 2004 loss=0.29, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=328.1, nsentences=8, sample_size=328.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=966.7, ups=2.95, wpb=328.1, bsz=8, num_updates=27630, lr=7.31567e-05, gnorm=2.966, clip=0, loss_scale=2048, train_wall=3, gb_free=15.9, wall=9464
2023-03-15 16:37:30 - progress_bar.py[line:272] - INFO: epoch 014:   1766 / 2004 loss=0.283, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=318.3, nsentences=8, sample_size=318.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=955.4, ups=3, wpb=318.3, bsz=8, num_updates=27640, lr=7.31466e-05, gnorm=3.272, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=9468
2023-03-15 16:37:34 - progress_bar.py[line:272] - INFO: epoch 014:   1776 / 2004 loss=0.287, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=347.4, nsentences=8, sample_size=347.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1020.8, ups=2.94, wpb=347.4, bsz=8, num_updates=27650, lr=7.31366e-05, gnorm=2.991, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=9471
2023-03-15 16:37:37 - progress_bar.py[line:272] - INFO: epoch 014:   1786 / 2004 loss=0.258, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=317, nsentences=8, sample_size=317, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=924.1, ups=2.91, wpb=317, bsz=8, num_updates=27660, lr=7.31265e-05, gnorm=2.712, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=9475
2023-03-15 16:37:40 - progress_bar.py[line:272] - INFO: epoch 014:   1796 / 2004 loss=0.282, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=337.2, nsentences=8, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1007.7, ups=2.99, wpb=337.2, bsz=8, num_updates=27670, lr=7.31164e-05, gnorm=2.88, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=9478
2023-03-15 16:37:44 - progress_bar.py[line:272] - INFO: epoch 014:   1806 / 2004 loss=0.283, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=345.6, nsentences=8, sample_size=345.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1015.4, ups=2.94, wpb=345.6, bsz=8, num_updates=27680, lr=7.31063e-05, gnorm=3.014, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=9481
2023-03-15 16:37:47 - progress_bar.py[line:272] - INFO: epoch 014:   1816 / 2004 loss=0.292, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=347.7, nsentences=8, sample_size=347.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1022.9, ups=2.94, wpb=347.7, bsz=8, num_updates=27690, lr=7.30962e-05, gnorm=3.016, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=9485
2023-03-15 16:37:51 - progress_bar.py[line:272] - INFO: epoch 014:   1826 / 2004 loss=0.268, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=365.7, nsentences=8, sample_size=365.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1065.8, ups=2.91, wpb=365.7, bsz=8, num_updates=27700, lr=7.30862e-05, gnorm=2.722, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=9488
2023-03-15 16:37:54 - progress_bar.py[line:272] - INFO: epoch 014:   1836 / 2004 loss=0.286, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=327.2, nsentences=8, sample_size=327.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=959.6, ups=2.93, wpb=327.2, bsz=8, num_updates=27710, lr=7.30761e-05, gnorm=2.905, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=9492
2023-03-15 16:37:57 - progress_bar.py[line:272] - INFO: epoch 014:   1846 / 2004 loss=0.284, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=360.5, nsentences=8, sample_size=360.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1049.4, ups=2.91, wpb=360.5, bsz=8, num_updates=27720, lr=7.3066e-05, gnorm=2.841, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=9495
2023-03-15 16:38:01 - progress_bar.py[line:272] - INFO: epoch 014:   1856 / 2004 loss=0.258, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=312.9, nsentences=8, sample_size=312.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=918.5, ups=2.94, wpb=312.9, bsz=8, num_updates=27730, lr=7.30559e-05, gnorm=2.76, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=9498
2023-03-15 16:38:04 - progress_bar.py[line:272] - INFO: epoch 014:   1866 / 2004 loss=0.287, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=343.7, nsentences=8, sample_size=343.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=996, ups=2.9, wpb=343.7, bsz=8, num_updates=27740, lr=7.30458e-05, gnorm=2.782, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=9502
2023-03-15 16:38:08 - progress_bar.py[line:272] - INFO: epoch 014:   1876 / 2004 loss=0.285, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=337.8, nsentences=8, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=986.5, ups=2.92, wpb=337.8, bsz=8, num_updates=27750, lr=7.30357e-05, gnorm=2.964, clip=0, loss_scale=4096, train_wall=3, gb_free=14.6, wall=9505
2023-03-15 16:38:08 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 16:38:11 - progress_bar.py[line:272] - INFO: epoch 014:   1887 / 2004 loss=0.261, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=319.5, nsentences=8, sample_size=319.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=871.8, ups=2.73, wpb=319.5, bsz=8, num_updates=27760, lr=7.30257e-05, gnorm=2.825, clip=0, loss_scale=2048, train_wall=4, gb_free=15.4, wall=9509
2023-03-15 16:38:15 - progress_bar.py[line:272] - INFO: epoch 014:   1897 / 2004 loss=0.276, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=352.5, nsentences=8, sample_size=352.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1029, ups=2.92, wpb=352.5, bsz=8, num_updates=27770, lr=7.30156e-05, gnorm=2.937, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=9512
2023-03-15 16:38:18 - progress_bar.py[line:272] - INFO: epoch 014:   1907 / 2004 loss=0.294, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=333.2, nsentences=8, sample_size=333.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=1007.1, ups=3.02, wpb=333.2, bsz=8, num_updates=27780, lr=7.30055e-05, gnorm=2.964, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=9516
2023-03-15 16:38:22 - progress_bar.py[line:272] - INFO: epoch 014:   1917 / 2004 loss=0.27, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=332, nsentences=8, sample_size=332, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=971.2, ups=2.93, wpb=332, bsz=8, num_updates=27790, lr=7.29954e-05, gnorm=3.063, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=9519
2023-03-15 16:38:25 - progress_bar.py[line:272] - INFO: epoch 014:   1927 / 2004 loss=0.258, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=330.9, nsentences=8, sample_size=330.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=973.9, ups=2.94, wpb=330.9, bsz=8, num_updates=27800, lr=7.29853e-05, gnorm=2.817, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=9523
2023-03-15 16:38:28 - progress_bar.py[line:272] - INFO: epoch 014:   1937 / 2004 loss=0.263, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=337.9, nsentences=8, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=974.5, ups=2.88, wpb=337.9, bsz=8, num_updates=27810, lr=7.29753e-05, gnorm=2.832, clip=0, loss_scale=2048, train_wall=3, gb_free=13.8, wall=9526
2023-03-15 16:38:32 - progress_bar.py[line:272] - INFO: epoch 014:   1947 / 2004 loss=0.271, loss_v1=0, loss_v2=0, nll_loss=0.271, ntokens=344.1, nsentences=8, sample_size=344.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1012.8, ups=2.94, wpb=344.1, bsz=8, num_updates=27820, lr=7.29652e-05, gnorm=2.952, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=9529
2023-03-15 16:38:35 - progress_bar.py[line:272] - INFO: epoch 014:   1957 / 2004 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=354.9, nsentences=8, sample_size=354.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=1038.6, ups=2.93, wpb=354.9, bsz=8, num_updates=27830, lr=7.29551e-05, gnorm=3.074, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=9533
2023-03-15 16:38:39 - progress_bar.py[line:272] - INFO: epoch 014:   1967 / 2004 loss=0.265, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=352.3, nsentences=8, sample_size=352.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1008.4, ups=2.86, wpb=352.3, bsz=8, num_updates=27840, lr=7.2945e-05, gnorm=2.732, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=9536
2023-03-15 16:38:42 - progress_bar.py[line:272] - INFO: epoch 014:   1977 / 2004 loss=0.283, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=346.4, nsentences=8, sample_size=346.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1015.4, ups=2.93, wpb=346.4, bsz=8, num_updates=27850, lr=7.29349e-05, gnorm=3.036, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=9540
2023-03-15 16:38:46 - progress_bar.py[line:272] - INFO: epoch 014:   1987 / 2004 loss=0.29, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=323.2, nsentences=8, sample_size=323.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=948.1, ups=2.93, wpb=323.2, bsz=8, num_updates=27860, lr=7.29249e-05, gnorm=3.01, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=9543
2023-03-15 16:38:49 - progress_bar.py[line:272] - INFO: epoch 014:   1997 / 2004 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=398.1, nsentences=8, sample_size=398.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=1183.6, ups=2.97, wpb=398.1, bsz=8, num_updates=27870, lr=7.29148e-05, gnorm=2.957, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=9547
2023-03-15 16:38:51 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 14 @ 27877 updates
2023-03-15 16:38:51 - trainer.py[line:431] - INFO: Saving checkpoint to ./checkpoints/checkpoint14.pt
2023-03-15 16:38:58 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./checkpoints/checkpoint14.pt
2023-03-15 16:39:00 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./checkpoints/checkpoint14.pt (epoch 14 @ 27877 updates, score None) (writing took 9.267900116741657 seconds)
2023-03-15 16:39:01 - train.py[line:332] - INFO: end of epoch 14 (average epoch stats below)
2023-03-15 16:39:01 - progress_bar.py[line:282] - INFO: epoch 014 | loss 0.294 | loss_v1 0 | loss_v2 0 | nll_loss 0.294 | ntokens 345.351 | nsentences 7.999 | sample_size 345.351 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.23 | wps 991.3 | ups 2.87 | wpb 345.4 | bsz 8 | num_updates 27877 | lr 7.29077e-05 | gnorm 2.959 | clip 0.1 | loss_scale 2048 | train_wall 672 | gb_free 13.9 | wall 9558
2023-03-15 16:39:01 - trainer.py[line:639] - INFO: loading train data for epoch 15
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 row count 8015 total row count 8015
slice_id 0 seek offset 0
2023-03-15 16:39:01 - trainer.py[line:703] - INFO: begin training epoch 15
2023-03-15 16:39:01 - train.py[line:305] - INFO: Start iterating over samples
2023-03-15 16:39:02 - progress_bar.py[line:272] - INFO: epoch 015:      3 / 2004 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=360.7, nsentences=8, sample_size=360.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=267.6, ups=0.74, wpb=360.7, bsz=8, num_updates=27880, lr=7.29047e-05, gnorm=3.261, clip=0, loss_scale=4096, train_wall=3, gb_free=15.6, wall=9560
2023-03-15 16:39:03 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 16:39:06 - progress_bar.py[line:272] - INFO: epoch 015:     14 / 2004 loss=0.285, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=320.6, nsentences=8, sample_size=320.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=865, ups=2.7, wpb=320.6, bsz=8, num_updates=27890, lr=7.28946e-05, gnorm=3.12, clip=10, loss_scale=2048, train_wall=4, gb_free=14.5, wall=9564
2023-03-15 16:39:10 - progress_bar.py[line:272] - INFO: epoch 015:     24 / 2004 loss=0.29, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=362.6, nsentences=8, sample_size=362.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1057.8, ups=2.92, wpb=362.6, bsz=8, num_updates=27900, lr=7.28845e-05, gnorm=2.984, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=9567
2023-03-15 16:39:13 - progress_bar.py[line:272] - INFO: epoch 015:     34 / 2004 loss=0.287, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=347.1, nsentences=8, sample_size=347.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1033.9, ups=2.98, wpb=347.1, bsz=8, num_updates=27910, lr=7.28745e-05, gnorm=2.987, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=9571
2023-03-15 16:39:16 - progress_bar.py[line:272] - INFO: epoch 015:     44 / 2004 loss=0.292, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=354.6, nsentences=8, sample_size=354.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1035.4, ups=2.92, wpb=354.6, bsz=8, num_updates=27920, lr=7.28644e-05, gnorm=3.103, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=9574
2023-03-15 16:39:20 - progress_bar.py[line:272] - INFO: epoch 015:     54 / 2004 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=351.6, nsentences=8, sample_size=351.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=1036.7, ups=2.95, wpb=351.6, bsz=8, num_updates=27930, lr=7.28543e-05, gnorm=2.853, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=9577
2023-03-15 16:39:23 - progress_bar.py[line:272] - INFO: epoch 015:     64 / 2004 loss=0.283, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=320.8, nsentences=8, sample_size=320.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=958.8, ups=2.99, wpb=320.8, bsz=8, num_updates=27940, lr=7.28442e-05, gnorm=3.024, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=9581
2023-03-15 16:39:26 - progress_bar.py[line:272] - INFO: epoch 015:     74 / 2004 loss=0.292, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=359.2, nsentences=8, sample_size=359.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1055.1, ups=2.94, wpb=359.2, bsz=8, num_updates=27950, lr=7.28341e-05, gnorm=2.837, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=9584
2023-03-15 16:39:30 - progress_bar.py[line:272] - INFO: epoch 015:     84 / 2004 loss=0.29, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=335.3, nsentences=8, sample_size=335.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=984.8, ups=2.94, wpb=335.3, bsz=8, num_updates=27960, lr=7.2824e-05, gnorm=2.98, clip=0, loss_scale=2048, train_wall=3, gb_free=13.5, wall=9587
2023-03-15 16:39:33 - progress_bar.py[line:272] - INFO: epoch 015:     94 / 2004 loss=0.27, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=369.4, nsentences=8, sample_size=369.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1054.5, ups=2.85, wpb=369.4, bsz=8, num_updates=27970, lr=7.2814e-05, gnorm=2.863, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=9591
2023-03-15 16:39:37 - progress_bar.py[line:272] - INFO: epoch 015:    104 / 2004 loss=0.281, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=374.2, nsentences=8, sample_size=374.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1086.7, ups=2.9, wpb=374.2, bsz=8, num_updates=27980, lr=7.28039e-05, gnorm=3.1, clip=0, loss_scale=2048, train_wall=3, gb_free=13.7, wall=9594
2023-03-15 16:39:40 - progress_bar.py[line:272] - INFO: epoch 015:    114 / 2004 loss=0.283, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=326.5, nsentences=8, sample_size=326.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=973, ups=2.98, wpb=326.5, bsz=8, num_updates=27990, lr=7.27938e-05, gnorm=3.126, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=9598
2023-03-15 16:39:44 - progress_bar.py[line:272] - INFO: epoch 015:    124 / 2004 loss=0.29, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=351.1, nsentences=8, sample_size=351.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1009.2, ups=2.87, wpb=351.1, bsz=8, num_updates=28000, lr=7.27837e-05, gnorm=2.98, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=9601
2023-03-15 16:39:47 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 16:39:47 - progress_bar.py[line:272] - INFO: epoch 015:    135 / 2004 loss=0.28, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=328.9, nsentences=8, sample_size=328.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=879.1, ups=2.67, wpb=328.9, bsz=8, num_updates=28010, lr=7.27736e-05, gnorm=2.872, clip=0, loss_scale=2048, train_wall=4, gb_free=14.6, wall=9605
2023-03-15 16:39:51 - progress_bar.py[line:272] - INFO: epoch 015:    145 / 2004 loss=0.279, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=332.7, nsentences=8, sample_size=332.7, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=991.4, ups=2.98, wpb=332.7, bsz=8, num_updates=28020, lr=7.27636e-05, gnorm=2.849, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=9608
2023-03-15 16:39:54 - progress_bar.py[line:272] - INFO: epoch 015:    155 / 2004 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=339.4, nsentences=8, sample_size=339.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=1008.5, ups=2.97, wpb=339.4, bsz=8, num_updates=28030, lr=7.27535e-05, gnorm=3.278, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=9612
2023-03-15 16:39:58 - progress_bar.py[line:272] - INFO: epoch 015:    165 / 2004 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=353.9, nsentences=8, sample_size=353.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=1036.7, ups=2.93, wpb=353.9, bsz=8, num_updates=28040, lr=7.27434e-05, gnorm=2.987, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=9615
2023-03-15 16:40:01 - progress_bar.py[line:272] - INFO: epoch 015:    175 / 2004 loss=0.291, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=331.9, nsentences=8, sample_size=331.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=981.8, ups=2.96, wpb=331.9, bsz=8, num_updates=28050, lr=7.27333e-05, gnorm=2.909, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=9619
2023-03-15 16:40:04 - progress_bar.py[line:272] - INFO: epoch 015:    185 / 2004 loss=0.275, loss_v1=0, loss_v2=0, nll_loss=0.275, ntokens=336.3, nsentences=8, sample_size=336.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=983.1, ups=2.92, wpb=336.3, bsz=8, num_updates=28060, lr=7.27232e-05, gnorm=2.81, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=9622
2023-03-15 16:40:09 - progress_bar.py[line:272] - INFO: epoch 015:    195 / 2004 loss=0.266, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=321.6, nsentences=8, sample_size=321.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=729, ups=2.27, wpb=321.6, bsz=8, num_updates=28070, lr=7.27132e-05, gnorm=2.728, clip=0, loss_scale=2048, train_wall=4, gb_free=15.7, wall=9626
2023-03-15 16:40:12 - progress_bar.py[line:272] - INFO: epoch 015:    205 / 2004 loss=0.3, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=336.6, nsentences=8, sample_size=336.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=969.3, ups=2.88, wpb=336.6, bsz=8, num_updates=28080, lr=7.27031e-05, gnorm=3.114, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=9630
2023-03-15 16:40:16 - progress_bar.py[line:272] - INFO: epoch 015:    215 / 2004 loss=0.279, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=334.6, nsentences=8, sample_size=334.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=967.6, ups=2.89, wpb=334.6, bsz=8, num_updates=28090, lr=7.2693e-05, gnorm=2.864, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=9633
2023-03-15 16:40:19 - progress_bar.py[line:272] - INFO: epoch 015:    225 / 2004 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=333.2, nsentences=8, sample_size=333.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=969.6, ups=2.91, wpb=333.2, bsz=8, num_updates=28100, lr=7.26829e-05, gnorm=2.677, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=9637
2023-03-15 16:40:23 - progress_bar.py[line:272] - INFO: epoch 015:    235 / 2004 loss=0.271, loss_v1=0, loss_v2=0, nll_loss=0.271, ntokens=371.3, nsentences=8, sample_size=371.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1037.6, ups=2.79, wpb=371.3, bsz=8, num_updates=28110, lr=7.26728e-05, gnorm=2.755, clip=0, loss_scale=2048, train_wall=4, gb_free=14.7, wall=9640
2023-03-15 16:40:26 - progress_bar.py[line:272] - INFO: epoch 015:    245 / 2004 loss=0.286, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=353.4, nsentences=8, sample_size=353.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1019.9, ups=2.89, wpb=353.4, bsz=8, num_updates=28120, lr=7.26628e-05, gnorm=2.892, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=9644
2023-03-15 16:40:30 - progress_bar.py[line:272] - INFO: epoch 015:    255 / 2004 loss=0.26, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=338.4, nsentences=8, sample_size=338.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=965.6, ups=2.85, wpb=338.4, bsz=8, num_updates=28130, lr=7.26527e-05, gnorm=2.737, clip=0, loss_scale=2048, train_wall=3, gb_free=13.8, wall=9647
2023-03-15 16:40:33 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 16:40:33 - progress_bar.py[line:272] - INFO: epoch 015:    266 / 2004 loss=0.272, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=339.9, nsentences=8, sample_size=339.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=911.9, ups=2.68, wpb=339.9, bsz=8, num_updates=28140, lr=7.26426e-05, gnorm=2.999, clip=0, loss_scale=2048, train_wall=4, gb_free=15.1, wall=9651
2023-03-15 16:40:37 - progress_bar.py[line:272] - INFO: epoch 015:    276 / 2004 loss=0.296, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=342.3, nsentences=8, sample_size=342.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=1011, ups=2.95, wpb=342.3, bsz=8, num_updates=28150, lr=7.26325e-05, gnorm=3.129, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=9654
2023-03-15 16:40:40 - progress_bar.py[line:272] - INFO: epoch 015:    286 / 2004 loss=0.275, loss_v1=0, loss_v2=0, nll_loss=0.275, ntokens=366.8, nsentences=8, sample_size=366.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1060.1, ups=2.89, wpb=366.8, bsz=8, num_updates=28160, lr=7.26224e-05, gnorm=2.793, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=9658
2023-03-15 16:40:44 - progress_bar.py[line:272] - INFO: epoch 015:    296 / 2004 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=352.6, nsentences=8, sample_size=352.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=1040.1, ups=2.95, wpb=352.6, bsz=8, num_updates=28170, lr=7.26124e-05, gnorm=2.943, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=9661
2023-03-15 16:40:47 - progress_bar.py[line:272] - INFO: epoch 015:    306 / 2004 loss=0.275, loss_v1=0, loss_v2=0, nll_loss=0.275, ntokens=340.2, nsentences=8, sample_size=340.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1011.4, ups=2.97, wpb=340.2, bsz=8, num_updates=28180, lr=7.26023e-05, gnorm=2.961, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=9665
2023-03-15 16:40:50 - progress_bar.py[line:272] - INFO: epoch 015:    316 / 2004 loss=0.283, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=362.2, nsentences=8, sample_size=362.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1045.4, ups=2.89, wpb=362.2, bsz=8, num_updates=28190, lr=7.25922e-05, gnorm=2.896, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=9668
2023-03-15 16:40:54 - progress_bar.py[line:272] - INFO: epoch 015:    326 / 2004 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.247, ntokens=324.5, nsentences=8, sample_size=324.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=967.2, ups=2.98, wpb=324.5, bsz=8, num_updates=28200, lr=7.25821e-05, gnorm=2.843, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=9671
2023-03-15 16:40:57 - progress_bar.py[line:272] - INFO: epoch 015:    336 / 2004 loss=0.276, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=339, nsentences=8, sample_size=339, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1009.9, ups=2.98, wpb=339, bsz=8, num_updates=28210, lr=7.2572e-05, gnorm=2.99, clip=0, loss_scale=2048, train_wall=3, gb_free=13.9, wall=9675
2023-03-15 16:41:01 - progress_bar.py[line:272] - INFO: epoch 015:    346 / 2004 loss=0.276, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=374, nsentences=8, sample_size=374, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1085.9, ups=2.9, wpb=374, bsz=8, num_updates=28220, lr=7.25619e-05, gnorm=2.886, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=9678
2023-03-15 16:41:04 - progress_bar.py[line:272] - INFO: epoch 015:    356 / 2004 loss=0.278, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=335.2, nsentences=8, sample_size=335.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=978.8, ups=2.92, wpb=335.2, bsz=8, num_updates=28230, lr=7.25519e-05, gnorm=3.002, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=9682
2023-03-15 16:41:07 - progress_bar.py[line:272] - INFO: epoch 015:    366 / 2004 loss=0.269, loss_v1=0, loss_v2=0, nll_loss=0.269, ntokens=366.6, nsentences=8, sample_size=366.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1075.7, ups=2.93, wpb=366.6, bsz=8, num_updates=28240, lr=7.25418e-05, gnorm=2.971, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=9685
2023-03-15 16:41:11 - progress_bar.py[line:272] - INFO: epoch 015:    376 / 2004 loss=0.262, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=307.5, nsentences=8, sample_size=307.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=913.8, ups=2.97, wpb=307.5, bsz=8, num_updates=28250, lr=7.25317e-05, gnorm=2.931, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=9688
2023-03-15 16:41:14 - progress_bar.py[line:272] - INFO: epoch 015:    386 / 2004 loss=0.261, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=325.8, nsentences=8, sample_size=325.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=948.5, ups=2.91, wpb=325.8, bsz=8, num_updates=28260, lr=7.25216e-05, gnorm=2.872, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=9692
2023-03-15 16:41:17 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 16:41:18 - progress_bar.py[line:272] - INFO: epoch 015:    397 / 2004 loss=0.277, loss_v1=0, loss_v2=0, nll_loss=0.277, ntokens=348.6, nsentences=8, sample_size=348.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=925.9, ups=2.66, wpb=348.6, bsz=8, num_updates=28270, lr=7.25115e-05, gnorm=3, clip=0, loss_scale=2048, train_wall=4, gb_free=15.2, wall=9696
2023-03-15 16:41:21 - progress_bar.py[line:272] - INFO: epoch 015:    407 / 2004 loss=0.291, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=382, nsentences=8, sample_size=382, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1121.1, ups=2.93, wpb=382, bsz=8, num_updates=28280, lr=7.25015e-05, gnorm=2.901, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=9699
2023-03-15 16:41:25 - progress_bar.py[line:272] - INFO: epoch 015:    417 / 2004 loss=0.261, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=337.8, nsentences=8, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=986, ups=2.92, wpb=337.8, bsz=8, num_updates=28290, lr=7.24914e-05, gnorm=2.842, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=9702
2023-03-15 16:41:28 - progress_bar.py[line:272] - INFO: epoch 015:    427 / 2004 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=338.1, nsentences=8, sample_size=338.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1002.8, ups=2.97, wpb=338.1, bsz=8, num_updates=28300, lr=7.24813e-05, gnorm=2.642, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=9706
2023-03-15 16:41:32 - progress_bar.py[line:272] - INFO: epoch 015:    437 / 2004 loss=0.262, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=350.6, nsentences=8, sample_size=350.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=998.2, ups=2.85, wpb=350.6, bsz=8, num_updates=28310, lr=7.24712e-05, gnorm=3.048, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=9709
2023-03-15 16:41:35 - progress_bar.py[line:272] - INFO: epoch 015:    447 / 2004 loss=0.264, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=374.5, nsentences=8, sample_size=374.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1057.1, ups=2.82, wpb=374.5, bsz=8, num_updates=28320, lr=7.24611e-05, gnorm=2.771, clip=0, loss_scale=2048, train_wall=3, gb_free=13.9, wall=9713
2023-03-15 16:41:39 - progress_bar.py[line:272] - INFO: epoch 015:    457 / 2004 loss=0.297, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=390, nsentences=8, sample_size=390, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=1109.9, ups=2.85, wpb=390, bsz=8, num_updates=28330, lr=7.24511e-05, gnorm=2.959, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=9716
2023-03-15 16:41:42 - progress_bar.py[line:272] - INFO: epoch 015:    467 / 2004 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=359.1, nsentences=8, sample_size=359.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=1033.3, ups=2.88, wpb=359.1, bsz=8, num_updates=28340, lr=7.2441e-05, gnorm=3.029, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=9720
2023-03-15 16:41:44 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 16:41:46 - progress_bar.py[line:272] - INFO: epoch 015:    478 / 2004 loss=0.267, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=326.6, nsentences=8, sample_size=326.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=873.7, ups=2.68, wpb=326.6, bsz=8, num_updates=28350, lr=7.24309e-05, gnorm=3.028, clip=0, loss_scale=1024, train_wall=4, gb_free=14.3, wall=9724
2023-03-15 16:41:49 - progress_bar.py[line:272] - INFO: epoch 015:    488 / 2004 loss=0.27, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=375.5, nsentences=8, sample_size=375.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1091.1, ups=2.91, wpb=375.5, bsz=8, num_updates=28360, lr=7.24208e-05, gnorm=2.897, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=9727
2023-03-15 16:41:53 - progress_bar.py[line:272] - INFO: epoch 015:    498 / 2004 loss=0.273, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=365.1, nsentences=8, sample_size=365.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1065.1, ups=2.92, wpb=365.1, bsz=8, num_updates=28370, lr=7.24107e-05, gnorm=2.961, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=9730
2023-03-15 16:41:56 - progress_bar.py[line:272] - INFO: epoch 015:    508 / 2004 loss=0.278, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=352.5, nsentences=8, sample_size=352.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1009.1, ups=2.86, wpb=352.5, bsz=8, num_updates=28380, lr=7.24007e-05, gnorm=2.766, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=9734
2023-03-15 16:42:00 - progress_bar.py[line:272] - INFO: epoch 015:    518 / 2004 loss=0.282, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=351.6, nsentences=8, sample_size=351.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1039.4, ups=2.96, wpb=351.6, bsz=8, num_updates=28390, lr=7.23906e-05, gnorm=3.059, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=9737
2023-03-15 16:42:03 - progress_bar.py[line:272] - INFO: epoch 015:    528 / 2004 loss=0.289, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=402.8, nsentences=8, sample_size=402.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1179.3, ups=2.93, wpb=402.8, bsz=8, num_updates=28400, lr=7.23805e-05, gnorm=2.857, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=9741
2023-03-15 16:42:07 - progress_bar.py[line:272] - INFO: epoch 015:    538 / 2004 loss=0.285, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=385.5, nsentences=8, sample_size=385.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1112.8, ups=2.89, wpb=385.5, bsz=8, num_updates=28410, lr=7.23704e-05, gnorm=2.856, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=9744
2023-03-15 16:42:10 - progress_bar.py[line:272] - INFO: epoch 015:    548 / 2004 loss=0.279, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=350.6, nsentences=8, sample_size=350.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1023.7, ups=2.92, wpb=350.6, bsz=8, num_updates=28420, lr=7.23603e-05, gnorm=2.989, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=9748
2023-03-15 16:42:13 - progress_bar.py[line:272] - INFO: epoch 015:    558 / 2004 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=378.2, nsentences=8, sample_size=378.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=1106.1, ups=2.92, wpb=378.2, bsz=8, num_updates=28430, lr=7.23502e-05, gnorm=2.932, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=9751
2023-03-15 16:42:17 - progress_bar.py[line:272] - INFO: epoch 015:    568 / 2004 loss=0.287, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=377.4, nsentences=8, sample_size=377.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1106.8, ups=2.93, wpb=377.4, bsz=8, num_updates=28440, lr=7.23402e-05, gnorm=2.903, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=9755
2023-03-15 16:42:20 - progress_bar.py[line:272] - INFO: epoch 015:    578 / 2004 loss=0.289, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=329.9, nsentences=8, sample_size=329.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1008.2, ups=3.06, wpb=329.9, bsz=8, num_updates=28450, lr=7.23301e-05, gnorm=2.971, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=9758
2023-03-15 16:42:24 - progress_bar.py[line:272] - INFO: epoch 015:    588 / 2004 loss=0.282, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=372.9, nsentences=8, sample_size=372.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1079.9, ups=2.9, wpb=372.9, bsz=8, num_updates=28460, lr=7.232e-05, gnorm=2.731, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=9761
2023-03-15 16:42:27 - progress_bar.py[line:272] - INFO: epoch 015:    598 / 2004 loss=0.27, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=334.5, nsentences=8, sample_size=334.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=975.6, ups=2.92, wpb=334.5, bsz=8, num_updates=28470, lr=7.23099e-05, gnorm=3.012, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=9765
2023-03-15 16:42:30 - progress_bar.py[line:272] - INFO: epoch 015:    608 / 2004 loss=0.279, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=351.9, nsentences=8, sample_size=351.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1029.1, ups=2.92, wpb=351.9, bsz=8, num_updates=28480, lr=7.22998e-05, gnorm=2.827, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=9768
2023-03-15 16:42:34 - progress_bar.py[line:272] - INFO: epoch 015:    618 / 2004 loss=0.261, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=354, nsentences=8, sample_size=354, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1022.4, ups=2.89, wpb=354, bsz=8, num_updates=28490, lr=7.22898e-05, gnorm=2.868, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=9772
2023-03-15 16:42:37 - progress_bar.py[line:272] - INFO: epoch 015:    628 / 2004 loss=0.268, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=368.7, nsentences=8, sample_size=368.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1084, ups=2.94, wpb=368.7, bsz=8, num_updates=28500, lr=7.22797e-05, gnorm=2.873, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=9775
2023-03-15 16:42:41 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 16:42:41 - progress_bar.py[line:272] - INFO: epoch 015:    639 / 2004 loss=0.279, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=328.2, nsentences=8, sample_size=328.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=873.2, ups=2.66, wpb=328.2, bsz=8, num_updates=28510, lr=7.22696e-05, gnorm=3.105, clip=0, loss_scale=1024, train_wall=4, gb_free=14.7, wall=9779
2023-03-15 16:42:45 - progress_bar.py[line:272] - INFO: epoch 015:    649 / 2004 loss=0.284, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=335.9, nsentences=8, sample_size=335.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=982.5, ups=2.92, wpb=335.9, bsz=8, num_updates=28520, lr=7.22595e-05, gnorm=3.02, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=9782
2023-03-15 16:42:48 - progress_bar.py[line:272] - INFO: epoch 015:    659 / 2004 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=342, nsentences=8, sample_size=342, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=1003.5, ups=2.93, wpb=342, bsz=8, num_updates=28530, lr=7.22494e-05, gnorm=2.888, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=9786
2023-03-15 16:42:51 - progress_bar.py[line:272] - INFO: epoch 015:    669 / 2004 loss=0.263, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=304.6, nsentences=8, sample_size=304.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=929.4, ups=3.05, wpb=304.6, bsz=8, num_updates=28540, lr=7.22394e-05, gnorm=2.82, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=9789
2023-03-15 16:42:55 - progress_bar.py[line:272] - INFO: epoch 015:    679 / 2004 loss=0.278, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=353.2, nsentences=8, sample_size=353.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1039.5, ups=2.94, wpb=353.2, bsz=8, num_updates=28550, lr=7.22293e-05, gnorm=2.865, clip=0, loss_scale=1024, train_wall=3, gb_free=14.2, wall=9792
2023-03-15 16:42:58 - progress_bar.py[line:272] - INFO: epoch 015:    689 / 2004 loss=0.266, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=343.1, nsentences=8, sample_size=343.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1027.2, ups=2.99, wpb=343.1, bsz=8, num_updates=28560, lr=7.22192e-05, gnorm=2.875, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=9796
2023-03-15 16:43:01 - progress_bar.py[line:272] - INFO: epoch 015:    699 / 2004 loss=0.278, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=350.5, nsentences=8, sample_size=350.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1031.7, ups=2.94, wpb=350.5, bsz=8, num_updates=28570, lr=7.22091e-05, gnorm=2.992, clip=0, loss_scale=1024, train_wall=3, gb_free=15.8, wall=9799
2023-03-15 16:43:05 - progress_bar.py[line:272] - INFO: epoch 015:    709 / 2004 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=331.9, nsentences=8, sample_size=331.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=974, ups=2.93, wpb=331.9, bsz=8, num_updates=28580, lr=7.2199e-05, gnorm=3.02, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=9802
2023-03-15 16:43:08 - progress_bar.py[line:272] - INFO: epoch 015:    719 / 2004 loss=0.265, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=346.6, nsentences=8, sample_size=346.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1035.2, ups=2.99, wpb=346.6, bsz=8, num_updates=28590, lr=7.2189e-05, gnorm=2.773, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=9806
2023-03-15 16:43:11 - progress_bar.py[line:272] - INFO: epoch 015:    729 / 2004 loss=0.278, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=358.8, nsentences=8, sample_size=358.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1059.4, ups=2.95, wpb=358.8, bsz=8, num_updates=28600, lr=7.21789e-05, gnorm=3.084, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=9809
2023-03-15 16:43:15 - progress_bar.py[line:272] - INFO: epoch 015:    739 / 2004 loss=0.268, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=332.5, nsentences=8, sample_size=332.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=960.2, ups=2.89, wpb=332.5, bsz=8, num_updates=28610, lr=7.21688e-05, gnorm=2.841, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=9813
2023-03-15 16:43:18 - progress_bar.py[line:272] - INFO: epoch 015:    749 / 2004 loss=0.286, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=366.9, nsentences=8, sample_size=366.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1071, ups=2.92, wpb=366.9, bsz=8, num_updates=28620, lr=7.21587e-05, gnorm=3.014, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=9816
2023-03-15 16:43:22 - progress_bar.py[line:272] - INFO: epoch 015:    759 / 2004 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=303.1, nsentences=8, sample_size=303.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=888.1, ups=2.93, wpb=303.1, bsz=8, num_updates=28630, lr=7.21486e-05, gnorm=2.668, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=9819
2023-03-15 16:43:25 - progress_bar.py[line:272] - INFO: epoch 015:    769 / 2004 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=409.5, nsentences=8, sample_size=409.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=1226.3, ups=2.99, wpb=409.5, bsz=8, num_updates=28640, lr=7.21386e-05, gnorm=3.217, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=9823
2023-03-15 16:43:28 - progress_bar.py[line:272] - INFO: epoch 015:    779 / 2004 loss=0.276, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=342.3, nsentences=8, sample_size=342.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1019.4, ups=2.98, wpb=342.3, bsz=8, num_updates=28650, lr=7.21285e-05, gnorm=3.069, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=9826
2023-03-15 16:43:32 - progress_bar.py[line:272] - INFO: epoch 015:    789 / 2004 loss=0.258, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=336.9, nsentences=8, sample_size=336.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=995, ups=2.95, wpb=336.9, bsz=8, num_updates=28660, lr=7.21184e-05, gnorm=2.754, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=9829
2023-03-15 16:43:35 - progress_bar.py[line:272] - INFO: epoch 015:    799 / 2004 loss=0.268, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=332.5, nsentences=8, sample_size=332.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1008.4, ups=3.03, wpb=332.5, bsz=8, num_updates=28670, lr=7.21083e-05, gnorm=2.963, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=9833
2023-03-15 16:43:38 - progress_bar.py[line:272] - INFO: epoch 015:    809 / 2004 loss=0.277, loss_v1=0, loss_v2=0, nll_loss=0.277, ntokens=345.3, nsentences=8, sample_size=345.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1109.9, ups=3.21, wpb=345.3, bsz=8, num_updates=28680, lr=7.20982e-05, gnorm=3.056, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=9836
2023-03-15 16:43:41 - progress_bar.py[line:272] - INFO: epoch 015:    819 / 2004 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.254, ntokens=325.4, nsentences=8, sample_size=325.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1041.2, ups=3.2, wpb=325.4, bsz=8, num_updates=28690, lr=7.20881e-05, gnorm=2.775, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=9839
2023-03-15 16:43:45 - progress_bar.py[line:272] - INFO: epoch 015:    829 / 2004 loss=0.291, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=369.5, nsentences=8, sample_size=369.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1189.8, ups=3.22, wpb=369.5, bsz=8, num_updates=28700, lr=7.20781e-05, gnorm=3.139, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=9842
2023-03-15 16:43:48 - progress_bar.py[line:272] - INFO: epoch 015:    839 / 2004 loss=0.236, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=335.5, nsentences=8, sample_size=335.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1082.5, ups=3.23, wpb=335.5, bsz=8, num_updates=28710, lr=7.2068e-05, gnorm=2.692, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=9845
2023-03-15 16:43:51 - progress_bar.py[line:272] - INFO: epoch 015:    849 / 2004 loss=0.297, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=365.8, nsentences=8, sample_size=365.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=1154.4, ups=3.16, wpb=365.8, bsz=8, num_updates=28720, lr=7.20579e-05, gnorm=2.86, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=9848
2023-03-15 16:43:54 - progress_bar.py[line:272] - INFO: epoch 015:    859 / 2004 loss=0.263, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=346.7, nsentences=8, sample_size=346.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1132.8, ups=3.27, wpb=346.7, bsz=8, num_updates=28730, lr=7.20478e-05, gnorm=2.824, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=9851
2023-03-15 16:43:57 - progress_bar.py[line:272] - INFO: epoch 015:    869 / 2004 loss=0.281, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=365.4, nsentences=8, sample_size=365.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1193.3, ups=3.27, wpb=365.4, bsz=8, num_updates=28740, lr=7.20377e-05, gnorm=2.906, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=9855
2023-03-15 16:44:00 - progress_bar.py[line:272] - INFO: epoch 015:    879 / 2004 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.256, ntokens=325.6, nsentences=8, sample_size=325.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1058.7, ups=3.25, wpb=325.6, bsz=8, num_updates=28750, lr=7.20277e-05, gnorm=2.843, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=9858
2023-03-15 16:44:03 - progress_bar.py[line:272] - INFO: epoch 015:    889 / 2004 loss=0.276, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=311.6, nsentences=8, sample_size=311.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=980.2, ups=3.15, wpb=311.6, bsz=8, num_updates=28760, lr=7.20176e-05, gnorm=3.121, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=9861
2023-03-15 16:44:05 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 16:44:07 - progress_bar.py[line:272] - INFO: epoch 015:    900 / 2004 loss=0.27, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=344.9, nsentences=8, sample_size=344.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=994.8, ups=2.88, wpb=344.9, bsz=8, num_updates=28770, lr=7.20075e-05, gnorm=2.996, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=9864
2023-03-15 16:44:10 - progress_bar.py[line:272] - INFO: epoch 015:    910 / 2004 loss=0.276, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=358, nsentences=8, sample_size=358, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1154.1, ups=3.22, wpb=358, bsz=8, num_updates=28780, lr=7.19974e-05, gnorm=2.934, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=9867
2023-03-15 16:44:13 - progress_bar.py[line:272] - INFO: epoch 015:    920 / 2004 loss=0.264, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=340.4, nsentences=7.8, sample_size=340.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1125.3, ups=3.31, wpb=340.4, bsz=7.8, num_updates=28790, lr=7.19873e-05, gnorm=2.968, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=9870
2023-03-15 16:44:16 - progress_bar.py[line:272] - INFO: epoch 015:    930 / 2004 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=331.7, nsentences=8, sample_size=331.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1073.4, ups=3.24, wpb=331.7, bsz=8, num_updates=28800, lr=7.19773e-05, gnorm=2.705, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=9873
2023-03-15 16:44:19 - progress_bar.py[line:272] - INFO: epoch 015:    940 / 2004 loss=0.267, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=359, nsentences=8, sample_size=359, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1148.4, ups=3.2, wpb=359, bsz=8, num_updates=28810, lr=7.19672e-05, gnorm=2.875, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=9877
2023-03-15 16:44:22 - progress_bar.py[line:272] - INFO: epoch 015:    950 / 2004 loss=0.27, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=361.5, nsentences=8, sample_size=361.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1144.5, ups=3.17, wpb=361.5, bsz=8, num_updates=28820, lr=7.19571e-05, gnorm=2.865, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=9880
2023-03-15 16:44:25 - progress_bar.py[line:272] - INFO: epoch 015:    960 / 2004 loss=0.276, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=355.6, nsentences=8, sample_size=355.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1148.1, ups=3.23, wpb=355.6, bsz=8, num_updates=28830, lr=7.1947e-05, gnorm=2.991, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=9883
2023-03-15 16:44:28 - progress_bar.py[line:272] - INFO: epoch 015:    970 / 2004 loss=0.279, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=341.3, nsentences=8, sample_size=341.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1045.7, ups=3.06, wpb=341.3, bsz=8, num_updates=28840, lr=7.19369e-05, gnorm=3.04, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=9886
2023-03-15 16:44:32 - progress_bar.py[line:272] - INFO: epoch 015:    980 / 2004 loss=0.289, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=333.8, nsentences=8, sample_size=333.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1083.3, ups=3.25, wpb=333.8, bsz=8, num_updates=28850, lr=7.19269e-05, gnorm=3.009, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=9889
2023-03-15 16:44:35 - progress_bar.py[line:272] - INFO: epoch 015:    990 / 2004 loss=0.28, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=374.7, nsentences=8, sample_size=374.7, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1163.1, ups=3.1, wpb=374.7, bsz=8, num_updates=28860, lr=7.19168e-05, gnorm=2.923, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=9892
2023-03-15 16:44:38 - progress_bar.py[line:272] - INFO: epoch 015:   1000 / 2004 loss=0.259, loss_v1=0, loss_v2=0, nll_loss=0.259, ntokens=345.5, nsentences=8, sample_size=345.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1124.4, ups=3.25, wpb=345.5, bsz=8, num_updates=28870, lr=7.19067e-05, gnorm=2.766, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=9895
2023-03-15 16:44:41 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 16:44:41 - progress_bar.py[line:272] - INFO: epoch 015:   1011 / 2004 loss=0.273, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=304.6, nsentences=8, sample_size=304.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=906.4, ups=2.98, wpb=304.6, bsz=8, num_updates=28880, lr=7.18966e-05, gnorm=2.899, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=9899
2023-03-15 16:44:44 - progress_bar.py[line:272] - INFO: epoch 015:   1021 / 2004 loss=0.26, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=344.8, nsentences=8, sample_size=344.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1109.7, ups=3.22, wpb=344.8, bsz=8, num_updates=28890, lr=7.18865e-05, gnorm=2.794, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=9902
2023-03-15 16:44:47 - progress_bar.py[line:272] - INFO: epoch 015:   1031 / 2004 loss=0.259, loss_v1=0, loss_v2=0, nll_loss=0.259, ntokens=310.2, nsentences=8, sample_size=310.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1022, ups=3.29, wpb=310.2, bsz=8, num_updates=28900, lr=7.18764e-05, gnorm=2.98, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=9905
2023-03-15 16:44:51 - progress_bar.py[line:272] - INFO: epoch 015:   1041 / 2004 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=338, nsentences=8, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=1066.7, ups=3.16, wpb=338, bsz=8, num_updates=28910, lr=7.18664e-05, gnorm=3.106, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=9908
2023-03-15 16:44:54 - progress_bar.py[line:272] - INFO: epoch 015:   1051 / 2004 loss=0.267, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=375, nsentences=8, sample_size=375, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1174.2, ups=3.13, wpb=375, bsz=8, num_updates=28920, lr=7.18563e-05, gnorm=2.921, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=9911
2023-03-15 16:44:57 - progress_bar.py[line:272] - INFO: epoch 015:   1061 / 2004 loss=0.264, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=334.5, nsentences=8, sample_size=334.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1091, ups=3.26, wpb=334.5, bsz=8, num_updates=28930, lr=7.18462e-05, gnorm=3.141, clip=10, loss_scale=1024, train_wall=3, gb_free=15.4, wall=9914
2023-03-15 16:45:00 - progress_bar.py[line:272] - INFO: epoch 015:   1071 / 2004 loss=0.27, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=362.4, nsentences=8, sample_size=362.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1154.4, ups=3.19, wpb=362.4, bsz=8, num_updates=28940, lr=7.18361e-05, gnorm=2.836, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=9918
2023-03-15 16:45:03 - progress_bar.py[line:272] - INFO: epoch 015:   1081 / 2004 loss=0.27, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=358.9, nsentences=8, sample_size=358.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1134.7, ups=3.16, wpb=358.9, bsz=8, num_updates=28950, lr=7.1826e-05, gnorm=2.875, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=9921
2023-03-15 16:45:06 - progress_bar.py[line:272] - INFO: epoch 015:   1091 / 2004 loss=0.278, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=339.3, nsentences=8, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1095.8, ups=3.23, wpb=339.3, bsz=8, num_updates=28960, lr=7.1816e-05, gnorm=2.931, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=9924
2023-03-15 16:45:09 - progress_bar.py[line:272] - INFO: epoch 015:   1101 / 2004 loss=0.283, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=349.6, nsentences=8, sample_size=349.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1129.4, ups=3.23, wpb=349.6, bsz=8, num_updates=28970, lr=7.18059e-05, gnorm=2.96, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=9927
2023-03-15 16:45:12 - progress_bar.py[line:272] - INFO: epoch 015:   1111 / 2004 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=373, nsentences=8, sample_size=373, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=1176.2, ups=3.15, wpb=373, bsz=8, num_updates=28980, lr=7.17958e-05, gnorm=3.091, clip=0, loss_scale=1024, train_wall=3, gb_free=14.2, wall=9930
2023-03-15 16:45:16 - progress_bar.py[line:272] - INFO: epoch 015:   1121 / 2004 loss=0.23, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=314, nsentences=8, sample_size=314, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1018.8, ups=3.24, wpb=314, bsz=8, num_updates=28990, lr=7.17857e-05, gnorm=2.571, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=9933
2023-03-15 16:45:19 - progress_bar.py[line:272] - INFO: epoch 015:   1131 / 2004 loss=0.276, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=370.8, nsentences=8, sample_size=370.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1201.8, ups=3.24, wpb=370.8, bsz=8, num_updates=29000, lr=7.17756e-05, gnorm=2.823, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=9936
2023-03-15 16:45:22 - progress_bar.py[line:272] - INFO: epoch 015:   1141 / 2004 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.254, ntokens=362.1, nsentences=8, sample_size=362.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1155.8, ups=3.19, wpb=362.1, bsz=8, num_updates=29010, lr=7.17656e-05, gnorm=2.75, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=9939
2023-03-15 16:45:25 - progress_bar.py[line:272] - INFO: epoch 015:   1151 / 2004 loss=0.264, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=365.2, nsentences=8, sample_size=365.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1159.4, ups=3.17, wpb=365.2, bsz=8, num_updates=29020, lr=7.17555e-05, gnorm=2.736, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=9943
2023-03-15 16:45:28 - progress_bar.py[line:272] - INFO: epoch 015:   1161 / 2004 loss=0.27, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=385.8, nsentences=8, sample_size=385.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1204.3, ups=3.12, wpb=385.8, bsz=8, num_updates=29030, lr=7.17454e-05, gnorm=2.866, clip=0, loss_scale=2048, train_wall=3, gb_free=15.8, wall=9946
2023-03-15 16:45:31 - progress_bar.py[line:272] - INFO: epoch 015:   1171 / 2004 loss=0.26, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=346.1, nsentences=8, sample_size=346.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1139.5, ups=3.29, wpb=346.1, bsz=8, num_updates=29040, lr=7.17353e-05, gnorm=2.877, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=9949
2023-03-15 16:45:34 - progress_bar.py[line:272] - INFO: epoch 015:   1181 / 2004 loss=0.273, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=347.7, nsentences=8, sample_size=347.7, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1120.8, ups=3.22, wpb=347.7, bsz=8, num_updates=29050, lr=7.17252e-05, gnorm=3.131, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=9952
2023-03-15 16:45:38 - progress_bar.py[line:272] - INFO: epoch 015:   1191 / 2004 loss=0.267, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=339.3, nsentences=8, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1037.2, ups=3.06, wpb=339.3, bsz=8, num_updates=29060, lr=7.17152e-05, gnorm=2.909, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=9955
2023-03-15 16:45:41 - progress_bar.py[line:272] - INFO: epoch 015:   1201 / 2004 loss=0.276, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=349.8, nsentences=8, sample_size=349.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1013.8, ups=2.9, wpb=349.8, bsz=8, num_updates=29070, lr=7.17051e-05, gnorm=2.911, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=9959
2023-03-15 16:45:44 - progress_bar.py[line:272] - INFO: epoch 015:   1211 / 2004 loss=0.233, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=282.4, nsentences=8, sample_size=282.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=850, ups=3.01, wpb=282.4, bsz=8, num_updates=29080, lr=7.1695e-05, gnorm=2.49, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=9962
2023-03-15 16:45:47 - progress_bar.py[line:272] - INFO: epoch 015:   1221 / 2004 loss=0.258, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=331.6, nsentences=8, sample_size=331.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1066.3, ups=3.22, wpb=331.6, bsz=8, num_updates=29090, lr=7.16849e-05, gnorm=2.928, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=9965
2023-03-15 16:45:50 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 16:45:51 - progress_bar.py[line:272] - INFO: epoch 015:   1232 / 2004 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=313.8, nsentences=8, sample_size=313.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=940.6, ups=3, wpb=313.8, bsz=8, num_updates=29100, lr=7.16748e-05, gnorm=2.825, clip=0, loss_scale=1024, train_wall=3, gb_free=13.6, wall=9968
2023-03-15 16:45:54 - progress_bar.py[line:272] - INFO: epoch 015:   1242 / 2004 loss=0.286, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=390.3, nsentences=8, sample_size=390.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1217, ups=3.12, wpb=390.3, bsz=8, num_updates=29110, lr=7.16648e-05, gnorm=3.013, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=9972
2023-03-15 16:45:57 - progress_bar.py[line:272] - INFO: epoch 015:   1252 / 2004 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.241, ntokens=345, nsentences=8, sample_size=345, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1101, ups=3.19, wpb=345, bsz=8, num_updates=29120, lr=7.16547e-05, gnorm=2.613, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=9975
2023-03-15 16:46:00 - progress_bar.py[line:272] - INFO: epoch 015:   1262 / 2004 loss=0.26, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=343.6, nsentences=8, sample_size=343.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1107.5, ups=3.22, wpb=343.6, bsz=8, num_updates=29130, lr=7.16446e-05, gnorm=2.821, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=9978
2023-03-15 16:46:03 - progress_bar.py[line:272] - INFO: epoch 015:   1272 / 2004 loss=0.273, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=348.7, nsentences=8, sample_size=348.7, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1100.2, ups=3.16, wpb=348.7, bsz=8, num_updates=29140, lr=7.16345e-05, gnorm=3.041, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=9981
2023-03-15 16:46:06 - progress_bar.py[line:272] - INFO: epoch 015:   1282 / 2004 loss=0.236, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=327.8, nsentences=8, sample_size=327.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1064.5, ups=3.25, wpb=327.8, bsz=8, num_updates=29150, lr=7.16244e-05, gnorm=2.801, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=9984
2023-03-15 16:46:09 - progress_bar.py[line:272] - INFO: epoch 015:   1292 / 2004 loss=0.232, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=312.9, nsentences=8, sample_size=312.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1027.5, ups=3.28, wpb=312.9, bsz=8, num_updates=29160, lr=7.16143e-05, gnorm=2.58, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=9987
2023-03-15 16:46:13 - progress_bar.py[line:272] - INFO: epoch 015:   1302 / 2004 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=314.8, nsentences=8, sample_size=314.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1019.9, ups=3.24, wpb=314.8, bsz=8, num_updates=29170, lr=7.16043e-05, gnorm=2.824, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=9990
2023-03-15 16:46:16 - progress_bar.py[line:272] - INFO: epoch 015:   1312 / 2004 loss=0.272, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=337.2, nsentences=8, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1106.1, ups=3.28, wpb=337.2, bsz=8, num_updates=29180, lr=7.15942e-05, gnorm=2.84, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=9993
2023-03-15 16:46:19 - progress_bar.py[line:272] - INFO: epoch 015:   1322 / 2004 loss=0.265, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=317.7, nsentences=8, sample_size=317.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1028.3, ups=3.24, wpb=317.7, bsz=8, num_updates=29190, lr=7.15841e-05, gnorm=2.781, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=9996
2023-03-15 16:46:22 - progress_bar.py[line:272] - INFO: epoch 015:   1332 / 2004 loss=0.263, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=321.9, nsentences=8, sample_size=321.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1046.8, ups=3.25, wpb=321.9, bsz=8, num_updates=29200, lr=7.1574e-05, gnorm=2.806, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=9999
2023-03-15 16:46:25 - progress_bar.py[line:272] - INFO: epoch 015:   1342 / 2004 loss=0.272, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=329.3, nsentences=8, sample_size=329.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1055.1, ups=3.2, wpb=329.3, bsz=8, num_updates=29210, lr=7.15639e-05, gnorm=2.919, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=10003
2023-03-15 16:46:28 - progress_bar.py[line:272] - INFO: epoch 015:   1352 / 2004 loss=0.274, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=323.5, nsentences=8, sample_size=323.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1060.3, ups=3.28, wpb=323.5, bsz=8, num_updates=29220, lr=7.15539e-05, gnorm=2.859, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=10006
2023-03-15 16:46:31 - progress_bar.py[line:272] - INFO: epoch 015:   1362 / 2004 loss=0.257, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=324.4, nsentences=8, sample_size=324.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1052.1, ups=3.24, wpb=324.4, bsz=8, num_updates=29230, lr=7.15438e-05, gnorm=2.921, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=10009
2023-03-15 16:46:34 - progress_bar.py[line:272] - INFO: epoch 015:   1372 / 2004 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=298.5, nsentences=8, sample_size=298.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=930.4, ups=3.12, wpb=298.5, bsz=8, num_updates=29240, lr=7.15337e-05, gnorm=2.917, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=10012
2023-03-15 16:46:38 - progress_bar.py[line:272] - INFO: epoch 015:   1382 / 2004 loss=0.293, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=381.1, nsentences=8, sample_size=381.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1136.6, ups=2.98, wpb=381.1, bsz=8, num_updates=29250, lr=7.15236e-05, gnorm=2.99, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=10015
2023-03-15 16:46:41 - progress_bar.py[line:272] - INFO: epoch 015:   1392 / 2004 loss=0.28, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=357.9, nsentences=8, sample_size=357.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1132, ups=3.16, wpb=357.9, bsz=8, num_updates=29260, lr=7.15135e-05, gnorm=2.923, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=10018
2023-03-15 16:46:44 - progress_bar.py[line:272] - INFO: epoch 015:   1402 / 2004 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.241, ntokens=347.8, nsentences=8, sample_size=347.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1091.6, ups=3.14, wpb=347.8, bsz=8, num_updates=29270, lr=7.15035e-05, gnorm=2.856, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=10022
2023-03-15 16:46:47 - progress_bar.py[line:272] - INFO: epoch 015:   1412 / 2004 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=375.7, nsentences=8, sample_size=375.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=1185.1, ups=3.15, wpb=375.7, bsz=8, num_updates=29280, lr=7.14934e-05, gnorm=3.186, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=10025
2023-03-15 16:46:50 - progress_bar.py[line:272] - INFO: epoch 015:   1422 / 2004 loss=0.258, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=319.1, nsentences=8, sample_size=319.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1053.6, ups=3.3, wpb=319.1, bsz=8, num_updates=29290, lr=7.14833e-05, gnorm=2.874, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=10028
2023-03-15 16:46:53 - progress_bar.py[line:272] - INFO: epoch 015:   1432 / 2004 loss=0.265, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=337.5, nsentences=8, sample_size=337.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1061.3, ups=3.14, wpb=337.5, bsz=8, num_updates=29300, lr=7.14732e-05, gnorm=2.84, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=10031
2023-03-15 16:46:57 - progress_bar.py[line:272] - INFO: epoch 015:   1442 / 2004 loss=0.288, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=354.2, nsentences=8, sample_size=354.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1103.6, ups=3.12, wpb=354.2, bsz=8, num_updates=29310, lr=7.14631e-05, gnorm=2.9, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=10034
2023-03-15 16:47:00 - progress_bar.py[line:272] - INFO: epoch 015:   1452 / 2004 loss=0.278, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=326.8, nsentences=8, sample_size=326.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1039.3, ups=3.18, wpb=326.8, bsz=8, num_updates=29320, lr=7.14531e-05, gnorm=2.94, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=10037
2023-03-15 16:47:00 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 16:47:03 - progress_bar.py[line:272] - INFO: epoch 015:   1463 / 2004 loss=0.278, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=382.5, nsentences=8, sample_size=382.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1099.2, ups=2.87, wpb=382.5, bsz=8, num_updates=29330, lr=7.1443e-05, gnorm=3.065, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=10041
2023-03-15 16:47:06 - progress_bar.py[line:272] - INFO: epoch 015:   1473 / 2004 loss=0.294, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=400.9, nsentences=8, sample_size=400.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=1258.8, ups=3.14, wpb=400.9, bsz=8, num_updates=29340, lr=7.14329e-05, gnorm=3.055, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=10044
2023-03-15 16:47:10 - progress_bar.py[line:272] - INFO: epoch 015:   1483 / 2004 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=370.3, nsentences=8, sample_size=370.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1141.5, ups=3.08, wpb=370.3, bsz=8, num_updates=29350, lr=7.14228e-05, gnorm=2.732, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=10047
2023-03-15 16:47:13 - progress_bar.py[line:272] - INFO: epoch 015:   1493 / 2004 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.25, ntokens=310.3, nsentences=8, sample_size=310.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1001.5, ups=3.23, wpb=310.3, bsz=8, num_updates=29360, lr=7.14127e-05, gnorm=2.628, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=10050
2023-03-15 16:47:16 - progress_bar.py[line:272] - INFO: epoch 015:   1503 / 2004 loss=0.27, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=341.9, nsentences=8, sample_size=341.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1099.7, ups=3.22, wpb=341.9, bsz=8, num_updates=29370, lr=7.14026e-05, gnorm=2.989, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=10053
2023-03-15 16:47:19 - progress_bar.py[line:272] - INFO: epoch 015:   1513 / 2004 loss=0.261, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=333.6, nsentences=8, sample_size=333.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1080.6, ups=3.24, wpb=333.6, bsz=8, num_updates=29380, lr=7.13926e-05, gnorm=2.919, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=10057
2023-03-15 16:47:22 - progress_bar.py[line:272] - INFO: epoch 015:   1523 / 2004 loss=0.274, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=327.5, nsentences=8, sample_size=327.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1045.4, ups=3.19, wpb=327.5, bsz=8, num_updates=29390, lr=7.13825e-05, gnorm=3.103, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=10060
2023-03-15 16:47:25 - progress_bar.py[line:272] - INFO: epoch 015:   1533 / 2004 loss=0.287, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=356.6, nsentences=8, sample_size=356.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1119.8, ups=3.14, wpb=356.6, bsz=8, num_updates=29400, lr=7.13724e-05, gnorm=2.877, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=10063
2023-03-15 16:47:28 - progress_bar.py[line:272] - INFO: epoch 015:   1543 / 2004 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=316.9, nsentences=8, sample_size=316.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1004.2, ups=3.17, wpb=316.9, bsz=8, num_updates=29410, lr=7.13623e-05, gnorm=2.936, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=10066
2023-03-15 16:47:32 - progress_bar.py[line:272] - INFO: epoch 015:   1553 / 2004 loss=0.262, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=321.4, nsentences=8, sample_size=321.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1022, ups=3.18, wpb=321.4, bsz=8, num_updates=29420, lr=7.13522e-05, gnorm=2.942, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=10069
2023-03-15 16:47:35 - progress_bar.py[line:272] - INFO: epoch 015:   1563 / 2004 loss=0.281, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=360.8, nsentences=8, sample_size=360.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1132.2, ups=3.14, wpb=360.8, bsz=8, num_updates=29430, lr=7.13422e-05, gnorm=2.914, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=10072
2023-03-15 16:47:38 - progress_bar.py[line:272] - INFO: epoch 015:   1573 / 2004 loss=0.265, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=333.8, nsentences=8, sample_size=333.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1050.2, ups=3.15, wpb=333.8, bsz=8, num_updates=29440, lr=7.13321e-05, gnorm=2.941, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=10075
2023-03-15 16:47:41 - progress_bar.py[line:272] - INFO: epoch 015:   1583 / 2004 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=340.7, nsentences=8, sample_size=340.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1058.1, ups=3.11, wpb=340.7, bsz=8, num_updates=29450, lr=7.1322e-05, gnorm=2.777, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=10079
2023-03-15 16:47:44 - progress_bar.py[line:272] - INFO: epoch 015:   1593 / 2004 loss=0.257, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=353.8, nsentences=8, sample_size=353.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1086.6, ups=3.07, wpb=353.8, bsz=8, num_updates=29460, lr=7.13119e-05, gnorm=2.729, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=10082
2023-03-15 16:47:48 - progress_bar.py[line:272] - INFO: epoch 015:   1603 / 2004 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=330.8, nsentences=8, sample_size=330.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1044.4, ups=3.16, wpb=330.8, bsz=8, num_updates=29470, lr=7.13018e-05, gnorm=2.738, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=10085
2023-03-15 16:47:51 - progress_bar.py[line:272] - INFO: epoch 015:   1613 / 2004 loss=0.277, loss_v1=0, loss_v2=0, nll_loss=0.277, ntokens=360.7, nsentences=8, sample_size=360.7, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1100.9, ups=3.05, wpb=360.7, bsz=8, num_updates=29480, lr=7.12918e-05, gnorm=3.169, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=10088
2023-03-15 16:47:53 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 16:47:55 - progress_bar.py[line:272] - INFO: epoch 015:   1624 / 2004 loss=0.267, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=327.4, nsentences=8, sample_size=327.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=839.8, ups=2.57, wpb=327.4, bsz=8, num_updates=29490, lr=7.12817e-05, gnorm=2.977, clip=0, loss_scale=1024, train_wall=4, gb_free=15, wall=10092
2023-03-15 16:47:58 - progress_bar.py[line:272] - INFO: epoch 015:   1634 / 2004 loss=0.274, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=338.9, nsentences=8, sample_size=338.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=979.5, ups=2.89, wpb=338.9, bsz=8, num_updates=29500, lr=7.12716e-05, gnorm=2.958, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=10096
2023-03-15 16:48:02 - progress_bar.py[line:272] - INFO: epoch 015:   1644 / 2004 loss=0.26, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=309.4, nsentences=8, sample_size=309.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=894, ups=2.89, wpb=309.4, bsz=8, num_updates=29510, lr=7.12615e-05, gnorm=2.848, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=10099
2023-03-15 16:48:05 - progress_bar.py[line:272] - INFO: epoch 015:   1654 / 2004 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=338.6, nsentences=8, sample_size=338.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=960.6, ups=2.84, wpb=338.6, bsz=8, num_updates=29520, lr=7.12514e-05, gnorm=2.725, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=10103
2023-03-15 16:48:09 - progress_bar.py[line:272] - INFO: epoch 015:   1664 / 2004 loss=0.26, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=358.4, nsentences=8, sample_size=358.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1038.4, ups=2.9, wpb=358.4, bsz=8, num_updates=29530, lr=7.12414e-05, gnorm=2.678, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=10106
2023-03-15 16:48:12 - progress_bar.py[line:272] - INFO: epoch 015:   1674 / 2004 loss=0.287, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=316.3, nsentences=8, sample_size=316.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=893.9, ups=2.83, wpb=316.3, bsz=8, num_updates=29540, lr=7.12313e-05, gnorm=3.018, clip=0, loss_scale=1024, train_wall=3, gb_free=15.9, wall=10110
2023-03-15 16:48:16 - progress_bar.py[line:272] - INFO: epoch 015:   1684 / 2004 loss=0.269, loss_v1=0, loss_v2=0, nll_loss=0.269, ntokens=349.4, nsentences=8, sample_size=349.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=991.5, ups=2.84, wpb=349.4, bsz=8, num_updates=29550, lr=7.12212e-05, gnorm=3.004, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=10113
2023-03-15 16:48:19 - progress_bar.py[line:272] - INFO: epoch 015:   1694 / 2004 loss=0.282, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=338.3, nsentences=8, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=976.2, ups=2.89, wpb=338.3, bsz=8, num_updates=29560, lr=7.12111e-05, gnorm=3.08, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=10117
2023-03-15 16:48:23 - progress_bar.py[line:272] - INFO: epoch 015:   1704 / 2004 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=334.7, nsentences=8, sample_size=334.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=961.7, ups=2.87, wpb=334.7, bsz=8, num_updates=29570, lr=7.1201e-05, gnorm=2.736, clip=0, loss_scale=1024, train_wall=3, gb_free=14.1, wall=10120
2023-03-15 16:48:26 - progress_bar.py[line:272] - INFO: epoch 015:   1714 / 2004 loss=0.265, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=364, nsentences=8, sample_size=364, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1035.5, ups=2.84, wpb=364, bsz=8, num_updates=29580, lr=7.1191e-05, gnorm=2.866, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=10124
2023-03-15 16:48:30 - progress_bar.py[line:272] - INFO: epoch 015:   1724 / 2004 loss=0.26, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=380.9, nsentences=8, sample_size=380.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1094.2, ups=2.87, wpb=380.9, bsz=8, num_updates=29590, lr=7.11809e-05, gnorm=2.884, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=10127
2023-03-15 16:48:33 - progress_bar.py[line:272] - INFO: epoch 015:   1734 / 2004 loss=0.261, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=350.8, nsentences=8, sample_size=350.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1011.8, ups=2.88, wpb=350.8, bsz=8, num_updates=29600, lr=7.11708e-05, gnorm=2.867, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=10131
2023-03-15 16:48:37 - progress_bar.py[line:272] - INFO: epoch 015:   1744 / 2004 loss=0.262, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=346.2, nsentences=8, sample_size=346.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=984, ups=2.84, wpb=346.2, bsz=8, num_updates=29610, lr=7.11607e-05, gnorm=2.875, clip=0, loss_scale=1024, train_wall=3, gb_free=13.9, wall=10134
2023-03-15 16:48:40 - progress_bar.py[line:272] - INFO: epoch 015:   1754 / 2004 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.238, ntokens=347.7, nsentences=8, sample_size=347.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1007.7, ups=2.9, wpb=347.7, bsz=8, num_updates=29620, lr=7.11506e-05, gnorm=2.574, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=10138
2023-03-15 16:48:44 - progress_bar.py[line:272] - INFO: epoch 015:   1764 / 2004 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.256, ntokens=303.9, nsentences=8, sample_size=303.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=872.4, ups=2.87, wpb=303.9, bsz=8, num_updates=29630, lr=7.11405e-05, gnorm=3.095, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=10141
2023-03-15 16:48:47 - progress_bar.py[line:272] - INFO: epoch 015:   1774 / 2004 loss=0.266, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=346.8, nsentences=8, sample_size=346.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=987.1, ups=2.85, wpb=346.8, bsz=8, num_updates=29640, lr=7.11305e-05, gnorm=2.981, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=10145
2023-03-15 16:48:51 - progress_bar.py[line:272] - INFO: epoch 015:   1784 / 2004 loss=0.263, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=323.6, nsentences=8, sample_size=323.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=928.5, ups=2.87, wpb=323.6, bsz=8, num_updates=29650, lr=7.11204e-05, gnorm=2.899, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=10148
2023-03-15 16:48:54 - progress_bar.py[line:272] - INFO: epoch 015:   1794 / 2004 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.254, ntokens=324.6, nsentences=8, sample_size=324.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=949.9, ups=2.93, wpb=324.6, bsz=8, num_updates=29660, lr=7.11103e-05, gnorm=2.828, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=10152
2023-03-15 16:48:57 - progress_bar.py[line:272] - INFO: epoch 015:   1804 / 2004 loss=0.272, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=335.3, nsentences=8, sample_size=335.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=978, ups=2.92, wpb=335.3, bsz=8, num_updates=29670, lr=7.11002e-05, gnorm=3.005, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=10155
2023-03-15 16:49:01 - progress_bar.py[line:272] - INFO: epoch 015:   1814 / 2004 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=364.4, nsentences=8, sample_size=364.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1039.6, ups=2.85, wpb=364.4, bsz=8, num_updates=29680, lr=7.10901e-05, gnorm=2.82, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=10158
2023-03-15 16:49:04 - progress_bar.py[line:272] - INFO: epoch 015:   1824 / 2004 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=357.5, nsentences=8, sample_size=357.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1027.7, ups=2.87, wpb=357.5, bsz=8, num_updates=29690, lr=7.10801e-05, gnorm=2.613, clip=0, loss_scale=2048, train_wall=3, gb_free=13.7, wall=10162
2023-03-15 16:49:08 - progress_bar.py[line:272] - INFO: epoch 015:   1834 / 2004 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=345.3, nsentences=8, sample_size=345.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=982.2, ups=2.84, wpb=345.3, bsz=8, num_updates=29700, lr=7.107e-05, gnorm=2.611, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=10165
2023-03-15 16:49:11 - progress_bar.py[line:272] - INFO: epoch 015:   1844 / 2004 loss=0.257, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=333.3, nsentences=8, sample_size=333.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=957.2, ups=2.87, wpb=333.3, bsz=8, num_updates=29710, lr=7.10599e-05, gnorm=2.724, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=10169
2023-03-15 16:49:15 - progress_bar.py[line:272] - INFO: epoch 015:   1854 / 2004 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.247, ntokens=331.8, nsentences=8, sample_size=331.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=937.6, ups=2.83, wpb=331.8, bsz=8, num_updates=29720, lr=7.10498e-05, gnorm=2.686, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=10173
2023-03-15 16:49:19 - progress_bar.py[line:272] - INFO: epoch 015:   1864 / 2004 loss=0.275, loss_v1=0, loss_v2=0, nll_loss=0.275, ntokens=347.7, nsentences=8, sample_size=347.7, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=963.6, ups=2.77, wpb=347.7, bsz=8, num_updates=29730, lr=7.10397e-05, gnorm=2.93, clip=0, loss_scale=2048, train_wall=4, gb_free=15.1, wall=10176
2023-03-15 16:49:22 - progress_bar.py[line:272] - INFO: epoch 015:   1874 / 2004 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=333.6, nsentences=8, sample_size=333.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=954.8, ups=2.86, wpb=333.6, bsz=8, num_updates=29740, lr=7.10297e-05, gnorm=2.816, clip=0, loss_scale=2048, train_wall=3, gb_free=13.7, wall=10180
2023-03-15 16:49:25 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 16:49:26 - progress_bar.py[line:272] - INFO: epoch 015:   1885 / 2004 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.25, ntokens=313.2, nsentences=8, sample_size=313.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=837.5, ups=2.67, wpb=313.2, bsz=8, num_updates=29750, lr=7.10196e-05, gnorm=2.812, clip=0, loss_scale=2048, train_wall=4, gb_free=15.2, wall=10183
2023-03-15 16:49:29 - progress_bar.py[line:272] - INFO: epoch 015:   1895 / 2004 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.256, ntokens=338.2, nsentences=8, sample_size=338.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=968.3, ups=2.86, wpb=338.2, bsz=8, num_updates=29760, lr=7.10095e-05, gnorm=2.943, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=10187
2023-03-15 16:49:33 - progress_bar.py[line:272] - INFO: epoch 015:   1905 / 2004 loss=0.263, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=352.6, nsentences=8, sample_size=352.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1013, ups=2.87, wpb=352.6, bsz=8, num_updates=29770, lr=7.09994e-05, gnorm=3.047, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=10190
2023-03-15 16:49:36 - progress_bar.py[line:272] - INFO: epoch 015:   1915 / 2004 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.241, ntokens=306.6, nsentences=8, sample_size=306.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=907.9, ups=2.96, wpb=306.6, bsz=8, num_updates=29780, lr=7.09893e-05, gnorm=2.698, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=10194
2023-03-15 16:49:39 - progress_bar.py[line:272] - INFO: epoch 015:   1925 / 2004 loss=0.27, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=340.3, nsentences=8, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1001.5, ups=2.94, wpb=340.3, bsz=8, num_updates=29790, lr=7.09793e-05, gnorm=3.219, clip=10, loss_scale=2048, train_wall=3, gb_free=14.9, wall=10197
2023-03-15 16:49:43 - progress_bar.py[line:272] - INFO: epoch 015:   1935 / 2004 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.256, ntokens=327.9, nsentences=8, sample_size=327.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=976.3, ups=2.98, wpb=327.9, bsz=8, num_updates=29800, lr=7.09692e-05, gnorm=2.891, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=10200
2023-03-15 16:49:46 - progress_bar.py[line:272] - INFO: epoch 015:   1945 / 2004 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=355.2, nsentences=8, sample_size=355.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1038.3, ups=2.92, wpb=355.2, bsz=8, num_updates=29810, lr=7.09591e-05, gnorm=2.812, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=10204
2023-03-15 16:49:50 - progress_bar.py[line:272] - INFO: epoch 015:   1955 / 2004 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=355, nsentences=8, sample_size=355, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1028.7, ups=2.9, wpb=355, bsz=8, num_updates=29820, lr=7.0949e-05, gnorm=2.663, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=10207
2023-03-15 16:49:53 - progress_bar.py[line:272] - INFO: epoch 015:   1965 / 2004 loss=0.259, loss_v1=0, loss_v2=0, nll_loss=0.259, ntokens=349.1, nsentences=8, sample_size=349.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1015.2, ups=2.91, wpb=349.1, bsz=8, num_updates=29830, lr=7.09389e-05, gnorm=3.031, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=10211
2023-03-15 16:49:57 - progress_bar.py[line:272] - INFO: epoch 015:   1975 / 2004 loss=0.264, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=344.5, nsentences=8, sample_size=344.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=987.4, ups=2.87, wpb=344.5, bsz=8, num_updates=29840, lr=7.09288e-05, gnorm=2.857, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=10214
2023-03-15 16:50:00 - progress_bar.py[line:272] - INFO: epoch 015:   1985 / 2004 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=307.7, nsentences=8, sample_size=307.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=892, ups=2.9, wpb=307.7, bsz=8, num_updates=29850, lr=7.09188e-05, gnorm=2.831, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=10218
2023-03-15 16:50:04 - progress_bar.py[line:272] - INFO: epoch 015:   1995 / 2004 loss=0.279, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=396.1, nsentences=8, sample_size=396.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1137.8, ups=2.87, wpb=396.1, bsz=8, num_updates=29860, lr=7.09087e-05, gnorm=3.045, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=10221
2023-03-15 16:50:06 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 15 @ 29869 updates
2023-03-15 16:50:06 - trainer.py[line:431] - INFO: Saving checkpoint to ./checkpoints/checkpoint15.pt
2023-03-15 16:50:13 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./checkpoints/checkpoint15.pt
2023-03-15 16:50:15 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./checkpoints/checkpoint15.pt (epoch 15 @ 29869 updates, score None) (writing took 8.727576835080981 seconds)
2023-03-15 16:50:15 - train.py[line:332] - INFO: end of epoch 15 (average epoch stats below)
2023-03-15 16:50:15 - progress_bar.py[line:282] - INFO: epoch 015 | loss 0.271 | loss_v1 0 | loss_v2 0 | nll_loss 0.271 | ntokens 345.049 | nsentences 7.999 | sample_size 345.049 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.21 | wps 1018.7 | ups 2.95 | wpb 345 | bsz 8 | num_updates 29869 | lr 7.08996e-05 | gnorm 2.903 | clip 0.2 | loss_scale 2048 | train_wall 653 | gb_free 14.4 | wall 10233
2023-03-15 16:50:15 - trainer.py[line:639] - INFO: loading train data for epoch 16
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 row count 8015 total row count 8015
slice_id 0 seek offset 0
2023-03-15 16:50:16 - trainer.py[line:703] - INFO: begin training epoch 16
2023-03-15 16:50:16 - train.py[line:305] - INFO: Start iterating over samples
2023-03-15 16:50:17 - progress_bar.py[line:272] - INFO: epoch 016:      1 / 2004 loss=0.273, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=378.7, nsentences=8, sample_size=378.7, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=291.8, ups=0.77, wpb=378.7, bsz=8, num_updates=29870, lr=7.08986e-05, gnorm=2.993, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=10234
2023-03-15 16:50:19 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 16:50:21 - progress_bar.py[line:272] - INFO: epoch 016:     12 / 2004 loss=0.276, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=337.2, nsentences=8, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=852.2, ups=2.53, wpb=337.2, bsz=8, num_updates=29880, lr=7.08885e-05, gnorm=3.077, clip=0, loss_scale=2048, train_wall=4, gb_free=15.5, wall=10238
2023-03-15 16:50:21 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 16:50:24 - progress_bar.py[line:272] - INFO: epoch 016:     23 / 2004 loss=0.288, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=337.9, nsentences=8, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=885.1, ups=2.62, wpb=337.9, bsz=8, num_updates=29890, lr=7.08784e-05, gnorm=3.174, clip=0, loss_scale=1024, train_wall=4, gb_free=15, wall=10242
2023-03-15 16:50:28 - progress_bar.py[line:272] - INFO: epoch 016:     33 / 2004 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=361.3, nsentences=8, sample_size=361.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1047.8, ups=2.9, wpb=361.3, bsz=8, num_updates=29900, lr=7.08684e-05, gnorm=2.787, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=10245
2023-03-15 16:50:31 - progress_bar.py[line:272] - INFO: epoch 016:     43 / 2004 loss=0.261, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=353.2, nsentences=8, sample_size=353.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=991.8, ups=2.81, wpb=353.2, bsz=8, num_updates=29910, lr=7.08583e-05, gnorm=2.787, clip=0, loss_scale=1024, train_wall=4, gb_free=15.2, wall=10249
2023-03-15 16:50:35 - progress_bar.py[line:272] - INFO: epoch 016:     53 / 2004 loss=0.285, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=344.3, nsentences=8, sample_size=344.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1004.7, ups=2.92, wpb=344.3, bsz=8, num_updates=29920, lr=7.08482e-05, gnorm=3.053, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=10252
2023-03-15 16:50:38 - progress_bar.py[line:272] - INFO: epoch 016:     63 / 2004 loss=0.269, loss_v1=0, loss_v2=0, nll_loss=0.269, ntokens=338.5, nsentences=8, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=971.5, ups=2.87, wpb=338.5, bsz=8, num_updates=29930, lr=7.08381e-05, gnorm=3.113, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=10256
2023-03-15 16:50:42 - progress_bar.py[line:272] - INFO: epoch 016:     73 / 2004 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=348.7, nsentences=8, sample_size=348.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=995, ups=2.85, wpb=348.7, bsz=8, num_updates=29940, lr=7.0828e-05, gnorm=2.916, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=10259
2023-03-15 16:50:45 - progress_bar.py[line:272] - INFO: epoch 016:     83 / 2004 loss=0.261, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=328.5, nsentences=8, sample_size=328.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=955.3, ups=2.91, wpb=328.5, bsz=8, num_updates=29950, lr=7.0818e-05, gnorm=2.773, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=10263
2023-03-15 16:50:49 - progress_bar.py[line:272] - INFO: epoch 016:     93 / 2004 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=369.6, nsentences=8, sample_size=369.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=1038.2, ups=2.81, wpb=369.6, bsz=8, num_updates=29960, lr=7.08079e-05, gnorm=3.317, clip=0, loss_scale=1024, train_wall=4, gb_free=12.9, wall=10266
2023-03-15 16:50:52 - progress_bar.py[line:272] - INFO: epoch 016:    103 / 2004 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.25, ntokens=367.3, nsentences=8, sample_size=367.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1054.1, ups=2.87, wpb=367.3, bsz=8, num_updates=29970, lr=7.07978e-05, gnorm=2.929, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=10270
2023-03-15 16:50:56 - progress_bar.py[line:272] - INFO: epoch 016:    113 / 2004 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.247, ntokens=339.8, nsentences=8, sample_size=339.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=983.6, ups=2.89, wpb=339.8, bsz=8, num_updates=29980, lr=7.07877e-05, gnorm=2.637, clip=0, loss_scale=1024, train_wall=3, gb_free=13.7, wall=10273
2023-03-15 16:50:59 - progress_bar.py[line:272] - INFO: epoch 016:    123 / 2004 loss=0.271, loss_v1=0, loss_v2=0, nll_loss=0.271, ntokens=349.4, nsentences=8, sample_size=349.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1002.1, ups=2.87, wpb=349.4, bsz=8, num_updates=29990, lr=7.07776e-05, gnorm=2.978, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=10277
2023-03-15 16:51:03 - progress_bar.py[line:272] - INFO: epoch 016:    133 / 2004 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=316.1, nsentences=8, sample_size=316.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=916.1, ups=2.9, wpb=316.1, bsz=8, num_updates=30000, lr=7.07676e-05, gnorm=2.629, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=10280
2023-03-15 16:51:03 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 16 @ 30000 updates
2023-03-15 16:51:03 - trainer.py[line:431] - INFO: Saving checkpoint to ./checkpoints/checkpoint_16_30000.pt
2023-03-15 16:51:09 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./checkpoints/checkpoint_16_30000.pt
2023-03-15 16:51:12 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./checkpoints/checkpoint_16_30000.pt (epoch 16 @ 30000 updates, score None) (writing took 9.420520128682256 seconds)
2023-03-15 16:51:15 - progress_bar.py[line:272] - INFO: epoch 016:    143 / 2004 loss=0.26, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=348.9, nsentences=8, sample_size=348.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=271.8, ups=0.78, wpb=348.9, bsz=8, num_updates=30010, lr=7.07575e-05, gnorm=2.9, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=10293
2023-03-15 16:51:19 - progress_bar.py[line:272] - INFO: epoch 016:    153 / 2004 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=323, nsentences=8, sample_size=323, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=946.8, ups=2.93, wpb=323, bsz=8, num_updates=30020, lr=7.07474e-05, gnorm=2.688, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=10297
2023-03-15 16:51:22 - progress_bar.py[line:272] - INFO: epoch 016:    163 / 2004 loss=0.274, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=369.2, nsentences=8, sample_size=369.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1092.2, ups=2.96, wpb=369.2, bsz=8, num_updates=30030, lr=7.07373e-05, gnorm=2.81, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=10300
2023-03-15 16:51:26 - progress_bar.py[line:272] - INFO: epoch 016:    173 / 2004 loss=0.272, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=335, nsentences=8, sample_size=335, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=997, ups=2.98, wpb=335, bsz=8, num_updates=30040, lr=7.07272e-05, gnorm=2.851, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=10303
2023-03-15 16:51:29 - progress_bar.py[line:272] - INFO: epoch 016:    183 / 2004 loss=0.262, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=322.9, nsentences=8, sample_size=322.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=980.7, ups=3.04, wpb=322.9, bsz=8, num_updates=30050, lr=7.07172e-05, gnorm=2.9, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=10307
2023-03-15 16:51:32 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 16:51:32 - progress_bar.py[line:272] - INFO: epoch 016:    194 / 2004 loss=0.226, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=340.4, nsentences=8, sample_size=340.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=960.7, ups=2.82, wpb=340.4, bsz=8, num_updates=30060, lr=7.07071e-05, gnorm=2.528, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=10310
2023-03-15 16:51:33 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-03-15 16:51:36 - progress_bar.py[line:272] - INFO: epoch 016:    205 / 2004 loss=0.258, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=330.6, nsentences=8, sample_size=330.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=889, ups=2.69, wpb=330.6, bsz=8, num_updates=30070, lr=7.0697e-05, gnorm=2.973, clip=0, loss_scale=512, train_wall=4, gb_free=15.2, wall=10314
2023-03-15 16:51:39 - progress_bar.py[line:272] - INFO: epoch 016:    215 / 2004 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=334.6, nsentences=8, sample_size=334.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1067.8, ups=3.19, wpb=334.6, bsz=8, num_updates=30080, lr=7.06869e-05, gnorm=2.673, clip=0, loss_scale=512, train_wall=3, gb_free=14.8, wall=10317
2023-03-15 16:51:43 - progress_bar.py[line:272] - INFO: epoch 016:    225 / 2004 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.241, ntokens=333.2, nsentences=8, sample_size=333.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=995.5, ups=2.99, wpb=333.2, bsz=8, num_updates=30090, lr=7.06768e-05, gnorm=2.749, clip=0, loss_scale=512, train_wall=3, gb_free=14.5, wall=10320
2023-03-15 16:51:46 - progress_bar.py[line:272] - INFO: epoch 016:    235 / 2004 loss=0.271, loss_v1=0, loss_v2=0, nll_loss=0.271, ntokens=371.3, nsentences=8, sample_size=371.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1084.2, ups=2.92, wpb=371.3, bsz=8, num_updates=30100, lr=7.06667e-05, gnorm=3, clip=0, loss_scale=512, train_wall=3, gb_free=15.4, wall=10324
2023-03-15 16:51:49 - progress_bar.py[line:272] - INFO: epoch 016:    245 / 2004 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=353.4, nsentences=8, sample_size=353.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1041.6, ups=2.95, wpb=353.4, bsz=8, num_updates=30110, lr=7.06567e-05, gnorm=2.827, clip=0, loss_scale=512, train_wall=3, gb_free=14.8, wall=10327
2023-03-15 16:51:53 - progress_bar.py[line:272] - INFO: epoch 016:    255 / 2004 loss=0.275, loss_v1=0, loss_v2=0, nll_loss=0.275, ntokens=338.4, nsentences=8, sample_size=338.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1000.5, ups=2.96, wpb=338.4, bsz=8, num_updates=30120, lr=7.06466e-05, gnorm=3.052, clip=0, loss_scale=512, train_wall=3, gb_free=13.8, wall=10330
2023-03-15 16:51:56 - progress_bar.py[line:272] - INFO: epoch 016:    265 / 2004 loss=0.278, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=357, nsentences=8, sample_size=357, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1053.4, ups=2.95, wpb=357, bsz=8, num_updates=30130, lr=7.06365e-05, gnorm=2.885, clip=0, loss_scale=512, train_wall=3, gb_free=14.8, wall=10334
2023-03-15 16:52:00 - progress_bar.py[line:272] - INFO: epoch 016:    275 / 2004 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=330.2, nsentences=8, sample_size=330.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=984.2, ups=2.98, wpb=330.2, bsz=8, num_updates=30140, lr=7.06264e-05, gnorm=2.785, clip=0, loss_scale=512, train_wall=3, gb_free=15, wall=10337
2023-03-15 16:52:03 - progress_bar.py[line:272] - INFO: epoch 016:    285 / 2004 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=376.6, nsentences=8, sample_size=376.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1057, ups=2.81, wpb=376.6, bsz=8, num_updates=30150, lr=7.06163e-05, gnorm=2.691, clip=0, loss_scale=512, train_wall=4, gb_free=14.7, wall=10341
2023-03-15 16:52:07 - progress_bar.py[line:272] - INFO: epoch 016:    295 / 2004 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=351.5, nsentences=8, sample_size=351.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=1017.8, ups=2.9, wpb=351.5, bsz=8, num_updates=30160, lr=7.06063e-05, gnorm=3.063, clip=0, loss_scale=512, train_wall=3, gb_free=14.6, wall=10344
2023-03-15 16:52:10 - progress_bar.py[line:272] - INFO: epoch 016:    305 / 2004 loss=0.281, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=352.2, nsentences=8, sample_size=352.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1035.9, ups=2.94, wpb=352.2, bsz=8, num_updates=30170, lr=7.05962e-05, gnorm=3.009, clip=0, loss_scale=512, train_wall=3, gb_free=14.6, wall=10348
2023-03-15 16:52:13 - progress_bar.py[line:272] - INFO: epoch 016:    315 / 2004 loss=0.26, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=356.3, nsentences=8, sample_size=356.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1129, ups=3.17, wpb=356.3, bsz=8, num_updates=30180, lr=7.05861e-05, gnorm=3.003, clip=0, loss_scale=512, train_wall=3, gb_free=14.8, wall=10351
2023-03-15 16:52:16 - progress_bar.py[line:272] - INFO: epoch 016:    325 / 2004 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=325.9, nsentences=8, sample_size=325.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1066.8, ups=3.27, wpb=325.9, bsz=8, num_updates=30190, lr=7.0576e-05, gnorm=2.822, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=10354
2023-03-15 16:52:19 - progress_bar.py[line:272] - INFO: epoch 016:    335 / 2004 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=320.6, nsentences=8, sample_size=320.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1051.5, ups=3.28, wpb=320.6, bsz=8, num_updates=30200, lr=7.05659e-05, gnorm=2.846, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=10357
2023-03-15 16:52:23 - progress_bar.py[line:272] - INFO: epoch 016:    345 / 2004 loss=0.263, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=388.7, nsentences=8, sample_size=388.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1124.2, ups=2.89, wpb=388.7, bsz=8, num_updates=30210, lr=7.05559e-05, gnorm=2.913, clip=0, loss_scale=1024, train_wall=3, gb_free=13.9, wall=10360
2023-03-15 16:52:26 - progress_bar.py[line:272] - INFO: epoch 016:    355 / 2004 loss=0.265, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=337.5, nsentences=8, sample_size=337.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=963, ups=2.85, wpb=337.5, bsz=8, num_updates=30220, lr=7.05458e-05, gnorm=3.074, clip=0, loss_scale=1024, train_wall=3, gb_free=14, wall=10364
2023-03-15 16:52:30 - progress_bar.py[line:272] - INFO: epoch 016:    365 / 2004 loss=0.272, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=355.8, nsentences=8, sample_size=355.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1013.6, ups=2.85, wpb=355.8, bsz=8, num_updates=30230, lr=7.05357e-05, gnorm=3.005, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=10367
2023-03-15 16:52:33 - progress_bar.py[line:272] - INFO: epoch 016:    375 / 2004 loss=0.232, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=319.3, nsentences=8, sample_size=319.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=917.4, ups=2.87, wpb=319.3, bsz=8, num_updates=30240, lr=7.05256e-05, gnorm=2.706, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=10371
2023-03-15 16:52:37 - progress_bar.py[line:272] - INFO: epoch 016:    385 / 2004 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.254, ntokens=326.1, nsentences=8, sample_size=326.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=924.9, ups=2.84, wpb=326.1, bsz=8, num_updates=30250, lr=7.05155e-05, gnorm=2.978, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=10374
2023-03-15 16:52:40 - progress_bar.py[line:272] - INFO: epoch 016:    395 / 2004 loss=0.28, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=354.5, nsentences=8, sample_size=354.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=998, ups=2.82, wpb=354.5, bsz=8, num_updates=30260, lr=7.05055e-05, gnorm=2.992, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=10378
2023-03-15 16:52:44 - progress_bar.py[line:272] - INFO: epoch 016:    405 / 2004 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=363.7, nsentences=8, sample_size=363.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1049.5, ups=2.89, wpb=363.7, bsz=8, num_updates=30270, lr=7.04954e-05, gnorm=2.671, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=10381
2023-03-15 16:52:47 - progress_bar.py[line:272] - INFO: epoch 016:    415 / 2004 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=351.8, nsentences=8, sample_size=351.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1013.8, ups=2.88, wpb=351.8, bsz=8, num_updates=30280, lr=7.04853e-05, gnorm=2.851, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=10385
2023-03-15 16:52:51 - progress_bar.py[line:272] - INFO: epoch 016:    425 / 2004 loss=0.268, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=331.5, nsentences=8, sample_size=331.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=951.7, ups=2.87, wpb=331.5, bsz=8, num_updates=30290, lr=7.04752e-05, gnorm=3.092, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=10388
2023-03-15 16:52:54 - progress_bar.py[line:272] - INFO: epoch 016:    435 / 2004 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=363.6, nsentences=8, sample_size=363.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1032, ups=2.84, wpb=363.6, bsz=8, num_updates=30300, lr=7.04651e-05, gnorm=2.816, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=10392
2023-03-15 16:52:58 - progress_bar.py[line:272] - INFO: epoch 016:    445 / 2004 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=366.6, nsentences=8, sample_size=366.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1031.6, ups=2.81, wpb=366.6, bsz=8, num_updates=30310, lr=7.0455e-05, gnorm=2.944, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=10395
2023-03-15 16:53:01 - progress_bar.py[line:272] - INFO: epoch 016:    455 / 2004 loss=0.282, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=380.2, nsentences=8, sample_size=380.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1090.9, ups=2.87, wpb=380.2, bsz=8, num_updates=30320, lr=7.0445e-05, gnorm=3.13, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=10399
2023-03-15 16:53:05 - progress_bar.py[line:272] - INFO: epoch 016:    465 / 2004 loss=0.269, loss_v1=0, loss_v2=0, nll_loss=0.269, ntokens=338.9, nsentences=8, sample_size=338.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=976.5, ups=2.88, wpb=338.9, bsz=8, num_updates=30330, lr=7.04349e-05, gnorm=2.754, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=10402
2023-03-15 16:53:08 - progress_bar.py[line:272] - INFO: epoch 016:    475 / 2004 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=379.1, nsentences=8, sample_size=379.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=1072.9, ups=2.83, wpb=379.1, bsz=8, num_updates=30340, lr=7.04248e-05, gnorm=2.982, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=10406
2023-03-15 16:53:12 - progress_bar.py[line:272] - INFO: epoch 016:    485 / 2004 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=366.1, nsentences=8, sample_size=366.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1050, ups=2.87, wpb=366.1, bsz=8, num_updates=30350, lr=7.04147e-05, gnorm=2.714, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=10409
2023-03-15 16:53:15 - progress_bar.py[line:272] - INFO: epoch 016:    495 / 2004 loss=0.232, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=359.9, nsentences=8, sample_size=359.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1047.8, ups=2.91, wpb=359.9, bsz=8, num_updates=30360, lr=7.04046e-05, gnorm=2.672, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=10413
2023-03-15 16:53:19 - progress_bar.py[line:272] - INFO: epoch 016:    505 / 2004 loss=0.273, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=353.8, nsentences=8, sample_size=353.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1026.3, ups=2.9, wpb=353.8, bsz=8, num_updates=30370, lr=7.03946e-05, gnorm=2.875, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=10416
2023-03-15 16:53:22 - progress_bar.py[line:272] - INFO: epoch 016:    515 / 2004 loss=0.257, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=359, nsentences=8, sample_size=359, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1021.7, ups=2.85, wpb=359, bsz=8, num_updates=30380, lr=7.03845e-05, gnorm=2.723, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=10420
2023-03-15 16:53:26 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 16:53:26 - progress_bar.py[line:272] - INFO: epoch 016:    526 / 2004 loss=0.275, loss_v1=0, loss_v2=0, nll_loss=0.275, ntokens=388.6, nsentences=8, sample_size=388.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1003.8, ups=2.58, wpb=388.6, bsz=8, num_updates=30390, lr=7.03744e-05, gnorm=2.903, clip=0, loss_scale=1024, train_wall=4, gb_free=14.5, wall=10424
2023-03-15 16:53:30 - progress_bar.py[line:272] - INFO: epoch 016:    536 / 2004 loss=0.263, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=382.9, nsentences=8, sample_size=382.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1086.5, ups=2.84, wpb=382.9, bsz=8, num_updates=30400, lr=7.03643e-05, gnorm=2.743, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=10427
2023-03-15 16:53:33 - progress_bar.py[line:272] - INFO: epoch 016:    546 / 2004 loss=0.274, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=361.2, nsentences=8, sample_size=361.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1025.4, ups=2.84, wpb=361.2, bsz=8, num_updates=30410, lr=7.03542e-05, gnorm=2.82, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=10431
2023-03-15 16:53:37 - progress_bar.py[line:272] - INFO: epoch 016:    556 / 2004 loss=0.261, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=370.6, nsentences=8, sample_size=370.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1045.4, ups=2.82, wpb=370.6, bsz=8, num_updates=30420, lr=7.03442e-05, gnorm=2.945, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=10434
2023-03-15 16:53:40 - progress_bar.py[line:272] - INFO: epoch 016:    566 / 2004 loss=0.27, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=380.4, nsentences=8, sample_size=380.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1095.7, ups=2.88, wpb=380.4, bsz=8, num_updates=30430, lr=7.03341e-05, gnorm=2.963, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=10438
2023-03-15 16:53:44 - progress_bar.py[line:272] - INFO: epoch 016:    576 / 2004 loss=0.259, loss_v1=0, loss_v2=0, nll_loss=0.259, ntokens=341.9, nsentences=8, sample_size=341.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=988, ups=2.89, wpb=341.9, bsz=8, num_updates=30440, lr=7.0324e-05, gnorm=2.851, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=10441
2023-03-15 16:53:47 - progress_bar.py[line:272] - INFO: epoch 016:    586 / 2004 loss=0.282, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=348, nsentences=8, sample_size=348, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=983.1, ups=2.82, wpb=348, bsz=8, num_updates=30450, lr=7.03139e-05, gnorm=2.906, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=10445
2023-03-15 16:53:51 - progress_bar.py[line:272] - INFO: epoch 016:    596 / 2004 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=344.2, nsentences=8, sample_size=344.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=974.9, ups=2.83, wpb=344.2, bsz=8, num_updates=30460, lr=7.03038e-05, gnorm=2.827, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=10448
2023-03-15 16:53:54 - progress_bar.py[line:272] - INFO: epoch 016:    606 / 2004 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=346.3, nsentences=8, sample_size=346.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1001.6, ups=2.89, wpb=346.3, bsz=8, num_updates=30470, lr=7.02938e-05, gnorm=2.807, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=10452
2023-03-15 16:53:58 - progress_bar.py[line:272] - INFO: epoch 016:    616 / 2004 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=360.8, nsentences=8, sample_size=360.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1016.8, ups=2.82, wpb=360.8, bsz=8, num_updates=30480, lr=7.02837e-05, gnorm=2.692, clip=0, loss_scale=1024, train_wall=3, gb_free=13.4, wall=10455
2023-03-15 16:54:01 - progress_bar.py[line:272] - INFO: epoch 016:    626 / 2004 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.241, ntokens=360.5, nsentences=8, sample_size=360.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1043.7, ups=2.9, wpb=360.5, bsz=8, num_updates=30490, lr=7.02736e-05, gnorm=2.827, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=10459
2023-03-15 16:54:05 - progress_bar.py[line:272] - INFO: epoch 016:    636 / 2004 loss=0.257, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=339.4, nsentences=8, sample_size=339.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=975.8, ups=2.88, wpb=339.4, bsz=8, num_updates=30500, lr=7.02635e-05, gnorm=2.873, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=10462
2023-03-15 16:54:08 - progress_bar.py[line:272] - INFO: epoch 016:    646 / 2004 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=327.6, nsentences=8, sample_size=327.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=953.3, ups=2.91, wpb=327.6, bsz=8, num_updates=30510, lr=7.02534e-05, gnorm=2.736, clip=0, loss_scale=1024, train_wall=3, gb_free=15.7, wall=10466
2023-03-15 16:54:11 - progress_bar.py[line:272] - INFO: epoch 016:    656 / 2004 loss=0.27, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=355.7, nsentences=8, sample_size=355.7, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1039.6, ups=2.92, wpb=355.7, bsz=8, num_updates=30520, lr=7.02434e-05, gnorm=2.991, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=10469
2023-03-15 16:54:15 - progress_bar.py[line:272] - INFO: epoch 016:    666 / 2004 loss=0.229, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=289.7, nsentences=8, sample_size=289.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=848.5, ups=2.93, wpb=289.7, bsz=8, num_updates=30530, lr=7.02333e-05, gnorm=2.695, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=10473
2023-03-15 16:54:18 - progress_bar.py[line:272] - INFO: epoch 016:    676 / 2004 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=342.5, nsentences=8, sample_size=342.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=982.3, ups=2.87, wpb=342.5, bsz=8, num_updates=30540, lr=7.02232e-05, gnorm=2.649, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=10476
2023-03-15 16:54:22 - progress_bar.py[line:272] - INFO: epoch 016:    686 / 2004 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.256, ntokens=363.1, nsentences=8, sample_size=363.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1026.6, ups=2.83, wpb=363.1, bsz=8, num_updates=30550, lr=7.02131e-05, gnorm=2.855, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=10480
2023-03-15 16:54:25 - progress_bar.py[line:272] - INFO: epoch 016:    696 / 2004 loss=0.284, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=341.4, nsentences=8, sample_size=341.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=974.2, ups=2.85, wpb=341.4, bsz=8, num_updates=30560, lr=7.0203e-05, gnorm=3.23, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=10483
2023-03-15 16:54:29 - progress_bar.py[line:272] - INFO: epoch 016:    706 / 2004 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=346.8, nsentences=8, sample_size=346.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1004.2, ups=2.9, wpb=346.8, bsz=8, num_updates=30570, lr=7.01929e-05, gnorm=2.599, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=10486
2023-03-15 16:54:32 - progress_bar.py[line:272] - INFO: epoch 016:    716 / 2004 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=333.6, nsentences=8, sample_size=333.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=947.9, ups=2.84, wpb=333.6, bsz=8, num_updates=30580, lr=7.01829e-05, gnorm=2.748, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=10490
2023-03-15 16:54:36 - progress_bar.py[line:272] - INFO: epoch 016:    726 / 2004 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.254, ntokens=357.4, nsentences=8, sample_size=357.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1025.4, ups=2.87, wpb=357.4, bsz=8, num_updates=30590, lr=7.01728e-05, gnorm=3.039, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=10493
2023-03-15 16:54:39 - progress_bar.py[line:272] - INFO: epoch 016:    736 / 2004 loss=0.26, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=350.1, nsentences=8, sample_size=350.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=999.9, ups=2.86, wpb=350.1, bsz=8, num_updates=30600, lr=7.01627e-05, gnorm=2.905, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=10497
2023-03-15 16:54:43 - progress_bar.py[line:272] - INFO: epoch 016:    746 / 2004 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=341, nsentences=8, sample_size=341, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=984.6, ups=2.89, wpb=341, bsz=8, num_updates=30610, lr=7.01526e-05, gnorm=2.917, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=10500
2023-03-15 16:54:46 - progress_bar.py[line:272] - INFO: epoch 016:    756 / 2004 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=319.5, nsentences=8, sample_size=319.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=928.3, ups=2.91, wpb=319.5, bsz=8, num_updates=30620, lr=7.01425e-05, gnorm=2.757, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=10504
2023-03-15 16:54:50 - progress_bar.py[line:272] - INFO: epoch 016:    766 / 2004 loss=0.272, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=377.9, nsentences=8, sample_size=377.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1092.5, ups=2.89, wpb=377.9, bsz=8, num_updates=30630, lr=7.01325e-05, gnorm=3.056, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=10507
2023-03-15 16:54:52 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 16:54:54 - progress_bar.py[line:272] - INFO: epoch 016:    777 / 2004 loss=0.263, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=368.7, nsentences=8, sample_size=368.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=954.9, ups=2.59, wpb=368.7, bsz=8, num_updates=30640, lr=7.01224e-05, gnorm=2.958, clip=0, loss_scale=1024, train_wall=4, gb_free=14.4, wall=10511
2023-03-15 16:54:57 - progress_bar.py[line:272] - INFO: epoch 016:    787 / 2004 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=331.4, nsentences=8, sample_size=331.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=964.6, ups=2.91, wpb=331.4, bsz=8, num_updates=30650, lr=7.01123e-05, gnorm=3.023, clip=0, loss_scale=1024, train_wall=3, gb_free=15.9, wall=10515
2023-03-15 16:55:01 - progress_bar.py[line:272] - INFO: epoch 016:    797 / 2004 loss=0.227, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=319.8, nsentences=8, sample_size=319.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=926.4, ups=2.9, wpb=319.8, bsz=8, num_updates=30660, lr=7.01022e-05, gnorm=2.518, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=10518
2023-03-15 16:55:04 - progress_bar.py[line:272] - INFO: epoch 016:    807 / 2004 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=346.2, nsentences=8, sample_size=346.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1009.9, ups=2.92, wpb=346.2, bsz=8, num_updates=30670, lr=7.00921e-05, gnorm=2.762, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=10522
2023-03-15 16:55:07 - progress_bar.py[line:272] - INFO: epoch 016:    817 / 2004 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.241, ntokens=326.3, nsentences=8, sample_size=326.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=925.3, ups=2.84, wpb=326.3, bsz=8, num_updates=30680, lr=7.00821e-05, gnorm=2.832, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=10525
2023-03-15 16:55:11 - progress_bar.py[line:272] - INFO: epoch 016:    827 / 2004 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=374.4, nsentences=8, sample_size=374.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1051.4, ups=2.81, wpb=374.4, bsz=8, num_updates=30690, lr=7.0072e-05, gnorm=2.805, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=10529
2023-03-15 16:55:15 - progress_bar.py[line:272] - INFO: epoch 016:    837 / 2004 loss=0.232, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=317.4, nsentences=8, sample_size=317.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=911.3, ups=2.87, wpb=317.4, bsz=8, num_updates=30700, lr=7.00619e-05, gnorm=2.752, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=10532
2023-03-15 16:55:18 - progress_bar.py[line:272] - INFO: epoch 016:    847 / 2004 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.247, ntokens=363.7, nsentences=8, sample_size=363.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1023.3, ups=2.81, wpb=363.7, bsz=8, num_updates=30710, lr=7.00518e-05, gnorm=2.824, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=10536
2023-03-15 16:55:22 - progress_bar.py[line:272] - INFO: epoch 016:    857 / 2004 loss=0.264, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=364.2, nsentences=8, sample_size=364.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1032.3, ups=2.83, wpb=364.2, bsz=8, num_updates=30720, lr=7.00417e-05, gnorm=3.023, clip=0, loss_scale=1024, train_wall=3, gb_free=14.2, wall=10539
2023-03-15 16:55:25 - progress_bar.py[line:272] - INFO: epoch 016:    867 / 2004 loss=0.264, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=363.7, nsentences=8, sample_size=363.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1043.1, ups=2.87, wpb=363.7, bsz=8, num_updates=30730, lr=7.00317e-05, gnorm=2.966, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=10543
2023-03-15 16:55:29 - progress_bar.py[line:272] - INFO: epoch 016:    877 / 2004 loss=0.226, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=331.4, nsentences=8, sample_size=331.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=955.2, ups=2.88, wpb=331.4, bsz=8, num_updates=30740, lr=7.00216e-05, gnorm=2.729, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=10546
2023-03-15 16:55:32 - progress_bar.py[line:272] - INFO: epoch 016:    887 / 2004 loss=0.236, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=315.9, nsentences=8, sample_size=315.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=900.5, ups=2.85, wpb=315.9, bsz=8, num_updates=30750, lr=7.00115e-05, gnorm=2.804, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=10550
2023-03-15 16:55:36 - progress_bar.py[line:272] - INFO: epoch 016:    897 / 2004 loss=0.272, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=343.3, nsentences=8, sample_size=343.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=988.3, ups=2.88, wpb=343.3, bsz=8, num_updates=30760, lr=7.00014e-05, gnorm=2.792, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=10553
2023-03-15 16:55:39 - progress_bar.py[line:272] - INFO: epoch 016:    907 / 2004 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=358.2, nsentences=8, sample_size=358.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1026.2, ups=2.86, wpb=358.2, bsz=8, num_updates=30770, lr=6.99913e-05, gnorm=2.852, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=10557
2023-03-15 16:55:43 - progress_bar.py[line:272] - INFO: epoch 016:    917 / 2004 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=368.8, nsentences=8, sample_size=368.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1052.1, ups=2.85, wpb=368.8, bsz=8, num_updates=30780, lr=6.99812e-05, gnorm=2.883, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=10560
2023-03-15 16:55:46 - progress_bar.py[line:272] - INFO: epoch 016:    927 / 2004 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=332.1, nsentences=8, sample_size=332.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=968.1, ups=2.92, wpb=332.1, bsz=8, num_updates=30790, lr=6.99712e-05, gnorm=2.803, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=10564
2023-03-15 16:55:49 - progress_bar.py[line:272] - INFO: epoch 016:    937 / 2004 loss=0.257, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=362.7, nsentences=8, sample_size=362.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1049.3, ups=2.89, wpb=362.7, bsz=8, num_updates=30800, lr=6.99611e-05, gnorm=2.809, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=10567
2023-03-15 16:55:53 - progress_bar.py[line:272] - INFO: epoch 016:    947 / 2004 loss=0.278, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=345.2, nsentences=7.8, sample_size=345.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=982.7, ups=2.85, wpb=345.2, bsz=7.8, num_updates=30810, lr=6.9951e-05, gnorm=3.236, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=10571
2023-03-15 16:55:56 - progress_bar.py[line:272] - INFO: epoch 016:    957 / 2004 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=336.7, nsentences=8, sample_size=336.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=982.9, ups=2.92, wpb=336.7, bsz=8, num_updates=30820, lr=6.99409e-05, gnorm=2.775, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=10574
2023-03-15 16:56:00 - progress_bar.py[line:272] - INFO: epoch 016:    967 / 2004 loss=0.28, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=370.4, nsentences=8, sample_size=370.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1066.7, ups=2.88, wpb=370.4, bsz=8, num_updates=30830, lr=6.99308e-05, gnorm=2.792, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=10577
2023-03-15 16:56:03 - progress_bar.py[line:272] - INFO: epoch 016:    977 / 2004 loss=0.274, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=334.8, nsentences=8, sample_size=334.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=974.7, ups=2.91, wpb=334.8, bsz=8, num_updates=30840, lr=6.99208e-05, gnorm=3.052, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=10581
2023-03-15 16:56:07 - progress_bar.py[line:272] - INFO: epoch 016:    987 / 2004 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=341.2, nsentences=8, sample_size=341.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=997.2, ups=2.92, wpb=341.2, bsz=8, num_updates=30850, lr=6.99107e-05, gnorm=2.774, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=10584
2023-03-15 16:56:12 - progress_bar.py[line:272] - INFO: epoch 016:    997 / 2004 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=373, nsentences=8, sample_size=373, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=737.1, ups=1.98, wpb=373, bsz=8, num_updates=30860, lr=6.99006e-05, gnorm=2.607, clip=0, loss_scale=2048, train_wall=5, gb_free=13.4, wall=10589
2023-03-15 16:56:15 - progress_bar.py[line:272] - INFO: epoch 016:   1007 / 2004 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=300.4, nsentences=8, sample_size=300.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=850.8, ups=2.83, wpb=300.4, bsz=8, num_updates=30870, lr=6.98905e-05, gnorm=2.823, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=10593
2023-03-15 16:56:19 - progress_bar.py[line:272] - INFO: epoch 016:   1017 / 2004 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=343.5, nsentences=8, sample_size=343.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1000.9, ups=2.91, wpb=343.5, bsz=8, num_updates=30880, lr=6.98804e-05, gnorm=2.868, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=10596
2023-03-15 16:56:22 - progress_bar.py[line:272] - INFO: epoch 016:   1027 / 2004 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=326.7, nsentences=8, sample_size=326.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=938.7, ups=2.87, wpb=326.7, bsz=8, num_updates=30890, lr=6.98704e-05, gnorm=2.915, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=10600
2023-03-15 16:56:24 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 16:56:26 - progress_bar.py[line:272] - INFO: epoch 016:   1038 / 2004 loss=0.236, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=320.4, nsentences=8, sample_size=320.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=835.3, ups=2.61, wpb=320.4, bsz=8, num_updates=30900, lr=6.98603e-05, gnorm=2.809, clip=0, loss_scale=2048, train_wall=4, gb_free=14.6, wall=10604
2023-03-15 16:56:30 - progress_bar.py[line:272] - INFO: epoch 016:   1048 / 2004 loss=0.261, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=387, nsentences=8, sample_size=387, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1104.3, ups=2.85, wpb=387, bsz=8, num_updates=30910, lr=6.98502e-05, gnorm=2.867, clip=0, loss_scale=2048, train_wall=3, gb_free=13.9, wall=10607
2023-03-15 16:56:33 - progress_bar.py[line:272] - INFO: epoch 016:   1058 / 2004 loss=0.274, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=348.4, nsentences=8, sample_size=348.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=998.7, ups=2.87, wpb=348.4, bsz=8, num_updates=30920, lr=6.98401e-05, gnorm=3.1, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=10611
2023-03-15 16:56:36 - progress_bar.py[line:272] - INFO: epoch 016:   1068 / 2004 loss=0.266, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=327, nsentences=8, sample_size=327, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=946, ups=2.89, wpb=327, bsz=8, num_updates=30930, lr=6.983e-05, gnorm=2.991, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=10614
2023-03-15 16:56:40 - progress_bar.py[line:272] - INFO: epoch 016:   1078 / 2004 loss=0.264, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=356.1, nsentences=8, sample_size=356.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1019.3, ups=2.86, wpb=356.1, bsz=8, num_updates=30940, lr=6.982e-05, gnorm=2.887, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=10618
2023-03-15 16:56:43 - progress_bar.py[line:272] - INFO: epoch 016:   1088 / 2004 loss=0.262, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=378.7, nsentences=8, sample_size=378.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1076.4, ups=2.84, wpb=378.7, bsz=8, num_updates=30950, lr=6.98099e-05, gnorm=2.84, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=10621
2023-03-15 16:56:47 - progress_bar.py[line:272] - INFO: epoch 016:   1098 / 2004 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=329.7, nsentences=8, sample_size=329.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=957, ups=2.9, wpb=329.7, bsz=8, num_updates=30960, lr=6.97998e-05, gnorm=2.839, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=10625
2023-03-15 16:56:50 - progress_bar.py[line:272] - INFO: epoch 016:   1108 / 2004 loss=0.274, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=366.4, nsentences=8, sample_size=366.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1055.3, ups=2.88, wpb=366.4, bsz=8, num_updates=30970, lr=6.97897e-05, gnorm=2.9, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=10628
2023-03-15 16:56:54 - progress_bar.py[line:272] - INFO: epoch 016:   1118 / 2004 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=333.8, nsentences=8, sample_size=333.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=950.9, ups=2.85, wpb=333.8, bsz=8, num_updates=30980, lr=6.97796e-05, gnorm=2.625, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=10632
2023-03-15 16:56:57 - progress_bar.py[line:272] - INFO: epoch 016:   1128 / 2004 loss=0.27, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=342.8, nsentences=8, sample_size=342.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=956.8, ups=2.79, wpb=342.8, bsz=8, num_updates=30990, lr=6.97696e-05, gnorm=2.81, clip=0, loss_scale=2048, train_wall=4, gb_free=14.6, wall=10635
2023-03-15 16:57:01 - progress_bar.py[line:272] - INFO: epoch 016:   1138 / 2004 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=388.8, nsentences=8, sample_size=388.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1097, ups=2.82, wpb=388.8, bsz=8, num_updates=31000, lr=6.97595e-05, gnorm=2.664, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=10639
2023-03-15 16:57:04 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 16:57:05 - progress_bar.py[line:272] - INFO: epoch 016:   1149 / 2004 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=338.9, nsentences=8, sample_size=338.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=878.1, ups=2.59, wpb=338.9, bsz=8, num_updates=31010, lr=6.97494e-05, gnorm=2.809, clip=0, loss_scale=1024, train_wall=4, gb_free=14.6, wall=10643
2023-03-15 16:57:08 - progress_bar.py[line:272] - INFO: epoch 016:   1159 / 2004 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=407.1, nsentences=8, sample_size=407.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1150.9, ups=2.83, wpb=407.1, bsz=8, num_updates=31020, lr=6.97393e-05, gnorm=2.589, clip=0, loss_scale=1024, train_wall=3, gb_free=14.2, wall=10646
2023-03-15 16:57:12 - progress_bar.py[line:272] - INFO: epoch 016:   1169 / 2004 loss=0.228, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=320.5, nsentences=8, sample_size=320.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=926.8, ups=2.89, wpb=320.5, bsz=8, num_updates=31030, lr=6.97292e-05, gnorm=2.368, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=10650
2023-03-15 16:57:15 - progress_bar.py[line:272] - INFO: epoch 016:   1179 / 2004 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=355.8, nsentences=8, sample_size=355.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1005.2, ups=2.83, wpb=355.8, bsz=8, num_updates=31040, lr=6.97191e-05, gnorm=2.781, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=10653
2023-03-15 16:57:19 - progress_bar.py[line:272] - INFO: epoch 016:   1189 / 2004 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=339.9, nsentences=8, sample_size=339.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=942.2, ups=2.77, wpb=339.9, bsz=8, num_updates=31050, lr=6.97091e-05, gnorm=2.867, clip=0, loss_scale=1024, train_wall=4, gb_free=14.6, wall=10657
2023-03-15 16:57:23 - progress_bar.py[line:272] - INFO: epoch 016:   1199 / 2004 loss=0.259, loss_v1=0, loss_v2=0, nll_loss=0.259, ntokens=354.4, nsentences=8, sample_size=354.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=993.4, ups=2.8, wpb=354.4, bsz=8, num_updates=31060, lr=6.9699e-05, gnorm=2.74, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=10660
2023-03-15 16:57:26 - progress_bar.py[line:272] - INFO: epoch 016:   1209 / 2004 loss=0.228, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=286.6, nsentences=8, sample_size=286.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=834.4, ups=2.91, wpb=286.6, bsz=8, num_updates=31070, lr=6.96889e-05, gnorm=2.584, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=10664
2023-03-15 16:57:29 - progress_bar.py[line:272] - INFO: epoch 016:   1219 / 2004 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=333.3, nsentences=8, sample_size=333.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=973.6, ups=2.92, wpb=333.3, bsz=8, num_updates=31080, lr=6.96788e-05, gnorm=2.775, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=10667
2023-03-15 16:57:33 - progress_bar.py[line:272] - INFO: epoch 016:   1229 / 2004 loss=0.233, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=307, nsentences=8, sample_size=307, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=886.8, ups=2.89, wpb=307, bsz=8, num_updates=31090, lr=6.96687e-05, gnorm=2.684, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=10671
2023-03-15 16:57:36 - progress_bar.py[line:272] - INFO: epoch 016:   1239 / 2004 loss=0.265, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=382.6, nsentences=8, sample_size=382.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1089.5, ups=2.85, wpb=382.6, bsz=8, num_updates=31100, lr=6.96587e-05, gnorm=3.013, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=10674
2023-03-15 16:57:40 - progress_bar.py[line:272] - INFO: epoch 016:   1249 / 2004 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=338.6, nsentences=8, sample_size=338.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=964.3, ups=2.85, wpb=338.6, bsz=8, num_updates=31110, lr=6.96486e-05, gnorm=2.726, clip=0, loss_scale=1024, train_wall=3, gb_free=14.2, wall=10678
2023-03-15 16:57:43 - progress_bar.py[line:272] - INFO: epoch 016:   1259 / 2004 loss=0.225, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=348.2, nsentences=8, sample_size=348.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=989.4, ups=2.84, wpb=348.2, bsz=8, num_updates=31120, lr=6.96385e-05, gnorm=2.7, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=10681
2023-03-15 16:57:47 - progress_bar.py[line:272] - INFO: epoch 016:   1269 / 2004 loss=0.228, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=346.7, nsentences=8, sample_size=346.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1010.2, ups=2.91, wpb=346.7, bsz=8, num_updates=31130, lr=6.96284e-05, gnorm=2.67, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=10685
2023-03-15 16:57:50 - progress_bar.py[line:272] - INFO: epoch 016:   1279 / 2004 loss=0.23, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=343.5, nsentences=8, sample_size=343.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=989.9, ups=2.88, wpb=343.5, bsz=8, num_updates=31140, lr=6.96183e-05, gnorm=2.678, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=10688
2023-03-15 16:57:54 - progress_bar.py[line:272] - INFO: epoch 016:   1289 / 2004 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=310.5, nsentences=8, sample_size=310.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=909.4, ups=2.93, wpb=310.5, bsz=8, num_updates=31150, lr=6.96083e-05, gnorm=2.745, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=10691
2023-03-15 16:57:57 - progress_bar.py[line:272] - INFO: epoch 016:   1299 / 2004 loss=0.228, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=309.4, nsentences=8, sample_size=309.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=916.1, ups=2.96, wpb=309.4, bsz=8, num_updates=31160, lr=6.95982e-05, gnorm=2.701, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=10695
2023-03-15 16:58:01 - progress_bar.py[line:272] - INFO: epoch 016:   1309 / 2004 loss=0.267, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=332.4, nsentences=8, sample_size=332.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=975.1, ups=2.93, wpb=332.4, bsz=8, num_updates=31170, lr=6.95881e-05, gnorm=3.016, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=10698
2023-03-15 16:58:04 - progress_bar.py[line:272] - INFO: epoch 016:   1319 / 2004 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=338.5, nsentences=8, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=994.1, ups=2.94, wpb=338.5, bsz=8, num_updates=31180, lr=6.9578e-05, gnorm=2.942, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=10702
2023-03-15 16:58:07 - progress_bar.py[line:272] - INFO: epoch 016:   1329 / 2004 loss=0.265, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=294.3, nsentences=8, sample_size=294.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=879.7, ups=2.99, wpb=294.3, bsz=8, num_updates=31190, lr=6.95679e-05, gnorm=3.04, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=10705
2023-03-15 16:58:11 - progress_bar.py[line:272] - INFO: epoch 016:   1339 / 2004 loss=0.261, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=360.4, nsentences=8, sample_size=360.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1092.2, ups=3.03, wpb=360.4, bsz=8, num_updates=31200, lr=6.95579e-05, gnorm=3.001, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=10708
2023-03-15 16:58:14 - progress_bar.py[line:272] - INFO: epoch 016:   1349 / 2004 loss=0.22, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=300.2, nsentences=8, sample_size=300.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=894.6, ups=2.98, wpb=300.2, bsz=8, num_updates=31210, lr=6.95478e-05, gnorm=2.622, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=10712
2023-03-15 16:58:17 - progress_bar.py[line:272] - INFO: epoch 016:   1359 / 2004 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=325.9, nsentences=8, sample_size=325.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1064.7, ups=3.27, wpb=325.9, bsz=8, num_updates=31220, lr=6.95377e-05, gnorm=2.89, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=10715
2023-03-15 16:58:18 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 16:58:21 - progress_bar.py[line:272] - INFO: epoch 016:   1370 / 2004 loss=0.236, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=290.7, nsentences=8, sample_size=290.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=833.6, ups=2.87, wpb=290.7, bsz=8, num_updates=31230, lr=6.95276e-05, gnorm=2.867, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=10718
2023-03-15 16:58:24 - progress_bar.py[line:272] - INFO: epoch 016:   1380 / 2004 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=352.8, nsentences=8, sample_size=352.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1058.5, ups=3, wpb=352.8, bsz=8, num_updates=31240, lr=6.95175e-05, gnorm=2.817, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=10721
2023-03-15 16:58:27 - progress_bar.py[line:272] - INFO: epoch 016:   1390 / 2004 loss=0.263, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=375.5, nsentences=8, sample_size=375.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1180.1, ups=3.14, wpb=375.5, bsz=8, num_updates=31250, lr=6.95074e-05, gnorm=2.896, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=10725
2023-03-15 16:58:30 - progress_bar.py[line:272] - INFO: epoch 016:   1400 / 2004 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=339.1, nsentences=8, sample_size=339.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=991.8, ups=2.92, wpb=339.1, bsz=8, num_updates=31260, lr=6.94974e-05, gnorm=2.85, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=10728
2023-03-15 16:58:34 - progress_bar.py[line:272] - INFO: epoch 016:   1410 / 2004 loss=0.26, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=366.7, nsentences=8, sample_size=366.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1083.5, ups=2.95, wpb=366.7, bsz=8, num_updates=31270, lr=6.94873e-05, gnorm=3.113, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=10731
2023-03-15 16:58:37 - progress_bar.py[line:272] - INFO: epoch 016:   1420 / 2004 loss=0.231, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=361.8, nsentences=8, sample_size=361.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1156.3, ups=3.2, wpb=361.8, bsz=8, num_updates=31280, lr=6.94772e-05, gnorm=2.769, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=10735
2023-03-15 16:58:40 - progress_bar.py[line:272] - INFO: epoch 016:   1430 / 2004 loss=0.233, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=304.9, nsentences=8, sample_size=304.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=978, ups=3.21, wpb=304.9, bsz=8, num_updates=31290, lr=6.94671e-05, gnorm=2.705, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=10738
2023-03-15 16:58:43 - progress_bar.py[line:272] - INFO: epoch 016:   1440 / 2004 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.25, ntokens=366.1, nsentences=8, sample_size=366.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1164.3, ups=3.18, wpb=366.1, bsz=8, num_updates=31300, lr=6.9457e-05, gnorm=2.89, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=10741
2023-03-15 16:58:47 - progress_bar.py[line:272] - INFO: epoch 016:   1450 / 2004 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=324.1, nsentences=8, sample_size=324.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=941.1, ups=2.9, wpb=324.1, bsz=8, num_updates=31310, lr=6.9447e-05, gnorm=2.745, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=10744
2023-03-15 16:58:50 - progress_bar.py[line:272] - INFO: epoch 016:   1460 / 2004 loss=0.287, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=383.2, nsentences=8, sample_size=383.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=1175.9, ups=3.07, wpb=383.2, bsz=8, num_updates=31320, lr=6.94369e-05, gnorm=3.196, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=10748
2023-03-15 16:58:53 - progress_bar.py[line:272] - INFO: epoch 016:   1470 / 2004 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.256, ntokens=389.4, nsentences=8, sample_size=389.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1117.6, ups=2.87, wpb=389.4, bsz=8, num_updates=31330, lr=6.94268e-05, gnorm=2.796, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=10751
2023-03-15 16:58:57 - progress_bar.py[line:272] - INFO: epoch 016:   1480 / 2004 loss=0.277, loss_v1=0, loss_v2=0, nll_loss=0.277, ntokens=401, nsentences=8, sample_size=401, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1143.6, ups=2.85, wpb=401, bsz=8, num_updates=31340, lr=6.94167e-05, gnorm=2.993, clip=0, loss_scale=1024, train_wall=3, gb_free=15.8, wall=10755
2023-03-15 16:59:00 - progress_bar.py[line:272] - INFO: epoch 016:   1490 / 2004 loss=0.267, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=311.5, nsentences=8, sample_size=311.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=892.9, ups=2.87, wpb=311.5, bsz=8, num_updates=31350, lr=6.94066e-05, gnorm=3.159, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=10758
2023-03-15 16:59:04 - progress_bar.py[line:272] - INFO: epoch 016:   1500 / 2004 loss=0.267, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=352.4, nsentences=8, sample_size=352.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1019.1, ups=2.89, wpb=352.4, bsz=8, num_updates=31360, lr=6.93966e-05, gnorm=2.891, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=10762
2023-03-15 16:59:06 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 16:59:08 - progress_bar.py[line:272] - INFO: epoch 016:   1511 / 2004 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=319.6, nsentences=8, sample_size=319.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=842.7, ups=2.64, wpb=319.6, bsz=8, num_updates=31370, lr=6.93865e-05, gnorm=2.641, clip=0, loss_scale=1024, train_wall=4, gb_free=15, wall=10765
2023-03-15 16:59:11 - progress_bar.py[line:272] - INFO: epoch 016:   1521 / 2004 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=332.1, nsentences=8, sample_size=332.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=958, ups=2.88, wpb=332.1, bsz=8, num_updates=31380, lr=6.93764e-05, gnorm=2.996, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=10769
2023-03-15 16:59:15 - progress_bar.py[line:272] - INFO: epoch 016:   1531 / 2004 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.254, ntokens=343.2, nsentences=8, sample_size=343.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=997.3, ups=2.91, wpb=343.2, bsz=8, num_updates=31390, lr=6.93663e-05, gnorm=2.904, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=10772
2023-03-15 16:59:18 - progress_bar.py[line:272] - INFO: epoch 016:   1541 / 2004 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=316.3, nsentences=8, sample_size=316.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=911.3, ups=2.88, wpb=316.3, bsz=8, num_updates=31400, lr=6.93562e-05, gnorm=2.73, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=10776
2023-03-15 16:59:22 - progress_bar.py[line:272] - INFO: epoch 016:   1551 / 2004 loss=0.284, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=338.2, nsentences=8, sample_size=338.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=976.5, ups=2.89, wpb=338.2, bsz=8, num_updates=31410, lr=6.93462e-05, gnorm=3.12, clip=0, loss_scale=1024, train_wall=3, gb_free=13.9, wall=10779
2023-03-15 16:59:25 - progress_bar.py[line:272] - INFO: epoch 016:   1561 / 2004 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=350.8, nsentences=8, sample_size=350.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1009.5, ups=2.88, wpb=350.8, bsz=8, num_updates=31420, lr=6.93361e-05, gnorm=2.68, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=10783
2023-03-15 16:59:26 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-03-15 16:59:29 - progress_bar.py[line:272] - INFO: epoch 016:   1572 / 2004 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=318.6, nsentences=8, sample_size=318.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=843.3, ups=2.65, wpb=318.6, bsz=8, num_updates=31430, lr=6.9326e-05, gnorm=2.792, clip=0, loss_scale=512, train_wall=4, gb_free=14.7, wall=10786
2023-03-15 16:59:32 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-03-15 16:59:33 - progress_bar.py[line:272] - INFO: epoch 016:   1583 / 2004 loss=0.263, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=349.2, nsentences=8, sample_size=349.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=923.3, ups=2.64, wpb=349.2, bsz=8, num_updates=31440, lr=6.93159e-05, gnorm=3.055, clip=0, loss_scale=256, train_wall=4, gb_free=14.2, wall=10790
2023-03-15 16:59:36 - progress_bar.py[line:272] - INFO: epoch 016:   1593 / 2004 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.241, ntokens=353.8, nsentences=8, sample_size=353.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1019.7, ups=2.88, wpb=353.8, bsz=8, num_updates=31450, lr=6.93058e-05, gnorm=2.739, clip=0, loss_scale=256, train_wall=3, gb_free=14.7, wall=10794
2023-03-15 16:59:39 - progress_bar.py[line:272] - INFO: epoch 016:   1603 / 2004 loss=0.262, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=330.8, nsentences=8, sample_size=330.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=991.9, ups=3, wpb=330.8, bsz=8, num_updates=31460, lr=6.92958e-05, gnorm=3.031, clip=0, loss_scale=256, train_wall=3, gb_free=14.9, wall=10797
2023-03-15 16:59:43 - progress_bar.py[line:272] - INFO: epoch 016:   1613 / 2004 loss=0.261, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=360.7, nsentences=8, sample_size=360.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1150.8, ups=3.19, wpb=360.7, bsz=8, num_updates=31470, lr=6.92857e-05, gnorm=2.781, clip=0, loss_scale=256, train_wall=3, gb_free=14.8, wall=10800
2023-03-15 16:59:46 - progress_bar.py[line:272] - INFO: epoch 016:   1623 / 2004 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=346.4, nsentences=8, sample_size=346.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=1099.8, ups=3.18, wpb=346.4, bsz=8, num_updates=31480, lr=6.92756e-05, gnorm=2.934, clip=0, loss_scale=256, train_wall=3, gb_free=14.2, wall=10803
2023-03-15 16:59:49 - progress_bar.py[line:272] - INFO: epoch 016:   1633 / 2004 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=334.5, nsentences=8, sample_size=334.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1087.1, ups=3.25, wpb=334.5, bsz=8, num_updates=31490, lr=6.92655e-05, gnorm=2.756, clip=0, loss_scale=256, train_wall=3, gb_free=15.2, wall=10806
2023-03-15 16:59:52 - progress_bar.py[line:272] - INFO: epoch 016:   1643 / 2004 loss=0.22, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=313.7, nsentences=8, sample_size=313.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1015.3, ups=3.24, wpb=313.7, bsz=8, num_updates=31500, lr=6.92554e-05, gnorm=2.401, clip=0, loss_scale=256, train_wall=3, gb_free=15.1, wall=10809
2023-03-15 16:59:55 - progress_bar.py[line:272] - INFO: epoch 016:   1653 / 2004 loss=0.259, loss_v1=0, loss_v2=0, nll_loss=0.259, ntokens=333.5, nsentences=8, sample_size=333.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1061.5, ups=3.18, wpb=333.5, bsz=8, num_updates=31510, lr=6.92453e-05, gnorm=2.968, clip=0, loss_scale=256, train_wall=3, gb_free=14.6, wall=10813
2023-03-15 16:59:58 - progress_bar.py[line:272] - INFO: epoch 016:   1663 / 2004 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.24, ntokens=349.5, nsentences=8, sample_size=349.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1011.7, ups=2.89, wpb=349.5, bsz=8, num_updates=31520, lr=6.92353e-05, gnorm=2.732, clip=0, loss_scale=256, train_wall=3, gb_free=15.5, wall=10816
2023-03-15 17:00:02 - progress_bar.py[line:272] - INFO: epoch 016:   1673 / 2004 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.238, ntokens=340.4, nsentences=8, sample_size=340.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=989.7, ups=2.91, wpb=340.4, bsz=8, num_updates=31530, lr=6.92252e-05, gnorm=2.956, clip=0, loss_scale=256, train_wall=3, gb_free=14.8, wall=10819
2023-03-15 17:00:05 - progress_bar.py[line:272] - INFO: epoch 016:   1683 / 2004 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=332, nsentences=8, sample_size=332, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=985.8, ups=2.97, wpb=332, bsz=8, num_updates=31540, lr=6.92151e-05, gnorm=2.53, clip=0, loss_scale=256, train_wall=3, gb_free=15.3, wall=10823
2023-03-15 17:00:09 - progress_bar.py[line:272] - INFO: epoch 016:   1693 / 2004 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=335.9, nsentences=8, sample_size=335.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=965.5, ups=2.87, wpb=335.9, bsz=8, num_updates=31550, lr=6.9205e-05, gnorm=2.891, clip=0, loss_scale=256, train_wall=3, gb_free=15.2, wall=10826
2023-03-15 17:00:12 - progress_bar.py[line:272] - INFO: epoch 016:   1703 / 2004 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=332.6, nsentences=8, sample_size=332.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=963.5, ups=2.9, wpb=332.6, bsz=8, num_updates=31560, lr=6.91949e-05, gnorm=2.786, clip=0, loss_scale=256, train_wall=3, gb_free=14.9, wall=10830
2023-03-15 17:00:16 - progress_bar.py[line:272] - INFO: epoch 016:   1713 / 2004 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=361.7, nsentences=8, sample_size=361.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1040, ups=2.88, wpb=361.7, bsz=8, num_updates=31570, lr=6.91849e-05, gnorm=2.804, clip=0, loss_scale=512, train_wall=3, gb_free=14.9, wall=10833
2023-03-15 17:00:19 - progress_bar.py[line:272] - INFO: epoch 016:   1723 / 2004 loss=0.227, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=380.9, nsentences=8, sample_size=380.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1113.7, ups=2.92, wpb=380.9, bsz=8, num_updates=31580, lr=6.91748e-05, gnorm=2.63, clip=0, loss_scale=512, train_wall=3, gb_free=15.4, wall=10837
2023-03-15 17:00:23 - progress_bar.py[line:272] - INFO: epoch 016:   1733 / 2004 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.238, ntokens=361.7, nsentences=8, sample_size=361.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1014.4, ups=2.8, wpb=361.7, bsz=8, num_updates=31590, lr=6.91647e-05, gnorm=2.704, clip=0, loss_scale=512, train_wall=4, gb_free=15, wall=10840
2023-03-15 17:00:26 - progress_bar.py[line:272] - INFO: epoch 016:   1743 / 2004 loss=0.229, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=330.8, nsentences=8, sample_size=330.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=945.2, ups=2.86, wpb=330.8, bsz=8, num_updates=31600, lr=6.91546e-05, gnorm=2.964, clip=0, loss_scale=512, train_wall=3, gb_free=14.9, wall=10844
2023-03-15 17:00:30 - progress_bar.py[line:272] - INFO: epoch 016:   1753 / 2004 loss=0.264, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=362.9, nsentences=8, sample_size=362.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1001.6, ups=2.76, wpb=362.9, bsz=8, num_updates=31610, lr=6.91445e-05, gnorm=2.862, clip=0, loss_scale=512, train_wall=4, gb_free=14.6, wall=10847
2023-03-15 17:00:33 - progress_bar.py[line:272] - INFO: epoch 016:   1763 / 2004 loss=0.235, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=307.5, nsentences=8, sample_size=307.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=870, ups=2.83, wpb=307.5, bsz=8, num_updates=31620, lr=6.91345e-05, gnorm=2.733, clip=0, loss_scale=512, train_wall=3, gb_free=15, wall=10851
2023-03-15 17:00:37 - progress_bar.py[line:272] - INFO: epoch 016:   1773 / 2004 loss=0.23, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=333, nsentences=8, sample_size=333, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=968.6, ups=2.91, wpb=333, bsz=8, num_updates=31630, lr=6.91244e-05, gnorm=2.654, clip=0, loss_scale=512, train_wall=3, gb_free=15.1, wall=10854
2023-03-15 17:00:40 - progress_bar.py[line:272] - INFO: epoch 016:   1783 / 2004 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=335.1, nsentences=8, sample_size=335.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=969.7, ups=2.89, wpb=335.1, bsz=8, num_updates=31640, lr=6.91143e-05, gnorm=2.788, clip=0, loss_scale=512, train_wall=3, gb_free=15.6, wall=10858
2023-03-15 17:00:44 - progress_bar.py[line:272] - INFO: epoch 016:   1793 / 2004 loss=0.263, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=318.8, nsentences=8, sample_size=318.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=928.6, ups=2.91, wpb=318.8, bsz=8, num_updates=31650, lr=6.91042e-05, gnorm=2.923, clip=0, loss_scale=512, train_wall=3, gb_free=14.5, wall=10861
2023-03-15 17:00:47 - progress_bar.py[line:272] - INFO: epoch 016:   1803 / 2004 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=349.1, nsentences=8, sample_size=349.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1025.9, ups=2.94, wpb=349.1, bsz=8, num_updates=31660, lr=6.90941e-05, gnorm=2.845, clip=0, loss_scale=512, train_wall=3, gb_free=14.8, wall=10865
2023-03-15 17:00:50 - progress_bar.py[line:272] - INFO: epoch 016:   1813 / 2004 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=349.5, nsentences=8, sample_size=349.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1020.6, ups=2.92, wpb=349.5, bsz=8, num_updates=31670, lr=6.90841e-05, gnorm=2.924, clip=0, loss_scale=512, train_wall=3, gb_free=15.3, wall=10868
2023-03-15 17:00:54 - progress_bar.py[line:272] - INFO: epoch 016:   1823 / 2004 loss=0.263, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=344.8, nsentences=8, sample_size=344.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1043.8, ups=3.03, wpb=344.8, bsz=8, num_updates=31680, lr=6.9074e-05, gnorm=2.952, clip=0, loss_scale=512, train_wall=3, gb_free=15.4, wall=10871
2023-03-15 17:00:57 - progress_bar.py[line:272] - INFO: epoch 016:   1833 / 2004 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.254, ntokens=366.1, nsentences=8, sample_size=366.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1144.9, ups=3.13, wpb=366.1, bsz=8, num_updates=31690, lr=6.90639e-05, gnorm=2.913, clip=0, loss_scale=512, train_wall=3, gb_free=15.1, wall=10875
2023-03-15 17:01:00 - progress_bar.py[line:272] - INFO: epoch 016:   1843 / 2004 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.247, ntokens=318.6, nsentences=8, sample_size=318.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=985.5, ups=3.09, wpb=318.6, bsz=8, num_updates=31700, lr=6.90538e-05, gnorm=2.852, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=10878
2023-03-15 17:01:03 - progress_bar.py[line:272] - INFO: epoch 016:   1853 / 2004 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.25, ntokens=357.1, nsentences=8, sample_size=357.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1104, ups=3.09, wpb=357.1, bsz=8, num_updates=31710, lr=6.90437e-05, gnorm=2.664, clip=0, loss_scale=1024, train_wall=3, gb_free=14.2, wall=10881
2023-03-15 17:01:07 - progress_bar.py[line:272] - INFO: epoch 016:   1863 / 2004 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.254, ntokens=336.6, nsentences=8, sample_size=336.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1045.4, ups=3.11, wpb=336.6, bsz=8, num_updates=31720, lr=6.90336e-05, gnorm=2.696, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=10884
2023-03-15 17:01:10 - progress_bar.py[line:272] - INFO: epoch 016:   1873 / 2004 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=323, nsentences=8, sample_size=323, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1001.1, ups=3.1, wpb=323, bsz=8, num_updates=31730, lr=6.90236e-05, gnorm=2.863, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=10887
2023-03-15 17:01:13 - progress_bar.py[line:272] - INFO: epoch 016:   1883 / 2004 loss=0.262, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=346.8, nsentences=8, sample_size=346.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1077, ups=3.11, wpb=346.8, bsz=8, num_updates=31740, lr=6.90135e-05, gnorm=2.772, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=10891
2023-03-15 17:01:16 - progress_bar.py[line:272] - INFO: epoch 016:   1893 / 2004 loss=0.233, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=324.1, nsentences=8, sample_size=324.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1032.7, ups=3.19, wpb=324.1, bsz=8, num_updates=31750, lr=6.90034e-05, gnorm=2.705, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=10894
2023-03-15 17:01:19 - progress_bar.py[line:272] - INFO: epoch 016:   1903 / 2004 loss=0.23, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=356.7, nsentences=8, sample_size=356.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1098.9, ups=3.08, wpb=356.7, bsz=8, num_updates=31760, lr=6.89933e-05, gnorm=2.733, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=10897
2023-03-15 17:01:23 - progress_bar.py[line:272] - INFO: epoch 016:   1913 / 2004 loss=0.219, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=303, nsentences=8, sample_size=303, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=959.2, ups=3.17, wpb=303, bsz=8, num_updates=31770, lr=6.89832e-05, gnorm=2.581, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=10900
2023-03-15 17:01:26 - progress_bar.py[line:272] - INFO: epoch 016:   1923 / 2004 loss=0.229, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=335.9, nsentences=8, sample_size=335.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1045.8, ups=3.11, wpb=335.9, bsz=8, num_updates=31780, lr=6.89732e-05, gnorm=2.686, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=10903
2023-03-15 17:01:29 - progress_bar.py[line:272] - INFO: epoch 016:   1933 / 2004 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.256, ntokens=327.4, nsentences=8, sample_size=327.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=999.3, ups=3.05, wpb=327.4, bsz=8, num_updates=31790, lr=6.89631e-05, gnorm=2.91, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=10907
2023-03-15 17:01:32 - progress_bar.py[line:272] - INFO: epoch 016:   1943 / 2004 loss=0.218, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=352.8, nsentences=8, sample_size=352.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1081.6, ups=3.07, wpb=352.8, bsz=8, num_updates=31800, lr=6.8953e-05, gnorm=2.574, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=10910
2023-03-15 17:01:36 - progress_bar.py[line:272] - INFO: epoch 016:   1953 / 2004 loss=0.234, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=345.8, nsentences=8, sample_size=345.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1094.8, ups=3.17, wpb=345.8, bsz=8, num_updates=31810, lr=6.89429e-05, gnorm=2.678, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=10913
2023-03-15 17:01:39 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-03-15 17:01:39 - progress_bar.py[line:272] - INFO: epoch 016:   1964 / 2004 loss=0.225, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=353.8, nsentences=8, sample_size=353.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1003.1, ups=2.84, wpb=353.8, bsz=8, num_updates=31820, lr=6.89328e-05, gnorm=2.713, clip=0, loss_scale=512, train_wall=3, gb_free=14.5, wall=10917
2023-03-15 17:01:42 - progress_bar.py[line:272] - INFO: epoch 016:   1974 / 2004 loss=0.262, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=346.8, nsentences=8, sample_size=346.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1099.3, ups=3.17, wpb=346.8, bsz=8, num_updates=31830, lr=6.89228e-05, gnorm=3.062, clip=0, loss_scale=512, train_wall=3, gb_free=15.3, wall=10920
2023-03-15 17:01:45 - progress_bar.py[line:272] - INFO: epoch 016:   1984 / 2004 loss=0.222, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=317.9, nsentences=8, sample_size=317.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=997.5, ups=3.14, wpb=317.9, bsz=8, num_updates=31840, lr=6.89127e-05, gnorm=2.764, clip=0, loss_scale=512, train_wall=3, gb_free=15.1, wall=10923
2023-03-15 17:01:49 - progress_bar.py[line:272] - INFO: epoch 016:   1994 / 2004 loss=0.267, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=375.8, nsentences=8, sample_size=375.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1166.5, ups=3.1, wpb=375.8, bsz=8, num_updates=31850, lr=6.89026e-05, gnorm=3.122, clip=0, loss_scale=512, train_wall=3, gb_free=14.8, wall=10926
2023-03-15 17:01:52 - progress_bar.py[line:272] - INFO: epoch 016:   2004 / 2004 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.25, ntokens=389.4, nsentences=8, sample_size=389.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1251.7, ups=3.21, wpb=389.4, bsz=8, num_updates=31860, lr=6.88925e-05, gnorm=2.968, clip=0, loss_scale=512, train_wall=3, gb_free=13.9, wall=10929
2023-03-15 17:01:52 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 16 @ 31860 updates
2023-03-15 17:01:52 - trainer.py[line:431] - INFO: Saving checkpoint to ./checkpoints/checkpoint16.pt
2023-03-15 17:01:57 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./checkpoints/checkpoint16.pt
2023-03-15 17:02:00 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./checkpoints/checkpoint16.pt (epoch 16 @ 31860 updates, score None) (writing took 8.172823479399085 seconds)
2023-03-15 17:02:00 - train.py[line:332] - INFO: end of epoch 16 (average epoch stats below)
2023-03-15 17:02:00 - progress_bar.py[line:282] - INFO: epoch 016 | loss 0.254 | loss_v1 0 | loss_v2 0 | nll_loss 0.254 | ntokens 345.277 | nsentences 7.999 | sample_size 345.277 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.19 | wps 975.5 | ups 2.83 | wpb 345.3 | bsz 8 | num_updates 31860 | lr 6.88925e-05 | gnorm 2.844 | clip 0 | loss_scale 512 | train_wall 674 | gb_free 13.9 | wall 10938
2023-03-15 17:02:00 - trainer.py[line:639] - INFO: loading train data for epoch 17
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 row count 8015 total row count 8015
slice_id 0 seek offset 0
2023-03-15 17:02:01 - trainer.py[line:703] - INFO: begin training epoch 17
2023-03-15 17:02:01 - train.py[line:305] - INFO: Start iterating over samples
2023-03-15 17:02:04 - progress_bar.py[line:272] - INFO: epoch 017:     10 / 2004 loss=0.268, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=359.7, nsentences=8, sample_size=359.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=287, ups=0.8, wpb=359.7, bsz=8, num_updates=31870, lr=6.88824e-05, gnorm=3.032, clip=0, loss_scale=512, train_wall=3, gb_free=14.8, wall=10942
2023-03-15 17:02:08 - progress_bar.py[line:272] - INFO: epoch 017:     20 / 2004 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=333, nsentences=8, sample_size=333, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=948.3, ups=2.85, wpb=333, bsz=8, num_updates=31880, lr=6.88724e-05, gnorm=2.757, clip=0, loss_scale=512, train_wall=3, gb_free=15.1, wall=10945
2023-03-15 17:02:11 - progress_bar.py[line:272] - INFO: epoch 017:     30 / 2004 loss=0.259, loss_v1=0, loss_v2=0, nll_loss=0.259, ntokens=350.1, nsentences=8, sample_size=350.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1064.7, ups=3.04, wpb=350.1, bsz=8, num_updates=31890, lr=6.88623e-05, gnorm=2.921, clip=0, loss_scale=512, train_wall=3, gb_free=14.8, wall=10949
2023-03-15 17:02:15 - progress_bar.py[line:272] - INFO: epoch 017:     40 / 2004 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=353.8, nsentences=8, sample_size=353.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=989.2, ups=2.8, wpb=353.8, bsz=8, num_updates=31900, lr=6.88522e-05, gnorm=2.849, clip=0, loss_scale=512, train_wall=4, gb_free=14, wall=10952
2023-03-15 17:02:18 - progress_bar.py[line:272] - INFO: epoch 017:     50 / 2004 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=337.3, nsentences=8, sample_size=337.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1009.5, ups=2.99, wpb=337.3, bsz=8, num_updates=31910, lr=6.88421e-05, gnorm=3.055, clip=0, loss_scale=512, train_wall=3, gb_free=14.3, wall=10956
2023-03-15 17:02:21 - progress_bar.py[line:272] - INFO: epoch 017:     60 / 2004 loss=0.27, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=351, nsentences=8, sample_size=351, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1085.7, ups=3.09, wpb=351, bsz=8, num_updates=31920, lr=6.8832e-05, gnorm=2.923, clip=0, loss_scale=512, train_wall=3, gb_free=15.3, wall=10959
2023-03-15 17:02:24 - progress_bar.py[line:272] - INFO: epoch 017:     70 / 2004 loss=0.263, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=346.9, nsentences=8, sample_size=346.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1109.9, ups=3.2, wpb=346.9, bsz=8, num_updates=31930, lr=6.8822e-05, gnorm=2.894, clip=0, loss_scale=512, train_wall=3, gb_free=14.6, wall=10962
2023-03-15 17:02:27 - progress_bar.py[line:272] - INFO: epoch 017:     80 / 2004 loss=0.228, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=321.9, nsentences=8, sample_size=321.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1032.5, ups=3.21, wpb=321.9, bsz=8, num_updates=31940, lr=6.88119e-05, gnorm=2.507, clip=0, loss_scale=512, train_wall=3, gb_free=14.8, wall=10965
2023-03-15 17:02:31 - progress_bar.py[line:272] - INFO: epoch 017:     90 / 2004 loss=0.232, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=359.2, nsentences=8, sample_size=359.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1114.4, ups=3.1, wpb=359.2, bsz=8, num_updates=31950, lr=6.88018e-05, gnorm=2.786, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=10968
2023-03-15 17:02:34 - progress_bar.py[line:272] - INFO: epoch 017:    100 / 2004 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.256, ntokens=385.5, nsentences=8, sample_size=385.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1203.3, ups=3.12, wpb=385.5, bsz=8, num_updates=31960, lr=6.87917e-05, gnorm=2.724, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=10972
2023-03-15 17:02:37 - progress_bar.py[line:272] - INFO: epoch 017:    110 / 2004 loss=0.22, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=340.3, nsentences=8, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1109.7, ups=3.26, wpb=340.3, bsz=8, num_updates=31970, lr=6.87816e-05, gnorm=2.581, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=10975
2023-03-15 17:02:40 - progress_bar.py[line:272] - INFO: epoch 017:    120 / 2004 loss=0.278, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=353, nsentences=8, sample_size=353, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1088.3, ups=3.08, wpb=353, bsz=8, num_updates=31980, lr=6.87715e-05, gnorm=2.972, clip=0, loss_scale=1024, train_wall=3, gb_free=14.2, wall=10978
2023-03-15 17:02:43 - progress_bar.py[line:272] - INFO: epoch 017:    130 / 2004 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.25, ntokens=315.3, nsentences=8, sample_size=315.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=996.1, ups=3.16, wpb=315.3, bsz=8, num_updates=31990, lr=6.87615e-05, gnorm=2.92, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=10981
2023-03-15 17:02:47 - progress_bar.py[line:272] - INFO: epoch 017:    140 / 2004 loss=0.266, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=349.5, nsentences=8, sample_size=349.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1101.1, ups=3.15, wpb=349.5, bsz=8, num_updates=32000, lr=6.87514e-05, gnorm=3.048, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=10984
2023-03-15 17:02:50 - progress_bar.py[line:272] - INFO: epoch 017:    150 / 2004 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=322.7, nsentences=8, sample_size=322.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1017.4, ups=3.15, wpb=322.7, bsz=8, num_updates=32010, lr=6.87413e-05, gnorm=2.72, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=10987
2023-03-15 17:02:53 - progress_bar.py[line:272] - INFO: epoch 017:    160 / 2004 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=368.3, nsentences=8, sample_size=368.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1129.3, ups=3.07, wpb=368.3, bsz=8, num_updates=32020, lr=6.87312e-05, gnorm=2.805, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=10991
2023-03-15 17:02:56 - progress_bar.py[line:272] - INFO: epoch 017:    170 / 2004 loss=0.226, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=335.2, nsentences=8, sample_size=335.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1050.3, ups=3.13, wpb=335.2, bsz=8, num_updates=32030, lr=6.87211e-05, gnorm=2.649, clip=0, loss_scale=1024, train_wall=3, gb_free=14.2, wall=10994
2023-03-15 17:02:59 - progress_bar.py[line:272] - INFO: epoch 017:    180 / 2004 loss=0.229, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=332.1, nsentences=8, sample_size=332.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1044.9, ups=3.15, wpb=332.1, bsz=8, num_updates=32040, lr=6.87111e-05, gnorm=2.604, clip=0, loss_scale=1024, train_wall=3, gb_free=14.2, wall=10997
2023-03-15 17:03:02 - progress_bar.py[line:272] - INFO: epoch 017:    190 / 2004 loss=0.228, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=322.8, nsentences=8, sample_size=322.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1038.3, ups=3.22, wpb=322.8, bsz=8, num_updates=32050, lr=6.8701e-05, gnorm=2.661, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=11000
2023-03-15 17:03:06 - progress_bar.py[line:272] - INFO: epoch 017:    200 / 2004 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.256, ntokens=329.6, nsentences=8, sample_size=329.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1009.4, ups=3.06, wpb=329.6, bsz=8, num_updates=32060, lr=6.86909e-05, gnorm=2.83, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=11003
2023-03-15 17:03:09 - progress_bar.py[line:272] - INFO: epoch 017:    210 / 2004 loss=0.22, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=335.4, nsentences=8, sample_size=335.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=974.1, ups=2.9, wpb=335.4, bsz=8, num_updates=32070, lr=6.86808e-05, gnorm=2.626, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=11007
2023-03-15 17:03:13 - progress_bar.py[line:272] - INFO: epoch 017:    220 / 2004 loss=0.209, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=338.8, nsentences=8, sample_size=338.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=987.7, ups=2.92, wpb=338.8, bsz=8, num_updates=32080, lr=6.86707e-05, gnorm=2.633, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=11010
2023-03-15 17:03:16 - progress_bar.py[line:272] - INFO: epoch 017:    230 / 2004 loss=0.229, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=320.9, nsentences=8, sample_size=320.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=903.9, ups=2.82, wpb=320.9, bsz=8, num_updates=32090, lr=6.86607e-05, gnorm=2.651, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=11014
2023-03-15 17:03:20 - progress_bar.py[line:272] - INFO: epoch 017:    240 / 2004 loss=0.262, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=403.2, nsentences=8, sample_size=403.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1137.8, ups=2.82, wpb=403.2, bsz=8, num_updates=32100, lr=6.86506e-05, gnorm=2.776, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=11017
2023-03-15 17:03:23 - progress_bar.py[line:272] - INFO: epoch 017:    250 / 2004 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.24, ntokens=346.3, nsentences=8, sample_size=346.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1004.9, ups=2.9, wpb=346.3, bsz=8, num_updates=32110, lr=6.86405e-05, gnorm=2.746, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=11021
2023-03-15 17:03:27 - progress_bar.py[line:272] - INFO: epoch 017:    260 / 2004 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.256, ntokens=336, nsentences=8, sample_size=336, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=972.6, ups=2.89, wpb=336, bsz=8, num_updates=32120, lr=6.86304e-05, gnorm=2.989, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=11024
2023-03-15 17:03:30 - progress_bar.py[line:272] - INFO: epoch 017:    270 / 2004 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=347.4, nsentences=8, sample_size=347.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=999.2, ups=2.88, wpb=347.4, bsz=8, num_updates=32130, lr=6.86203e-05, gnorm=2.869, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=11028
2023-03-15 17:03:34 - progress_bar.py[line:272] - INFO: epoch 017:    280 / 2004 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=325.3, nsentences=8, sample_size=325.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=928.7, ups=2.85, wpb=325.3, bsz=8, num_updates=32140, lr=6.86103e-05, gnorm=2.733, clip=0, loss_scale=2048, train_wall=3, gb_free=15.8, wall=11031
2023-03-15 17:03:37 - progress_bar.py[line:272] - INFO: epoch 017:    290 / 2004 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=374.1, nsentences=8, sample_size=374.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1070.6, ups=2.86, wpb=374.1, bsz=8, num_updates=32150, lr=6.86002e-05, gnorm=2.686, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=11035
2023-03-15 17:03:41 - progress_bar.py[line:272] - INFO: epoch 017:    300 / 2004 loss=0.268, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=366.8, nsentences=8, sample_size=366.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1059.1, ups=2.89, wpb=366.8, bsz=8, num_updates=32160, lr=6.85901e-05, gnorm=2.754, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=11038
2023-03-15 17:03:44 - progress_bar.py[line:272] - INFO: epoch 017:    310 / 2004 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.24, ntokens=343.9, nsentences=8, sample_size=343.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=982, ups=2.86, wpb=343.9, bsz=8, num_updates=32170, lr=6.858e-05, gnorm=2.947, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=11042
2023-03-15 17:03:48 - progress_bar.py[line:272] - INFO: epoch 017:    320 / 2004 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.238, ntokens=346.2, nsentences=8, sample_size=346.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=982.3, ups=2.84, wpb=346.2, bsz=8, num_updates=32180, lr=6.85699e-05, gnorm=2.873, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=11045
2023-03-15 17:03:51 - progress_bar.py[line:272] - INFO: epoch 017:    330 / 2004 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=336, nsentences=8, sample_size=336, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=961.3, ups=2.86, wpb=336, bsz=8, num_updates=32190, lr=6.85598e-05, gnorm=2.775, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=11049
2023-03-15 17:03:55 - progress_bar.py[line:272] - INFO: epoch 017:    340 / 2004 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.241, ntokens=335.9, nsentences=8, sample_size=335.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=966.6, ups=2.88, wpb=335.9, bsz=8, num_updates=32200, lr=6.85498e-05, gnorm=2.663, clip=0, loss_scale=2048, train_wall=3, gb_free=15.8, wall=11052
2023-03-15 17:03:56 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 17:03:58 - progress_bar.py[line:272] - INFO: epoch 017:    351 / 2004 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=357.7, nsentences=8, sample_size=357.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=934.6, ups=2.61, wpb=357.7, bsz=8, num_updates=32210, lr=6.85397e-05, gnorm=2.744, clip=0, loss_scale=2048, train_wall=4, gb_free=15, wall=11056
2023-03-15 17:04:02 - progress_bar.py[line:272] - INFO: epoch 017:    361 / 2004 loss=0.221, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=355.6, nsentences=8, sample_size=355.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1005.1, ups=2.83, wpb=355.6, bsz=8, num_updates=32220, lr=6.85296e-05, gnorm=2.617, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=11060
2023-03-15 17:04:05 - progress_bar.py[line:272] - INFO: epoch 017:    371 / 2004 loss=0.213, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=330.2, nsentences=8, sample_size=330.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1009.6, ups=3.06, wpb=330.2, bsz=8, num_updates=32230, lr=6.85195e-05, gnorm=2.564, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=11063
2023-03-15 17:04:08 - progress_bar.py[line:272] - INFO: epoch 017:    381 / 2004 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=314.1, nsentences=8, sample_size=314.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=952.6, ups=3.03, wpb=314.1, bsz=8, num_updates=32240, lr=6.85094e-05, gnorm=3.098, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=11066
2023-03-15 17:04:12 - progress_bar.py[line:272] - INFO: epoch 017:    391 / 2004 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=351.6, nsentences=8, sample_size=351.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1043.7, ups=2.97, wpb=351.6, bsz=8, num_updates=32250, lr=6.84994e-05, gnorm=2.785, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=11069
2023-03-15 17:04:15 - progress_bar.py[line:272] - INFO: epoch 017:    401 / 2004 loss=0.234, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=371, nsentences=8, sample_size=371, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1135.1, ups=3.06, wpb=371, bsz=8, num_updates=32260, lr=6.84893e-05, gnorm=2.777, clip=0, loss_scale=2048, train_wall=3, gb_free=13.6, wall=11073
2023-03-15 17:04:18 - progress_bar.py[line:272] - INFO: epoch 017:    411 / 2004 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=349.1, nsentences=8, sample_size=349.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1122.6, ups=3.22, wpb=349.1, bsz=8, num_updates=32270, lr=6.84792e-05, gnorm=2.743, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=11076
2023-03-15 17:04:21 - progress_bar.py[line:272] - INFO: epoch 017:    421 / 2004 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.25, ntokens=344.5, nsentences=8, sample_size=344.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1077, ups=3.13, wpb=344.5, bsz=8, num_updates=32280, lr=6.84691e-05, gnorm=3.127, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=11079
2023-03-15 17:04:25 - progress_bar.py[line:272] - INFO: epoch 017:    431 / 2004 loss=0.196, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=329.9, nsentences=8, sample_size=329.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1049.4, ups=3.18, wpb=329.9, bsz=8, num_updates=32290, lr=6.8459e-05, gnorm=2.289, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=11082
2023-03-15 17:04:28 - progress_bar.py[line:272] - INFO: epoch 017:    441 / 2004 loss=0.293, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=370.9, nsentences=8, sample_size=370.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=1080.5, ups=2.91, wpb=370.9, bsz=8, num_updates=32300, lr=6.8449e-05, gnorm=3.31, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=11086
2023-03-15 17:04:31 - progress_bar.py[line:272] - INFO: epoch 017:    451 / 2004 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=369.6, nsentences=8, sample_size=369.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1136.5, ups=3.07, wpb=369.6, bsz=8, num_updates=32310, lr=6.84389e-05, gnorm=2.944, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=11089
2023-03-15 17:04:35 - progress_bar.py[line:272] - INFO: epoch 017:    461 / 2004 loss=0.259, loss_v1=0, loss_v2=0, nll_loss=0.259, ntokens=379.4, nsentences=8, sample_size=379.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1119.4, ups=2.95, wpb=379.4, bsz=8, num_updates=32320, lr=6.84288e-05, gnorm=2.882, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=11092
2023-03-15 17:04:38 - progress_bar.py[line:272] - INFO: epoch 017:    471 / 2004 loss=0.287, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=356.9, nsentences=8, sample_size=356.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=997.4, ups=2.79, wpb=356.9, bsz=8, num_updates=32330, lr=6.84187e-05, gnorm=3.062, clip=0, loss_scale=2048, train_wall=4, gb_free=15.1, wall=11096
2023-03-15 17:04:39 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 17:04:42 - progress_bar.py[line:272] - INFO: epoch 017:    482 / 2004 loss=0.234, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=341.9, nsentences=8, sample_size=341.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=893.2, ups=2.61, wpb=341.9, bsz=8, num_updates=32340, lr=6.84086e-05, gnorm=2.843, clip=0, loss_scale=2048, train_wall=4, gb_free=14.7, wall=11100
2023-03-15 17:04:46 - progress_bar.py[line:272] - INFO: epoch 017:    492 / 2004 loss=0.231, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=376.1, nsentences=8, sample_size=376.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1078.4, ups=2.87, wpb=376.1, bsz=8, num_updates=32350, lr=6.83986e-05, gnorm=2.692, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=11103
2023-03-15 17:04:49 - progress_bar.py[line:272] - INFO: epoch 017:    502 / 2004 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=362.2, nsentences=8, sample_size=362.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1099, ups=3.03, wpb=362.2, bsz=8, num_updates=32360, lr=6.83885e-05, gnorm=2.86, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=11106
2023-03-15 17:04:52 - progress_bar.py[line:272] - INFO: epoch 017:    512 / 2004 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.238, ntokens=347.2, nsentences=8, sample_size=347.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1078.6, ups=3.11, wpb=347.2, bsz=8, num_updates=32370, lr=6.83784e-05, gnorm=2.591, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=11110
2023-03-15 17:04:55 - progress_bar.py[line:272] - INFO: epoch 017:    522 / 2004 loss=0.261, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=377.6, nsentences=8, sample_size=377.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1169.9, ups=3.1, wpb=377.6, bsz=8, num_updates=32380, lr=6.83683e-05, gnorm=3.082, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=11113
2023-03-15 17:04:58 - progress_bar.py[line:272] - INFO: epoch 017:    532 / 2004 loss=0.264, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=385.3, nsentences=8, sample_size=385.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1201.3, ups=3.12, wpb=385.3, bsz=8, num_updates=32390, lr=6.83582e-05, gnorm=2.799, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=11116
2023-03-15 17:05:02 - progress_bar.py[line:272] - INFO: epoch 017:    542 / 2004 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=374.1, nsentences=8, sample_size=374.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1174.5, ups=3.14, wpb=374.1, bsz=8, num_updates=32400, lr=6.83482e-05, gnorm=2.787, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=11119
2023-03-15 17:05:05 - progress_bar.py[line:272] - INFO: epoch 017:    552 / 2004 loss=0.235, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=362.2, nsentences=8, sample_size=362.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1134.8, ups=3.13, wpb=362.2, bsz=8, num_updates=32410, lr=6.83381e-05, gnorm=2.727, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=11122
2023-03-15 17:05:08 - progress_bar.py[line:272] - INFO: epoch 017:    562 / 2004 loss=0.234, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=370.4, nsentences=8, sample_size=370.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1166, ups=3.15, wpb=370.4, bsz=8, num_updates=32420, lr=6.8328e-05, gnorm=2.649, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=11126
2023-03-15 17:05:11 - progress_bar.py[line:272] - INFO: epoch 017:    572 / 2004 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=367.1, nsentences=8, sample_size=367.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1104.1, ups=3.01, wpb=367.1, bsz=8, num_updates=32430, lr=6.83179e-05, gnorm=2.761, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=11129
2023-03-15 17:05:13 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 17:05:15 - progress_bar.py[line:272] - INFO: epoch 017:    583 / 2004 loss=0.263, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=356.6, nsentences=8, sample_size=356.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1025.8, ups=2.88, wpb=356.6, bsz=8, num_updates=32440, lr=6.83078e-05, gnorm=2.761, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=11132
2023-03-15 17:05:18 - progress_bar.py[line:272] - INFO: epoch 017:    593 / 2004 loss=0.217, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=342.9, nsentences=8, sample_size=342.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1083.4, ups=3.16, wpb=342.9, bsz=8, num_updates=32450, lr=6.82977e-05, gnorm=2.475, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=11136
2023-03-15 17:05:21 - progress_bar.py[line:272] - INFO: epoch 017:    603 / 2004 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=369.4, nsentences=8, sample_size=369.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1154.9, ups=3.13, wpb=369.4, bsz=8, num_updates=32460, lr=6.82877e-05, gnorm=2.834, clip=0, loss_scale=1024, train_wall=3, gb_free=14, wall=11139
2023-03-15 17:05:24 - progress_bar.py[line:272] - INFO: epoch 017:    613 / 2004 loss=0.231, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=345.4, nsentences=8, sample_size=345.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1094.5, ups=3.17, wpb=345.4, bsz=8, num_updates=32470, lr=6.82776e-05, gnorm=2.646, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=11142
2023-03-15 17:05:28 - progress_bar.py[line:272] - INFO: epoch 017:    623 / 2004 loss=0.231, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=353.7, nsentences=8, sample_size=353.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1126.5, ups=3.19, wpb=353.7, bsz=8, num_updates=32480, lr=6.82675e-05, gnorm=2.649, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=11145
2023-03-15 17:05:31 - progress_bar.py[line:272] - INFO: epoch 017:    633 / 2004 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.24, ntokens=351.3, nsentences=8, sample_size=351.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1118.8, ups=3.18, wpb=351.3, bsz=8, num_updates=32490, lr=6.82574e-05, gnorm=2.805, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=11148
2023-03-15 17:05:34 - progress_bar.py[line:272] - INFO: epoch 017:    643 / 2004 loss=0.222, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=340.1, nsentences=8, sample_size=340.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1014.6, ups=2.98, wpb=340.1, bsz=8, num_updates=32500, lr=6.82473e-05, gnorm=2.687, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=11152
2023-03-15 17:05:37 - progress_bar.py[line:272] - INFO: epoch 017:    653 / 2004 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=321.6, nsentences=8, sample_size=321.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=961, ups=2.99, wpb=321.6, bsz=8, num_updates=32510, lr=6.82373e-05, gnorm=2.905, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=11155
2023-03-15 17:05:41 - progress_bar.py[line:272] - INFO: epoch 017:    663 / 2004 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.256, ntokens=321.2, nsentences=8, sample_size=321.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=935.8, ups=2.91, wpb=321.2, bsz=8, num_updates=32520, lr=6.82272e-05, gnorm=2.82, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=11158
2023-03-15 17:05:44 - progress_bar.py[line:272] - INFO: epoch 017:    673 / 2004 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=341.2, nsentences=8, sample_size=341.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1052.1, ups=3.08, wpb=341.2, bsz=8, num_updates=32530, lr=6.82171e-05, gnorm=2.614, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=11162
2023-03-15 17:05:47 - progress_bar.py[line:272] - INFO: epoch 017:    683 / 2004 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=345.5, nsentences=8, sample_size=345.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1088.3, ups=3.15, wpb=345.5, bsz=8, num_updates=32540, lr=6.8207e-05, gnorm=2.839, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=11165
2023-03-15 17:05:50 - progress_bar.py[line:272] - INFO: epoch 017:    693 / 2004 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=350.8, nsentences=8, sample_size=350.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1117.5, ups=3.19, wpb=350.8, bsz=8, num_updates=32550, lr=6.81969e-05, gnorm=2.832, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=11168
2023-03-15 17:05:54 - progress_bar.py[line:272] - INFO: epoch 017:    703 / 2004 loss=0.232, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=324.2, nsentences=8, sample_size=324.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=986.1, ups=3.04, wpb=324.2, bsz=8, num_updates=32560, lr=6.81869e-05, gnorm=2.642, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=11171
2023-03-15 17:05:57 - progress_bar.py[line:272] - INFO: epoch 017:    713 / 2004 loss=0.222, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=335.3, nsentences=8, sample_size=335.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=985.2, ups=2.94, wpb=335.3, bsz=8, num_updates=32570, lr=6.81768e-05, gnorm=2.61, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=11175
2023-03-15 17:06:00 - progress_bar.py[line:272] - INFO: epoch 017:    723 / 2004 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.247, ntokens=357.8, nsentences=8, sample_size=357.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1040.6, ups=2.91, wpb=357.8, bsz=8, num_updates=32580, lr=6.81667e-05, gnorm=2.941, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=11178
2023-03-15 17:06:04 - progress_bar.py[line:272] - INFO: epoch 017:    733 / 2004 loss=0.232, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=352.7, nsentences=8, sample_size=352.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1034, ups=2.93, wpb=352.7, bsz=8, num_updates=32590, lr=6.81566e-05, gnorm=2.698, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=11181
2023-03-15 17:06:07 - progress_bar.py[line:272] - INFO: epoch 017:    743 / 2004 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.24, ntokens=348.7, nsentences=8, sample_size=348.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1005.5, ups=2.88, wpb=348.7, bsz=8, num_updates=32600, lr=6.81465e-05, gnorm=2.765, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=11185
2023-03-15 17:06:11 - progress_bar.py[line:272] - INFO: epoch 017:    753 / 2004 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=338.2, nsentences=8, sample_size=338.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=991.3, ups=2.93, wpb=338.2, bsz=8, num_updates=32610, lr=6.81365e-05, gnorm=2.699, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=11188
2023-03-15 17:06:14 - progress_bar.py[line:272] - INFO: epoch 017:    763 / 2004 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.238, ntokens=353.4, nsentences=8, sample_size=353.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1030.2, ups=2.92, wpb=353.4, bsz=8, num_updates=32620, lr=6.81264e-05, gnorm=2.738, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=11192
2023-03-15 17:06:18 - progress_bar.py[line:272] - INFO: epoch 017:    773 / 2004 loss=0.272, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=398.9, nsentences=8, sample_size=398.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1137.1, ups=2.85, wpb=398.9, bsz=8, num_updates=32630, lr=6.81163e-05, gnorm=2.878, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=11195
2023-03-15 17:06:21 - progress_bar.py[line:272] - INFO: epoch 017:    783 / 2004 loss=0.228, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=330.3, nsentences=8, sample_size=330.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=958.9, ups=2.9, wpb=330.3, bsz=8, num_updates=32640, lr=6.81062e-05, gnorm=2.753, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=11199
2023-03-15 17:06:25 - progress_bar.py[line:272] - INFO: epoch 017:    793 / 2004 loss=0.234, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=319.8, nsentences=8, sample_size=319.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=950.1, ups=2.97, wpb=319.8, bsz=8, num_updates=32650, lr=6.80961e-05, gnorm=2.562, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=11202
2023-03-15 17:06:28 - progress_bar.py[line:272] - INFO: epoch 017:    803 / 2004 loss=0.229, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=336, nsentences=8, sample_size=336, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=959.2, ups=2.85, wpb=336, bsz=8, num_updates=32660, lr=6.80861e-05, gnorm=2.627, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=11206
2023-03-15 17:06:31 - progress_bar.py[line:272] - INFO: epoch 017:    813 / 2004 loss=0.222, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=341.4, nsentences=8, sample_size=341.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=986.5, ups=2.89, wpb=341.4, bsz=8, num_updates=32670, lr=6.8076e-05, gnorm=2.71, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=11209
2023-03-15 17:06:35 - progress_bar.py[line:272] - INFO: epoch 017:    823 / 2004 loss=0.224, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=353.6, nsentences=8, sample_size=353.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1003.5, ups=2.84, wpb=353.6, bsz=8, num_updates=32680, lr=6.80659e-05, gnorm=2.691, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=11213
2023-03-15 17:06:39 - progress_bar.py[line:272] - INFO: epoch 017:    833 / 2004 loss=0.228, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=337.4, nsentences=8, sample_size=337.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=954.8, ups=2.83, wpb=337.4, bsz=8, num_updates=32690, lr=6.80558e-05, gnorm=2.79, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=11216
2023-03-15 17:06:40 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 17:06:42 - progress_bar.py[line:272] - INFO: epoch 017:    844 / 2004 loss=0.224, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=353.9, nsentences=8, sample_size=353.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=935.2, ups=2.64, wpb=353.9, bsz=8, num_updates=32700, lr=6.80457e-05, gnorm=2.738, clip=0, loss_scale=2048, train_wall=4, gb_free=15.4, wall=11220
2023-03-15 17:06:46 - progress_bar.py[line:272] - INFO: epoch 017:    854 / 2004 loss=0.23, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=359.8, nsentences=8, sample_size=359.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1070.5, ups=2.98, wpb=359.8, bsz=8, num_updates=32710, lr=6.80356e-05, gnorm=2.676, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=11223
2023-03-15 17:06:49 - progress_bar.py[line:272] - INFO: epoch 017:    864 / 2004 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=350.1, nsentences=8, sample_size=350.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1018.5, ups=2.91, wpb=350.1, bsz=8, num_updates=32720, lr=6.80256e-05, gnorm=2.838, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=11227
2023-03-15 17:06:53 - progress_bar.py[line:272] - INFO: epoch 017:    874 / 2004 loss=0.257, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=355.6, nsentences=8, sample_size=355.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1020.6, ups=2.87, wpb=355.6, bsz=8, num_updates=32730, lr=6.80155e-05, gnorm=2.971, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=11230
2023-03-15 17:06:56 - progress_bar.py[line:272] - INFO: epoch 017:    884 / 2004 loss=0.23, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=316.2, nsentences=8, sample_size=316.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=888.5, ups=2.81, wpb=316.2, bsz=8, num_updates=32740, lr=6.80054e-05, gnorm=2.812, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=11234
2023-03-15 17:07:00 - progress_bar.py[line:272] - INFO: epoch 017:    894 / 2004 loss=0.217, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=312, nsentences=8, sample_size=312, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=909.5, ups=2.92, wpb=312, bsz=8, num_updates=32750, lr=6.79953e-05, gnorm=2.65, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=11237
2023-03-15 17:07:03 - progress_bar.py[line:272] - INFO: epoch 017:    904 / 2004 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.256, ntokens=377.7, nsentences=8, sample_size=377.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1103.4, ups=2.92, wpb=377.7, bsz=8, num_updates=32760, lr=6.79852e-05, gnorm=2.731, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=11241
2023-03-15 17:07:06 - progress_bar.py[line:272] - INFO: epoch 017:    914 / 2004 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=374.9, nsentences=8, sample_size=374.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1179, ups=3.14, wpb=374.9, bsz=8, num_updates=32770, lr=6.79752e-05, gnorm=2.848, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=11244
2023-03-15 17:07:09 - progress_bar.py[line:272] - INFO: epoch 017:    924 / 2004 loss=0.235, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=325.9, nsentences=8, sample_size=325.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1043.6, ups=3.2, wpb=325.9, bsz=8, num_updates=32780, lr=6.79651e-05, gnorm=2.986, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=11247
2023-03-15 17:07:12 - progress_bar.py[line:272] - INFO: epoch 017:    934 / 2004 loss=0.215, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=340.5, nsentences=8, sample_size=340.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1089.3, ups=3.2, wpb=340.5, bsz=8, num_updates=32790, lr=6.7955e-05, gnorm=2.664, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=11250
2023-03-15 17:07:16 - progress_bar.py[line:272] - INFO: epoch 017:    944 / 2004 loss=0.229, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=370, nsentences=8, sample_size=370, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1165, ups=3.15, wpb=370, bsz=8, num_updates=32800, lr=6.79449e-05, gnorm=2.875, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=11253
2023-03-15 17:07:19 - progress_bar.py[line:272] - INFO: epoch 017:    954 / 2004 loss=0.257, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=335, nsentences=8, sample_size=335, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1043.3, ups=3.11, wpb=335, bsz=8, num_updates=32810, lr=6.79348e-05, gnorm=3.067, clip=0, loss_scale=2048, train_wall=3, gb_free=13.8, wall=11256
2023-03-15 17:07:22 - progress_bar.py[line:272] - INFO: epoch 017:    964 / 2004 loss=0.273, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=382.1, nsentences=8, sample_size=382.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1205, ups=3.15, wpb=382.1, bsz=8, num_updates=32820, lr=6.79248e-05, gnorm=2.893, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=11260
2023-03-15 17:07:23 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 17:07:25 - progress_bar.py[line:272] - INFO: epoch 017:    975 / 2004 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=325.5, nsentences=8, sample_size=325.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=953, ups=2.93, wpb=325.5, bsz=8, num_updates=32830, lr=6.79147e-05, gnorm=3.038, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=11263
2023-03-15 17:07:28 - progress_bar.py[line:272] - INFO: epoch 017:    985 / 2004 loss=0.227, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=313.1, nsentences=7.8, sample_size=313.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1023.4, ups=3.27, wpb=313.1, bsz=7.8, num_updates=32840, lr=6.79046e-05, gnorm=2.731, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=11266
2023-03-15 17:07:32 - progress_bar.py[line:272] - INFO: epoch 017:    995 / 2004 loss=0.273, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=389.9, nsentences=8, sample_size=389.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1229.2, ups=3.15, wpb=389.9, bsz=8, num_updates=32850, lr=6.78945e-05, gnorm=3.082, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=11269
2023-03-15 17:07:35 - progress_bar.py[line:272] - INFO: epoch 017:   1005 / 2004 loss=0.235, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=312.5, nsentences=8, sample_size=312.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=983.1, ups=3.15, wpb=312.5, bsz=8, num_updates=32860, lr=6.78844e-05, gnorm=2.72, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=11272
2023-03-15 17:07:35 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 17:07:38 - progress_bar.py[line:272] - INFO: epoch 017:   1016 / 2004 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=342.8, nsentences=8, sample_size=342.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1014.3, ups=2.96, wpb=342.8, bsz=8, num_updates=32870, lr=6.78744e-05, gnorm=2.836, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=11276
2023-03-15 17:07:41 - progress_bar.py[line:272] - INFO: epoch 017:   1026 / 2004 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=325.7, nsentences=8, sample_size=325.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1041.1, ups=3.2, wpb=325.7, bsz=8, num_updates=32880, lr=6.78643e-05, gnorm=2.727, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=11279
2023-03-15 17:07:44 - progress_bar.py[line:272] - INFO: epoch 017:   1036 / 2004 loss=0.229, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=319.1, nsentences=8, sample_size=319.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1028.2, ups=3.22, wpb=319.1, bsz=8, num_updates=32890, lr=6.78542e-05, gnorm=2.714, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=11282
2023-03-15 17:07:48 - progress_bar.py[line:272] - INFO: epoch 017:   1046 / 2004 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=379.8, nsentences=8, sample_size=379.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1204.8, ups=3.17, wpb=379.8, bsz=8, num_updates=32900, lr=6.78441e-05, gnorm=3.107, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=11285
2023-03-15 17:07:51 - progress_bar.py[line:272] - INFO: epoch 017:   1056 / 2004 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.238, ntokens=349.5, nsentences=8, sample_size=349.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1095.1, ups=3.13, wpb=349.5, bsz=8, num_updates=32910, lr=6.7834e-05, gnorm=2.751, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=11288
2023-03-15 17:07:54 - progress_bar.py[line:272] - INFO: epoch 017:   1066 / 2004 loss=0.233, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=340.9, nsentences=8, sample_size=340.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1079.9, ups=3.17, wpb=340.9, bsz=8, num_updates=32920, lr=6.78239e-05, gnorm=2.757, clip=0, loss_scale=1024, train_wall=3, gb_free=14.1, wall=11292
2023-03-15 17:07:57 - progress_bar.py[line:272] - INFO: epoch 017:   1076 / 2004 loss=0.235, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=354.1, nsentences=8, sample_size=354.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1107.8, ups=3.13, wpb=354.1, bsz=8, num_updates=32930, lr=6.78139e-05, gnorm=2.756, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=11295
2023-03-15 17:08:00 - progress_bar.py[line:272] - INFO: epoch 017:   1086 / 2004 loss=0.229, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=377.6, nsentences=8, sample_size=377.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1173.6, ups=3.11, wpb=377.6, bsz=8, num_updates=32940, lr=6.78038e-05, gnorm=2.632, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=11298
2023-03-15 17:08:04 - progress_bar.py[line:272] - INFO: epoch 017:   1096 / 2004 loss=0.235, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=322.8, nsentences=8, sample_size=322.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1027.2, ups=3.18, wpb=322.8, bsz=8, num_updates=32950, lr=6.77937e-05, gnorm=2.764, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=11301
2023-03-15 17:08:07 - progress_bar.py[line:272] - INFO: epoch 017:   1106 / 2004 loss=0.276, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=378.9, nsentences=8, sample_size=378.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1187, ups=3.13, wpb=378.9, bsz=8, num_updates=32960, lr=6.77836e-05, gnorm=3.057, clip=0, loss_scale=1024, train_wall=3, gb_free=13.3, wall=11304
2023-03-15 17:08:10 - progress_bar.py[line:272] - INFO: epoch 017:   1116 / 2004 loss=0.224, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=336.3, nsentences=8, sample_size=336.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1085.5, ups=3.23, wpb=336.3, bsz=8, num_updates=32970, lr=6.77735e-05, gnorm=2.576, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=11307
2023-03-15 17:08:13 - progress_bar.py[line:272] - INFO: epoch 017:   1126 / 2004 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=321.6, nsentences=8, sample_size=321.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1021.4, ups=3.18, wpb=321.6, bsz=8, num_updates=32980, lr=6.77635e-05, gnorm=2.947, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=11311
2023-03-15 17:08:16 - progress_bar.py[line:272] - INFO: epoch 017:   1136 / 2004 loss=0.236, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=384.6, nsentences=8, sample_size=384.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1204.5, ups=3.13, wpb=384.6, bsz=8, num_updates=32990, lr=6.77534e-05, gnorm=2.76, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=11314
2023-03-15 17:08:19 - progress_bar.py[line:272] - INFO: epoch 017:   1146 / 2004 loss=0.23, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=343.5, nsentences=8, sample_size=343.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1094.6, ups=3.19, wpb=343.5, bsz=8, num_updates=33000, lr=6.77433e-05, gnorm=2.776, clip=0, loss_scale=2048, train_wall=3, gb_free=13.8, wall=11317
2023-03-15 17:08:22 - progress_bar.py[line:272] - INFO: epoch 017:   1156 / 2004 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=392.2, nsentences=8, sample_size=392.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1228.3, ups=3.13, wpb=392.2, bsz=8, num_updates=33010, lr=6.77332e-05, gnorm=2.852, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=11320
2023-03-15 17:08:26 - progress_bar.py[line:272] - INFO: epoch 017:   1166 / 2004 loss=0.231, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=351.7, nsentences=8, sample_size=351.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1097.6, ups=3.12, wpb=351.7, bsz=8, num_updates=33020, lr=6.77231e-05, gnorm=2.607, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=11323
2023-03-15 17:08:29 - progress_bar.py[line:272] - INFO: epoch 017:   1176 / 2004 loss=0.219, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=363.7, nsentences=8, sample_size=363.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1154.3, ups=3.17, wpb=363.7, bsz=8, num_updates=33030, lr=6.77131e-05, gnorm=2.622, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=11326
2023-03-15 17:08:32 - progress_bar.py[line:272] - INFO: epoch 017:   1186 / 2004 loss=0.231, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=333.3, nsentences=8, sample_size=333.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1072.5, ups=3.22, wpb=333.3, bsz=8, num_updates=33040, lr=6.7703e-05, gnorm=2.56, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=11330
2023-03-15 17:08:35 - progress_bar.py[line:272] - INFO: epoch 017:   1196 / 2004 loss=0.226, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=362.6, nsentences=8, sample_size=362.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1134.3, ups=3.13, wpb=362.6, bsz=8, num_updates=33050, lr=6.76929e-05, gnorm=2.702, clip=0, loss_scale=2048, train_wall=3, gb_free=13.5, wall=11333
2023-03-15 17:08:38 - progress_bar.py[line:272] - INFO: epoch 017:   1206 / 2004 loss=0.232, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=291.8, nsentences=8, sample_size=291.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=932, ups=3.19, wpb=291.8, bsz=8, num_updates=33060, lr=6.76828e-05, gnorm=2.53, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=11336
2023-03-15 17:08:41 - progress_bar.py[line:272] - INFO: epoch 017:   1216 / 2004 loss=0.221, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=322.4, nsentences=8, sample_size=322.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1017.4, ups=3.16, wpb=322.4, bsz=8, num_updates=33070, lr=6.76727e-05, gnorm=2.651, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=11339
2023-03-15 17:08:44 - progress_bar.py[line:272] - INFO: epoch 017:   1226 / 2004 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=306.6, nsentences=8, sample_size=306.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1000, ups=3.26, wpb=306.6, bsz=8, num_updates=33080, lr=6.76627e-05, gnorm=2.848, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=11342
2023-03-15 17:08:48 - progress_bar.py[line:272] - INFO: epoch 017:   1236 / 2004 loss=0.226, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=357.7, nsentences=8, sample_size=357.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1127.9, ups=3.15, wpb=357.7, bsz=8, num_updates=33090, lr=6.76526e-05, gnorm=2.509, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=11345
2023-03-15 17:08:51 - progress_bar.py[line:272] - INFO: epoch 017:   1246 / 2004 loss=0.235, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=355.5, nsentences=8, sample_size=355.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1105.2, ups=3.11, wpb=355.5, bsz=8, num_updates=33100, lr=6.76425e-05, gnorm=2.747, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=11349
2023-03-15 17:08:54 - progress_bar.py[line:272] - INFO: epoch 017:   1256 / 2004 loss=0.235, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=353.5, nsentences=8, sample_size=353.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1095.4, ups=3.1, wpb=353.5, bsz=8, num_updates=33110, lr=6.76324e-05, gnorm=2.746, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=11352
2023-03-15 17:08:57 - progress_bar.py[line:272] - INFO: epoch 017:   1266 / 2004 loss=0.221, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=337.8, nsentences=8, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1093.3, ups=3.24, wpb=337.8, bsz=8, num_updates=33120, lr=6.76223e-05, gnorm=2.744, clip=0, loss_scale=4096, train_wall=3, gb_free=14.8, wall=11355
2023-03-15 17:08:58 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 17:09:01 - progress_bar.py[line:272] - INFO: epoch 017:   1277 / 2004 loss=0.214, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=337.2, nsentences=8, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=977.9, ups=2.9, wpb=337.2, bsz=8, num_updates=33130, lr=6.76123e-05, gnorm=2.511, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=11358
2023-03-15 17:09:04 - progress_bar.py[line:272] - INFO: epoch 017:   1287 / 2004 loss=0.206, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=321, nsentences=8, sample_size=321, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1011.8, ups=3.15, wpb=321, bsz=8, num_updates=33140, lr=6.76022e-05, gnorm=2.683, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=11361
2023-03-15 17:09:07 - progress_bar.py[line:272] - INFO: epoch 017:   1297 / 2004 loss=0.213, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=306.7, nsentences=8, sample_size=306.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1006.4, ups=3.28, wpb=306.7, bsz=8, num_updates=33150, lr=6.75921e-05, gnorm=2.634, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=11364
2023-03-15 17:09:10 - progress_bar.py[line:272] - INFO: epoch 017:   1307 / 2004 loss=0.219, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=320.1, nsentences=8, sample_size=320.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1017, ups=3.18, wpb=320.1, bsz=8, num_updates=33160, lr=6.7582e-05, gnorm=2.704, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=11368
2023-03-15 17:09:13 - progress_bar.py[line:272] - INFO: epoch 017:   1317 / 2004 loss=0.229, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=346, nsentences=8, sample_size=346, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1120.8, ups=3.24, wpb=346, bsz=8, num_updates=33170, lr=6.75719e-05, gnorm=2.727, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=11371
2023-03-15 17:09:16 - progress_bar.py[line:272] - INFO: epoch 017:   1327 / 2004 loss=0.22, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=290, nsentences=8, sample_size=290, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=939.1, ups=3.24, wpb=290, bsz=8, num_updates=33180, lr=6.75618e-05, gnorm=2.593, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=11374
2023-03-15 17:09:19 - progress_bar.py[line:272] - INFO: epoch 017:   1337 / 2004 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=371.2, nsentences=8, sample_size=371.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1179.8, ups=3.18, wpb=371.2, bsz=8, num_updates=33190, lr=6.75518e-05, gnorm=2.809, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=11377
2023-03-15 17:09:22 - progress_bar.py[line:272] - INFO: epoch 017:   1347 / 2004 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=298.5, nsentences=8, sample_size=298.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=949.9, ups=3.18, wpb=298.5, bsz=8, num_updates=33200, lr=6.75417e-05, gnorm=2.895, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=11380
2023-03-15 17:09:26 - progress_bar.py[line:272] - INFO: epoch 017:   1357 / 2004 loss=0.207, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=321, nsentences=8, sample_size=321, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1057.9, ups=3.3, wpb=321, bsz=8, num_updates=33210, lr=6.75316e-05, gnorm=2.61, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=11383
2023-03-15 17:09:29 - progress_bar.py[line:272] - INFO: epoch 017:   1367 / 2004 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.25, ntokens=314.9, nsentences=8, sample_size=314.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1020.5, ups=3.24, wpb=314.9, bsz=8, num_updates=33220, lr=6.75215e-05, gnorm=2.845, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=11386
2023-03-15 17:09:32 - progress_bar.py[line:272] - INFO: epoch 017:   1377 / 2004 loss=0.212, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=326, nsentences=8, sample_size=326, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1022.4, ups=3.14, wpb=326, bsz=8, num_updates=33230, lr=6.75114e-05, gnorm=2.518, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=11389
2023-03-15 17:09:35 - progress_bar.py[line:272] - INFO: epoch 017:   1387 / 2004 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.241, ntokens=400.3, nsentences=8, sample_size=400.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1252.4, ups=3.13, wpb=400.3, bsz=8, num_updates=33240, lr=6.75014e-05, gnorm=2.888, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=11393
2023-03-15 17:09:38 - progress_bar.py[line:272] - INFO: epoch 017:   1397 / 2004 loss=0.207, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=339.6, nsentences=8, sample_size=339.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1096.3, ups=3.23, wpb=339.6, bsz=8, num_updates=33250, lr=6.74913e-05, gnorm=2.627, clip=0, loss_scale=4096, train_wall=3, gb_free=14.9, wall=11396
2023-03-15 17:09:40 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 17:09:42 - progress_bar.py[line:272] - INFO: epoch 017:   1408 / 2004 loss=0.23, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=341.9, nsentences=8, sample_size=341.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=972.5, ups=2.84, wpb=341.9, bsz=8, num_updates=33260, lr=6.74812e-05, gnorm=2.899, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=11399
2023-03-15 17:09:45 - progress_bar.py[line:272] - INFO: epoch 017:   1418 / 2004 loss=0.265, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=372.2, nsentences=8, sample_size=372.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1158.4, ups=3.11, wpb=372.2, bsz=8, num_updates=33270, lr=6.74711e-05, gnorm=2.954, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=11402
2023-03-15 17:09:48 - progress_bar.py[line:272] - INFO: epoch 017:   1428 / 2004 loss=0.224, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=309.5, nsentences=8, sample_size=309.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=968.5, ups=3.13, wpb=309.5, bsz=8, num_updates=33280, lr=6.7461e-05, gnorm=2.776, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=11406
2023-03-15 17:09:51 - progress_bar.py[line:272] - INFO: epoch 017:   1438 / 2004 loss=0.229, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=359.9, nsentences=8, sample_size=359.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1112.8, ups=3.09, wpb=359.9, bsz=8, num_updates=33290, lr=6.7451e-05, gnorm=2.922, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=11409
2023-03-15 17:09:54 - progress_bar.py[line:272] - INFO: epoch 017:   1448 / 2004 loss=0.221, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=317.7, nsentences=8, sample_size=317.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1009.9, ups=3.18, wpb=317.7, bsz=8, num_updates=33300, lr=6.74409e-05, gnorm=2.686, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=11412
2023-03-15 17:09:58 - progress_bar.py[line:272] - INFO: epoch 017:   1458 / 2004 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.256, ntokens=382.4, nsentences=8, sample_size=382.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1184.1, ups=3.1, wpb=382.4, bsz=8, num_updates=33310, lr=6.74308e-05, gnorm=2.967, clip=0, loss_scale=2048, train_wall=3, gb_free=14, wall=11415
2023-03-15 17:10:01 - progress_bar.py[line:272] - INFO: epoch 017:   1468 / 2004 loss=0.235, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=394.2, nsentences=8, sample_size=394.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1231.1, ups=3.12, wpb=394.2, bsz=8, num_updates=33320, lr=6.74207e-05, gnorm=2.726, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=11418
2023-03-15 17:10:04 - progress_bar.py[line:272] - INFO: epoch 017:   1478 / 2004 loss=0.257, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=404.3, nsentences=8, sample_size=404.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1173.6, ups=2.9, wpb=404.3, bsz=8, num_updates=33330, lr=6.74106e-05, gnorm=3.04, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=11422
2023-03-15 17:10:08 - progress_bar.py[line:272] - INFO: epoch 017:   1488 / 2004 loss=0.209, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=320.4, nsentences=8, sample_size=320.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=918.6, ups=2.87, wpb=320.4, bsz=8, num_updates=33340, lr=6.74006e-05, gnorm=2.49, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=11425
2023-03-15 17:10:11 - progress_bar.py[line:272] - INFO: epoch 017:   1498 / 2004 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.24, ntokens=342.5, nsentences=8, sample_size=342.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=981.5, ups=2.87, wpb=342.5, bsz=8, num_updates=33350, lr=6.73905e-05, gnorm=2.762, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=11429
2023-03-15 17:10:14 - progress_bar.py[line:272] - INFO: epoch 017:   1508 / 2004 loss=0.227, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=329, nsentences=8, sample_size=329, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1038, ups=3.15, wpb=329, bsz=8, num_updates=33360, lr=6.73804e-05, gnorm=2.759, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=11432
2023-03-15 17:10:18 - progress_bar.py[line:272] - INFO: epoch 017:   1518 / 2004 loss=0.229, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=328.3, nsentences=8, sample_size=328.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1039.8, ups=3.17, wpb=328.3, bsz=8, num_updates=33370, lr=6.73703e-05, gnorm=2.907, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=11435
2023-03-15 17:10:21 - progress_bar.py[line:272] - INFO: epoch 017:   1528 / 2004 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.238, ntokens=321.6, nsentences=8, sample_size=321.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1020.3, ups=3.17, wpb=321.6, bsz=8, num_updates=33380, lr=6.73602e-05, gnorm=2.679, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=11438
2023-03-15 17:10:22 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 17:10:24 - progress_bar.py[line:272] - INFO: epoch 017:   1539 / 2004 loss=0.217, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=344.6, nsentences=8, sample_size=344.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=978.8, ups=2.84, wpb=344.6, bsz=8, num_updates=33390, lr=6.73501e-05, gnorm=2.538, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=11442
2023-03-15 17:10:27 - progress_bar.py[line:272] - INFO: epoch 017:   1549 / 2004 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=317.1, nsentences=8, sample_size=317.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1006.7, ups=3.17, wpb=317.1, bsz=8, num_updates=33400, lr=6.73401e-05, gnorm=2.804, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=11445
2023-03-15 17:10:31 - progress_bar.py[line:272] - INFO: epoch 017:   1559 / 2004 loss=0.229, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=353.3, nsentences=8, sample_size=353.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1119.2, ups=3.17, wpb=353.3, bsz=8, num_updates=33410, lr=6.733e-05, gnorm=2.655, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=11448
2023-03-15 17:10:34 - progress_bar.py[line:272] - INFO: epoch 017:   1569 / 2004 loss=0.228, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=325.9, nsentences=8, sample_size=325.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1033.7, ups=3.17, wpb=325.9, bsz=8, num_updates=33420, lr=6.73199e-05, gnorm=2.693, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=11451
2023-03-15 17:10:37 - progress_bar.py[line:272] - INFO: epoch 017:   1579 / 2004 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=354, nsentences=8, sample_size=354, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1120.8, ups=3.17, wpb=354, bsz=8, num_updates=33430, lr=6.73098e-05, gnorm=2.633, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=11454
2023-03-15 17:10:40 - progress_bar.py[line:272] - INFO: epoch 017:   1589 / 2004 loss=0.233, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=328.2, nsentences=8, sample_size=328.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1041.5, ups=3.17, wpb=328.2, bsz=8, num_updates=33440, lr=6.72997e-05, gnorm=2.693, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=11458
2023-03-15 17:10:43 - progress_bar.py[line:272] - INFO: epoch 017:   1599 / 2004 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=345.9, nsentences=8, sample_size=345.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1105.8, ups=3.2, wpb=345.9, bsz=8, num_updates=33450, lr=6.72897e-05, gnorm=2.87, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=11461
2023-03-15 17:10:46 - progress_bar.py[line:272] - INFO: epoch 017:   1609 / 2004 loss=0.23, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=336.5, nsentences=8, sample_size=336.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1051.8, ups=3.13, wpb=336.5, bsz=8, num_updates=33460, lr=6.72796e-05, gnorm=2.86, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=11464
2023-03-15 17:10:50 - progress_bar.py[line:272] - INFO: epoch 017:   1619 / 2004 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.241, ntokens=342.5, nsentences=8, sample_size=342.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1087.1, ups=3.17, wpb=342.5, bsz=8, num_updates=33470, lr=6.72695e-05, gnorm=2.764, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=11467
2023-03-15 17:10:53 - progress_bar.py[line:272] - INFO: epoch 017:   1629 / 2004 loss=0.263, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=362.5, nsentences=8, sample_size=362.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1170.9, ups=3.23, wpb=362.5, bsz=8, num_updates=33480, lr=6.72594e-05, gnorm=2.952, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=11470
2023-03-15 17:10:56 - progress_bar.py[line:272] - INFO: epoch 017:   1639 / 2004 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=328.8, nsentences=8, sample_size=328.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1048.2, ups=3.19, wpb=328.8, bsz=8, num_updates=33490, lr=6.72493e-05, gnorm=2.698, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=11473
2023-03-15 17:10:59 - progress_bar.py[line:272] - INFO: epoch 017:   1649 / 2004 loss=0.221, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=315, nsentences=8, sample_size=315, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1004, ups=3.19, wpb=315, bsz=8, num_updates=33500, lr=6.72393e-05, gnorm=2.85, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=11476
2023-03-15 17:11:02 - progress_bar.py[line:272] - INFO: epoch 017:   1659 / 2004 loss=0.233, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=348.3, nsentences=8, sample_size=348.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1089.2, ups=3.13, wpb=348.3, bsz=8, num_updates=33510, lr=6.72292e-05, gnorm=2.816, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=11480
2023-03-15 17:11:04 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 17:11:05 - progress_bar.py[line:272] - INFO: epoch 017:   1670 / 2004 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=350.2, nsentences=8, sample_size=350.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1024.5, ups=2.93, wpb=350.2, bsz=8, num_updates=33520, lr=6.72191e-05, gnorm=3.135, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=11483
2023-03-15 17:11:09 - progress_bar.py[line:272] - INFO: epoch 017:   1680 / 2004 loss=0.234, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=314, nsentences=8, sample_size=314, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1006.6, ups=3.21, wpb=314, bsz=8, num_updates=33530, lr=6.7209e-05, gnorm=2.787, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=11486
2023-03-15 17:11:12 - progress_bar.py[line:272] - INFO: epoch 017:   1690 / 2004 loss=0.225, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=347.7, nsentences=8, sample_size=347.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1104.6, ups=3.18, wpb=347.7, bsz=8, num_updates=33540, lr=6.71989e-05, gnorm=2.597, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=11489
2023-03-15 17:11:15 - progress_bar.py[line:272] - INFO: epoch 017:   1700 / 2004 loss=0.233, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=335.8, nsentences=8, sample_size=335.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1062.5, ups=3.16, wpb=335.8, bsz=8, num_updates=33550, lr=6.71889e-05, gnorm=2.843, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=11493
2023-03-15 17:11:18 - progress_bar.py[line:272] - INFO: epoch 017:   1710 / 2004 loss=0.234, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=346.6, nsentences=8, sample_size=346.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1085.8, ups=3.13, wpb=346.6, bsz=8, num_updates=33560, lr=6.71788e-05, gnorm=2.781, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=11496
2023-03-15 17:11:21 - progress_bar.py[line:272] - INFO: epoch 017:   1720 / 2004 loss=0.228, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=379, nsentences=8, sample_size=379, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1191.9, ups=3.14, wpb=379, bsz=8, num_updates=33570, lr=6.71687e-05, gnorm=2.711, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=11499
2023-03-15 17:11:25 - progress_bar.py[line:272] - INFO: epoch 017:   1730 / 2004 loss=0.217, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=379.3, nsentences=8, sample_size=379.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1176.7, ups=3.1, wpb=379.3, bsz=8, num_updates=33580, lr=6.71586e-05, gnorm=2.587, clip=0, loss_scale=2048, train_wall=3, gb_free=14, wall=11502
2023-03-15 17:11:28 - progress_bar.py[line:272] - INFO: epoch 017:   1740 / 2004 loss=0.232, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=314.8, nsentences=8, sample_size=314.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1005.5, ups=3.19, wpb=314.8, bsz=8, num_updates=33590, lr=6.71485e-05, gnorm=2.765, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=11505
2023-03-15 17:11:31 - progress_bar.py[line:272] - INFO: epoch 017:   1750 / 2004 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.25, ntokens=357.9, nsentences=8, sample_size=357.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1146.1, ups=3.2, wpb=357.9, bsz=8, num_updates=33600, lr=6.71385e-05, gnorm=3.04, clip=0, loss_scale=2048, train_wall=3, gb_free=15.8, wall=11508
2023-03-15 17:11:36 - progress_bar.py[line:272] - INFO: epoch 017:   1760 / 2004 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=325.3, nsentences=8, sample_size=325.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=608.7, ups=1.87, wpb=325.3, bsz=8, num_updates=33610, lr=6.71284e-05, gnorm=2.873, clip=0, loss_scale=2048, train_wall=5, gb_free=14.9, wall=11514
2023-03-15 17:11:39 - progress_bar.py[line:272] - INFO: epoch 017:   1770 / 2004 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=339.2, nsentences=8, sample_size=339.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1105.8, ups=3.26, wpb=339.2, bsz=8, num_updates=33620, lr=6.71183e-05, gnorm=2.936, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=11517
2023-03-15 17:11:42 - progress_bar.py[line:272] - INFO: epoch 017:   1780 / 2004 loss=0.215, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=330.8, nsentences=8, sample_size=330.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1053.2, ups=3.18, wpb=330.8, bsz=8, num_updates=33630, lr=6.71082e-05, gnorm=2.569, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=11520
2023-03-15 17:11:45 - progress_bar.py[line:272] - INFO: epoch 017:   1790 / 2004 loss=0.22, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=306.4, nsentences=8, sample_size=306.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=983, ups=3.21, wpb=306.4, bsz=8, num_updates=33640, lr=6.70981e-05, gnorm=2.845, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=11523
2023-03-15 17:11:46 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 17:11:49 - progress_bar.py[line:272] - INFO: epoch 017:   1801 / 2004 loss=0.233, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=341.9, nsentences=8, sample_size=341.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=989.2, ups=2.89, wpb=341.9, bsz=8, num_updates=33650, lr=6.7088e-05, gnorm=2.781, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=11527
2023-03-15 17:11:52 - progress_bar.py[line:272] - INFO: epoch 017:   1811 / 2004 loss=0.232, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=339.5, nsentences=8, sample_size=339.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1103.2, ups=3.25, wpb=339.5, bsz=8, num_updates=33660, lr=6.7078e-05, gnorm=2.764, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=11530
2023-03-15 17:11:55 - progress_bar.py[line:272] - INFO: epoch 017:   1821 / 2004 loss=0.228, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=356.6, nsentences=8, sample_size=356.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1155.9, ups=3.24, wpb=356.6, bsz=8, num_updates=33670, lr=6.70679e-05, gnorm=2.686, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=11533
2023-03-15 17:11:58 - progress_bar.py[line:272] - INFO: epoch 017:   1831 / 2004 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=357, nsentences=8, sample_size=357, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1137.5, ups=3.19, wpb=357, bsz=8, num_updates=33680, lr=6.70578e-05, gnorm=2.683, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=11536
2023-03-15 17:12:01 - progress_bar.py[line:272] - INFO: epoch 017:   1841 / 2004 loss=0.227, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=331.9, nsentences=8, sample_size=331.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1061.4, ups=3.2, wpb=331.9, bsz=8, num_updates=33690, lr=6.70477e-05, gnorm=2.745, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=11539
2023-03-15 17:12:04 - progress_bar.py[line:272] - INFO: epoch 017:   1851 / 2004 loss=0.217, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=339.1, nsentences=8, sample_size=339.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1071.8, ups=3.16, wpb=339.1, bsz=8, num_updates=33700, lr=6.70376e-05, gnorm=2.555, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=11542
2023-03-15 17:12:08 - progress_bar.py[line:272] - INFO: epoch 017:   1861 / 2004 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=338, nsentences=8, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1035.7, ups=3.06, wpb=338, bsz=8, num_updates=33710, lr=6.70276e-05, gnorm=2.829, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=11545
2023-03-15 17:12:11 - progress_bar.py[line:272] - INFO: epoch 017:   1871 / 2004 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=331.6, nsentences=8, sample_size=331.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1054.8, ups=3.18, wpb=331.6, bsz=8, num_updates=33720, lr=6.70175e-05, gnorm=2.778, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=11549
2023-03-15 17:12:14 - progress_bar.py[line:272] - INFO: epoch 017:   1881 / 2004 loss=0.214, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=329.2, nsentences=8, sample_size=329.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1059.6, ups=3.22, wpb=329.2, bsz=8, num_updates=33730, lr=6.70074e-05, gnorm=2.699, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=11552
2023-03-15 17:12:17 - progress_bar.py[line:272] - INFO: epoch 017:   1891 / 2004 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=337.8, nsentences=8, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1091.2, ups=3.23, wpb=337.8, bsz=8, num_updates=33740, lr=6.69973e-05, gnorm=2.911, clip=0, loss_scale=2048, train_wall=3, gb_free=13.8, wall=11555
2023-03-15 17:12:20 - progress_bar.py[line:272] - INFO: epoch 017:   1901 / 2004 loss=0.199, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=346.1, nsentences=8, sample_size=346.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1095.5, ups=3.17, wpb=346.1, bsz=8, num_updates=33750, lr=6.69872e-05, gnorm=2.369, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=11558
2023-03-15 17:12:23 - progress_bar.py[line:272] - INFO: epoch 017:   1911 / 2004 loss=0.217, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=334.7, nsentences=8, sample_size=334.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1070.1, ups=3.2, wpb=334.7, bsz=8, num_updates=33760, lr=6.69772e-05, gnorm=2.645, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=11561
2023-03-15 17:12:26 - progress_bar.py[line:272] - INFO: epoch 017:   1921 / 2004 loss=0.226, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=323.1, nsentences=8, sample_size=323.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1043.6, ups=3.23, wpb=323.1, bsz=8, num_updates=33770, lr=6.69671e-05, gnorm=2.621, clip=0, loss_scale=4096, train_wall=3, gb_free=15.6, wall=11564
2023-03-15 17:12:28 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 17:12:30 - progress_bar.py[line:272] - INFO: epoch 017:   1932 / 2004 loss=0.22, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=320.5, nsentences=8, sample_size=320.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=936.1, ups=2.92, wpb=320.5, bsz=8, num_updates=33780, lr=6.6957e-05, gnorm=2.672, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=11568
2023-03-15 17:12:33 - progress_bar.py[line:272] - INFO: epoch 017:   1942 / 2004 loss=0.215, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=344.6, nsentences=8, sample_size=344.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1094.8, ups=3.18, wpb=344.6, bsz=8, num_updates=33790, lr=6.69469e-05, gnorm=2.502, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=11571
2023-03-15 17:12:36 - progress_bar.py[line:272] - INFO: epoch 017:   1952 / 2004 loss=0.214, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=346.9, nsentences=8, sample_size=346.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1084.6, ups=3.13, wpb=346.9, bsz=8, num_updates=33800, lr=6.69368e-05, gnorm=2.526, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=11574
2023-03-15 17:12:39 - progress_bar.py[line:272] - INFO: epoch 017:   1962 / 2004 loss=0.213, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=347.8, nsentences=8, sample_size=347.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1095, ups=3.15, wpb=347.8, bsz=8, num_updates=33810, lr=6.69268e-05, gnorm=2.685, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=11577
2023-03-15 17:12:43 - progress_bar.py[line:272] - INFO: epoch 017:   1972 / 2004 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=371.1, nsentences=8, sample_size=371.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1168.2, ups=3.15, wpb=371.1, bsz=8, num_updates=33820, lr=6.69167e-05, gnorm=2.914, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=11580
2023-03-15 17:12:46 - progress_bar.py[line:272] - INFO: epoch 017:   1982 / 2004 loss=0.215, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=310.5, nsentences=8, sample_size=310.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1004.5, ups=3.24, wpb=310.5, bsz=8, num_updates=33830, lr=6.69066e-05, gnorm=2.704, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=11583
2023-03-15 17:12:49 - progress_bar.py[line:272] - INFO: epoch 017:   1992 / 2004 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=368.5, nsentences=8, sample_size=368.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1167.8, ups=3.17, wpb=368.5, bsz=8, num_updates=33840, lr=6.68965e-05, gnorm=2.798, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=11586
2023-03-15 17:12:52 - progress_bar.py[line:272] - INFO: epoch 017:   2002 / 2004 loss=0.222, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=373.6, nsentences=8, sample_size=373.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1207.8, ups=3.23, wpb=373.6, bsz=8, num_updates=33850, lr=6.68864e-05, gnorm=2.687, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=11590
2023-03-15 17:12:53 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 17 @ 33852 updates
2023-03-15 17:12:53 - trainer.py[line:431] - INFO: Saving checkpoint to ./checkpoints/checkpoint17.pt
2023-03-15 17:12:59 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./checkpoints/checkpoint17.pt
2023-03-15 17:13:02 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./checkpoints/checkpoint17.pt (epoch 17 @ 33852 updates, score None) (writing took 9.15264904126525 seconds)
2023-03-15 17:13:02 - train.py[line:332] - INFO: end of epoch 17 (average epoch stats below)
2023-03-15 17:13:02 - progress_bar.py[line:282] - INFO: epoch 017 | loss 0.237 | loss_v1 0 | loss_v2 0 | nll_loss 0.237 | ntokens 345.181 | nsentences 7.999 | sample_size 345.181 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.18 | wps 1038.8 | ups 3.01 | wpb 345.2 | bsz 8 | num_updates 33852 | lr 6.68844e-05 | gnorm 2.767 | clip 0 | loss_scale 2048 | train_wall 641 | gb_free 13.9 | wall 11599
2023-03-15 17:13:02 - trainer.py[line:639] - INFO: loading train data for epoch 18
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 row count 8015 total row count 8015
slice_id 0 seek offset 0
2023-03-15 17:13:03 - trainer.py[line:703] - INFO: begin training epoch 18
2023-03-15 17:13:03 - train.py[line:305] - INFO: Start iterating over samples
2023-03-15 17:13:06 - progress_bar.py[line:272] - INFO: epoch 018:      8 / 2004 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=379.4, nsentences=8, sample_size=379.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=278.8, ups=0.73, wpb=379.4, bsz=8, num_updates=33860, lr=6.68763e-05, gnorm=2.879, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=11603
2023-03-15 17:13:09 - progress_bar.py[line:272] - INFO: epoch 018:     18 / 2004 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=330.2, nsentences=8, sample_size=330.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1063, ups=3.22, wpb=330.2, bsz=8, num_updates=33870, lr=6.68663e-05, gnorm=2.881, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=11606
2023-03-15 17:13:12 - progress_bar.py[line:272] - INFO: epoch 018:     28 / 2004 loss=0.221, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=347.2, nsentences=8, sample_size=347.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1105, ups=3.18, wpb=347.2, bsz=8, num_updates=33880, lr=6.68562e-05, gnorm=2.562, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=11609
2023-03-15 17:13:15 - progress_bar.py[line:272] - INFO: epoch 018:     38 / 2004 loss=0.232, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=348.1, nsentences=8, sample_size=348.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1108.1, ups=3.18, wpb=348.1, bsz=8, num_updates=33890, lr=6.68461e-05, gnorm=2.776, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=11613
2023-03-15 17:13:18 - progress_bar.py[line:272] - INFO: epoch 018:     48 / 2004 loss=0.214, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=348.2, nsentences=8, sample_size=348.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1115.7, ups=3.2, wpb=348.2, bsz=8, num_updates=33900, lr=6.6836e-05, gnorm=2.625, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=11616
2023-03-15 17:13:19 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 17:13:21 - progress_bar.py[line:272] - INFO: epoch 018:     59 / 2004 loss=0.231, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=349.8, nsentences=8, sample_size=349.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1024.3, ups=2.93, wpb=349.8, bsz=8, num_updates=33910, lr=6.68259e-05, gnorm=2.782, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=11619
2023-03-15 17:13:25 - progress_bar.py[line:272] - INFO: epoch 018:     69 / 2004 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.254, ntokens=341, nsentences=8, sample_size=341, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1084.9, ups=3.18, wpb=341, bsz=8, num_updates=33920, lr=6.68159e-05, gnorm=2.819, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=11622
2023-03-15 17:13:28 - progress_bar.py[line:272] - INFO: epoch 018:     79 / 2004 loss=0.23, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=322.9, nsentences=8, sample_size=322.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1052.4, ups=3.26, wpb=322.9, bsz=8, num_updates=33930, lr=6.68058e-05, gnorm=2.777, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=11625
2023-03-15 17:13:28 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 17:13:31 - progress_bar.py[line:272] - INFO: epoch 018:     90 / 2004 loss=0.227, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=359.2, nsentences=8, sample_size=359.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1047.6, ups=2.92, wpb=359.2, bsz=8, num_updates=33940, lr=6.67957e-05, gnorm=2.602, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=11629
2023-03-15 17:13:34 - progress_bar.py[line:272] - INFO: epoch 018:    100 / 2004 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=385.5, nsentences=8, sample_size=385.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1216.3, ups=3.16, wpb=385.5, bsz=8, num_updates=33950, lr=6.67856e-05, gnorm=2.778, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=11632
2023-03-15 17:13:37 - progress_bar.py[line:272] - INFO: epoch 018:    110 / 2004 loss=0.228, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=340.3, nsentences=8, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1082.1, ups=3.18, wpb=340.3, bsz=8, num_updates=33960, lr=6.67755e-05, gnorm=2.834, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=11635
2023-03-15 17:13:41 - progress_bar.py[line:272] - INFO: epoch 018:    120 / 2004 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=353, nsentences=8, sample_size=353, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1088.3, ups=3.08, wpb=353, bsz=8, num_updates=33970, lr=6.67655e-05, gnorm=2.979, clip=0, loss_scale=1024, train_wall=3, gb_free=14.2, wall=11638
2023-03-15 17:13:44 - progress_bar.py[line:272] - INFO: epoch 018:    130 / 2004 loss=0.235, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=315.3, nsentences=8, sample_size=315.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=994.2, ups=3.15, wpb=315.3, bsz=8, num_updates=33980, lr=6.67554e-05, gnorm=2.812, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=11641
2023-03-15 17:13:47 - progress_bar.py[line:272] - INFO: epoch 018:    140 / 2004 loss=0.218, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=349.5, nsentences=8, sample_size=349.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1110.6, ups=3.18, wpb=349.5, bsz=8, num_updates=33990, lr=6.67453e-05, gnorm=2.648, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=11645
2023-03-15 17:13:50 - progress_bar.py[line:272] - INFO: epoch 018:    150 / 2004 loss=0.23, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=322.7, nsentences=8, sample_size=322.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1035.3, ups=3.21, wpb=322.7, bsz=8, num_updates=34000, lr=6.67352e-05, gnorm=2.826, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=11648
2023-03-15 17:13:53 - progress_bar.py[line:272] - INFO: epoch 018:    160 / 2004 loss=0.231, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=368.3, nsentences=8, sample_size=368.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1093.4, ups=2.97, wpb=368.3, bsz=8, num_updates=34010, lr=6.67251e-05, gnorm=2.607, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=11651
2023-03-15 17:13:57 - progress_bar.py[line:272] - INFO: epoch 018:    170 / 2004 loss=0.225, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=335.2, nsentences=8, sample_size=335.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=962.7, ups=2.87, wpb=335.2, bsz=8, num_updates=34020, lr=6.67151e-05, gnorm=2.755, clip=0, loss_scale=1024, train_wall=3, gb_free=14.2, wall=11655
2023-03-15 17:14:00 - progress_bar.py[line:272] - INFO: epoch 018:    180 / 2004 loss=0.216, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=332.1, nsentences=8, sample_size=332.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1045.4, ups=3.15, wpb=332.1, bsz=8, num_updates=34030, lr=6.6705e-05, gnorm=2.517, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=11658
2023-03-15 17:14:03 - progress_bar.py[line:272] - INFO: epoch 018:    190 / 2004 loss=0.208, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=322.8, nsentences=8, sample_size=322.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1015.4, ups=3.15, wpb=322.8, bsz=8, num_updates=34040, lr=6.66949e-05, gnorm=2.613, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=11661
2023-03-15 17:14:06 - progress_bar.py[line:272] - INFO: epoch 018:    200 / 2004 loss=0.221, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=329.6, nsentences=8, sample_size=329.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1048.5, ups=3.18, wpb=329.6, bsz=8, num_updates=34050, lr=6.66848e-05, gnorm=2.785, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=11664
2023-03-15 17:14:10 - progress_bar.py[line:272] - INFO: epoch 018:    210 / 2004 loss=0.206, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=335.4, nsentences=8, sample_size=335.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1065.9, ups=3.18, wpb=335.4, bsz=8, num_updates=34060, lr=6.66747e-05, gnorm=2.423, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=11667
2023-03-15 17:14:13 - progress_bar.py[line:272] - INFO: epoch 018:    220 / 2004 loss=0.217, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=338.8, nsentences=8, sample_size=338.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1071.5, ups=3.16, wpb=338.8, bsz=8, num_updates=34070, lr=6.66647e-05, gnorm=2.558, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=11670
2023-03-15 17:14:16 - progress_bar.py[line:272] - INFO: epoch 018:    230 / 2004 loss=0.216, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=320.9, nsentences=8, sample_size=320.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=991.5, ups=3.09, wpb=320.9, bsz=8, num_updates=34080, lr=6.66546e-05, gnorm=2.626, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=11674
2023-03-15 17:14:19 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 17:14:20 - progress_bar.py[line:272] - INFO: epoch 018:    241 / 2004 loss=0.218, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=382.2, nsentences=8, sample_size=382.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1079.6, ups=2.82, wpb=382.2, bsz=8, num_updates=34090, lr=6.66445e-05, gnorm=2.4, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=11677
2023-03-15 17:14:23 - progress_bar.py[line:272] - INFO: epoch 018:    251 / 2004 loss=0.218, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=344.3, nsentences=8, sample_size=344.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1092.2, ups=3.17, wpb=344.3, bsz=8, num_updates=34100, lr=6.66344e-05, gnorm=2.654, clip=0, loss_scale=1024, train_wall=3, gb_free=15.9, wall=11680
2023-03-15 17:14:26 - progress_bar.py[line:272] - INFO: epoch 018:    261 / 2004 loss=0.201, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=348.2, nsentences=8, sample_size=348.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1101.1, ups=3.16, wpb=348.2, bsz=8, num_updates=34110, lr=6.66243e-05, gnorm=2.357, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=11683
2023-03-15 17:14:29 - progress_bar.py[line:272] - INFO: epoch 018:    271 / 2004 loss=0.221, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=342, nsentences=8, sample_size=342, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1099.5, ups=3.21, wpb=342, bsz=8, num_updates=34120, lr=6.66142e-05, gnorm=2.835, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=11687
2023-03-15 17:14:32 - progress_bar.py[line:272] - INFO: epoch 018:    281 / 2004 loss=0.231, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=328.4, nsentences=8, sample_size=328.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1031.4, ups=3.14, wpb=328.4, bsz=8, num_updates=34130, lr=6.66042e-05, gnorm=2.705, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=11690
2023-03-15 17:14:35 - progress_bar.py[line:272] - INFO: epoch 018:    291 / 2004 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.247, ntokens=396.7, nsentences=8, sample_size=396.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1200.7, ups=3.03, wpb=396.7, bsz=8, num_updates=34140, lr=6.65941e-05, gnorm=2.801, clip=0, loss_scale=1024, train_wall=3, gb_free=14, wall=11693
2023-03-15 17:14:39 - progress_bar.py[line:272] - INFO: epoch 018:    301 / 2004 loss=0.233, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=346.9, nsentences=8, sample_size=346.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1097.7, ups=3.16, wpb=346.9, bsz=8, num_updates=34150, lr=6.6584e-05, gnorm=2.72, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=11696
2023-03-15 17:14:42 - progress_bar.py[line:272] - INFO: epoch 018:    311 / 2004 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.238, ntokens=352.9, nsentences=8, sample_size=352.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1089.1, ups=3.09, wpb=352.9, bsz=8, num_updates=34160, lr=6.65739e-05, gnorm=2.657, clip=0, loss_scale=1024, train_wall=3, gb_free=14.1, wall=11699
2023-03-15 17:14:45 - progress_bar.py[line:272] - INFO: epoch 018:    321 / 2004 loss=0.224, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=330, nsentences=8, sample_size=330, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1061, ups=3.22, wpb=330, bsz=8, num_updates=34170, lr=6.65638e-05, gnorm=2.757, clip=0, loss_scale=1024, train_wall=3, gb_free=15.7, wall=11703
2023-03-15 17:14:48 - progress_bar.py[line:272] - INFO: epoch 018:    331 / 2004 loss=0.224, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=337.6, nsentences=8, sample_size=337.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1060, ups=3.14, wpb=337.6, bsz=8, num_updates=34180, lr=6.65538e-05, gnorm=2.731, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=11706
2023-03-15 17:14:51 - progress_bar.py[line:272] - INFO: epoch 018:    341 / 2004 loss=0.226, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=349.5, nsentences=8, sample_size=349.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1080.3, ups=3.09, wpb=349.5, bsz=8, num_updates=34190, lr=6.65437e-05, gnorm=2.601, clip=0, loss_scale=1024, train_wall=3, gb_free=14.2, wall=11709
2023-03-15 17:14:55 - progress_bar.py[line:272] - INFO: epoch 018:    351 / 2004 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=359.7, nsentences=8, sample_size=359.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1099.2, ups=3.06, wpb=359.7, bsz=8, num_updates=34200, lr=6.65336e-05, gnorm=2.995, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=11712
2023-03-15 17:14:58 - progress_bar.py[line:272] - INFO: epoch 018:    361 / 2004 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=355.6, nsentences=8, sample_size=355.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1118.4, ups=3.15, wpb=355.6, bsz=8, num_updates=34210, lr=6.65235e-05, gnorm=2.713, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=11715
2023-03-15 17:15:01 - progress_bar.py[line:272] - INFO: epoch 018:    371 / 2004 loss=0.208, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=330.2, nsentences=8, sample_size=330.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1039.2, ups=3.15, wpb=330.2, bsz=8, num_updates=34220, lr=6.65134e-05, gnorm=2.629, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=11719
2023-03-15 17:15:04 - progress_bar.py[line:272] - INFO: epoch 018:    381 / 2004 loss=0.204, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=314.1, nsentences=8, sample_size=314.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=998.7, ups=3.18, wpb=314.1, bsz=8, num_updates=34230, lr=6.65034e-05, gnorm=2.428, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=11722
2023-03-15 17:15:07 - progress_bar.py[line:272] - INFO: epoch 018:    391 / 2004 loss=0.206, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=351.6, nsentences=8, sample_size=351.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1086.5, ups=3.09, wpb=351.6, bsz=8, num_updates=34240, lr=6.64933e-05, gnorm=2.461, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=11725
2023-03-15 17:15:11 - progress_bar.py[line:272] - INFO: epoch 018:    401 / 2004 loss=0.225, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=371, nsentences=8, sample_size=371, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1197.8, ups=3.23, wpb=371, bsz=8, num_updates=34250, lr=6.64832e-05, gnorm=2.68, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=11728
2023-03-15 17:15:14 - progress_bar.py[line:272] - INFO: epoch 018:    411 / 2004 loss=0.215, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=349.1, nsentences=8, sample_size=349.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1094.3, ups=3.13, wpb=349.1, bsz=8, num_updates=34260, lr=6.64731e-05, gnorm=2.683, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=11731
2023-03-15 17:15:17 - progress_bar.py[line:272] - INFO: epoch 018:    421 / 2004 loss=0.225, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=344.5, nsentences=8, sample_size=344.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1065.3, ups=3.09, wpb=344.5, bsz=8, num_updates=34270, lr=6.6463e-05, gnorm=2.731, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=11735
2023-03-15 17:15:20 - progress_bar.py[line:272] - INFO: epoch 018:    431 / 2004 loss=0.191, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=329.9, nsentences=8, sample_size=329.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1034.6, ups=3.14, wpb=329.9, bsz=8, num_updates=34280, lr=6.6453e-05, gnorm=2.288, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=11738
2023-03-15 17:15:23 - progress_bar.py[line:272] - INFO: epoch 018:    441 / 2004 loss=0.216, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=370.9, nsentences=8, sample_size=370.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1157.7, ups=3.12, wpb=370.9, bsz=8, num_updates=34290, lr=6.64429e-05, gnorm=2.617, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=11741
2023-03-15 17:15:27 - progress_bar.py[line:272] - INFO: epoch 018:    451 / 2004 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=369.6, nsentences=8, sample_size=369.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1145, ups=3.1, wpb=369.6, bsz=8, num_updates=34300, lr=6.64328e-05, gnorm=2.865, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=11744
2023-03-15 17:15:30 - progress_bar.py[line:272] - INFO: epoch 018:    461 / 2004 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=379.4, nsentences=8, sample_size=379.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1195.7, ups=3.15, wpb=379.4, bsz=8, num_updates=34310, lr=6.64227e-05, gnorm=2.833, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=11747
2023-03-15 17:15:33 - progress_bar.py[line:272] - INFO: epoch 018:    471 / 2004 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=356.9, nsentences=8, sample_size=356.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1114.6, ups=3.12, wpb=356.9, bsz=8, num_updates=34320, lr=6.64126e-05, gnorm=2.799, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=11751
2023-03-15 17:15:36 - progress_bar.py[line:272] - INFO: epoch 018:    481 / 2004 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=358.2, nsentences=8, sample_size=358.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1131.8, ups=3.16, wpb=358.2, bsz=8, num_updates=34330, lr=6.64025e-05, gnorm=2.761, clip=0, loss_scale=2048, train_wall=3, gb_free=14, wall=11754
2023-03-15 17:15:40 - progress_bar.py[line:272] - INFO: epoch 018:    491 / 2004 loss=0.226, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=372.5, nsentences=8, sample_size=372.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1093.1, ups=2.93, wpb=372.5, bsz=8, num_updates=34340, lr=6.63925e-05, gnorm=2.757, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=11757
2023-03-15 17:15:43 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 17:15:43 - progress_bar.py[line:272] - INFO: epoch 018:    502 / 2004 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=364.5, nsentences=8, sample_size=364.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=961.4, ups=2.64, wpb=364.5, bsz=8, num_updates=34350, lr=6.63824e-05, gnorm=2.577, clip=0, loss_scale=2048, train_wall=4, gb_free=15.4, wall=11761
2023-03-15 17:15:47 - progress_bar.py[line:272] - INFO: epoch 018:    512 / 2004 loss=0.26, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=347.2, nsentences=8, sample_size=347.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=977.5, ups=2.82, wpb=347.2, bsz=8, num_updates=34360, lr=6.63723e-05, gnorm=3.159, clip=10, loss_scale=2048, train_wall=3, gb_free=15.3, wall=11764
2023-03-15 17:15:50 - progress_bar.py[line:272] - INFO: epoch 018:    522 / 2004 loss=0.228, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=377.6, nsentences=8, sample_size=377.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1088.4, ups=2.88, wpb=377.6, bsz=8, num_updates=34370, lr=6.63622e-05, gnorm=2.683, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=11768
2023-03-15 17:15:54 - progress_bar.py[line:272] - INFO: epoch 018:    532 / 2004 loss=0.222, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=385.3, nsentences=8, sample_size=385.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1190.5, ups=3.09, wpb=385.3, bsz=8, num_updates=34380, lr=6.63521e-05, gnorm=2.607, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=11771
2023-03-15 17:15:57 - progress_bar.py[line:272] - INFO: epoch 018:    542 / 2004 loss=0.222, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=374.1, nsentences=8, sample_size=374.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1192.6, ups=3.19, wpb=374.1, bsz=8, num_updates=34390, lr=6.63421e-05, gnorm=2.548, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=11774
2023-03-15 17:16:00 - progress_bar.py[line:272] - INFO: epoch 018:    552 / 2004 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=362.2, nsentences=8, sample_size=362.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1138.8, ups=3.14, wpb=362.2, bsz=8, num_updates=34400, lr=6.6332e-05, gnorm=2.783, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=11778
2023-03-15 17:16:03 - progress_bar.py[line:272] - INFO: epoch 018:    562 / 2004 loss=0.225, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=370.4, nsentences=8, sample_size=370.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1170.9, ups=3.16, wpb=370.4, bsz=8, num_updates=34410, lr=6.63219e-05, gnorm=2.756, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=11781
2023-03-15 17:16:06 - progress_bar.py[line:272] - INFO: epoch 018:    572 / 2004 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=359.5, nsentences=7.8, sample_size=359.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1140.3, ups=3.17, wpb=359.5, bsz=7.8, num_updates=34420, lr=6.63118e-05, gnorm=2.739, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=11784
2023-03-15 17:16:09 - progress_bar.py[line:272] - INFO: epoch 018:    582 / 2004 loss=0.264, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=354.6, nsentences=8, sample_size=354.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1096.7, ups=3.09, wpb=354.6, bsz=8, num_updates=34430, lr=6.63017e-05, gnorm=3.047, clip=0, loss_scale=2048, train_wall=3, gb_free=13.7, wall=11787
2023-03-15 17:16:13 - progress_bar.py[line:272] - INFO: epoch 018:    592 / 2004 loss=0.211, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=340.7, nsentences=8, sample_size=340.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1065.3, ups=3.13, wpb=340.7, bsz=8, num_updates=34440, lr=6.62917e-05, gnorm=2.63, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=11790
2023-03-15 17:16:16 - progress_bar.py[line:272] - INFO: epoch 018:    602 / 2004 loss=0.221, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=359.4, nsentences=8, sample_size=359.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1124.9, ups=3.13, wpb=359.4, bsz=8, num_updates=34450, lr=6.62816e-05, gnorm=2.75, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=11793
2023-03-15 17:16:19 - progress_bar.py[line:272] - INFO: epoch 018:    612 / 2004 loss=0.235, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=353.4, nsentences=8, sample_size=353.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1129.1, ups=3.19, wpb=353.4, bsz=8, num_updates=34460, lr=6.62715e-05, gnorm=2.743, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=11797
2023-03-15 17:16:22 - progress_bar.py[line:272] - INFO: epoch 018:    622 / 2004 loss=0.201, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=356.3, nsentences=8, sample_size=356.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1146.2, ups=3.22, wpb=356.3, bsz=8, num_updates=34470, lr=6.62614e-05, gnorm=2.382, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=11800
2023-03-15 17:16:25 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 17:16:26 - progress_bar.py[line:272] - INFO: epoch 018:    633 / 2004 loss=0.215, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=346.4, nsentences=8, sample_size=346.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1005.4, ups=2.9, wpb=346.4, bsz=8, num_updates=34480, lr=6.62513e-05, gnorm=2.677, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=11803
2023-03-15 17:16:29 - progress_bar.py[line:272] - INFO: epoch 018:    643 / 2004 loss=0.216, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=343.6, nsentences=8, sample_size=343.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1078.9, ups=3.14, wpb=343.6, bsz=8, num_updates=34490, lr=6.62413e-05, gnorm=2.904, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=11806
2023-03-15 17:16:32 - progress_bar.py[line:272] - INFO: epoch 018:    653 / 2004 loss=0.222, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=318.7, nsentences=8, sample_size=318.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1024.6, ups=3.21, wpb=318.7, bsz=8, num_updates=34500, lr=6.62312e-05, gnorm=2.724, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=11809
2023-03-15 17:16:35 - progress_bar.py[line:272] - INFO: epoch 018:    663 / 2004 loss=0.222, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=326.4, nsentences=8, sample_size=326.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1001.9, ups=3.07, wpb=326.4, bsz=8, num_updates=34510, lr=6.62211e-05, gnorm=2.703, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=11813
2023-03-15 17:16:38 - progress_bar.py[line:272] - INFO: epoch 018:    673 / 2004 loss=0.222, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=334.1, nsentences=8, sample_size=334.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1048.1, ups=3.14, wpb=334.1, bsz=8, num_updates=34520, lr=6.6211e-05, gnorm=2.646, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=11816
2023-03-15 17:16:41 - progress_bar.py[line:272] - INFO: epoch 018:    683 / 2004 loss=0.224, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=349.2, nsentences=8, sample_size=349.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1104.6, ups=3.16, wpb=349.2, bsz=8, num_updates=34530, lr=6.62009e-05, gnorm=2.686, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=11819
2023-03-15 17:16:45 - progress_bar.py[line:272] - INFO: epoch 018:    693 / 2004 loss=0.214, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=354, nsentences=8, sample_size=354, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1125.7, ups=3.18, wpb=354, bsz=8, num_updates=34540, lr=6.61909e-05, gnorm=2.852, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=11822
2023-03-15 17:16:48 - progress_bar.py[line:272] - INFO: epoch 018:    703 / 2004 loss=0.234, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=328, nsentences=8, sample_size=328, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1030.9, ups=3.14, wpb=328, bsz=8, num_updates=34550, lr=6.61808e-05, gnorm=2.847, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=11825
2023-03-15 17:16:51 - progress_bar.py[line:272] - INFO: epoch 018:    713 / 2004 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=327.8, nsentences=8, sample_size=327.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1037.2, ups=3.16, wpb=327.8, bsz=8, num_updates=34560, lr=6.61707e-05, gnorm=2.856, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=11829
2023-03-15 17:16:54 - progress_bar.py[line:272] - INFO: epoch 018:    723 / 2004 loss=0.236, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=360.9, nsentences=8, sample_size=360.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1110.2, ups=3.08, wpb=360.9, bsz=8, num_updates=34570, lr=6.61606e-05, gnorm=2.683, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=11832
2023-03-15 17:16:57 - progress_bar.py[line:272] - INFO: epoch 018:    733 / 2004 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=356, nsentences=8, sample_size=356, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1125.3, ups=3.16, wpb=356, bsz=8, num_updates=34580, lr=6.61505e-05, gnorm=2.793, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=11835
2023-03-15 17:17:00 - progress_bar.py[line:272] - INFO: epoch 018:    743 / 2004 loss=0.258, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=343.9, nsentences=8, sample_size=343.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=1094.6, ups=3.18, wpb=343.9, bsz=8, num_updates=34590, lr=6.61404e-05, gnorm=2.974, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=11838
2023-03-15 17:17:04 - progress_bar.py[line:272] - INFO: epoch 018:    753 / 2004 loss=0.217, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=341, nsentences=8, sample_size=341, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1077.7, ups=3.16, wpb=341, bsz=8, num_updates=34600, lr=6.61304e-05, gnorm=2.634, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=11841
2023-03-15 17:17:06 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 17:17:07 - progress_bar.py[line:272] - INFO: epoch 018:    764 / 2004 loss=0.218, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=346, nsentences=8, sample_size=346, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1008.6, ups=2.92, wpb=346, bsz=8, num_updates=34610, lr=6.61203e-05, gnorm=2.59, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=11845
2023-03-15 17:17:10 - progress_bar.py[line:272] - INFO: epoch 018:    774 / 2004 loss=0.235, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=378.9, nsentences=8, sample_size=378.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1183.2, ups=3.12, wpb=378.9, bsz=8, num_updates=34620, lr=6.61102e-05, gnorm=2.837, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=11848
2023-03-15 17:17:13 - progress_bar.py[line:272] - INFO: epoch 018:    784 / 2004 loss=0.22, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=332.8, nsentences=8, sample_size=332.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1042.7, ups=3.13, wpb=332.8, bsz=8, num_updates=34630, lr=6.61001e-05, gnorm=2.649, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=11851
2023-03-15 17:17:17 - progress_bar.py[line:272] - INFO: epoch 018:    794 / 2004 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=333.3, nsentences=8, sample_size=333.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1051, ups=3.15, wpb=333.3, bsz=8, num_updates=34640, lr=6.609e-05, gnorm=3.065, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=11854
2023-03-15 17:17:20 - progress_bar.py[line:272] - INFO: epoch 018:    804 / 2004 loss=0.226, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=323.4, nsentences=8, sample_size=323.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1033.7, ups=3.2, wpb=323.4, bsz=8, num_updates=34650, lr=6.608e-05, gnorm=2.757, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=11857
2023-03-15 17:17:23 - progress_bar.py[line:272] - INFO: epoch 018:    814 / 2004 loss=0.223, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=344.4, nsentences=8, sample_size=344.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1079.8, ups=3.14, wpb=344.4, bsz=8, num_updates=34660, lr=6.60699e-05, gnorm=2.584, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=11861
2023-03-15 17:17:26 - progress_bar.py[line:272] - INFO: epoch 018:    824 / 2004 loss=0.224, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=351.7, nsentences=8, sample_size=351.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1117.5, ups=3.18, wpb=351.7, bsz=8, num_updates=34670, lr=6.60598e-05, gnorm=2.813, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=11864
2023-03-15 17:17:29 - progress_bar.py[line:272] - INFO: epoch 018:    834 / 2004 loss=0.194, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=344.3, nsentences=8, sample_size=344.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1090.3, ups=3.17, wpb=344.3, bsz=8, num_updates=34680, lr=6.60497e-05, gnorm=2.351, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=11867
2023-03-15 17:17:32 - progress_bar.py[line:272] - INFO: epoch 018:    844 / 2004 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=356.2, nsentences=8, sample_size=356.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1116.1, ups=3.13, wpb=356.2, bsz=8, num_updates=34690, lr=6.60396e-05, gnorm=2.979, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=11870
2023-03-15 17:17:36 - progress_bar.py[line:272] - INFO: epoch 018:    854 / 2004 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.238, ntokens=366.6, nsentences=8, sample_size=366.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1172, ups=3.2, wpb=366.6, bsz=8, num_updates=34700, lr=6.60296e-05, gnorm=2.82, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=11873
2023-03-15 17:17:39 - progress_bar.py[line:272] - INFO: epoch 018:    864 / 2004 loss=0.235, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=344, nsentences=8, sample_size=344, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1081, ups=3.14, wpb=344, bsz=8, num_updates=34710, lr=6.60195e-05, gnorm=2.795, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=11876
2023-03-15 17:17:42 - progress_bar.py[line:272] - INFO: epoch 018:    874 / 2004 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.24, ntokens=360.6, nsentences=8, sample_size=360.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1133.7, ups=3.14, wpb=360.6, bsz=8, num_updates=34720, lr=6.60094e-05, gnorm=2.808, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=11880
2023-03-15 17:17:45 - progress_bar.py[line:272] - INFO: epoch 018:    884 / 2004 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=306.9, nsentences=8, sample_size=306.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=979.7, ups=3.19, wpb=306.9, bsz=8, num_updates=34730, lr=6.59993e-05, gnorm=2.829, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=11883
2023-03-15 17:17:47 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 17:17:49 - progress_bar.py[line:272] - INFO: epoch 018:    895 / 2004 loss=0.213, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=318.7, nsentences=8, sample_size=318.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=910.9, ups=2.86, wpb=318.7, bsz=8, num_updates=34740, lr=6.59892e-05, gnorm=2.634, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=11886
2023-03-15 17:17:52 - progress_bar.py[line:272] - INFO: epoch 018:    905 / 2004 loss=0.22, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=362.2, nsentences=8, sample_size=362.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1137.8, ups=3.14, wpb=362.2, bsz=8, num_updates=34750, lr=6.59792e-05, gnorm=2.852, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=11889
2023-03-15 17:17:55 - progress_bar.py[line:272] - INFO: epoch 018:    915 / 2004 loss=0.207, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=374.4, nsentences=8, sample_size=374.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1168.7, ups=3.12, wpb=374.4, bsz=8, num_updates=34760, lr=6.59691e-05, gnorm=2.565, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=11893
2023-03-15 17:17:58 - progress_bar.py[line:272] - INFO: epoch 018:    925 / 2004 loss=0.218, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=334, nsentences=8, sample_size=334, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1056.4, ups=3.16, wpb=334, bsz=8, num_updates=34770, lr=6.5959e-05, gnorm=2.637, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=11896
2023-03-15 17:18:01 - progress_bar.py[line:272] - INFO: epoch 018:    935 / 2004 loss=0.227, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=345.2, nsentences=8, sample_size=345.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1083.8, ups=3.14, wpb=345.2, bsz=8, num_updates=34780, lr=6.59489e-05, gnorm=2.655, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=11899
2023-03-15 17:18:04 - progress_bar.py[line:272] - INFO: epoch 018:    945 / 2004 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.247, ntokens=364, nsentences=8, sample_size=364, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1142.7, ups=3.14, wpb=364, bsz=8, num_updates=34790, lr=6.59388e-05, gnorm=3.063, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=11902
2023-03-15 17:18:08 - progress_bar.py[line:272] - INFO: epoch 018:    955 / 2004 loss=0.231, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=342, nsentences=8, sample_size=342, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1087.7, ups=3.18, wpb=342, bsz=8, num_updates=34800, lr=6.59287e-05, gnorm=2.686, clip=0, loss_scale=2048, train_wall=3, gb_free=13.8, wall=11905
2023-03-15 17:18:11 - progress_bar.py[line:272] - INFO: epoch 018:    965 / 2004 loss=0.234, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=374, nsentences=8, sample_size=374, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1193.2, ups=3.19, wpb=374, bsz=8, num_updates=34810, lr=6.59187e-05, gnorm=2.663, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=11908
2023-03-15 17:18:14 - progress_bar.py[line:272] - INFO: epoch 018:    975 / 2004 loss=0.223, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=324.9, nsentences=8, sample_size=324.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1036.5, ups=3.19, wpb=324.9, bsz=8, num_updates=34820, lr=6.59086e-05, gnorm=2.782, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=11912
2023-03-15 17:18:17 - progress_bar.py[line:272] - INFO: epoch 018:    985 / 2004 loss=0.224, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=323.1, nsentences=8, sample_size=323.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1022.9, ups=3.17, wpb=323.1, bsz=8, num_updates=34830, lr=6.58985e-05, gnorm=2.633, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=11915
2023-03-15 17:18:20 - progress_bar.py[line:272] - INFO: epoch 018:    995 / 2004 loss=0.226, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=389.9, nsentences=8, sample_size=389.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1228.1, ups=3.15, wpb=389.9, bsz=8, num_updates=34840, lr=6.58884e-05, gnorm=2.632, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=11918
2023-03-15 17:18:23 - progress_bar.py[line:272] - INFO: epoch 018:   1005 / 2004 loss=0.204, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=312.5, nsentences=8, sample_size=312.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=996, ups=3.19, wpb=312.5, bsz=8, num_updates=34850, lr=6.58783e-05, gnorm=2.508, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=11921
2023-03-15 17:18:27 - progress_bar.py[line:272] - INFO: epoch 018:   1015 / 2004 loss=0.223, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=343.4, nsentences=8, sample_size=343.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1092.3, ups=3.18, wpb=343.4, bsz=8, num_updates=34860, lr=6.58683e-05, gnorm=2.724, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=11924
2023-03-15 17:18:29 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 17:18:30 - progress_bar.py[line:272] - INFO: epoch 018:   1026 / 2004 loss=0.219, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=321.9, nsentences=8, sample_size=321.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=942.5, ups=2.93, wpb=321.9, bsz=8, num_updates=34870, lr=6.58582e-05, gnorm=2.655, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=11928
2023-03-15 17:18:33 - progress_bar.py[line:272] - INFO: epoch 018:   1036 / 2004 loss=0.232, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=319.1, nsentences=8, sample_size=319.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1015, ups=3.18, wpb=319.1, bsz=8, num_updates=34880, lr=6.58481e-05, gnorm=2.681, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=11931
2023-03-15 17:18:36 - progress_bar.py[line:272] - INFO: epoch 018:   1046 / 2004 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=379.8, nsentences=8, sample_size=379.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1196, ups=3.15, wpb=379.8, bsz=8, num_updates=34890, lr=6.5838e-05, gnorm=2.898, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=11934
2023-03-15 17:18:40 - progress_bar.py[line:272] - INFO: epoch 018:   1056 / 2004 loss=0.227, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=349.5, nsentences=8, sample_size=349.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1026.4, ups=2.94, wpb=349.5, bsz=8, num_updates=34900, lr=6.58279e-05, gnorm=2.761, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=11937
2023-03-15 17:18:43 - progress_bar.py[line:272] - INFO: epoch 018:   1066 / 2004 loss=0.222, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=340.9, nsentences=8, sample_size=340.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1068.8, ups=3.14, wpb=340.9, bsz=8, num_updates=34910, lr=6.58179e-05, gnorm=2.669, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=11940
2023-03-15 17:18:46 - progress_bar.py[line:272] - INFO: epoch 018:   1076 / 2004 loss=0.228, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=354.1, nsentences=8, sample_size=354.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1136.5, ups=3.21, wpb=354.1, bsz=8, num_updates=34920, lr=6.58078e-05, gnorm=2.882, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=11944
2023-03-15 17:18:49 - progress_bar.py[line:272] - INFO: epoch 018:   1086 / 2004 loss=0.223, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=377.6, nsentences=8, sample_size=377.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1192.2, ups=3.16, wpb=377.6, bsz=8, num_updates=34930, lr=6.57977e-05, gnorm=2.823, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=11947
2023-03-15 17:18:52 - progress_bar.py[line:272] - INFO: epoch 018:   1096 / 2004 loss=0.23, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=322.8, nsentences=8, sample_size=322.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1056.1, ups=3.27, wpb=322.8, bsz=8, num_updates=34940, lr=6.57876e-05, gnorm=2.726, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=11950
2023-03-15 17:18:55 - progress_bar.py[line:272] - INFO: epoch 018:   1106 / 2004 loss=0.221, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=378.9, nsentences=8, sample_size=378.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1193.3, ups=3.15, wpb=378.9, bsz=8, num_updates=34950, lr=6.57775e-05, gnorm=2.786, clip=0, loss_scale=2048, train_wall=3, gb_free=13.3, wall=11953
2023-03-15 17:18:59 - progress_bar.py[line:272] - INFO: epoch 018:   1116 / 2004 loss=0.224, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=336.3, nsentences=8, sample_size=336.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1074.5, ups=3.2, wpb=336.3, bsz=8, num_updates=34960, lr=6.57675e-05, gnorm=2.677, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=11956
2023-03-15 17:19:02 - progress_bar.py[line:272] - INFO: epoch 018:   1126 / 2004 loss=0.211, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=321.6, nsentences=8, sample_size=321.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1010.8, ups=3.14, wpb=321.6, bsz=8, num_updates=34970, lr=6.57574e-05, gnorm=2.515, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=11959
2023-03-15 17:19:03 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 17:19:05 - progress_bar.py[line:272] - INFO: epoch 018:   1137 / 2004 loss=0.21, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=380.4, nsentences=8, sample_size=380.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1080.8, ups=2.84, wpb=380.4, bsz=8, num_updates=34980, lr=6.57473e-05, gnorm=2.51, clip=0, loss_scale=1024, train_wall=3, gb_free=14.1, wall=11963
2023-03-15 17:19:08 - progress_bar.py[line:272] - INFO: epoch 018:   1147 / 2004 loss=0.21, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=343.7, nsentences=8, sample_size=343.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1076.1, ups=3.13, wpb=343.7, bsz=8, num_updates=34990, lr=6.57372e-05, gnorm=2.477, clip=0, loss_scale=1024, train_wall=3, gb_free=14, wall=11966
2023-03-15 17:19:12 - progress_bar.py[line:272] - INFO: epoch 018:   1157 / 2004 loss=0.225, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=401.4, nsentences=8, sample_size=401.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1257.2, ups=3.13, wpb=401.4, bsz=8, num_updates=35000, lr=6.57271e-05, gnorm=2.522, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=11969
2023-03-15 17:19:15 - progress_bar.py[line:272] - INFO: epoch 018:   1167 / 2004 loss=0.215, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=332.3, nsentences=8, sample_size=332.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1043.9, ups=3.14, wpb=332.3, bsz=8, num_updates=35010, lr=6.57171e-05, gnorm=2.639, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=11972
2023-03-15 17:19:18 - progress_bar.py[line:272] - INFO: epoch 018:   1177 / 2004 loss=0.216, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=370.3, nsentences=8, sample_size=370.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1179.8, ups=3.19, wpb=370.3, bsz=8, num_updates=35020, lr=6.5707e-05, gnorm=2.661, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=11976
2023-03-15 17:19:21 - progress_bar.py[line:272] - INFO: epoch 018:   1187 / 2004 loss=0.2, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=327.9, nsentences=8, sample_size=327.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1037.8, ups=3.17, wpb=327.9, bsz=8, num_updates=35030, lr=6.56969e-05, gnorm=2.341, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=11979
2023-03-15 17:19:24 - progress_bar.py[line:272] - INFO: epoch 018:   1197 / 2004 loss=0.202, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=364.3, nsentences=8, sample_size=364.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1124.2, ups=3.09, wpb=364.3, bsz=8, num_updates=35040, lr=6.56868e-05, gnorm=2.476, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=11982
2023-03-15 17:19:27 - progress_bar.py[line:272] - INFO: epoch 018:   1207 / 2004 loss=0.234, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=289.7, nsentences=8, sample_size=289.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=928.2, ups=3.2, wpb=289.7, bsz=8, num_updates=35050, lr=6.56767e-05, gnorm=2.919, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=11985
2023-03-15 17:19:31 - progress_bar.py[line:272] - INFO: epoch 018:   1217 / 2004 loss=0.218, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=312.2, nsentences=8, sample_size=312.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1012.3, ups=3.24, wpb=312.2, bsz=8, num_updates=35060, lr=6.56666e-05, gnorm=2.576, clip=10, loss_scale=1024, train_wall=3, gb_free=15.9, wall=11988
2023-03-15 17:19:34 - progress_bar.py[line:272] - INFO: epoch 018:   1227 / 2004 loss=0.216, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=321.7, nsentences=8, sample_size=321.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1012, ups=3.15, wpb=321.7, bsz=8, num_updates=35070, lr=6.56566e-05, gnorm=2.714, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=11991
2023-03-15 17:19:37 - progress_bar.py[line:272] - INFO: epoch 018:   1237 / 2004 loss=0.221, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=368.6, nsentences=8, sample_size=368.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1154.7, ups=3.13, wpb=368.6, bsz=8, num_updates=35080, lr=6.56465e-05, gnorm=2.714, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=11995
2023-03-15 17:19:40 - progress_bar.py[line:272] - INFO: epoch 018:   1247 / 2004 loss=0.23, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=340.3, nsentences=8, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1065.7, ups=3.13, wpb=340.3, bsz=8, num_updates=35090, lr=6.56364e-05, gnorm=2.755, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=11998
2023-03-15 17:19:43 - progress_bar.py[line:272] - INFO: epoch 018:   1257 / 2004 loss=0.214, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=354.3, nsentences=8, sample_size=354.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1085.4, ups=3.06, wpb=354.3, bsz=8, num_updates=35100, lr=6.56263e-05, gnorm=2.623, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=12001
2023-03-15 17:19:47 - progress_bar.py[line:272] - INFO: epoch 018:   1267 / 2004 loss=0.206, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=335.2, nsentences=8, sample_size=335.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1056.3, ups=3.15, wpb=335.2, bsz=8, num_updates=35110, lr=6.56162e-05, gnorm=2.643, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=12004
2023-03-15 17:19:50 - progress_bar.py[line:272] - INFO: epoch 018:   1277 / 2004 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.238, ntokens=354.9, nsentences=8, sample_size=354.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1101.6, ups=3.1, wpb=354.9, bsz=8, num_updates=35120, lr=6.56062e-05, gnorm=2.83, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=12007
2023-03-15 17:19:53 - progress_bar.py[line:272] - INFO: epoch 018:   1287 / 2004 loss=0.196, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=321, nsentences=8, sample_size=321, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1010.2, ups=3.15, wpb=321, bsz=8, num_updates=35130, lr=6.55961e-05, gnorm=2.497, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=12011
2023-03-15 17:19:56 - progress_bar.py[line:272] - INFO: epoch 018:   1297 / 2004 loss=0.202, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=306.7, nsentences=8, sample_size=306.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=974.9, ups=3.18, wpb=306.7, bsz=8, num_updates=35140, lr=6.5586e-05, gnorm=2.558, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=12014
2023-03-15 17:19:59 - progress_bar.py[line:272] - INFO: epoch 018:   1307 / 2004 loss=0.223, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=320.1, nsentences=8, sample_size=320.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1022.9, ups=3.2, wpb=320.1, bsz=8, num_updates=35150, lr=6.55759e-05, gnorm=2.503, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=12017
2023-03-15 17:20:02 - progress_bar.py[line:272] - INFO: epoch 018:   1317 / 2004 loss=0.229, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=346, nsentences=8, sample_size=346, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1112.6, ups=3.22, wpb=346, bsz=8, num_updates=35160, lr=6.55658e-05, gnorm=2.767, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=12020
2023-03-15 17:20:05 - progress_bar.py[line:272] - INFO: epoch 018:   1327 / 2004 loss=0.22, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=290, nsentences=8, sample_size=290, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=933, ups=3.22, wpb=290, bsz=8, num_updates=35170, lr=6.55558e-05, gnorm=2.927, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=12023
2023-03-15 17:20:09 - progress_bar.py[line:272] - INFO: epoch 018:   1337 / 2004 loss=0.225, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=371.2, nsentences=8, sample_size=371.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1152.9, ups=3.11, wpb=371.2, bsz=8, num_updates=35180, lr=6.55457e-05, gnorm=2.711, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=12026
2023-03-15 17:20:12 - progress_bar.py[line:272] - INFO: epoch 018:   1347 / 2004 loss=0.201, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=298.5, nsentences=8, sample_size=298.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=954, ups=3.2, wpb=298.5, bsz=8, num_updates=35190, lr=6.55356e-05, gnorm=2.379, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=12029
2023-03-15 17:20:15 - progress_bar.py[line:272] - INFO: epoch 018:   1357 / 2004 loss=0.213, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=321, nsentences=8, sample_size=321, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1053, ups=3.28, wpb=321, bsz=8, num_updates=35200, lr=6.55255e-05, gnorm=2.689, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=12032
2023-03-15 17:20:18 - progress_bar.py[line:272] - INFO: epoch 018:   1367 / 2004 loss=0.202, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=314.9, nsentences=8, sample_size=314.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1017.8, ups=3.23, wpb=314.9, bsz=8, num_updates=35210, lr=6.55154e-05, gnorm=2.532, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=12036
2023-03-15 17:20:21 - progress_bar.py[line:272] - INFO: epoch 018:   1377 / 2004 loss=0.205, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=326, nsentences=8, sample_size=326, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1024.1, ups=3.14, wpb=326, bsz=8, num_updates=35220, lr=6.55054e-05, gnorm=2.572, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=12039
2023-03-15 17:20:24 - progress_bar.py[line:272] - INFO: epoch 018:   1387 / 2004 loss=0.235, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=400.3, nsentences=8, sample_size=400.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1235, ups=3.09, wpb=400.3, bsz=8, num_updates=35230, lr=6.54953e-05, gnorm=2.925, clip=0, loss_scale=4096, train_wall=3, gb_free=14.9, wall=12042
2023-03-15 17:20:27 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 17:20:28 - progress_bar.py[line:272] - INFO: epoch 018:   1398 / 2004 loss=0.199, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=340.8, nsentences=8, sample_size=340.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=986.7, ups=2.9, wpb=340.8, bsz=8, num_updates=35240, lr=6.54852e-05, gnorm=2.396, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=12045
2023-03-15 17:20:31 - progress_bar.py[line:272] - INFO: epoch 018:   1408 / 2004 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.241, ntokens=346, nsentences=8, sample_size=346, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1123.1, ups=3.25, wpb=346, bsz=8, num_updates=35250, lr=6.54751e-05, gnorm=2.791, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=12048
2023-03-15 17:20:34 - progress_bar.py[line:272] - INFO: epoch 018:   1418 / 2004 loss=0.209, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=372.2, nsentences=8, sample_size=372.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1172.4, ups=3.15, wpb=372.2, bsz=8, num_updates=35260, lr=6.5465e-05, gnorm=2.631, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=12052
2023-03-15 17:20:37 - progress_bar.py[line:272] - INFO: epoch 018:   1428 / 2004 loss=0.206, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=309.5, nsentences=8, sample_size=309.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=993.3, ups=3.21, wpb=309.5, bsz=8, num_updates=35270, lr=6.54549e-05, gnorm=2.336, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=12055
2023-03-15 17:20:40 - progress_bar.py[line:272] - INFO: epoch 018:   1438 / 2004 loss=0.231, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=359.9, nsentences=8, sample_size=359.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1128.3, ups=3.14, wpb=359.9, bsz=8, num_updates=35280, lr=6.54449e-05, gnorm=2.999, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=12058
2023-03-15 17:20:43 - progress_bar.py[line:272] - INFO: epoch 018:   1448 / 2004 loss=0.208, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=317.7, nsentences=8, sample_size=317.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1027, ups=3.23, wpb=317.7, bsz=8, num_updates=35290, lr=6.54348e-05, gnorm=2.498, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=12061
2023-03-15 17:20:47 - progress_bar.py[line:272] - INFO: epoch 018:   1458 / 2004 loss=0.212, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=382.4, nsentences=8, sample_size=382.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1163.5, ups=3.04, wpb=382.4, bsz=8, num_updates=35300, lr=6.54247e-05, gnorm=2.64, clip=0, loss_scale=2048, train_wall=3, gb_free=13.7, wall=12064
2023-03-15 17:20:50 - progress_bar.py[line:272] - INFO: epoch 018:   1468 / 2004 loss=0.204, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=394.2, nsentences=8, sample_size=394.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1267.6, ups=3.22, wpb=394.2, bsz=8, num_updates=35310, lr=6.54146e-05, gnorm=2.572, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=12067
2023-03-15 17:20:53 - progress_bar.py[line:272] - INFO: epoch 018:   1478 / 2004 loss=0.235, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=404.3, nsentences=8, sample_size=404.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1264.3, ups=3.13, wpb=404.3, bsz=8, num_updates=35320, lr=6.54045e-05, gnorm=2.936, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=12071
2023-03-15 17:20:56 - progress_bar.py[line:272] - INFO: epoch 018:   1488 / 2004 loss=0.22, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=320.4, nsentences=8, sample_size=320.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1034.4, ups=3.23, wpb=320.4, bsz=8, num_updates=35330, lr=6.53945e-05, gnorm=2.725, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=12074
2023-03-15 17:20:59 - progress_bar.py[line:272] - INFO: epoch 018:   1498 / 2004 loss=0.227, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=342.5, nsentences=8, sample_size=342.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1071.9, ups=3.13, wpb=342.5, bsz=8, num_updates=35340, lr=6.53844e-05, gnorm=2.65, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=12077
2023-03-15 17:21:02 - progress_bar.py[line:272] - INFO: epoch 018:   1508 / 2004 loss=0.224, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=329, nsentences=8, sample_size=329, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1047, ups=3.18, wpb=329, bsz=8, num_updates=35350, lr=6.53743e-05, gnorm=2.508, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=12080
2023-03-15 17:21:06 - progress_bar.py[line:272] - INFO: epoch 018:   1518 / 2004 loss=0.203, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=328.3, nsentences=8, sample_size=328.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1052.2, ups=3.2, wpb=328.3, bsz=8, num_updates=35360, lr=6.53642e-05, gnorm=2.51, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=12083
2023-03-15 17:21:07 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 17:21:09 - progress_bar.py[line:272] - INFO: epoch 018:   1529 / 2004 loss=0.211, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=335.4, nsentences=8, sample_size=335.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=959.9, ups=2.86, wpb=335.4, bsz=8, num_updates=35370, lr=6.53541e-05, gnorm=2.716, clip=0, loss_scale=2048, train_wall=3, gb_free=13.9, wall=12087
2023-03-15 17:21:12 - progress_bar.py[line:272] - INFO: epoch 018:   1539 / 2004 loss=0.216, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=346.3, nsentences=8, sample_size=346.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1103.7, ups=3.19, wpb=346.3, bsz=8, num_updates=35380, lr=6.53441e-05, gnorm=2.372, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=12090
2023-03-15 17:21:15 - progress_bar.py[line:272] - INFO: epoch 018:   1549 / 2004 loss=0.228, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=317.1, nsentences=8, sample_size=317.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1011, ups=3.19, wpb=317.1, bsz=8, num_updates=35390, lr=6.5334e-05, gnorm=2.8, clip=10, loss_scale=2048, train_wall=3, gb_free=15.1, wall=12093
2023-03-15 17:21:19 - progress_bar.py[line:272] - INFO: epoch 018:   1559 / 2004 loss=0.216, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=353.3, nsentences=8, sample_size=353.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1112.3, ups=3.15, wpb=353.3, bsz=8, num_updates=35400, lr=6.53239e-05, gnorm=2.697, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=12096
2023-03-15 17:21:22 - progress_bar.py[line:272] - INFO: epoch 018:   1569 / 2004 loss=0.211, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=325.9, nsentences=8, sample_size=325.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1033.6, ups=3.17, wpb=325.9, bsz=8, num_updates=35410, lr=6.53138e-05, gnorm=2.639, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=12099
2023-03-15 17:21:25 - progress_bar.py[line:272] - INFO: epoch 018:   1579 / 2004 loss=0.222, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=354, nsentences=8, sample_size=354, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1130.1, ups=3.19, wpb=354, bsz=8, num_updates=35420, lr=6.53037e-05, gnorm=2.658, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=12102
2023-03-15 17:21:28 - progress_bar.py[line:272] - INFO: epoch 018:   1589 / 2004 loss=0.211, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=328.2, nsentences=8, sample_size=328.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1051.7, ups=3.2, wpb=328.2, bsz=8, num_updates=35430, lr=6.52937e-05, gnorm=2.517, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=12106
2023-03-15 17:21:31 - progress_bar.py[line:272] - INFO: epoch 018:   1599 / 2004 loss=0.211, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=345.9, nsentences=8, sample_size=345.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1097.9, ups=3.17, wpb=345.9, bsz=8, num_updates=35440, lr=6.52836e-05, gnorm=2.51, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=12109
2023-03-15 17:21:34 - progress_bar.py[line:272] - INFO: epoch 018:   1609 / 2004 loss=0.199, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=336.5, nsentences=8, sample_size=336.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1061.3, ups=3.15, wpb=336.5, bsz=8, num_updates=35450, lr=6.52735e-05, gnorm=2.696, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=12112
2023-03-15 17:21:37 - progress_bar.py[line:272] - INFO: epoch 018:   1619 / 2004 loss=0.216, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=342.5, nsentences=8, sample_size=342.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1076.8, ups=3.14, wpb=342.5, bsz=8, num_updates=35460, lr=6.52634e-05, gnorm=2.657, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=12115
2023-03-15 17:21:41 - progress_bar.py[line:272] - INFO: epoch 018:   1629 / 2004 loss=0.226, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=362.5, nsentences=8, sample_size=362.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1140.9, ups=3.15, wpb=362.5, bsz=8, num_updates=35470, lr=6.52533e-05, gnorm=2.581, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=12118
2023-03-15 17:21:44 - progress_bar.py[line:272] - INFO: epoch 018:   1639 / 2004 loss=0.226, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=328.8, nsentences=8, sample_size=328.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1043.2, ups=3.17, wpb=328.8, bsz=8, num_updates=35480, lr=6.52433e-05, gnorm=2.695, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=12121
2023-03-15 17:21:46 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 17:21:47 - progress_bar.py[line:272] - INFO: epoch 018:   1650 / 2004 loss=0.214, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=323.6, nsentences=8, sample_size=323.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=925.3, ups=2.86, wpb=323.6, bsz=8, num_updates=35490, lr=6.52332e-05, gnorm=2.763, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=12125
2023-03-15 17:21:50 - progress_bar.py[line:272] - INFO: epoch 018:   1660 / 2004 loss=0.207, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=346.7, nsentences=8, sample_size=346.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1081, ups=3.12, wpb=346.7, bsz=8, num_updates=35500, lr=6.52231e-05, gnorm=2.494, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=12128
2023-03-15 17:21:54 - progress_bar.py[line:272] - INFO: epoch 018:   1670 / 2004 loss=0.274, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=352.2, nsentences=8, sample_size=352.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=1095.2, ups=3.11, wpb=352.2, bsz=8, num_updates=35510, lr=6.5213e-05, gnorm=2.99, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=12131
2023-03-15 17:21:57 - progress_bar.py[line:272] - INFO: epoch 018:   1680 / 2004 loss=0.229, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=314, nsentences=8, sample_size=314, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1002, ups=3.19, wpb=314, bsz=8, num_updates=35520, lr=6.52029e-05, gnorm=2.805, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=12134
2023-03-15 17:22:00 - progress_bar.py[line:272] - INFO: epoch 018:   1690 / 2004 loss=0.217, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=347.7, nsentences=8, sample_size=347.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1107.6, ups=3.19, wpb=347.7, bsz=8, num_updates=35530, lr=6.51928e-05, gnorm=2.604, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=12138
2023-03-15 17:22:03 - progress_bar.py[line:272] - INFO: epoch 018:   1700 / 2004 loss=0.214, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=335.8, nsentences=8, sample_size=335.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1057.2, ups=3.15, wpb=335.8, bsz=8, num_updates=35540, lr=6.51828e-05, gnorm=2.705, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=12141
2023-03-15 17:22:07 - progress_bar.py[line:272] - INFO: epoch 018:   1710 / 2004 loss=0.212, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=346.6, nsentences=8, sample_size=346.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1036.5, ups=2.99, wpb=346.6, bsz=8, num_updates=35550, lr=6.51727e-05, gnorm=2.605, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=12144
2023-03-15 17:22:10 - progress_bar.py[line:272] - INFO: epoch 018:   1720 / 2004 loss=0.218, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=379, nsentences=8, sample_size=379, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1204.8, ups=3.18, wpb=379, bsz=8, num_updates=35560, lr=6.51626e-05, gnorm=2.58, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=12147
2023-03-15 17:22:13 - progress_bar.py[line:272] - INFO: epoch 018:   1730 / 2004 loss=0.2, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=379.3, nsentences=8, sample_size=379.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1183.9, ups=3.12, wpb=379.3, bsz=8, num_updates=35570, lr=6.51525e-05, gnorm=2.488, clip=0, loss_scale=1024, train_wall=3, gb_free=14.2, wall=12150
2023-03-15 17:22:16 - progress_bar.py[line:272] - INFO: epoch 018:   1740 / 2004 loss=0.207, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=314.8, nsentences=8, sample_size=314.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1008.5, ups=3.2, wpb=314.8, bsz=8, num_updates=35580, lr=6.51424e-05, gnorm=2.596, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=12154
2023-03-15 17:22:19 - progress_bar.py[line:272] - INFO: epoch 018:   1750 / 2004 loss=0.215, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=357.9, nsentences=8, sample_size=357.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1168, ups=3.26, wpb=357.9, bsz=8, num_updates=35590, lr=6.51324e-05, gnorm=2.688, clip=0, loss_scale=1024, train_wall=3, gb_free=15.9, wall=12157
2023-03-15 17:22:22 - progress_bar.py[line:272] - INFO: epoch 018:   1760 / 2004 loss=0.236, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=325.3, nsentences=8, sample_size=325.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1013.9, ups=3.12, wpb=325.3, bsz=8, num_updates=35600, lr=6.51223e-05, gnorm=3.116, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=12160
2023-03-15 17:22:25 - progress_bar.py[line:272] - INFO: epoch 018:   1770 / 2004 loss=0.221, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=339.2, nsentences=8, sample_size=339.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1061.6, ups=3.13, wpb=339.2, bsz=8, num_updates=35610, lr=6.51122e-05, gnorm=2.849, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=12163
2023-03-15 17:22:29 - progress_bar.py[line:272] - INFO: epoch 018:   1780 / 2004 loss=0.205, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=330.8, nsentences=8, sample_size=330.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1043.3, ups=3.15, wpb=330.8, bsz=8, num_updates=35620, lr=6.51021e-05, gnorm=2.544, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=12166
2023-03-15 17:22:32 - progress_bar.py[line:272] - INFO: epoch 018:   1790 / 2004 loss=0.21, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=306.4, nsentences=8, sample_size=306.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=983.4, ups=3.21, wpb=306.4, bsz=8, num_updates=35630, lr=6.5092e-05, gnorm=2.637, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=12169
2023-03-15 17:22:35 - progress_bar.py[line:272] - INFO: epoch 018:   1800 / 2004 loss=0.229, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=355.2, nsentences=8, sample_size=355.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1129.9, ups=3.18, wpb=355.2, bsz=8, num_updates=35640, lr=6.5082e-05, gnorm=2.754, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=12172
2023-03-15 17:22:38 - progress_bar.py[line:272] - INFO: epoch 018:   1810 / 2004 loss=0.212, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=343.4, nsentences=8, sample_size=343.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1106.7, ups=3.22, wpb=343.4, bsz=8, num_updates=35650, lr=6.50719e-05, gnorm=2.839, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=12176
2023-03-15 17:22:41 - progress_bar.py[line:272] - INFO: epoch 018:   1820 / 2004 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.247, ntokens=350.1, nsentences=8, sample_size=350.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1114.1, ups=3.18, wpb=350.1, bsz=8, num_updates=35660, lr=6.50618e-05, gnorm=2.883, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=12179
2023-03-15 17:22:44 - progress_bar.py[line:272] - INFO: epoch 018:   1830 / 2004 loss=0.217, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=347.9, nsentences=8, sample_size=347.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1070.5, ups=3.08, wpb=347.9, bsz=8, num_updates=35670, lr=6.50517e-05, gnorm=2.563, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=12182
2023-03-15 17:22:48 - progress_bar.py[line:272] - INFO: epoch 018:   1840 / 2004 loss=0.2, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=348.1, nsentences=8, sample_size=348.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1103, ups=3.17, wpb=348.1, bsz=8, num_updates=35680, lr=6.50416e-05, gnorm=2.318, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=12185
2023-03-15 17:22:51 - progress_bar.py[line:272] - INFO: epoch 018:   1850 / 2004 loss=0.221, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=338.2, nsentences=8, sample_size=338.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1059.2, ups=3.13, wpb=338.2, bsz=8, num_updates=35690, lr=6.50316e-05, gnorm=2.759, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=12188
2023-03-15 17:22:54 - progress_bar.py[line:272] - INFO: epoch 018:   1860 / 2004 loss=0.217, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=326.2, nsentences=8, sample_size=326.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1026.8, ups=3.15, wpb=326.2, bsz=8, num_updates=35700, lr=6.50215e-05, gnorm=2.628, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=12192
2023-03-15 17:22:57 - progress_bar.py[line:272] - INFO: epoch 018:   1870 / 2004 loss=0.215, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=343.6, nsentences=8, sample_size=343.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1074.8, ups=3.13, wpb=343.6, bsz=8, num_updates=35710, lr=6.50114e-05, gnorm=2.482, clip=0, loss_scale=2048, train_wall=3, gb_free=13.9, wall=12195
2023-03-15 17:23:00 - progress_bar.py[line:272] - INFO: epoch 018:   1880 / 2004 loss=0.22, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=332, nsentences=8, sample_size=332, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1074, ups=3.24, wpb=332, bsz=8, num_updates=35720, lr=6.50013e-05, gnorm=2.68, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=12198
2023-03-15 17:23:03 - progress_bar.py[line:272] - INFO: epoch 018:   1890 / 2004 loss=0.22, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=323, nsentences=8, sample_size=323, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1038.7, ups=3.22, wpb=323, bsz=8, num_updates=35730, lr=6.49912e-05, gnorm=2.819, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=12201
2023-03-15 17:23:06 - progress_bar.py[line:272] - INFO: epoch 018:   1900 / 2004 loss=0.205, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=352.6, nsentences=8, sample_size=352.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1114.6, ups=3.16, wpb=352.6, bsz=8, num_updates=35740, lr=6.49811e-05, gnorm=2.661, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=12204
2023-03-15 17:23:08 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 17:23:10 - progress_bar.py[line:272] - INFO: epoch 018:   1911 / 2004 loss=0.208, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=334, nsentences=8, sample_size=334, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=972.4, ups=2.91, wpb=334, bsz=8, num_updates=35750, lr=6.49711e-05, gnorm=2.675, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=12208
2023-03-15 17:23:13 - progress_bar.py[line:272] - INFO: epoch 018:   1921 / 2004 loss=0.214, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=323.1, nsentences=8, sample_size=323.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1025.6, ups=3.17, wpb=323.1, bsz=8, num_updates=35760, lr=6.4961e-05, gnorm=2.721, clip=0, loss_scale=2048, train_wall=3, gb_free=15.9, wall=12211
2023-03-15 17:23:16 - progress_bar.py[line:272] - INFO: epoch 018:   1931 / 2004 loss=0.225, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=326.7, nsentences=8, sample_size=326.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1026.1, ups=3.14, wpb=326.7, bsz=8, num_updates=35770, lr=6.49509e-05, gnorm=2.691, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=12214
2023-03-15 17:23:19 - progress_bar.py[line:272] - INFO: epoch 018:   1941 / 2004 loss=0.205, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=341.3, nsentences=8, sample_size=341.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1065.9, ups=3.12, wpb=341.3, bsz=8, num_updates=35780, lr=6.49408e-05, gnorm=2.504, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=12217
2023-03-15 17:23:20 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 17:23:23 - progress_bar.py[line:272] - INFO: epoch 018:   1952 / 2004 loss=0.22, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=350, nsentences=8, sample_size=350, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1006.4, ups=2.88, wpb=350, bsz=8, num_updates=35790, lr=6.49307e-05, gnorm=2.715, clip=0, loss_scale=1024, train_wall=3, gb_free=14.1, wall=12221
2023-03-15 17:23:26 - progress_bar.py[line:272] - INFO: epoch 018:   1962 / 2004 loss=0.2, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=347.8, nsentences=8, sample_size=347.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1092.6, ups=3.14, wpb=347.8, bsz=8, num_updates=35800, lr=6.49207e-05, gnorm=2.585, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=12224
2023-03-15 17:23:29 - progress_bar.py[line:272] - INFO: epoch 018:   1972 / 2004 loss=0.231, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=371.1, nsentences=8, sample_size=371.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1163.9, ups=3.14, wpb=371.1, bsz=8, num_updates=35810, lr=6.49106e-05, gnorm=2.697, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=12227
2023-03-15 17:23:32 - progress_bar.py[line:272] - INFO: epoch 018:   1982 / 2004 loss=0.209, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=310.5, nsentences=8, sample_size=310.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=996.8, ups=3.21, wpb=310.5, bsz=8, num_updates=35820, lr=6.49005e-05, gnorm=2.658, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=12230
2023-03-15 17:23:36 - progress_bar.py[line:272] - INFO: epoch 018:   1992 / 2004 loss=0.213, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=368.5, nsentences=8, sample_size=368.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1147.8, ups=3.11, wpb=368.5, bsz=8, num_updates=35830, lr=6.48904e-05, gnorm=2.646, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=12233
2023-03-15 17:23:39 - progress_bar.py[line:272] - INFO: epoch 018:   2002 / 2004 loss=0.222, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=373.6, nsentences=8, sample_size=373.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1232.5, ups=3.3, wpb=373.6, bsz=8, num_updates=35840, lr=6.48803e-05, gnorm=2.987, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=12236
2023-03-15 17:23:39 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 18 @ 35842 updates
2023-03-15 17:23:39 - trainer.py[line:431] - INFO: Saving checkpoint to ./checkpoints/checkpoint18.pt
2023-03-15 17:23:46 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./checkpoints/checkpoint18.pt
2023-03-15 17:23:48 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./checkpoints/checkpoint18.pt (epoch 18 @ 35842 updates, score None) (writing took 8.609705751761794 seconds)
2023-03-15 17:23:48 - train.py[line:332] - INFO: end of epoch 18 (average epoch stats below)
2023-03-15 17:23:48 - progress_bar.py[line:282] - INFO: epoch 018 | loss 0.223 | loss_v1 0 | loss_v2 0 | nll_loss 0.223 | ntokens 345.352 | nsentences 7.999 | sample_size 345.352 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.17 | wps 1063.5 | ups 3.08 | wpb 345.4 | bsz 8 | num_updates 35842 | lr 6.48783e-05 | gnorm 2.69 | clip 0.2 | loss_scale 1024 | train_wall 626 | gb_free 14.4 | wall 12246
2023-03-15 17:23:48 - trainer.py[line:639] - INFO: loading train data for epoch 19
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 row count 8015 total row count 8015
slice_id 0 seek offset 0
2023-03-15 17:23:49 - trainer.py[line:703] - INFO: begin training epoch 19
2023-03-15 17:23:49 - train.py[line:305] - INFO: Start iterating over samples
2023-03-15 17:23:52 - progress_bar.py[line:272] - INFO: epoch 019:      8 / 2004 loss=0.232, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=379.4, nsentences=8, sample_size=379.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=292.2, ups=0.77, wpb=379.4, bsz=8, num_updates=35850, lr=6.48703e-05, gnorm=2.71, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=12249
2023-03-15 17:23:55 - progress_bar.py[line:272] - INFO: epoch 019:     18 / 2004 loss=0.213, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=330.2, nsentences=8, sample_size=330.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1062.2, ups=3.22, wpb=330.2, bsz=8, num_updates=35860, lr=6.48602e-05, gnorm=2.594, clip=0, loss_scale=1024, train_wall=3, gb_free=14.2, wall=12252
2023-03-15 17:23:58 - progress_bar.py[line:272] - INFO: epoch 019:     28 / 2004 loss=0.213, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=347.2, nsentences=8, sample_size=347.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1115.5, ups=3.21, wpb=347.2, bsz=8, num_updates=35870, lr=6.48501e-05, gnorm=2.631, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=12255
2023-03-15 17:24:01 - progress_bar.py[line:272] - INFO: epoch 019:     38 / 2004 loss=0.229, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=348.1, nsentences=8, sample_size=348.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1105, ups=3.17, wpb=348.1, bsz=8, num_updates=35880, lr=6.484e-05, gnorm=2.705, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=12259
2023-03-15 17:24:04 - progress_bar.py[line:272] - INFO: epoch 019:     48 / 2004 loss=0.208, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=348.2, nsentences=8, sample_size=348.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1086.9, ups=3.12, wpb=348.2, bsz=8, num_updates=35890, lr=6.48299e-05, gnorm=2.486, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=12262
2023-03-15 17:24:07 - progress_bar.py[line:272] - INFO: epoch 019:     58 / 2004 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=359, nsentences=8, sample_size=359, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1155.8, ups=3.22, wpb=359, bsz=8, num_updates=35900, lr=6.48199e-05, gnorm=3.012, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=12265
2023-03-15 17:24:10 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 17:24:11 - progress_bar.py[line:272] - INFO: epoch 019:     69 / 2004 loss=0.221, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=333.2, nsentences=8, sample_size=333.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=971.1, ups=2.91, wpb=333.2, bsz=8, num_updates=35910, lr=6.48098e-05, gnorm=2.478, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=12268
2023-03-15 17:24:14 - progress_bar.py[line:272] - INFO: epoch 019:     79 / 2004 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=322.9, nsentences=8, sample_size=322.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1036.9, ups=3.21, wpb=322.9, bsz=8, num_updates=35920, lr=6.47997e-05, gnorm=2.751, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=12271
2023-03-15 17:24:17 - progress_bar.py[line:272] - INFO: epoch 019:     89 / 2004 loss=0.223, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=364.2, nsentences=8, sample_size=364.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1150.4, ups=3.16, wpb=364.2, bsz=8, num_updates=35930, lr=6.47896e-05, gnorm=2.668, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=12275
2023-03-15 17:24:20 - progress_bar.py[line:272] - INFO: epoch 019:     99 / 2004 loss=0.204, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=380.8, nsentences=8, sample_size=380.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1180.1, ups=3.1, wpb=380.8, bsz=8, num_updates=35940, lr=6.47795e-05, gnorm=2.599, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=12278
2023-03-15 17:24:23 - progress_bar.py[line:272] - INFO: epoch 019:    109 / 2004 loss=0.212, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=341.4, nsentences=8, sample_size=341.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1087.1, ups=3.18, wpb=341.4, bsz=8, num_updates=35950, lr=6.47695e-05, gnorm=2.655, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=12281
2023-03-15 17:24:27 - progress_bar.py[line:272] - INFO: epoch 019:    119 / 2004 loss=0.227, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=347.4, nsentences=8, sample_size=347.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1073.2, ups=3.09, wpb=347.4, bsz=8, num_updates=35960, lr=6.47594e-05, gnorm=2.727, clip=0, loss_scale=1024, train_wall=3, gb_free=12.7, wall=12284
2023-03-15 17:24:30 - progress_bar.py[line:272] - INFO: epoch 019:    129 / 2004 loss=0.225, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=333.8, nsentences=8, sample_size=333.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1066.3, ups=3.19, wpb=333.8, bsz=8, num_updates=35970, lr=6.47493e-05, gnorm=2.892, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=12287
2023-03-15 17:24:33 - progress_bar.py[line:272] - INFO: epoch 019:    139 / 2004 loss=0.229, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=329.9, nsentences=8, sample_size=329.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1081.3, ups=3.28, wpb=329.9, bsz=8, num_updates=35980, lr=6.47392e-05, gnorm=2.56, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=12290
2023-03-15 17:24:36 - progress_bar.py[line:272] - INFO: epoch 019:    149 / 2004 loss=0.222, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=322.7, nsentences=8, sample_size=322.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1027.2, ups=3.18, wpb=322.7, bsz=8, num_updates=35990, lr=6.47291e-05, gnorm=2.843, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=12294
2023-03-15 17:24:39 - progress_bar.py[line:272] - INFO: epoch 019:    159 / 2004 loss=0.223, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=377.6, nsentences=8, sample_size=377.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1189.3, ups=3.15, wpb=377.6, bsz=8, num_updates=36000, lr=6.4719e-05, gnorm=2.635, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=12297
2023-03-15 17:24:39 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 19 @ 36000 updates
2023-03-15 17:24:39 - trainer.py[line:431] - INFO: Saving checkpoint to ./checkpoints/checkpoint_19_36000.pt
2023-03-15 17:24:46 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./checkpoints/checkpoint_19_36000.pt
2023-03-15 17:24:49 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./checkpoints/checkpoint_19_36000.pt (epoch 19 @ 36000 updates, score None) (writing took 9.486075904220343 seconds)
2023-03-15 17:24:52 - progress_bar.py[line:272] - INFO: epoch 019:    169 / 2004 loss=0.206, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=326.8, nsentences=8, sample_size=326.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=262.1, ups=0.8, wpb=326.8, bsz=8, num_updates=36010, lr=6.4709e-05, gnorm=2.479, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=12309
2023-03-15 17:24:55 - progress_bar.py[line:272] - INFO: epoch 019:    179 / 2004 loss=0.2, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=323.9, nsentences=8, sample_size=323.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1036.4, ups=3.2, wpb=323.9, bsz=8, num_updates=36020, lr=6.46989e-05, gnorm=2.398, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=12312
2023-03-15 17:24:58 - progress_bar.py[line:272] - INFO: epoch 019:    189 / 2004 loss=0.203, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=338.3, nsentences=8, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1092.9, ups=3.23, wpb=338.3, bsz=8, num_updates=36030, lr=6.46888e-05, gnorm=2.593, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=12315
2023-03-15 17:25:01 - progress_bar.py[line:272] - INFO: epoch 019:    199 / 2004 loss=0.218, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=328.9, nsentences=8, sample_size=328.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1059.2, ups=3.22, wpb=328.9, bsz=8, num_updates=36040, lr=6.46787e-05, gnorm=2.635, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=12319
2023-03-15 17:25:04 - progress_bar.py[line:272] - INFO: epoch 019:    209 / 2004 loss=0.217, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=344, nsentences=8, sample_size=344, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1081.1, ups=3.14, wpb=344, bsz=8, num_updates=36050, lr=6.46686e-05, gnorm=2.768, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=12322
2023-03-15 17:25:07 - progress_bar.py[line:272] - INFO: epoch 019:    219 / 2004 loss=0.204, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=327.8, nsentences=8, sample_size=327.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1044.1, ups=3.19, wpb=327.8, bsz=8, num_updates=36060, lr=6.46586e-05, gnorm=2.541, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=12325
2023-03-15 17:25:10 - progress_bar.py[line:272] - INFO: epoch 019:    229 / 2004 loss=0.194, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=337.7, nsentences=8, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1057.9, ups=3.13, wpb=337.7, bsz=8, num_updates=36070, lr=6.46485e-05, gnorm=2.65, clip=0, loss_scale=2048, train_wall=3, gb_free=13.5, wall=12328
2023-03-15 17:25:14 - progress_bar.py[line:272] - INFO: epoch 019:    239 / 2004 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=384.6, nsentences=8, sample_size=384.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1219.9, ups=3.17, wpb=384.6, bsz=8, num_updates=36080, lr=6.46384e-05, gnorm=2.955, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=12331
2023-03-15 17:25:17 - progress_bar.py[line:272] - INFO: epoch 019:    249 / 2004 loss=0.23, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=346.2, nsentences=8, sample_size=346.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1095, ups=3.16, wpb=346.2, bsz=8, num_updates=36090, lr=6.46283e-05, gnorm=2.927, clip=10, loss_scale=2048, train_wall=3, gb_free=14.1, wall=12334
2023-03-15 17:25:20 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 17:25:20 - progress_bar.py[line:272] - INFO: epoch 019:    260 / 2004 loss=0.233, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=340.7, nsentences=8, sample_size=340.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=974.6, ups=2.86, wpb=340.7, bsz=8, num_updates=36100, lr=6.46182e-05, gnorm=2.781, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=12338
2023-03-15 17:25:23 - progress_bar.py[line:272] - INFO: epoch 019:    270 / 2004 loss=0.214, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=347.4, nsentences=8, sample_size=347.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1106.3, ups=3.18, wpb=347.4, bsz=8, num_updates=36110, lr=6.46082e-05, gnorm=2.559, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=12341
2023-03-15 17:25:26 - progress_bar.py[line:272] - INFO: epoch 019:    280 / 2004 loss=0.214, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=325.3, nsentences=8, sample_size=325.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1102.8, ups=3.39, wpb=325.3, bsz=8, num_updates=36120, lr=6.45981e-05, gnorm=2.696, clip=0, loss_scale=1024, train_wall=3, gb_free=15.7, wall=12344
2023-03-15 17:25:30 - progress_bar.py[line:272] - INFO: epoch 019:    290 / 2004 loss=0.208, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=374.1, nsentences=8, sample_size=374.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1168.1, ups=3.12, wpb=374.1, bsz=8, num_updates=36130, lr=6.4588e-05, gnorm=2.485, clip=0, loss_scale=1024, train_wall=3, gb_free=13.9, wall=12347
2023-03-15 17:25:33 - progress_bar.py[line:272] - INFO: epoch 019:    300 / 2004 loss=0.236, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=366.8, nsentences=8, sample_size=366.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1158.4, ups=3.16, wpb=366.8, bsz=8, num_updates=36140, lr=6.45779e-05, gnorm=2.874, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=12350
2023-03-15 17:25:36 - progress_bar.py[line:272] - INFO: epoch 019:    310 / 2004 loss=0.207, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=343.9, nsentences=8, sample_size=343.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1097.7, ups=3.19, wpb=343.9, bsz=8, num_updates=36150, lr=6.45678e-05, gnorm=2.496, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=12353
2023-03-15 17:25:39 - progress_bar.py[line:272] - INFO: epoch 019:    320 / 2004 loss=0.202, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=346.2, nsentences=8, sample_size=346.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1108.3, ups=3.2, wpb=346.2, bsz=8, num_updates=36160, lr=6.45578e-05, gnorm=2.502, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=12357
2023-03-15 17:25:42 - progress_bar.py[line:272] - INFO: epoch 019:    330 / 2004 loss=0.226, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=336, nsentences=8, sample_size=336, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1090, ups=3.24, wpb=336, bsz=8, num_updates=36170, lr=6.45477e-05, gnorm=2.666, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=12360
2023-03-15 17:25:45 - progress_bar.py[line:272] - INFO: epoch 019:    340 / 2004 loss=0.213, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=335.9, nsentences=8, sample_size=335.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1055.3, ups=3.14, wpb=335.9, bsz=8, num_updates=36180, lr=6.45376e-05, gnorm=2.382, clip=0, loss_scale=1024, train_wall=3, gb_free=15.7, wall=12363
2023-03-15 17:25:48 - progress_bar.py[line:272] - INFO: epoch 019:    350 / 2004 loss=0.213, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=366.8, nsentences=8, sample_size=366.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1153.9, ups=3.15, wpb=366.8, bsz=8, num_updates=36190, lr=6.45275e-05, gnorm=2.356, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=12366
2023-03-15 17:25:52 - progress_bar.py[line:272] - INFO: epoch 019:    360 / 2004 loss=0.231, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=349.9, nsentences=8, sample_size=349.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1101.2, ups=3.15, wpb=349.9, bsz=8, num_updates=36200, lr=6.45174e-05, gnorm=2.72, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=12369
2023-03-15 17:25:55 - progress_bar.py[line:272] - INFO: epoch 019:    370 / 2004 loss=0.207, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=337.5, nsentences=8, sample_size=337.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1069.5, ups=3.17, wpb=337.5, bsz=8, num_updates=36210, lr=6.45073e-05, gnorm=2.56, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=12372
2023-03-15 17:25:58 - progress_bar.py[line:272] - INFO: epoch 019:    380 / 2004 loss=0.176, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=316.2, nsentences=8, sample_size=316.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1005.1, ups=3.18, wpb=316.2, bsz=8, num_updates=36220, lr=6.44973e-05, gnorm=2.215, clip=0, loss_scale=1024, train_wall=3, gb_free=14, wall=12376
2023-03-15 17:26:01 - progress_bar.py[line:272] - INFO: epoch 019:    390 / 2004 loss=0.206, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=354.3, nsentences=8, sample_size=354.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1135, ups=3.2, wpb=354.3, bsz=8, num_updates=36230, lr=6.44872e-05, gnorm=2.562, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=12379
2023-03-15 17:26:04 - progress_bar.py[line:272] - INFO: epoch 019:    400 / 2004 loss=0.224, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=358.4, nsentences=8, sample_size=358.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1140.2, ups=3.18, wpb=358.4, bsz=8, num_updates=36240, lr=6.44771e-05, gnorm=2.721, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=12382
2023-03-15 17:26:08 - progress_bar.py[line:272] - INFO: epoch 019:    410 / 2004 loss=0.215, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=356, nsentences=8, sample_size=356, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=898.2, ups=2.52, wpb=356, bsz=8, num_updates=36250, lr=6.4467e-05, gnorm=2.604, clip=0, loss_scale=2048, train_wall=4, gb_free=14.5, wall=12386
2023-03-15 17:26:11 - progress_bar.py[line:272] - INFO: epoch 019:    420 / 2004 loss=0.196, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=337.1, nsentences=8, sample_size=337.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1062.6, ups=3.15, wpb=337.1, bsz=8, num_updates=36260, lr=6.44569e-05, gnorm=2.437, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=12389
2023-03-15 17:26:14 - progress_bar.py[line:272] - INFO: epoch 019:    430 / 2004 loss=0.201, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=335.9, nsentences=8, sample_size=335.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1069.2, ups=3.18, wpb=335.9, bsz=8, num_updates=36270, lr=6.44469e-05, gnorm=2.528, clip=0, loss_scale=2048, train_wall=3, gb_free=13.7, wall=12392
2023-03-15 17:26:18 - progress_bar.py[line:272] - INFO: epoch 019:    440 / 2004 loss=0.218, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=364.4, nsentences=8, sample_size=364.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1151.2, ups=3.16, wpb=364.4, bsz=8, num_updates=36280, lr=6.44368e-05, gnorm=2.816, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=12395
2023-03-15 17:26:21 - progress_bar.py[line:272] - INFO: epoch 019:    450 / 2004 loss=0.218, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=364.6, nsentences=8, sample_size=364.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1146.8, ups=3.15, wpb=364.6, bsz=8, num_updates=36290, lr=6.44267e-05, gnorm=2.825, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=12398
2023-03-15 17:26:24 - progress_bar.py[line:272] - INFO: epoch 019:    460 / 2004 loss=0.221, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=392.3, nsentences=8, sample_size=392.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1218.7, ups=3.11, wpb=392.3, bsz=8, num_updates=36300, lr=6.44166e-05, gnorm=2.556, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=12402
2023-03-15 17:26:27 - progress_bar.py[line:272] - INFO: epoch 019:    470 / 2004 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=364.1, nsentences=8, sample_size=364.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=1139.5, ups=3.13, wpb=364.1, bsz=8, num_updates=36310, lr=6.44065e-05, gnorm=2.802, clip=0, loss_scale=2048, train_wall=3, gb_free=14, wall=12405
2023-03-15 17:26:28 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 17:26:31 - progress_bar.py[line:272] - INFO: epoch 019:    481 / 2004 loss=0.196, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=334.2, nsentences=8, sample_size=334.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=982.1, ups=2.94, wpb=334.2, bsz=8, num_updates=36320, lr=6.43965e-05, gnorm=2.465, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=12408
2023-03-15 17:26:34 - progress_bar.py[line:272] - INFO: epoch 019:    491 / 2004 loss=0.214, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=372.5, nsentences=8, sample_size=372.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1170.5, ups=3.14, wpb=372.5, bsz=8, num_updates=36330, lr=6.43864e-05, gnorm=2.711, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=12411
2023-03-15 17:26:37 - progress_bar.py[line:272] - INFO: epoch 019:    501 / 2004 loss=0.206, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=364.5, nsentences=8, sample_size=364.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1135.5, ups=3.12, wpb=364.5, bsz=8, num_updates=36340, lr=6.43763e-05, gnorm=2.487, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=12415
2023-03-15 17:26:40 - progress_bar.py[line:272] - INFO: epoch 019:    511 / 2004 loss=0.229, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=351.3, nsentences=8, sample_size=351.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1102.2, ups=3.14, wpb=351.3, bsz=8, num_updates=36350, lr=6.43662e-05, gnorm=2.757, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=12418
2023-03-15 17:26:43 - progress_bar.py[line:272] - INFO: epoch 019:    521 / 2004 loss=0.22, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=364.3, nsentences=8, sample_size=364.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1150.2, ups=3.16, wpb=364.3, bsz=8, num_updates=36360, lr=6.43561e-05, gnorm=2.687, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=12421
2023-03-15 17:26:47 - progress_bar.py[line:272] - INFO: epoch 019:    531 / 2004 loss=0.199, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=394, nsentences=8, sample_size=394, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1242, ups=3.15, wpb=394, bsz=8, num_updates=36370, lr=6.43461e-05, gnorm=2.383, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=12424
2023-03-15 17:26:50 - progress_bar.py[line:272] - INFO: epoch 019:    541 / 2004 loss=0.197, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=375.7, nsentences=8, sample_size=375.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1192.6, ups=3.17, wpb=375.7, bsz=8, num_updates=36380, lr=6.4336e-05, gnorm=2.377, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=12427
2023-03-15 17:26:53 - progress_bar.py[line:272] - INFO: epoch 019:    551 / 2004 loss=0.201, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=364.4, nsentences=8, sample_size=364.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1134.3, ups=3.11, wpb=364.4, bsz=8, num_updates=36390, lr=6.43259e-05, gnorm=2.468, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=12430
2023-03-15 17:26:56 - progress_bar.py[line:272] - INFO: epoch 019:    561 / 2004 loss=0.22, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=367.8, nsentences=8, sample_size=367.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1166.7, ups=3.17, wpb=367.8, bsz=8, num_updates=36400, lr=6.43158e-05, gnorm=2.688, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=12434
2023-03-15 17:26:59 - progress_bar.py[line:272] - INFO: epoch 019:    571 / 2004 loss=0.223, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=372.4, nsentences=8, sample_size=372.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1165.3, ups=3.13, wpb=372.4, bsz=8, num_updates=36410, lr=6.43057e-05, gnorm=2.637, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=12437
2023-03-15 17:27:02 - progress_bar.py[line:272] - INFO: epoch 019:    581 / 2004 loss=0.212, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=348, nsentences=8, sample_size=348, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1107.1, ups=3.18, wpb=348, bsz=8, num_updates=36420, lr=6.42957e-05, gnorm=2.573, clip=0, loss_scale=1024, train_wall=3, gb_free=13, wall=12440
2023-03-15 17:27:06 - progress_bar.py[line:272] - INFO: epoch 019:    591 / 2004 loss=0.21, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=348.9, nsentences=8, sample_size=348.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1105.5, ups=3.17, wpb=348.9, bsz=8, num_updates=36430, lr=6.42856e-05, gnorm=2.668, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=12443
2023-03-15 17:27:09 - progress_bar.py[line:272] - INFO: epoch 019:    601 / 2004 loss=0.21, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=353.9, nsentences=8, sample_size=353.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1096.7, ups=3.1, wpb=353.9, bsz=8, num_updates=36440, lr=6.42755e-05, gnorm=2.675, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=12446
2023-03-15 17:27:12 - progress_bar.py[line:272] - INFO: epoch 019:    611 / 2004 loss=0.204, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=342.4, nsentences=8, sample_size=342.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1083.6, ups=3.16, wpb=342.4, bsz=8, num_updates=36450, lr=6.42654e-05, gnorm=2.394, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=12450
2023-03-15 17:27:15 - progress_bar.py[line:272] - INFO: epoch 019:    621 / 2004 loss=0.193, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=368.3, nsentences=8, sample_size=368.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1159.8, ups=3.15, wpb=368.3, bsz=8, num_updates=36460, lr=6.42553e-05, gnorm=2.503, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=12453
2023-03-15 17:27:18 - progress_bar.py[line:272] - INFO: epoch 019:    631 / 2004 loss=0.205, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=345.4, nsentences=8, sample_size=345.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1104.3, ups=3.2, wpb=345.4, bsz=8, num_updates=36470, lr=6.42452e-05, gnorm=2.66, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=12456
2023-03-15 17:27:21 - progress_bar.py[line:272] - INFO: epoch 019:    641 / 2004 loss=0.231, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=350.2, nsentences=8, sample_size=350.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1090.6, ups=3.11, wpb=350.2, bsz=8, num_updates=36480, lr=6.42352e-05, gnorm=2.794, clip=0, loss_scale=2048, train_wall=3, gb_free=14, wall=12459
2023-03-15 17:27:25 - progress_bar.py[line:272] - INFO: epoch 019:    651 / 2004 loss=0.192, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=309.9, nsentences=8, sample_size=309.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1003.2, ups=3.24, wpb=309.9, bsz=8, num_updates=36490, lr=6.42251e-05, gnorm=2.383, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=12462
2023-03-15 17:27:28 - progress_bar.py[line:272] - INFO: epoch 019:    661 / 2004 loss=0.229, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=339.1, nsentences=8, sample_size=339.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1067.1, ups=3.15, wpb=339.1, bsz=8, num_updates=36500, lr=6.4215e-05, gnorm=2.691, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=12465
2023-03-15 17:27:31 - progress_bar.py[line:272] - INFO: epoch 019:    671 / 2004 loss=0.203, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=323.2, nsentences=8, sample_size=323.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1021.1, ups=3.16, wpb=323.2, bsz=8, num_updates=36510, lr=6.42049e-05, gnorm=2.402, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=12468
2023-03-15 17:27:34 - progress_bar.py[line:272] - INFO: epoch 019:    681 / 2004 loss=0.203, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=343.7, nsentences=8, sample_size=343.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1101.6, ups=3.21, wpb=343.7, bsz=8, num_updates=36520, lr=6.41948e-05, gnorm=2.512, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=12472
2023-03-15 17:27:37 - progress_bar.py[line:272] - INFO: epoch 019:    691 / 2004 loss=0.196, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=353.8, nsentences=8, sample_size=353.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1037.1, ups=2.93, wpb=353.8, bsz=8, num_updates=36530, lr=6.41848e-05, gnorm=2.467, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=12475
2023-03-15 17:27:41 - progress_bar.py[line:272] - INFO: epoch 019:    701 / 2004 loss=0.217, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=335.4, nsentences=8, sample_size=335.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=973.9, ups=2.9, wpb=335.4, bsz=8, num_updates=36540, lr=6.41747e-05, gnorm=2.747, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=12478
2023-03-15 17:27:44 - progress_bar.py[line:272] - INFO: epoch 019:    711 / 2004 loss=0.19, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=335.6, nsentences=8, sample_size=335.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=980.5, ups=2.92, wpb=335.6, bsz=8, num_updates=36550, lr=6.41646e-05, gnorm=2.261, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=12482
2023-03-15 17:27:48 - progress_bar.py[line:272] - INFO: epoch 019:    721 / 2004 loss=0.202, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=351.6, nsentences=8, sample_size=351.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1068.2, ups=3.04, wpb=351.6, bsz=8, num_updates=36560, lr=6.41545e-05, gnorm=2.479, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=12485
2023-03-15 17:27:51 - progress_bar.py[line:272] - INFO: epoch 019:    731 / 2004 loss=0.19, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=356.9, nsentences=8, sample_size=356.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1123.2, ups=3.15, wpb=356.9, bsz=8, num_updates=36570, lr=6.41444e-05, gnorm=2.403, clip=0, loss_scale=4096, train_wall=3, gb_free=15.3, wall=12488
2023-03-15 17:27:52 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 17:27:54 - progress_bar.py[line:272] - INFO: epoch 019:    742 / 2004 loss=0.206, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=334.5, nsentences=8, sample_size=334.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=967.8, ups=2.89, wpb=334.5, bsz=8, num_updates=36580, lr=6.41344e-05, gnorm=2.524, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=12492
2023-03-15 17:27:57 - progress_bar.py[line:272] - INFO: epoch 019:    752 / 2004 loss=0.214, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=346.3, nsentences=8, sample_size=346.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1057.4, ups=3.05, wpb=346.3, bsz=8, num_updates=36590, lr=6.41243e-05, gnorm=2.829, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=12495
2023-03-15 17:28:01 - progress_bar.py[line:272] - INFO: epoch 019:    762 / 2004 loss=0.232, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=343, nsentences=8, sample_size=343, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1056.2, ups=3.08, wpb=343, bsz=8, num_updates=36600, lr=6.41142e-05, gnorm=2.706, clip=0, loss_scale=2048, train_wall=3, gb_free=13.2, wall=12498
2023-03-15 17:28:04 - progress_bar.py[line:272] - INFO: epoch 019:    772 / 2004 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=380.4, nsentences=8, sample_size=380.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1141.8, ups=3, wpb=380.4, bsz=8, num_updates=36610, lr=6.41041e-05, gnorm=2.807, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=12502
2023-03-15 17:28:07 - progress_bar.py[line:272] - INFO: epoch 019:    782 / 2004 loss=0.194, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=337.1, nsentences=8, sample_size=337.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1008.4, ups=2.99, wpb=337.1, bsz=8, num_updates=36620, lr=6.4094e-05, gnorm=2.37, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=12505
2023-03-15 17:28:11 - progress_bar.py[line:272] - INFO: epoch 019:    792 / 2004 loss=0.195, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=340.4, nsentences=8, sample_size=340.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1037.4, ups=3.05, wpb=340.4, bsz=8, num_updates=36630, lr=6.4084e-05, gnorm=2.434, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=12508
2023-03-15 17:28:14 - progress_bar.py[line:272] - INFO: epoch 019:    802 / 2004 loss=0.223, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=328.8, nsentences=8, sample_size=328.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=982.2, ups=2.99, wpb=328.8, bsz=8, num_updates=36640, lr=6.40739e-05, gnorm=2.811, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=12512
2023-03-15 17:28:17 - progress_bar.py[line:272] - INFO: epoch 019:    812 / 2004 loss=0.2, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=342.8, nsentences=8, sample_size=342.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1054.7, ups=3.08, wpb=342.8, bsz=8, num_updates=36650, lr=6.40638e-05, gnorm=2.707, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=12515
2023-03-15 17:28:21 - progress_bar.py[line:272] - INFO: epoch 019:    822 / 2004 loss=0.217, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=340.2, nsentences=8, sample_size=340.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=998.4, ups=2.93, wpb=340.2, bsz=8, num_updates=36660, lr=6.40537e-05, gnorm=2.93, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=12518
2023-03-15 17:28:24 - progress_bar.py[line:272] - INFO: epoch 019:    832 / 2004 loss=0.205, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=348.5, nsentences=8, sample_size=348.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1062.9, ups=3.05, wpb=348.5, bsz=8, num_updates=36670, lr=6.40436e-05, gnorm=2.584, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=12522
2023-03-15 17:28:27 - progress_bar.py[line:272] - INFO: epoch 019:    842 / 2004 loss=0.22, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=359, nsentences=8, sample_size=359, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1063.3, ups=2.96, wpb=359, bsz=8, num_updates=36680, lr=6.40335e-05, gnorm=2.929, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=12525
2023-03-15 17:28:31 - progress_bar.py[line:272] - INFO: epoch 019:    852 / 2004 loss=0.209, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=358.4, nsentences=8, sample_size=358.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1085.9, ups=3.03, wpb=358.4, bsz=8, num_updates=36690, lr=6.40235e-05, gnorm=2.736, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=12528
2023-03-15 17:28:34 - progress_bar.py[line:272] - INFO: epoch 019:    862 / 2004 loss=0.204, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=336.6, nsentences=8, sample_size=336.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=998.7, ups=2.97, wpb=336.6, bsz=8, num_updates=36700, lr=6.40134e-05, gnorm=2.465, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=12532
2023-03-15 17:28:36 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 17:28:38 - progress_bar.py[line:272] - INFO: epoch 019:    873 / 2004 loss=0.216, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=379.7, nsentences=8, sample_size=379.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1022.3, ups=2.69, wpb=379.7, bsz=8, num_updates=36710, lr=6.40033e-05, gnorm=2.635, clip=0, loss_scale=2048, train_wall=4, gb_free=14.3, wall=12535
2023-03-15 17:28:41 - progress_bar.py[line:272] - INFO: epoch 019:    883 / 2004 loss=0.21, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=319, nsentences=8, sample_size=319, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=960.3, ups=3.01, wpb=319, bsz=8, num_updates=36720, lr=6.39932e-05, gnorm=2.611, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=12539
2023-03-15 17:28:44 - progress_bar.py[line:272] - INFO: epoch 019:    893 / 2004 loss=0.212, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=299.1, nsentences=8, sample_size=299.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=893.2, ups=2.99, wpb=299.1, bsz=8, num_updates=36730, lr=6.39831e-05, gnorm=2.742, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=12542
2023-03-15 17:28:48 - progress_bar.py[line:272] - INFO: epoch 019:    903 / 2004 loss=0.209, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=373.1, nsentences=8, sample_size=373.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1112.2, ups=2.98, wpb=373.1, bsz=8, num_updates=36740, lr=6.39731e-05, gnorm=2.659, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=12545
2023-03-15 17:28:51 - progress_bar.py[line:272] - INFO: epoch 019:    913 / 2004 loss=0.209, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=374.1, nsentences=8, sample_size=374.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1125.3, ups=3.01, wpb=374.1, bsz=8, num_updates=36750, lr=6.3963e-05, gnorm=2.488, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=12549
2023-03-15 17:28:54 - progress_bar.py[line:272] - INFO: epoch 019:    923 / 2004 loss=0.207, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=324.4, nsentences=8, sample_size=324.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=978.3, ups=3.02, wpb=324.4, bsz=8, num_updates=36760, lr=6.39529e-05, gnorm=2.659, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=12552
2023-03-15 17:28:58 - progress_bar.py[line:272] - INFO: epoch 019:    933 / 2004 loss=0.203, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=352.4, nsentences=8, sample_size=352.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1078.5, ups=3.06, wpb=352.4, bsz=8, num_updates=36770, lr=6.39428e-05, gnorm=2.544, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=12555
2023-03-15 17:29:01 - progress_bar.py[line:272] - INFO: epoch 019:    943 / 2004 loss=0.199, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=373.2, nsentences=8, sample_size=373.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1127.4, ups=3.02, wpb=373.2, bsz=8, num_updates=36780, lr=6.39327e-05, gnorm=2.637, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=12559
2023-03-15 17:29:04 - progress_bar.py[line:272] - INFO: epoch 019:    953 / 2004 loss=0.198, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=319.8, nsentences=8, sample_size=319.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=974.8, ups=3.05, wpb=319.8, bsz=8, num_updates=36790, lr=6.39227e-05, gnorm=2.477, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=12562
2023-03-15 17:29:08 - progress_bar.py[line:272] - INFO: epoch 019:    963 / 2004 loss=0.221, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=396.1, nsentences=8, sample_size=396.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1170.2, ups=2.95, wpb=396.1, bsz=8, num_updates=36800, lr=6.39126e-05, gnorm=2.68, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=12565
2023-03-15 17:29:11 - progress_bar.py[line:272] - INFO: epoch 019:    973 / 2004 loss=0.214, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=327.1, nsentences=8, sample_size=327.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1004.3, ups=3.07, wpb=327.1, bsz=8, num_updates=36810, lr=6.39025e-05, gnorm=2.508, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=12569
2023-03-15 17:29:14 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 17:29:15 - progress_bar.py[line:272] - INFO: epoch 019:    984 / 2004 loss=0.214, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=309.8, nsentences=8, sample_size=309.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=840, ups=2.71, wpb=309.8, bsz=8, num_updates=36820, lr=6.38924e-05, gnorm=2.769, clip=0, loss_scale=1024, train_wall=4, gb_free=14.3, wall=12572
2023-03-15 17:29:18 - progress_bar.py[line:272] - INFO: epoch 019:    994 / 2004 loss=0.203, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=383.9, nsentences=7.8, sample_size=383.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1152.9, ups=3, wpb=383.9, bsz=7.8, num_updates=36830, lr=6.38823e-05, gnorm=2.552, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=12576
2023-03-15 17:29:21 - progress_bar.py[line:272] - INFO: epoch 019:   1004 / 2004 loss=0.206, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=318.5, nsentences=8, sample_size=318.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=957.4, ups=3.01, wpb=318.5, bsz=8, num_updates=36840, lr=6.38723e-05, gnorm=2.605, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=12579
2023-03-15 17:29:25 - progress_bar.py[line:272] - INFO: epoch 019:   1014 / 2004 loss=0.222, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=337.4, nsentences=8, sample_size=337.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1029.1, ups=3.05, wpb=337.4, bsz=8, num_updates=36850, lr=6.38622e-05, gnorm=2.91, clip=10, loss_scale=1024, train_wall=3, gb_free=15.1, wall=12582
2023-03-15 17:29:28 - progress_bar.py[line:272] - INFO: epoch 019:   1024 / 2004 loss=0.213, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=327.4, nsentences=8, sample_size=327.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=990.9, ups=3.03, wpb=327.4, bsz=8, num_updates=36860, lr=6.38521e-05, gnorm=2.653, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=12585
2023-03-15 17:29:31 - progress_bar.py[line:272] - INFO: epoch 019:   1034 / 2004 loss=0.206, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=305.6, nsentences=8, sample_size=305.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=916.1, ups=3, wpb=305.6, bsz=8, num_updates=36870, lr=6.3842e-05, gnorm=2.57, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=12589
2023-03-15 17:29:35 - progress_bar.py[line:272] - INFO: epoch 019:   1044 / 2004 loss=0.227, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=362.4, nsentences=8, sample_size=362.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1073.4, ups=2.96, wpb=362.4, bsz=8, num_updates=36880, lr=6.38319e-05, gnorm=2.901, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=12592
2023-03-15 17:29:38 - progress_bar.py[line:272] - INFO: epoch 019:   1054 / 2004 loss=0.225, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=381.1, nsentences=8, sample_size=381.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1168.7, ups=3.07, wpb=381.1, bsz=8, num_updates=36890, lr=6.38219e-05, gnorm=2.836, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=12595
2023-03-15 17:29:41 - progress_bar.py[line:272] - INFO: epoch 019:   1064 / 2004 loss=0.219, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=330.9, nsentences=8, sample_size=330.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1029.9, ups=3.11, wpb=330.9, bsz=8, num_updates=36900, lr=6.38118e-05, gnorm=2.68, clip=0, loss_scale=1024, train_wall=3, gb_free=13.9, wall=12599
2023-03-15 17:29:44 - progress_bar.py[line:272] - INFO: epoch 019:   1074 / 2004 loss=0.23, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=344.7, nsentences=8, sample_size=344.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1051.6, ups=3.05, wpb=344.7, bsz=8, num_updates=36910, lr=6.38017e-05, gnorm=2.797, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=12602
2023-03-15 17:29:48 - progress_bar.py[line:272] - INFO: epoch 019:   1084 / 2004 loss=0.222, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=383.1, nsentences=8, sample_size=383.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1139.9, ups=2.98, wpb=383.1, bsz=8, num_updates=36920, lr=6.37916e-05, gnorm=2.798, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=12605
2023-03-15 17:29:51 - progress_bar.py[line:272] - INFO: epoch 019:   1094 / 2004 loss=0.223, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=325.4, nsentences=8, sample_size=325.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=979.6, ups=3.01, wpb=325.4, bsz=8, num_updates=36930, lr=6.37815e-05, gnorm=2.853, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=12609
2023-03-15 17:29:54 - progress_bar.py[line:272] - INFO: epoch 019:   1104 / 2004 loss=0.204, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=370.4, nsentences=8, sample_size=370.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1087.1, ups=2.93, wpb=370.4, bsz=8, num_updates=36940, lr=6.37714e-05, gnorm=2.426, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=12612
2023-03-15 17:29:58 - progress_bar.py[line:272] - INFO: epoch 019:   1114 / 2004 loss=0.199, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=346.4, nsentences=8, sample_size=346.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1087.6, ups=3.14, wpb=346.4, bsz=8, num_updates=36950, lr=6.37614e-05, gnorm=2.433, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=12615
2023-03-15 17:30:01 - progress_bar.py[line:272] - INFO: epoch 019:   1124 / 2004 loss=0.199, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=309.8, nsentences=8, sample_size=309.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=937.1, ups=3.02, wpb=309.8, bsz=8, num_updates=36960, lr=6.37513e-05, gnorm=2.532, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=12618
2023-03-15 17:30:04 - progress_bar.py[line:272] - INFO: epoch 019:   1134 / 2004 loss=0.21, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=394.8, nsentences=8, sample_size=394.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1190, ups=3.01, wpb=394.8, bsz=8, num_updates=36970, lr=6.37412e-05, gnorm=2.605, clip=0, loss_scale=2048, train_wall=3, gb_free=13.9, wall=12622
2023-03-15 17:30:08 - progress_bar.py[line:272] - INFO: epoch 019:   1144 / 2004 loss=0.189, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=338.3, nsentences=8, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1010.9, ups=2.99, wpb=338.3, bsz=8, num_updates=36980, lr=6.37311e-05, gnorm=2.296, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=12625
2023-03-15 17:30:11 - progress_bar.py[line:272] - INFO: epoch 019:   1154 / 2004 loss=0.227, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=391.1, nsentences=8, sample_size=391.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1165, ups=2.98, wpb=391.1, bsz=8, num_updates=36990, lr=6.3721e-05, gnorm=2.663, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=12629
2023-03-15 17:30:14 - progress_bar.py[line:272] - INFO: epoch 019:   1164 / 2004 loss=0.214, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=364.6, nsentences=8, sample_size=364.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1112.2, ups=3.05, wpb=364.6, bsz=8, num_updates=37000, lr=6.3711e-05, gnorm=2.628, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=12632
2023-03-15 17:30:18 - progress_bar.py[line:272] - INFO: epoch 019:   1174 / 2004 loss=0.196, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=356.9, nsentences=8, sample_size=356.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1027.5, ups=2.88, wpb=356.9, bsz=8, num_updates=37010, lr=6.37009e-05, gnorm=2.313, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=12635
2023-03-15 17:30:21 - progress_bar.py[line:272] - INFO: epoch 019:   1184 / 2004 loss=0.198, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=328.1, nsentences=8, sample_size=328.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=959.4, ups=2.92, wpb=328.1, bsz=8, num_updates=37020, lr=6.36908e-05, gnorm=2.643, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=12639
2023-03-15 17:30:25 - progress_bar.py[line:272] - INFO: epoch 019:   1194 / 2004 loss=0.187, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=360.4, nsentences=8, sample_size=360.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1043.2, ups=2.89, wpb=360.4, bsz=8, num_updates=37030, lr=6.36807e-05, gnorm=2.273, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=12642
2023-03-15 17:30:28 - progress_bar.py[line:272] - INFO: epoch 019:   1204 / 2004 loss=0.232, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=313.8, nsentences=8, sample_size=313.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=914.6, ups=2.91, wpb=313.8, bsz=8, num_updates=37040, lr=6.36706e-05, gnorm=2.703, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=12646
2023-03-15 17:30:31 - progress_bar.py[line:272] - INFO: epoch 019:   1214 / 2004 loss=0.213, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=308.1, nsentences=8, sample_size=308.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=897.4, ups=2.91, wpb=308.1, bsz=8, num_updates=37050, lr=6.36606e-05, gnorm=2.46, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=12649
2023-03-15 17:30:35 - progress_bar.py[line:272] - INFO: epoch 019:   1224 / 2004 loss=0.206, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=323.6, nsentences=8, sample_size=323.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=917.5, ups=2.84, wpb=323.6, bsz=8, num_updates=37060, lr=6.36505e-05, gnorm=2.664, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=12653
2023-03-15 17:30:38 - progress_bar.py[line:272] - INFO: epoch 019:   1234 / 2004 loss=0.215, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=326, nsentences=8, sample_size=326, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=947.5, ups=2.91, wpb=326, bsz=8, num_updates=37070, lr=6.36404e-05, gnorm=2.34, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=12656
2023-03-15 17:30:40 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 17:30:42 - progress_bar.py[line:272] - INFO: epoch 019:   1245 / 2004 loss=0.213, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=368.7, nsentences=8, sample_size=368.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=947.2, ups=2.57, wpb=368.7, bsz=8, num_updates=37080, lr=6.36303e-05, gnorm=2.472, clip=0, loss_scale=2048, train_wall=4, gb_free=15.6, wall=12660
2023-03-15 17:30:46 - progress_bar.py[line:272] - INFO: epoch 019:   1255 / 2004 loss=0.195, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=347.9, nsentences=8, sample_size=347.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1002, ups=2.88, wpb=347.9, bsz=8, num_updates=37090, lr=6.36202e-05, gnorm=2.584, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=12663
2023-03-15 17:30:49 - progress_bar.py[line:272] - INFO: epoch 019:   1265 / 2004 loss=0.19, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=331.6, nsentences=8, sample_size=331.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=961.9, ups=2.9, wpb=331.6, bsz=8, num_updates=37100, lr=6.36102e-05, gnorm=2.336, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=12667
2023-03-15 17:30:49 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 17:30:53 - progress_bar.py[line:272] - INFO: epoch 019:   1276 / 2004 loss=0.193, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=348.6, nsentences=8, sample_size=348.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=903.2, ups=2.59, wpb=348.6, bsz=8, num_updates=37110, lr=6.36001e-05, gnorm=2.546, clip=0, loss_scale=1024, train_wall=4, gb_free=14.7, wall=12671
2023-03-15 17:30:56 - progress_bar.py[line:272] - INFO: epoch 019:   1286 / 2004 loss=0.186, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=320.2, nsentences=8, sample_size=320.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=926.4, ups=2.89, wpb=320.2, bsz=8, num_updates=37120, lr=6.359e-05, gnorm=2.423, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=12674
2023-03-15 17:31:00 - progress_bar.py[line:272] - INFO: epoch 019:   1296 / 2004 loss=0.216, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=317.6, nsentences=8, sample_size=317.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=929.9, ups=2.93, wpb=317.6, bsz=8, num_updates=37130, lr=6.35799e-05, gnorm=2.71, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=12678
2023-03-15 17:31:03 - progress_bar.py[line:272] - INFO: epoch 019:   1306 / 2004 loss=0.196, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=306.1, nsentences=8, sample_size=306.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=915.5, ups=2.99, wpb=306.1, bsz=8, num_updates=37140, lr=6.35698e-05, gnorm=2.4, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=12681
2023-03-15 17:31:07 - progress_bar.py[line:272] - INFO: epoch 019:   1316 / 2004 loss=0.221, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=349.7, nsentences=8, sample_size=349.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1010.2, ups=2.89, wpb=349.7, bsz=8, num_updates=37150, lr=6.35597e-05, gnorm=2.835, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=12684
2023-03-15 17:31:10 - progress_bar.py[line:272] - INFO: epoch 019:   1326 / 2004 loss=0.217, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=296, nsentences=8, sample_size=296, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=864.1, ups=2.92, wpb=296, bsz=8, num_updates=37160, lr=6.35497e-05, gnorm=2.622, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=12688
2023-03-15 17:31:14 - progress_bar.py[line:272] - INFO: epoch 019:   1336 / 2004 loss=0.235, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=361.4, nsentences=8, sample_size=361.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1040.3, ups=2.88, wpb=361.4, bsz=8, num_updates=37170, lr=6.35396e-05, gnorm=3.134, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=12691
2023-03-15 17:31:17 - progress_bar.py[line:272] - INFO: epoch 019:   1346 / 2004 loss=0.211, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=297.5, nsentences=8, sample_size=297.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=878, ups=2.95, wpb=297.5, bsz=8, num_updates=37180, lr=6.35295e-05, gnorm=2.761, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=12695
2023-03-15 17:31:20 - progress_bar.py[line:272] - INFO: epoch 019:   1356 / 2004 loss=0.186, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=327.6, nsentences=8, sample_size=327.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=948, ups=2.89, wpb=327.6, bsz=8, num_updates=37190, lr=6.35194e-05, gnorm=2.334, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=12698
2023-03-15 17:31:24 - progress_bar.py[line:272] - INFO: epoch 019:   1366 / 2004 loss=0.213, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=310.3, nsentences=8, sample_size=310.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=907.3, ups=2.92, wpb=310.3, bsz=8, num_updates=37200, lr=6.35093e-05, gnorm=2.751, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=12701
2023-03-15 17:31:27 - progress_bar.py[line:272] - INFO: epoch 019:   1376 / 2004 loss=0.216, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=329.6, nsentences=8, sample_size=329.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1036.6, ups=3.15, wpb=329.6, bsz=8, num_updates=37210, lr=6.34993e-05, gnorm=2.735, clip=0, loss_scale=1024, train_wall=3, gb_free=13.9, wall=12705
2023-03-15 17:31:30 - progress_bar.py[line:272] - INFO: epoch 019:   1386 / 2004 loss=0.202, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=398.5, nsentences=8, sample_size=398.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1213.4, ups=3.04, wpb=398.5, bsz=8, num_updates=37220, lr=6.34892e-05, gnorm=2.635, clip=0, loss_scale=1024, train_wall=3, gb_free=13.9, wall=12708
2023-03-15 17:31:34 - progress_bar.py[line:272] - INFO: epoch 019:   1396 / 2004 loss=0.195, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=344.1, nsentences=8, sample_size=344.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1025.2, ups=2.98, wpb=344.1, bsz=8, num_updates=37230, lr=6.34791e-05, gnorm=2.559, clip=0, loss_scale=2048, train_wall=3, gb_free=13.6, wall=12711
2023-03-15 17:31:37 - progress_bar.py[line:272] - INFO: epoch 019:   1406 / 2004 loss=0.206, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=335, nsentences=8, sample_size=335, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=958.6, ups=2.86, wpb=335, bsz=8, num_updates=37240, lr=6.3469e-05, gnorm=2.607, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=12715
2023-03-15 17:31:41 - progress_bar.py[line:272] - INFO: epoch 019:   1416 / 2004 loss=0.213, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=394.7, nsentences=8, sample_size=394.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1127.9, ups=2.86, wpb=394.7, bsz=8, num_updates=37250, lr=6.34589e-05, gnorm=2.75, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=12718
2023-03-15 17:31:44 - progress_bar.py[line:272] - INFO: epoch 019:   1426 / 2004 loss=0.195, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=282.6, nsentences=8, sample_size=282.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=830.3, ups=2.94, wpb=282.6, bsz=8, num_updates=37260, lr=6.34489e-05, gnorm=2.659, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=12722
2023-03-15 17:31:48 - progress_bar.py[line:272] - INFO: epoch 019:   1436 / 2004 loss=0.222, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=356.9, nsentences=8, sample_size=356.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1034.8, ups=2.9, wpb=356.9, bsz=8, num_updates=37270, lr=6.34388e-05, gnorm=2.88, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=12725
2023-03-15 17:31:51 - progress_bar.py[line:272] - INFO: epoch 019:   1446 / 2004 loss=0.224, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=340.3, nsentences=8, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=986.6, ups=2.9, wpb=340.3, bsz=8, num_updates=37280, lr=6.34287e-05, gnorm=2.542, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=12729
2023-03-15 17:31:55 - progress_bar.py[line:272] - INFO: epoch 019:   1456 / 2004 loss=0.233, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=369.2, nsentences=8, sample_size=369.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1046.2, ups=2.83, wpb=369.2, bsz=8, num_updates=37290, lr=6.34186e-05, gnorm=2.767, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=12732
2023-03-15 17:31:58 - progress_bar.py[line:272] - INFO: epoch 019:   1466 / 2004 loss=0.212, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=393.9, nsentences=8, sample_size=393.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1127, ups=2.86, wpb=393.9, bsz=8, num_updates=37300, lr=6.34085e-05, gnorm=2.544, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=12736
2023-03-15 17:32:02 - progress_bar.py[line:272] - INFO: epoch 019:   1476 / 2004 loss=0.23, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=399.2, nsentences=8, sample_size=399.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1122.8, ups=2.81, wpb=399.2, bsz=8, num_updates=37310, lr=6.33985e-05, gnorm=2.82, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=12739
2023-03-15 17:32:05 - progress_bar.py[line:272] - INFO: epoch 019:   1486 / 2004 loss=0.214, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=351.9, nsentences=8, sample_size=351.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1023.2, ups=2.91, wpb=351.9, bsz=8, num_updates=37320, lr=6.33884e-05, gnorm=2.725, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=12743
2023-03-15 17:32:09 - progress_bar.py[line:272] - INFO: epoch 019:   1496 / 2004 loss=0.218, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=334, nsentences=8, sample_size=334, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=956, ups=2.86, wpb=334, bsz=8, num_updates=37330, lr=6.33783e-05, gnorm=2.689, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=12746
2023-03-15 17:32:12 - progress_bar.py[line:272] - INFO: epoch 019:   1506 / 2004 loss=0.194, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=318.9, nsentences=8, sample_size=318.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=934.4, ups=2.93, wpb=318.9, bsz=8, num_updates=37340, lr=6.33682e-05, gnorm=2.242, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=12750
2023-03-15 17:32:15 - progress_bar.py[line:272] - INFO: epoch 019:   1516 / 2004 loss=0.191, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=327.6, nsentences=8, sample_size=327.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=957.8, ups=2.92, wpb=327.6, bsz=8, num_updates=37350, lr=6.33581e-05, gnorm=2.407, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=12753
2023-03-15 17:32:18 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 17:32:19 - progress_bar.py[line:272] - INFO: epoch 019:   1527 / 2004 loss=0.201, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=334.1, nsentences=8, sample_size=334.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=882.2, ups=2.64, wpb=334.1, bsz=8, num_updates=37360, lr=6.33481e-05, gnorm=2.545, clip=0, loss_scale=2048, train_wall=4, gb_free=15.4, wall=12757
2023-03-15 17:32:23 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 17:32:23 - progress_bar.py[line:272] - INFO: epoch 019:   1538 / 2004 loss=0.214, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=364.1, nsentences=8, sample_size=364.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=954.8, ups=2.62, wpb=364.1, bsz=8, num_updates=37370, lr=6.3338e-05, gnorm=2.379, clip=0, loss_scale=1024, train_wall=4, gb_free=13.8, wall=12761
2023-03-15 17:32:26 - progress_bar.py[line:272] - INFO: epoch 019:   1548 / 2004 loss=0.195, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=310, nsentences=8, sample_size=310, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=928.5, ups=3, wpb=310, bsz=8, num_updates=37380, lr=6.33279e-05, gnorm=2.53, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=12764
2023-03-15 17:32:30 - progress_bar.py[line:272] - INFO: epoch 019:   1558 / 2004 loss=0.233, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=354.8, nsentences=8, sample_size=354.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1033.9, ups=2.91, wpb=354.8, bsz=8, num_updates=37390, lr=6.33178e-05, gnorm=2.813, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=12767
2023-03-15 17:32:33 - progress_bar.py[line:272] - INFO: epoch 019:   1568 / 2004 loss=0.22, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=328.6, nsentences=8, sample_size=328.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=945.3, ups=2.88, wpb=328.6, bsz=8, num_updates=37400, lr=6.33077e-05, gnorm=2.828, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=12771
2023-03-15 17:32:37 - progress_bar.py[line:272] - INFO: epoch 019:   1578 / 2004 loss=0.211, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=359.8, nsentences=8, sample_size=359.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1022.1, ups=2.84, wpb=359.8, bsz=8, num_updates=37410, lr=6.32976e-05, gnorm=2.666, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=12774
2023-03-15 17:32:40 - progress_bar.py[line:272] - INFO: epoch 019:   1588 / 2004 loss=0.183, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=314.3, nsentences=8, sample_size=314.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=926.2, ups=2.95, wpb=314.3, bsz=8, num_updates=37420, lr=6.32876e-05, gnorm=2.193, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=12778
2023-03-15 17:32:44 - progress_bar.py[line:272] - INFO: epoch 019:   1598 / 2004 loss=0.211, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=352.1, nsentences=8, sample_size=352.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=992.7, ups=2.82, wpb=352.1, bsz=8, num_updates=37430, lr=6.32775e-05, gnorm=2.516, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=12781
2023-03-15 17:32:47 - progress_bar.py[line:272] - INFO: epoch 019:   1608 / 2004 loss=0.203, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=336.3, nsentences=8, sample_size=336.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=978.4, ups=2.91, wpb=336.3, bsz=8, num_updates=37440, lr=6.32674e-05, gnorm=2.518, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=12785
2023-03-15 17:32:51 - progress_bar.py[line:272] - INFO: epoch 019:   1618 / 2004 loss=0.202, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=345.6, nsentences=8, sample_size=345.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=983.1, ups=2.84, wpb=345.6, bsz=8, num_updates=37450, lr=6.32573e-05, gnorm=2.567, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=12788
2023-03-15 17:32:54 - progress_bar.py[line:272] - INFO: epoch 019:   1628 / 2004 loss=0.216, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=369.5, nsentences=8, sample_size=369.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1054.9, ups=2.86, wpb=369.5, bsz=8, num_updates=37460, lr=6.32472e-05, gnorm=2.635, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=12792
2023-03-15 17:32:58 - progress_bar.py[line:272] - INFO: epoch 019:   1638 / 2004 loss=0.223, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=319, nsentences=8, sample_size=319, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=916.4, ups=2.87, wpb=319, bsz=8, num_updates=37470, lr=6.32372e-05, gnorm=2.752, clip=0, loss_scale=1024, train_wall=3, gb_free=15.8, wall=12795
2023-03-15 17:33:01 - progress_bar.py[line:272] - INFO: epoch 019:   1648 / 2004 loss=0.196, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=315.7, nsentences=8, sample_size=315.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=910.2, ups=2.88, wpb=315.7, bsz=8, num_updates=37480, lr=6.32271e-05, gnorm=2.461, clip=0, loss_scale=1024, train_wall=3, gb_free=14.2, wall=12799
2023-03-15 17:33:05 - progress_bar.py[line:272] - INFO: epoch 019:   1658 / 2004 loss=0.191, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=343.7, nsentences=8, sample_size=343.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=999.9, ups=2.91, wpb=343.7, bsz=8, num_updates=37490, lr=6.3217e-05, gnorm=2.631, clip=0, loss_scale=1024, train_wall=3, gb_free=15.8, wall=12802
2023-03-15 17:33:08 - progress_bar.py[line:272] - INFO: epoch 019:   1668 / 2004 loss=0.212, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=355, nsentences=8, sample_size=355, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1026.8, ups=2.89, wpb=355, bsz=8, num_updates=37500, lr=6.32069e-05, gnorm=2.718, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=12806
2023-03-15 17:33:11 - progress_bar.py[line:272] - INFO: epoch 019:   1678 / 2004 loss=0.2, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=321.1, nsentences=8, sample_size=321.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=928.6, ups=2.89, wpb=321.1, bsz=8, num_updates=37510, lr=6.31968e-05, gnorm=2.519, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=12809
2023-03-15 17:33:15 - progress_bar.py[line:272] - INFO: epoch 019:   1688 / 2004 loss=0.198, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=341.6, nsentences=8, sample_size=341.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=981.6, ups=2.87, wpb=341.6, bsz=8, num_updates=37520, lr=6.31868e-05, gnorm=2.557, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=12813
2023-03-15 17:33:18 - progress_bar.py[line:272] - INFO: epoch 019:   1698 / 2004 loss=0.197, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=336.2, nsentences=8, sample_size=336.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=973.7, ups=2.9, wpb=336.2, bsz=8, num_updates=37530, lr=6.31767e-05, gnorm=2.511, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=12816
2023-03-15 17:33:22 - progress_bar.py[line:272] - INFO: epoch 019:   1708 / 2004 loss=0.192, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=343.8, nsentences=8, sample_size=343.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=982.3, ups=2.86, wpb=343.8, bsz=8, num_updates=37540, lr=6.31666e-05, gnorm=2.691, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=12819
2023-03-15 17:33:25 - progress_bar.py[line:272] - INFO: epoch 019:   1718 / 2004 loss=0.203, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=379.9, nsentences=8, sample_size=379.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1096.2, ups=2.89, wpb=379.9, bsz=8, num_updates=37550, lr=6.31565e-05, gnorm=2.569, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=12823
2023-03-15 17:33:29 - progress_bar.py[line:272] - INFO: epoch 019:   1728 / 2004 loss=0.199, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=390.8, nsentences=8, sample_size=390.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1123.2, ups=2.87, wpb=390.8, bsz=8, num_updates=37560, lr=6.31464e-05, gnorm=2.629, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=12826
2023-03-15 17:33:32 - progress_bar.py[line:272] - INFO: epoch 019:   1738 / 2004 loss=0.212, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=326.8, nsentences=8, sample_size=326.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=941.4, ups=2.88, wpb=326.8, bsz=8, num_updates=37570, lr=6.31364e-05, gnorm=2.456, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=12830
2023-03-15 17:33:36 - progress_bar.py[line:272] - INFO: epoch 019:   1748 / 2004 loss=0.211, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=348.9, nsentences=8, sample_size=348.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1012.5, ups=2.9, wpb=348.9, bsz=8, num_updates=37580, lr=6.31263e-05, gnorm=2.553, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=12833
2023-03-15 17:33:39 - progress_bar.py[line:272] - INFO: epoch 019:   1758 / 2004 loss=0.218, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=328, nsentences=8, sample_size=328, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=956.9, ups=2.92, wpb=328, bsz=8, num_updates=37590, lr=6.31162e-05, gnorm=2.739, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=12837
2023-03-15 17:33:43 - progress_bar.py[line:272] - INFO: epoch 019:   1768 / 2004 loss=0.191, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=323.1, nsentences=8, sample_size=323.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=946.1, ups=2.93, wpb=323.1, bsz=8, num_updates=37600, lr=6.31061e-05, gnorm=2.394, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=12840
2023-03-15 17:33:46 - progress_bar.py[line:272] - INFO: epoch 019:   1778 / 2004 loss=0.22, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=347.6, nsentences=8, sample_size=347.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1006.8, ups=2.9, wpb=347.6, bsz=8, num_updates=37610, lr=6.3096e-05, gnorm=2.684, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=12844
2023-03-15 17:33:49 - progress_bar.py[line:272] - INFO: epoch 019:   1788 / 2004 loss=0.204, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=297.6, nsentences=8, sample_size=297.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=868.5, ups=2.92, wpb=297.6, bsz=8, num_updates=37620, lr=6.30859e-05, gnorm=2.506, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=12847
2023-03-15 17:33:52 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 17:33:53 - progress_bar.py[line:272] - INFO: epoch 019:   1799 / 2004 loss=0.206, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=338.6, nsentences=8, sample_size=338.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=910.4, ups=2.69, wpb=338.6, bsz=8, num_updates=37630, lr=6.30759e-05, gnorm=2.62, clip=0, loss_scale=2048, train_wall=4, gb_free=14.7, wall=12851
2023-03-15 17:33:55 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 17:33:57 - progress_bar.py[line:272] - INFO: epoch 019:   1810 / 2004 loss=0.227, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=357.2, nsentences=8, sample_size=357.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=973.2, ups=2.72, wpb=357.2, bsz=8, num_updates=37640, lr=6.30658e-05, gnorm=3.008, clip=0, loss_scale=1024, train_wall=4, gb_free=15.2, wall=12854
2023-03-15 17:34:00 - progress_bar.py[line:272] - INFO: epoch 019:   1820 / 2004 loss=0.215, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=350.1, nsentences=8, sample_size=350.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1132.1, ups=3.23, wpb=350.1, bsz=8, num_updates=37650, lr=6.30557e-05, gnorm=2.7, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=12858
2023-03-15 17:34:03 - progress_bar.py[line:272] - INFO: epoch 019:   1830 / 2004 loss=0.196, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=347.9, nsentences=8, sample_size=347.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1080.6, ups=3.11, wpb=347.9, bsz=8, num_updates=37660, lr=6.30456e-05, gnorm=2.439, clip=0, loss_scale=1024, train_wall=3, gb_free=14.1, wall=12861
2023-03-15 17:34:07 - progress_bar.py[line:272] - INFO: epoch 019:   1840 / 2004 loss=0.196, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=348.1, nsentences=8, sample_size=348.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1007.3, ups=2.89, wpb=348.1, bsz=8, num_updates=37670, lr=6.30355e-05, gnorm=2.491, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=12864
2023-03-15 17:34:10 - progress_bar.py[line:272] - INFO: epoch 019:   1850 / 2004 loss=0.207, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=338.2, nsentences=8, sample_size=338.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=992.3, ups=2.93, wpb=338.2, bsz=8, num_updates=37680, lr=6.30255e-05, gnorm=2.657, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=12868
2023-03-15 17:34:13 - progress_bar.py[line:272] - INFO: epoch 019:   1860 / 2004 loss=0.192, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=326.2, nsentences=8, sample_size=326.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=974, ups=2.99, wpb=326.2, bsz=8, num_updates=37690, lr=6.30154e-05, gnorm=2.288, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=12871
2023-03-15 17:34:17 - progress_bar.py[line:272] - INFO: epoch 019:   1870 / 2004 loss=0.231, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=343.6, nsentences=8, sample_size=343.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1059.3, ups=3.08, wpb=343.6, bsz=8, num_updates=37700, lr=6.30053e-05, gnorm=2.509, clip=0, loss_scale=1024, train_wall=3, gb_free=13.9, wall=12874
2023-03-15 17:34:20 - progress_bar.py[line:272] - INFO: epoch 019:   1880 / 2004 loss=0.199, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=332, nsentences=8, sample_size=332, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1034.5, ups=3.12, wpb=332, bsz=8, num_updates=37710, lr=6.29952e-05, gnorm=2.572, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=12877
2023-03-15 17:34:23 - progress_bar.py[line:272] - INFO: epoch 019:   1890 / 2004 loss=0.189, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=323, nsentences=8, sample_size=323, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=991.5, ups=3.07, wpb=323, bsz=8, num_updates=37720, lr=6.29851e-05, gnorm=2.454, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=12881
2023-03-15 17:34:26 - progress_bar.py[line:272] - INFO: epoch 019:   1900 / 2004 loss=0.2, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=352.6, nsentences=8, sample_size=352.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1124.9, ups=3.19, wpb=352.6, bsz=8, num_updates=37730, lr=6.29751e-05, gnorm=2.44, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=12884
2023-03-15 17:34:29 - progress_bar.py[line:272] - INFO: epoch 019:   1910 / 2004 loss=0.203, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=339.3, nsentences=8, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1104, ups=3.25, wpb=339.3, bsz=8, num_updates=37740, lr=6.2965e-05, gnorm=2.53, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=12887
2023-03-15 17:34:32 - progress_bar.py[line:272] - INFO: epoch 019:   1920 / 2004 loss=0.195, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=330.2, nsentences=8, sample_size=330.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1064, ups=3.22, wpb=330.2, bsz=8, num_updates=37750, lr=6.29549e-05, gnorm=2.466, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=12890
2023-03-15 17:34:35 - progress_bar.py[line:272] - INFO: epoch 019:   1930 / 2004 loss=0.213, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=316.2, nsentences=8, sample_size=316.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1040.6, ups=3.29, wpb=316.2, bsz=8, num_updates=37760, lr=6.29448e-05, gnorm=2.737, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=12893
2023-03-15 17:34:39 - progress_bar.py[line:272] - INFO: epoch 019:   1940 / 2004 loss=0.204, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=349.9, nsentences=8, sample_size=349.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1126.5, ups=3.22, wpb=349.9, bsz=8, num_updates=37770, lr=6.29347e-05, gnorm=2.593, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=12896
2023-03-15 17:34:42 - progress_bar.py[line:272] - INFO: epoch 019:   1950 / 2004 loss=0.212, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=337.9, nsentences=8, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1096, ups=3.24, wpb=337.9, bsz=8, num_updates=37780, lr=6.29247e-05, gnorm=2.517, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=12899
2023-03-15 17:34:45 - progress_bar.py[line:272] - INFO: epoch 019:   1960 / 2004 loss=0.182, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=365.6, nsentences=8, sample_size=365.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1181.6, ups=3.23, wpb=365.6, bsz=8, num_updates=37790, lr=6.29146e-05, gnorm=2.514, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=12902
2023-03-15 17:34:47 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 17:34:48 - progress_bar.py[line:272] - INFO: epoch 019:   1971 / 2004 loss=0.205, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=344.9, nsentences=8, sample_size=344.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=939.5, ups=2.72, wpb=344.9, bsz=8, num_updates=37800, lr=6.29045e-05, gnorm=2.433, clip=0, loss_scale=1024, train_wall=4, gb_free=15, wall=12906
2023-03-15 17:34:52 - progress_bar.py[line:272] - INFO: epoch 019:   1981 / 2004 loss=0.218, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=321.6, nsentences=8, sample_size=321.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=911.3, ups=2.83, wpb=321.6, bsz=8, num_updates=37810, lr=6.28944e-05, gnorm=2.896, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=12910
2023-03-15 17:34:56 - progress_bar.py[line:272] - INFO: epoch 019:   1991 / 2004 loss=0.2, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=360.9, nsentences=8, sample_size=360.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1004.9, ups=2.78, wpb=360.9, bsz=8, num_updates=37820, lr=6.28843e-05, gnorm=2.659, clip=0, loss_scale=1024, train_wall=4, gb_free=14.5, wall=12913
2023-03-15 17:34:59 - progress_bar.py[line:272] - INFO: epoch 019:   2001 / 2004 loss=0.227, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=370.4, nsentences=8, sample_size=370.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1124.9, ups=3.04, wpb=370.4, bsz=8, num_updates=37830, lr=6.28743e-05, gnorm=2.703, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=12916
2023-03-15 17:35:00 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 19 @ 37833 updates
2023-03-15 17:35:00 - trainer.py[line:431] - INFO: Saving checkpoint to ./checkpoints/checkpoint19.pt
2023-03-15 17:35:08 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./checkpoints/checkpoint19.pt
2023-03-15 17:35:10 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./checkpoints/checkpoint19.pt (epoch 19 @ 37833 updates, score None) (writing took 10.41284397803247 seconds)
2023-03-15 17:35:10 - train.py[line:332] - INFO: end of epoch 19 (average epoch stats below)
2023-03-15 17:35:10 - progress_bar.py[line:282] - INFO: epoch 019 | loss 0.211 | loss_v1 0 | loss_v2 0 | nll_loss 0.211 | ntokens 345.384 | nsentences 7.999 | sample_size 345.384 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.16 | wps 1007.8 | ups 2.92 | wpb 345.4 | bsz 8 | num_updates 37833 | lr 6.28712e-05 | gnorm 2.607 | clip 0.1 | loss_scale 1024 | train_wall 650 | gb_free 13.9 | wall 12928
2023-03-15 17:35:10 - trainer.py[line:639] - INFO: loading train data for epoch 20
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 row count 8015 total row count 8015
slice_id 0 seek offset 0
2023-03-15 17:35:11 - trainer.py[line:703] - INFO: begin training epoch 20
2023-03-15 17:35:11 - train.py[line:305] - INFO: Start iterating over samples
2023-03-15 17:35:14 - progress_bar.py[line:272] - INFO: epoch 020:      7 / 2004 loss=0.199, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=384.9, nsentences=8, sample_size=384.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=259, ups=0.67, wpb=384.9, bsz=8, num_updates=37840, lr=6.28642e-05, gnorm=2.464, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=12931
2023-03-15 17:35:17 - progress_bar.py[line:272] - INFO: epoch 020:     17 / 2004 loss=0.214, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=320.8, nsentences=8, sample_size=320.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1021.5, ups=3.18, wpb=320.8, bsz=8, num_updates=37850, lr=6.28541e-05, gnorm=2.719, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=12934
2023-03-15 17:35:20 - progress_bar.py[line:272] - INFO: epoch 020:     27 / 2004 loss=0.216, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=357.9, nsentences=8, sample_size=357.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1102.9, ups=3.08, wpb=357.9, bsz=8, num_updates=37860, lr=6.2844e-05, gnorm=2.662, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=12938
2023-03-15 17:35:23 - progress_bar.py[line:272] - INFO: epoch 020:     37 / 2004 loss=0.186, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=347.8, nsentences=8, sample_size=347.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1085.2, ups=3.12, wpb=347.8, bsz=8, num_updates=37870, lr=6.28339e-05, gnorm=2.359, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=12941
2023-03-15 17:35:26 - progress_bar.py[line:272] - INFO: epoch 020:     47 / 2004 loss=0.224, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=350.5, nsentences=8, sample_size=350.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1100.9, ups=3.14, wpb=350.5, bsz=8, num_updates=37880, lr=6.28238e-05, gnorm=2.79, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=12944
2023-03-15 17:35:30 - progress_bar.py[line:272] - INFO: epoch 020:     57 / 2004 loss=0.219, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=360.4, nsentences=8, sample_size=360.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1102.4, ups=3.06, wpb=360.4, bsz=8, num_updates=37890, lr=6.28138e-05, gnorm=2.509, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=12947
2023-03-15 17:35:33 - progress_bar.py[line:272] - INFO: epoch 020:     67 / 2004 loss=0.192, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=328.9, nsentences=8, sample_size=328.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=959.6, ups=2.92, wpb=328.9, bsz=8, num_updates=37900, lr=6.28037e-05, gnorm=2.325, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=12951
2023-03-15 17:35:36 - progress_bar.py[line:272] - INFO: epoch 020:     77 / 2004 loss=0.181, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=336.2, nsentences=8, sample_size=336.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1047.6, ups=3.12, wpb=336.2, bsz=8, num_updates=37910, lr=6.27936e-05, gnorm=2.293, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=12954
2023-03-15 17:35:39 - progress_bar.py[line:272] - INFO: epoch 020:     87 / 2004 loss=0.191, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=353.6, nsentences=8, sample_size=353.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1129.2, ups=3.19, wpb=353.6, bsz=8, num_updates=37920, lr=6.27835e-05, gnorm=2.341, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=12957
2023-03-15 17:35:43 - progress_bar.py[line:272] - INFO: epoch 020:     97 / 2004 loss=0.201, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=371.5, nsentences=8, sample_size=371.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1137.4, ups=3.06, wpb=371.5, bsz=8, num_updates=37930, lr=6.27734e-05, gnorm=2.499, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=12960
2023-03-15 17:35:46 - progress_bar.py[line:272] - INFO: epoch 020:    107 / 2004 loss=0.192, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=363.5, nsentences=8, sample_size=363.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1053, ups=2.9, wpb=363.5, bsz=8, num_updates=37940, lr=6.27634e-05, gnorm=2.546, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=12964
2023-03-15 17:35:50 - progress_bar.py[line:272] - INFO: epoch 020:    117 / 2004 loss=0.197, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=328.6, nsentences=8, sample_size=328.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=959.8, ups=2.92, wpb=328.6, bsz=8, num_updates=37950, lr=6.27533e-05, gnorm=2.514, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=12967
2023-03-15 17:35:53 - progress_bar.py[line:272] - INFO: epoch 020:    127 / 2004 loss=0.194, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=344.5, nsentences=8, sample_size=344.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=997.4, ups=2.9, wpb=344.5, bsz=8, num_updates=37960, lr=6.27432e-05, gnorm=2.439, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=12971
2023-03-15 17:35:56 - progress_bar.py[line:272] - INFO: epoch 020:    137 / 2004 loss=0.189, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=325.1, nsentences=8, sample_size=325.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=951.2, ups=2.93, wpb=325.1, bsz=8, num_updates=37970, lr=6.27331e-05, gnorm=2.394, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=12974
2023-03-15 17:36:00 - progress_bar.py[line:272] - INFO: epoch 020:    147 / 2004 loss=0.182, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=336.8, nsentences=8, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=980.3, ups=2.91, wpb=336.8, bsz=8, num_updates=37980, lr=6.2723e-05, gnorm=2.273, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=12978
2023-03-15 17:36:03 - progress_bar.py[line:272] - INFO: epoch 020:    157 / 2004 loss=0.204, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=342.5, nsentences=8, sample_size=342.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1005.2, ups=2.93, wpb=342.5, bsz=8, num_updates=37990, lr=6.2713e-05, gnorm=2.688, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=12981
2023-03-15 17:36:07 - progress_bar.py[line:272] - INFO: epoch 020:    167 / 2004 loss=0.215, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=351.3, nsentences=8, sample_size=351.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1022.1, ups=2.91, wpb=351.3, bsz=8, num_updates=38000, lr=6.27029e-05, gnorm=2.434, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=12984
2023-03-15 17:36:10 - progress_bar.py[line:272] - INFO: epoch 020:    177 / 2004 loss=0.214, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=336.2, nsentences=8, sample_size=336.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=985.3, ups=2.93, wpb=336.2, bsz=8, num_updates=38010, lr=6.26928e-05, gnorm=2.815, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=12988
2023-03-15 17:36:14 - progress_bar.py[line:272] - INFO: epoch 020:    187 / 2004 loss=0.181, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=330.2, nsentences=8, sample_size=330.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=948, ups=2.87, wpb=330.2, bsz=8, num_updates=38020, lr=6.26827e-05, gnorm=2.22, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=12991
2023-03-15 17:36:17 - progress_bar.py[line:272] - INFO: epoch 020:    197 / 2004 loss=0.202, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=319.2, nsentences=8, sample_size=319.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=907.8, ups=2.84, wpb=319.2, bsz=8, num_updates=38030, lr=6.26726e-05, gnorm=2.524, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=12995
2023-03-15 17:36:21 - progress_bar.py[line:272] - INFO: epoch 020:    207 / 2004 loss=0.208, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=346.4, nsentences=8, sample_size=346.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1029, ups=2.97, wpb=346.4, bsz=8, num_updates=38040, lr=6.26626e-05, gnorm=2.555, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=12998
2023-03-15 17:36:24 - progress_bar.py[line:272] - INFO: epoch 020:    217 / 2004 loss=0.199, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=321.6, nsentences=8, sample_size=321.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=918.2, ups=2.86, wpb=321.6, bsz=8, num_updates=38050, lr=6.26525e-05, gnorm=2.407, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=13002
2023-03-15 17:36:25 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 17:36:28 - progress_bar.py[line:272] - INFO: epoch 020:    228 / 2004 loss=0.178, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=336.6, nsentences=8, sample_size=336.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=891.2, ups=2.65, wpb=336.6, bsz=8, num_updates=38060, lr=6.26424e-05, gnorm=2.263, clip=0, loss_scale=2048, train_wall=4, gb_free=15.5, wall=13005
2023-03-15 17:36:31 - progress_bar.py[line:272] - INFO: epoch 020:    238 / 2004 loss=0.199, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=377.6, nsentences=8, sample_size=377.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1065.2, ups=2.82, wpb=377.6, bsz=8, num_updates=38070, lr=6.26323e-05, gnorm=2.59, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=13009
2023-03-15 17:36:35 - progress_bar.py[line:272] - INFO: epoch 020:    248 / 2004 loss=0.199, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=349.8, nsentences=8, sample_size=349.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=998.8, ups=2.86, wpb=349.8, bsz=8, num_updates=38080, lr=6.26222e-05, gnorm=2.595, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=13012
2023-03-15 17:36:38 - progress_bar.py[line:272] - INFO: epoch 020:    258 / 2004 loss=0.205, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=336.9, nsentences=8, sample_size=336.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=982, ups=2.91, wpb=336.9, bsz=8, num_updates=38090, lr=6.26121e-05, gnorm=2.475, clip=0, loss_scale=2048, train_wall=3, gb_free=13.2, wall=13016
2023-03-15 17:36:42 - progress_bar.py[line:272] - INFO: epoch 020:    268 / 2004 loss=0.189, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=350.4, nsentences=8, sample_size=350.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1043.8, ups=2.98, wpb=350.4, bsz=8, num_updates=38100, lr=6.26021e-05, gnorm=2.414, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=13019
2023-03-15 17:36:45 - progress_bar.py[line:272] - INFO: epoch 020:    278 / 2004 loss=0.203, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=340.4, nsentences=8, sample_size=340.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=973.3, ups=2.86, wpb=340.4, bsz=8, num_updates=38110, lr=6.2592e-05, gnorm=2.668, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=13023
2023-03-15 17:36:49 - progress_bar.py[line:272] - INFO: epoch 020:    288 / 2004 loss=0.199, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=361.1, nsentences=8, sample_size=361.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1030, ups=2.85, wpb=361.1, bsz=8, num_updates=38120, lr=6.25819e-05, gnorm=2.358, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=13026
2023-03-15 17:36:52 - progress_bar.py[line:272] - INFO: epoch 020:    298 / 2004 loss=0.214, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=377.3, nsentences=8, sample_size=377.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1092.7, ups=2.9, wpb=377.3, bsz=8, num_updates=38130, lr=6.25718e-05, gnorm=2.346, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=13030
2023-03-15 17:36:56 - progress_bar.py[line:272] - INFO: epoch 020:    308 / 2004 loss=0.216, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=342.5, nsentences=8, sample_size=342.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1002.4, ups=2.93, wpb=342.5, bsz=8, num_updates=38140, lr=6.25617e-05, gnorm=2.709, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=13033
2023-03-15 17:36:59 - progress_bar.py[line:272] - INFO: epoch 020:    318 / 2004 loss=0.194, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=341.1, nsentences=8, sample_size=341.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1012.8, ups=2.97, wpb=341.1, bsz=8, num_updates=38150, lr=6.25517e-05, gnorm=2.431, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=13037
2023-03-15 17:37:02 - progress_bar.py[line:272] - INFO: epoch 020:    328 / 2004 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=331.4, nsentences=8, sample_size=331.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=970.8, ups=2.93, wpb=331.4, bsz=8, num_updates=38160, lr=6.25416e-05, gnorm=2.332, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=13040
2023-03-15 17:37:06 - progress_bar.py[line:272] - INFO: epoch 020:    338 / 2004 loss=0.203, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=344.4, nsentences=8, sample_size=344.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1004.7, ups=2.92, wpb=344.4, bsz=8, num_updates=38170, lr=6.25315e-05, gnorm=2.458, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=13043
2023-03-15 17:37:09 - progress_bar.py[line:272] - INFO: epoch 020:    348 / 2004 loss=0.192, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=367.8, nsentences=8, sample_size=367.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1069.4, ups=2.91, wpb=367.8, bsz=8, num_updates=38180, lr=6.25214e-05, gnorm=2.664, clip=0, loss_scale=4096, train_wall=3, gb_free=15.2, wall=13047
2023-03-15 17:37:10 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 17:37:13 - progress_bar.py[line:272] - INFO: epoch 020:    359 / 2004 loss=0.178, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=334.9, nsentences=8, sample_size=334.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=876.6, ups=2.62, wpb=334.9, bsz=8, num_updates=38190, lr=6.25113e-05, gnorm=2.2, clip=0, loss_scale=2048, train_wall=4, gb_free=15.2, wall=13051
2023-03-15 17:37:16 - progress_bar.py[line:272] - INFO: epoch 020:    369 / 2004 loss=0.215, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=354.7, nsentences=8, sample_size=354.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1043.8, ups=2.94, wpb=354.7, bsz=8, num_updates=38200, lr=6.25013e-05, gnorm=2.771, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=13054
2023-03-15 17:37:20 - progress_bar.py[line:272] - INFO: epoch 020:    379 / 2004 loss=0.19, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=303.7, nsentences=8, sample_size=303.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=887.6, ups=2.92, wpb=303.7, bsz=8, num_updates=38210, lr=6.24912e-05, gnorm=2.532, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=13057
2023-03-15 17:37:23 - progress_bar.py[line:272] - INFO: epoch 020:    389 / 2004 loss=0.211, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=356.9, nsentences=8, sample_size=356.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1036.3, ups=2.9, wpb=356.9, bsz=8, num_updates=38220, lr=6.24811e-05, gnorm=2.816, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=13061
2023-03-15 17:37:27 - progress_bar.py[line:272] - INFO: epoch 020:    399 / 2004 loss=0.198, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=352.8, nsentences=8, sample_size=352.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1011.9, ups=2.87, wpb=352.8, bsz=8, num_updates=38230, lr=6.2471e-05, gnorm=2.422, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=13064
2023-03-15 17:37:30 - progress_bar.py[line:272] - INFO: epoch 020:    409 / 2004 loss=0.201, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=351.5, nsentences=8, sample_size=351.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1010.1, ups=2.87, wpb=351.5, bsz=8, num_updates=38240, lr=6.24609e-05, gnorm=2.77, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=13068
2023-03-15 17:37:34 - progress_bar.py[line:272] - INFO: epoch 020:    419 / 2004 loss=0.19, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=361.7, nsentences=8, sample_size=361.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1046.2, ups=2.89, wpb=361.7, bsz=8, num_updates=38250, lr=6.24509e-05, gnorm=2.557, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=13071
2023-03-15 17:37:37 - progress_bar.py[line:272] - INFO: epoch 020:    429 / 2004 loss=0.205, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=316.8, nsentences=8, sample_size=316.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=923, ups=2.91, wpb=316.8, bsz=8, num_updates=38260, lr=6.24408e-05, gnorm=2.792, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=13075
2023-03-15 17:37:41 - progress_bar.py[line:272] - INFO: epoch 020:    439 / 2004 loss=0.191, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=368.1, nsentences=8, sample_size=368.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1054.3, ups=2.86, wpb=368.1, bsz=8, num_updates=38270, lr=6.24307e-05, gnorm=2.468, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=13078
2023-03-15 17:37:44 - progress_bar.py[line:272] - INFO: epoch 020:    449 / 2004 loss=0.217, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=377.3, nsentences=8, sample_size=377.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1059.7, ups=2.81, wpb=377.3, bsz=8, num_updates=38280, lr=6.24206e-05, gnorm=2.865, clip=0, loss_scale=2048, train_wall=4, gb_free=14.3, wall=13082
2023-03-15 17:37:48 - progress_bar.py[line:272] - INFO: epoch 020:    459 / 2004 loss=0.204, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=389.4, nsentences=8, sample_size=389.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1120.1, ups=2.88, wpb=389.4, bsz=8, num_updates=38290, lr=6.24105e-05, gnorm=2.556, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=13085
2023-03-15 17:37:51 - progress_bar.py[line:272] - INFO: epoch 020:    469 / 2004 loss=0.217, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=356, nsentences=8, sample_size=356, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1016.3, ups=2.85, wpb=356, bsz=8, num_updates=38300, lr=6.24005e-05, gnorm=2.732, clip=0, loss_scale=2048, train_wall=3, gb_free=13.9, wall=13089
2023-03-15 17:37:52 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 17:37:55 - progress_bar.py[line:272] - INFO: epoch 020:    480 / 2004 loss=0.185, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=331.7, nsentences=8, sample_size=331.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=892.3, ups=2.69, wpb=331.7, bsz=8, num_updates=38310, lr=6.23904e-05, gnorm=2.534, clip=0, loss_scale=1024, train_wall=4, gb_free=15, wall=13092
2023-03-15 17:37:58 - progress_bar.py[line:272] - INFO: epoch 020:    490 / 2004 loss=0.202, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=370.7, nsentences=8, sample_size=370.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1061.9, ups=2.86, wpb=370.7, bsz=8, num_updates=38320, lr=6.23803e-05, gnorm=2.813, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=13096
2023-03-15 17:38:02 - progress_bar.py[line:272] - INFO: epoch 020:    500 / 2004 loss=0.231, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=356.4, nsentences=8, sample_size=356.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1028, ups=2.88, wpb=356.4, bsz=8, num_updates=38330, lr=6.23702e-05, gnorm=3.069, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=13099
2023-03-15 17:38:05 - progress_bar.py[line:272] - INFO: epoch 020:    510 / 2004 loss=0.208, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=363.2, nsentences=8, sample_size=363.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1061.4, ups=2.92, wpb=363.2, bsz=8, num_updates=38340, lr=6.23601e-05, gnorm=2.667, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=13103
2023-03-15 17:38:09 - progress_bar.py[line:272] - INFO: epoch 020:    520 / 2004 loss=0.179, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=352.6, nsentences=8, sample_size=352.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=995.4, ups=2.82, wpb=352.6, bsz=8, num_updates=38350, lr=6.235e-05, gnorm=2.249, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=13106
2023-03-15 17:38:12 - progress_bar.py[line:272] - INFO: epoch 020:    530 / 2004 loss=0.222, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=402.7, nsentences=8, sample_size=402.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1121.6, ups=2.79, wpb=402.7, bsz=8, num_updates=38360, lr=6.234e-05, gnorm=2.814, clip=0, loss_scale=1024, train_wall=4, gb_free=14.6, wall=13110
2023-03-15 17:38:16 - progress_bar.py[line:272] - INFO: epoch 020:    540 / 2004 loss=0.199, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=391.4, nsentences=8, sample_size=391.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1123.8, ups=2.87, wpb=391.4, bsz=8, num_updates=38370, lr=6.23299e-05, gnorm=2.732, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=13113
2023-03-15 17:38:19 - progress_bar.py[line:272] - INFO: epoch 020:    550 / 2004 loss=0.207, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=350.7, nsentences=8, sample_size=350.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1007.2, ups=2.87, wpb=350.7, bsz=8, num_updates=38380, lr=6.23198e-05, gnorm=2.417, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=13117
2023-03-15 17:38:23 - progress_bar.py[line:272] - INFO: epoch 020:    560 / 2004 loss=0.216, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=362.5, nsentences=8, sample_size=362.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1031.8, ups=2.85, wpb=362.5, bsz=8, num_updates=38390, lr=6.23097e-05, gnorm=2.75, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=13120
2023-03-15 17:38:26 - progress_bar.py[line:272] - INFO: epoch 020:    570 / 2004 loss=0.204, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=382, nsentences=8, sample_size=382, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1084.6, ups=2.84, wpb=382, bsz=8, num_updates=38400, lr=6.22996e-05, gnorm=2.455, clip=0, loss_scale=1024, train_wall=3, gb_free=14.1, wall=13124
2023-03-15 17:38:30 - progress_bar.py[line:272] - INFO: epoch 020:    580 / 2004 loss=0.209, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=317.6, nsentences=8, sample_size=317.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=920.1, ups=2.9, wpb=317.6, bsz=8, num_updates=38410, lr=6.22896e-05, gnorm=2.662, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=13127
2023-03-15 17:38:33 - progress_bar.py[line:272] - INFO: epoch 020:    590 / 2004 loss=0.191, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=383, nsentences=8, sample_size=383, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1104.1, ups=2.88, wpb=383, bsz=8, num_updates=38420, lr=6.22795e-05, gnorm=2.377, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=13131
2023-03-15 17:38:37 - progress_bar.py[line:272] - INFO: epoch 020:    600 / 2004 loss=0.178, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=349.1, nsentences=8, sample_size=349.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=992.6, ups=2.84, wpb=349.1, bsz=8, num_updates=38430, lr=6.22694e-05, gnorm=2.266, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=13134
2023-03-15 17:38:40 - progress_bar.py[line:272] - INFO: epoch 020:    610 / 2004 loss=0.188, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=335.9, nsentences=8, sample_size=335.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=966.8, ups=2.88, wpb=335.9, bsz=8, num_updates=38440, lr=6.22593e-05, gnorm=2.341, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=13138
2023-03-15 17:38:44 - progress_bar.py[line:272] - INFO: epoch 020:    620 / 2004 loss=0.189, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=370.2, nsentences=8, sample_size=370.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1059.2, ups=2.86, wpb=370.2, bsz=8, num_updates=38450, lr=6.22492e-05, gnorm=2.41, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=13141
2023-03-15 17:38:47 - progress_bar.py[line:272] - INFO: epoch 020:    630 / 2004 loss=0.203, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=347.8, nsentences=8, sample_size=347.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1007.4, ups=2.9, wpb=347.8, bsz=8, num_updates=38460, lr=6.22392e-05, gnorm=2.632, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=13145
2023-03-15 17:38:51 - progress_bar.py[line:272] - INFO: epoch 020:    640 / 2004 loss=0.192, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=347.1, nsentences=8, sample_size=347.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=974.8, ups=2.81, wpb=347.1, bsz=8, num_updates=38470, lr=6.22291e-05, gnorm=2.627, clip=0, loss_scale=2048, train_wall=4, gb_free=13.5, wall=13148
2023-03-15 17:38:54 - progress_bar.py[line:272] - INFO: epoch 020:    650 / 2004 loss=0.182, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=321.3, nsentences=8, sample_size=321.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=939.3, ups=2.92, wpb=321.3, bsz=8, num_updates=38480, lr=6.2219e-05, gnorm=2.199, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=13152
2023-03-15 17:38:58 - progress_bar.py[line:272] - INFO: epoch 020:    660 / 2004 loss=0.198, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=341.3, nsentences=8, sample_size=341.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=967.9, ups=2.84, wpb=341.3, bsz=8, num_updates=38490, lr=6.22089e-05, gnorm=2.48, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=13155
2023-03-15 17:39:01 - progress_bar.py[line:272] - INFO: epoch 020:    670 / 2004 loss=0.211, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=323.1, nsentences=8, sample_size=323.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=946.7, ups=2.93, wpb=323.1, bsz=8, num_updates=38500, lr=6.21988e-05, gnorm=2.587, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=13159
2023-03-15 17:39:05 - progress_bar.py[line:272] - INFO: epoch 020:    680 / 2004 loss=0.182, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=332.9, nsentences=8, sample_size=332.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=985.4, ups=2.96, wpb=332.9, bsz=8, num_updates=38510, lr=6.21888e-05, gnorm=2.26, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=13162
2023-03-15 17:39:08 - progress_bar.py[line:272] - INFO: epoch 020:    690 / 2004 loss=0.189, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=355.4, nsentences=8, sample_size=355.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1029.9, ups=2.9, wpb=355.4, bsz=8, num_updates=38520, lr=6.21787e-05, gnorm=2.48, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=13166
2023-03-15 17:39:11 - progress_bar.py[line:272] - INFO: epoch 020:    700 / 2004 loss=0.194, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=341, nsentences=8, sample_size=341, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=983.4, ups=2.88, wpb=341, bsz=8, num_updates=38530, lr=6.21686e-05, gnorm=2.55, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=13169
2023-03-15 17:39:15 - progress_bar.py[line:272] - INFO: epoch 020:    710 / 2004 loss=0.211, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=334.2, nsentences=8, sample_size=334.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=961.8, ups=2.88, wpb=334.2, bsz=8, num_updates=38540, lr=6.21585e-05, gnorm=2.57, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=13173
2023-03-15 17:39:18 - progress_bar.py[line:272] - INFO: epoch 020:    720 / 2004 loss=0.211, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=351.7, nsentences=8, sample_size=351.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1014.2, ups=2.88, wpb=351.7, bsz=8, num_updates=38550, lr=6.21484e-05, gnorm=2.756, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=13176
2023-03-15 17:39:22 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 17:39:22 - progress_bar.py[line:272] - INFO: epoch 020:    731 / 2004 loss=0.214, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=352.5, nsentences=8, sample_size=352.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=933, ups=2.65, wpb=352.5, bsz=8, num_updates=38560, lr=6.21383e-05, gnorm=2.559, clip=0, loss_scale=2048, train_wall=4, gb_free=15, wall=13180
2023-03-15 17:39:26 - progress_bar.py[line:272] - INFO: epoch 020:    741 / 2004 loss=0.21, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=332.4, nsentences=8, sample_size=332.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=964.8, ups=2.9, wpb=332.4, bsz=8, num_updates=38570, lr=6.21283e-05, gnorm=2.7, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=13183
2023-03-15 17:39:29 - progress_bar.py[line:272] - INFO: epoch 020:    751 / 2004 loss=0.229, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=354.2, nsentences=8, sample_size=354.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1041.8, ups=2.94, wpb=354.2, bsz=8, num_updates=38580, lr=6.21182e-05, gnorm=2.945, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=13187
2023-03-15 17:39:32 - progress_bar.py[line:272] - INFO: epoch 020:    761 / 2004 loss=0.213, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=329.7, nsentences=8, sample_size=329.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=966.1, ups=2.93, wpb=329.7, bsz=8, num_updates=38590, lr=6.21081e-05, gnorm=2.666, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=13190
2023-03-15 17:39:36 - progress_bar.py[line:272] - INFO: epoch 020:    771 / 2004 loss=0.233, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=394.1, nsentences=8, sample_size=394.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1126.9, ups=2.86, wpb=394.1, bsz=8, num_updates=38600, lr=6.2098e-05, gnorm=2.882, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=13194
2023-03-15 17:39:39 - progress_bar.py[line:272] - INFO: epoch 020:    781 / 2004 loss=0.236, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=338.5, nsentences=8, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=986.9, ups=2.92, wpb=338.5, bsz=8, num_updates=38610, lr=6.20879e-05, gnorm=2.819, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=13197
2023-03-15 17:39:43 - progress_bar.py[line:272] - INFO: epoch 020:    791 / 2004 loss=0.214, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=346.9, nsentences=8, sample_size=346.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1006.9, ups=2.9, wpb=346.9, bsz=8, num_updates=38620, lr=6.20779e-05, gnorm=2.7, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=13200
2023-03-15 17:39:46 - progress_bar.py[line:272] - INFO: epoch 020:    801 / 2004 loss=0.208, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=323.7, nsentences=8, sample_size=323.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=948.6, ups=2.93, wpb=323.7, bsz=8, num_updates=38630, lr=6.20678e-05, gnorm=2.787, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=13204
2023-03-15 17:39:50 - progress_bar.py[line:272] - INFO: epoch 020:    811 / 2004 loss=0.184, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=350.3, nsentences=8, sample_size=350.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1002.6, ups=2.86, wpb=350.3, bsz=8, num_updates=38640, lr=6.20577e-05, gnorm=2.464, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=13207
2023-03-15 17:39:53 - progress_bar.py[line:272] - INFO: epoch 020:    821 / 2004 loss=0.202, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=324.2, nsentences=8, sample_size=324.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=941.4, ups=2.9, wpb=324.2, bsz=8, num_updates=38650, lr=6.20476e-05, gnorm=2.672, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=13211
2023-03-15 17:39:54 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 17:39:57 - progress_bar.py[line:272] - INFO: epoch 020:    832 / 2004 loss=0.223, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=347.8, nsentences=8, sample_size=347.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=904.4, ups=2.6, wpb=347.8, bsz=8, num_updates=38660, lr=6.20375e-05, gnorm=3.007, clip=0, loss_scale=1024, train_wall=4, gb_free=14.9, wall=13215
2023-03-15 17:40:00 - progress_bar.py[line:272] - INFO: epoch 020:    842 / 2004 loss=0.212, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=359, nsentences=8, sample_size=359, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1048.1, ups=2.92, wpb=359, bsz=8, num_updates=38670, lr=6.20275e-05, gnorm=2.668, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=13218
2023-03-15 17:40:04 - progress_bar.py[line:272] - INFO: epoch 020:    852 / 2004 loss=0.192, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=358.4, nsentences=8, sample_size=358.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1041.9, ups=2.91, wpb=358.4, bsz=8, num_updates=38680, lr=6.20174e-05, gnorm=2.476, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=13222
2023-03-15 17:40:07 - progress_bar.py[line:272] - INFO: epoch 020:    862 / 2004 loss=0.199, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=336.6, nsentences=8, sample_size=336.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=971.1, ups=2.88, wpb=336.6, bsz=8, num_updates=38690, lr=6.20073e-05, gnorm=2.575, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=13225
2023-03-15 17:40:11 - progress_bar.py[line:272] - INFO: epoch 020:    872 / 2004 loss=0.212, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=374.6, nsentences=8, sample_size=374.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1080.3, ups=2.88, wpb=374.6, bsz=8, num_updates=38700, lr=6.19972e-05, gnorm=2.502, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=13228
2023-03-15 17:40:14 - progress_bar.py[line:272] - INFO: epoch 020:    882 / 2004 loss=0.181, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=320.4, nsentences=8, sample_size=320.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=911.8, ups=2.85, wpb=320.4, bsz=8, num_updates=38710, lr=6.19871e-05, gnorm=2.294, clip=0, loss_scale=1024, train_wall=3, gb_free=13.7, wall=13232
2023-03-15 17:40:18 - progress_bar.py[line:272] - INFO: epoch 020:    892 / 2004 loss=0.2, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=310, nsentences=8, sample_size=310, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=901.3, ups=2.91, wpb=310, bsz=8, num_updates=38720, lr=6.19771e-05, gnorm=2.621, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=13235
2023-03-15 17:40:21 - progress_bar.py[line:272] - INFO: epoch 020:    902 / 2004 loss=0.206, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=363.8, nsentences=8, sample_size=363.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1039.5, ups=2.86, wpb=363.8, bsz=8, num_updates=38730, lr=6.1967e-05, gnorm=2.505, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=13239
2023-03-15 17:40:25 - progress_bar.py[line:272] - INFO: epoch 020:    912 / 2004 loss=0.199, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=379.3, nsentences=8, sample_size=379.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1102.8, ups=2.91, wpb=379.3, bsz=8, num_updates=38740, lr=6.19569e-05, gnorm=2.64, clip=0, loss_scale=1024, train_wall=3, gb_free=14, wall=13242
2023-03-15 17:40:28 - progress_bar.py[line:272] - INFO: epoch 020:    922 / 2004 loss=0.189, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=323.5, nsentences=8, sample_size=323.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=961.9, ups=2.97, wpb=323.5, bsz=8, num_updates=38750, lr=6.19468e-05, gnorm=2.523, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=13246
2023-03-15 17:40:32 - progress_bar.py[line:272] - INFO: epoch 020:    932 / 2004 loss=0.185, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=341.5, nsentences=8, sample_size=341.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=987.4, ups=2.89, wpb=341.5, bsz=8, num_updates=38760, lr=6.19367e-05, gnorm=2.378, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=13249
2023-03-15 17:40:35 - progress_bar.py[line:272] - INFO: epoch 020:    942 / 2004 loss=0.194, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=374, nsentences=8, sample_size=374, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1051.9, ups=2.81, wpb=374, bsz=8, num_updates=38770, lr=6.19267e-05, gnorm=2.426, clip=0, loss_scale=1024, train_wall=3, gb_free=13.9, wall=13253
2023-03-15 17:40:39 - progress_bar.py[line:272] - INFO: epoch 020:    952 / 2004 loss=0.218, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=335.9, nsentences=8, sample_size=335.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=969, ups=2.88, wpb=335.9, bsz=8, num_updates=38780, lr=6.19166e-05, gnorm=2.833, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=13256
2023-03-15 17:40:42 - progress_bar.py[line:272] - INFO: epoch 020:    962 / 2004 loss=0.226, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=383.1, nsentences=8, sample_size=383.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1110.7, ups=2.9, wpb=383.1, bsz=8, num_updates=38790, lr=6.19065e-05, gnorm=2.796, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=13260
2023-03-15 17:40:45 - progress_bar.py[line:272] - INFO: epoch 020:    972 / 2004 loss=0.207, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=337.4, nsentences=8, sample_size=337.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=993.5, ups=2.94, wpb=337.4, bsz=8, num_updates=38800, lr=6.18964e-05, gnorm=2.507, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=13263
2023-03-15 17:40:49 - progress_bar.py[line:272] - INFO: epoch 020:    982 / 2004 loss=0.209, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=316.7, nsentences=8, sample_size=316.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=947.8, ups=2.99, wpb=316.7, bsz=8, num_updates=38810, lr=6.18863e-05, gnorm=2.759, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=13266
2023-03-15 17:40:52 - progress_bar.py[line:272] - INFO: epoch 020:    992 / 2004 loss=0.189, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=380.5, nsentences=8, sample_size=380.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1096.7, ups=2.88, wpb=380.5, bsz=8, num_updates=38820, lr=6.18762e-05, gnorm=2.36, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=13270
2023-03-15 17:40:56 - progress_bar.py[line:272] - INFO: epoch 020:   1002 / 2004 loss=0.208, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=334.7, nsentences=8, sample_size=334.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=961.1, ups=2.87, wpb=334.7, bsz=8, num_updates=38830, lr=6.18662e-05, gnorm=2.821, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=13273
2023-03-15 17:40:59 - progress_bar.py[line:272] - INFO: epoch 020:   1012 / 2004 loss=0.207, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=329.9, nsentences=8, sample_size=329.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=963.2, ups=2.92, wpb=329.9, bsz=8, num_updates=38840, lr=6.18561e-05, gnorm=2.815, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=13277
2023-03-15 17:41:03 - progress_bar.py[line:272] - INFO: epoch 020:   1022 / 2004 loss=0.206, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=319.8, nsentences=8, sample_size=319.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=950.5, ups=2.97, wpb=319.8, bsz=8, num_updates=38850, lr=6.1846e-05, gnorm=2.709, clip=0, loss_scale=2048, train_wall=3, gb_free=15.8, wall=13280
2023-03-15 17:41:06 - progress_bar.py[line:272] - INFO: epoch 020:   1032 / 2004 loss=0.199, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=331, nsentences=8, sample_size=331, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=970, ups=2.93, wpb=331, bsz=8, num_updates=38860, lr=6.18359e-05, gnorm=2.543, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=13284
2023-03-15 17:41:09 - progress_bar.py[line:272] - INFO: epoch 020:   1042 / 2004 loss=0.217, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=338.7, nsentences=8, sample_size=338.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=980.5, ups=2.9, wpb=338.7, bsz=8, num_updates=38870, lr=6.18258e-05, gnorm=2.785, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=13287
2023-03-15 17:41:13 - progress_bar.py[line:272] - INFO: epoch 020:   1052 / 2004 loss=0.21, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=368, nsentences=8, sample_size=368, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1071, ups=2.91, wpb=368, bsz=8, num_updates=38880, lr=6.18158e-05, gnorm=2.72, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=13290
2023-03-15 17:41:16 - progress_bar.py[line:272] - INFO: epoch 020:   1062 / 2004 loss=0.218, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=338.8, nsentences=8, sample_size=338.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=996.1, ups=2.94, wpb=338.8, bsz=8, num_updates=38890, lr=6.18057e-05, gnorm=2.702, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=13294
2023-03-15 17:41:20 - progress_bar.py[line:272] - INFO: epoch 020:   1072 / 2004 loss=0.212, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=355.7, nsentences=8, sample_size=355.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1008.1, ups=2.83, wpb=355.7, bsz=8, num_updates=38900, lr=6.17956e-05, gnorm=2.802, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=13297
2023-03-15 17:41:23 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 17:41:24 - progress_bar.py[line:272] - INFO: epoch 020:   1083 / 2004 loss=0.202, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=359.6, nsentences=8, sample_size=359.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=946.6, ups=2.63, wpb=359.6, bsz=8, num_updates=38910, lr=6.17855e-05, gnorm=2.709, clip=0, loss_scale=2048, train_wall=4, gb_free=15.2, wall=13301
2023-03-15 17:41:27 - progress_bar.py[line:272] - INFO: epoch 020:   1093 / 2004 loss=0.203, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=334.9, nsentences=8, sample_size=334.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=988.2, ups=2.95, wpb=334.9, bsz=8, num_updates=38920, lr=6.17754e-05, gnorm=2.501, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=13305
2023-03-15 17:41:30 - progress_bar.py[line:272] - INFO: epoch 020:   1103 / 2004 loss=0.2, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=370.3, nsentences=8, sample_size=370.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1072.8, ups=2.9, wpb=370.3, bsz=8, num_updates=38930, lr=6.17654e-05, gnorm=2.452, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=13308
2023-03-15 17:41:34 - progress_bar.py[line:272] - INFO: epoch 020:   1113 / 2004 loss=0.193, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=348.1, nsentences=8, sample_size=348.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1035.4, ups=2.97, wpb=348.1, bsz=8, num_updates=38940, lr=6.17553e-05, gnorm=2.384, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=13311
2023-03-15 17:41:37 - progress_bar.py[line:272] - INFO: epoch 020:   1123 / 2004 loss=0.171, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=307.3, nsentences=8, sample_size=307.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=906.2, ups=2.95, wpb=307.3, bsz=8, num_updates=38950, lr=6.17452e-05, gnorm=2.267, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=13315
2023-03-15 17:41:41 - progress_bar.py[line:272] - INFO: epoch 020:   1133 / 2004 loss=0.204, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=376.8, nsentences=8, sample_size=376.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1066.8, ups=2.83, wpb=376.8, bsz=8, num_updates=38960, lr=6.17351e-05, gnorm=2.395, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=13318
2023-03-15 17:41:44 - progress_bar.py[line:272] - INFO: epoch 020:   1143 / 2004 loss=0.193, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=363.5, nsentences=8, sample_size=363.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1046, ups=2.88, wpb=363.5, bsz=8, num_updates=38970, lr=6.1725e-05, gnorm=2.48, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=13322
2023-03-15 17:41:49 - progress_bar.py[line:272] - INFO: epoch 020:   1153 / 2004 loss=0.214, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=380.2, nsentences=8, sample_size=380.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=863, ups=2.27, wpb=380.2, bsz=8, num_updates=38980, lr=6.1715e-05, gnorm=2.769, clip=0, loss_scale=2048, train_wall=4, gb_free=14.9, wall=13326
2023-03-15 17:41:52 - progress_bar.py[line:272] - INFO: epoch 020:   1163 / 2004 loss=0.194, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=369.2, nsentences=8, sample_size=369.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1056.6, ups=2.86, wpb=369.2, bsz=8, num_updates=38990, lr=6.17049e-05, gnorm=2.562, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=13330
2023-03-15 17:41:56 - progress_bar.py[line:272] - INFO: epoch 020:   1173 / 2004 loss=0.195, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=355.6, nsentences=8, sample_size=355.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1024.3, ups=2.88, wpb=355.6, bsz=8, num_updates=39000, lr=6.16948e-05, gnorm=2.451, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=13333
2023-03-15 17:41:59 - progress_bar.py[line:272] - INFO: epoch 020:   1183 / 2004 loss=0.209, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=333.7, nsentences=8, sample_size=333.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=970.1, ups=2.91, wpb=333.7, bsz=8, num_updates=39010, lr=6.16847e-05, gnorm=2.641, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=13337
2023-03-15 17:42:02 - progress_bar.py[line:272] - INFO: epoch 020:   1193 / 2004 loss=0.195, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=362.1, nsentences=8, sample_size=362.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1054.2, ups=2.91, wpb=362.1, bsz=8, num_updates=39020, lr=6.16746e-05, gnorm=2.514, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=13340
2023-03-15 17:42:06 - progress_bar.py[line:272] - INFO: epoch 020:   1203 / 2004 loss=0.206, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=324.4, nsentences=8, sample_size=324.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=956.2, ups=2.95, wpb=324.4, bsz=8, num_updates=39030, lr=6.16645e-05, gnorm=2.562, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=13343
2023-03-15 17:42:09 - progress_bar.py[line:272] - INFO: epoch 020:   1213 / 2004 loss=0.201, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=286.3, nsentences=8, sample_size=286.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=850.5, ups=2.97, wpb=286.3, bsz=8, num_updates=39040, lr=6.16545e-05, gnorm=2.609, clip=0, loss_scale=4096, train_wall=3, gb_free=15.6, wall=13347
2023-03-15 17:42:09 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 17:42:13 - progress_bar.py[line:272] - INFO: epoch 020:   1224 / 2004 loss=0.205, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=316.6, nsentences=8, sample_size=316.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=851.8, ups=2.69, wpb=316.6, bsz=8, num_updates=39050, lr=6.16444e-05, gnorm=2.364, clip=0, loss_scale=2048, train_wall=4, gb_free=15.8, wall=13350
2023-03-15 17:42:16 - progress_bar.py[line:272] - INFO: epoch 020:   1234 / 2004 loss=0.186, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=336.6, nsentences=8, sample_size=336.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=973.2, ups=2.89, wpb=336.6, bsz=8, num_updates=39060, lr=6.16343e-05, gnorm=2.283, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=13354
2023-03-15 17:42:20 - progress_bar.py[line:272] - INFO: epoch 020:   1244 / 2004 loss=0.216, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=377.6, nsentences=8, sample_size=377.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1072.7, ups=2.84, wpb=377.6, bsz=8, num_updates=39070, lr=6.16242e-05, gnorm=2.797, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=13357
2023-03-15 17:42:23 - progress_bar.py[line:272] - INFO: epoch 020:   1254 / 2004 loss=0.198, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=337.8, nsentences=8, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=974.1, ups=2.88, wpb=337.8, bsz=8, num_updates=39080, lr=6.16141e-05, gnorm=2.493, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=13361
2023-03-15 17:42:27 - progress_bar.py[line:272] - INFO: epoch 020:   1264 / 2004 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=339.2, nsentences=8, sample_size=339.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=998.8, ups=2.94, wpb=339.2, bsz=8, num_updates=39090, lr=6.16041e-05, gnorm=2.288, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=13364
2023-03-15 17:42:30 - progress_bar.py[line:272] - INFO: epoch 020:   1274 / 2004 loss=0.201, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=353.2, nsentences=8, sample_size=353.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1047.3, ups=2.97, wpb=353.2, bsz=8, num_updates=39100, lr=6.1594e-05, gnorm=2.717, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=13368
2023-03-15 17:42:33 - progress_bar.py[line:272] - INFO: epoch 020:   1284 / 2004 loss=0.189, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=329.3, nsentences=8, sample_size=329.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1052.7, ups=3.2, wpb=329.3, bsz=8, num_updates=39110, lr=6.15839e-05, gnorm=2.553, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=13371
2023-03-15 17:42:36 - progress_bar.py[line:272] - INFO: epoch 020:   1294 / 2004 loss=0.203, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=308.4, nsentences=8, sample_size=308.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=984.9, ups=3.19, wpb=308.4, bsz=8, num_updates=39120, lr=6.15738e-05, gnorm=2.594, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=13374
2023-03-15 17:42:40 - progress_bar.py[line:272] - INFO: epoch 020:   1304 / 2004 loss=0.202, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=325.4, nsentences=8, sample_size=325.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1028.8, ups=3.16, wpb=325.4, bsz=8, num_updates=39130, lr=6.15637e-05, gnorm=2.621, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=13377
2023-03-15 17:42:43 - progress_bar.py[line:272] - INFO: epoch 020:   1314 / 2004 loss=0.2, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=330, nsentences=8, sample_size=330, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1037.5, ups=3.14, wpb=330, bsz=8, num_updates=39140, lr=6.15537e-05, gnorm=2.545, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=13380
2023-03-15 17:42:46 - progress_bar.py[line:272] - INFO: epoch 020:   1324 / 2004 loss=0.215, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=310.7, nsentences=8, sample_size=310.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=918.4, ups=2.96, wpb=310.7, bsz=8, num_updates=39150, lr=6.15436e-05, gnorm=2.896, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=13384
2023-03-15 17:42:49 - progress_bar.py[line:272] - INFO: epoch 020:   1334 / 2004 loss=0.195, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=346.2, nsentences=8, sample_size=346.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1018.9, ups=2.94, wpb=346.2, bsz=8, num_updates=39160, lr=6.15335e-05, gnorm=2.541, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=13387
2023-03-15 17:42:53 - progress_bar.py[line:272] - INFO: epoch 020:   1344 / 2004 loss=0.187, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=305.3, nsentences=8, sample_size=305.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=931.8, ups=3.05, wpb=305.3, bsz=8, num_updates=39170, lr=6.15234e-05, gnorm=2.355, clip=0, loss_scale=4096, train_wall=3, gb_free=15.6, wall=13390
2023-03-15 17:42:54 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 17:42:57 - progress_bar.py[line:272] - INFO: epoch 020:   1355 / 2004 loss=0.197, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=316.1, nsentences=8, sample_size=316.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=840.4, ups=2.66, wpb=316.1, bsz=8, num_updates=39180, lr=6.15133e-05, gnorm=2.6, clip=0, loss_scale=2048, train_wall=4, gb_free=14.9, wall=13394
2023-03-15 17:43:00 - progress_bar.py[line:272] - INFO: epoch 020:   1365 / 2004 loss=0.19, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=309.6, nsentences=8, sample_size=309.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=895.2, ups=2.89, wpb=309.6, bsz=8, num_updates=39190, lr=6.15033e-05, gnorm=2.561, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=13398
2023-03-15 17:43:03 - progress_bar.py[line:272] - INFO: epoch 020:   1375 / 2004 loss=0.189, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=337, nsentences=8, sample_size=337, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=959.6, ups=2.85, wpb=337, bsz=8, num_updates=39200, lr=6.14932e-05, gnorm=2.392, clip=0, loss_scale=2048, train_wall=3, gb_free=14, wall=13401
2023-03-15 17:43:07 - progress_bar.py[line:272] - INFO: epoch 020:   1385 / 2004 loss=0.194, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=384.2, nsentences=8, sample_size=384.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1105.1, ups=2.88, wpb=384.2, bsz=8, num_updates=39210, lr=6.14831e-05, gnorm=2.533, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=13405
2023-03-15 17:43:10 - progress_bar.py[line:272] - INFO: epoch 020:   1395 / 2004 loss=0.215, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=358.4, nsentences=8, sample_size=358.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1046.2, ups=2.92, wpb=358.4, bsz=8, num_updates=39220, lr=6.1473e-05, gnorm=2.776, clip=0, loss_scale=2048, train_wall=3, gb_free=13.9, wall=13408
2023-03-15 17:43:14 - progress_bar.py[line:272] - INFO: epoch 020:   1405 / 2004 loss=0.197, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=330, nsentences=8, sample_size=330, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=973.7, ups=2.95, wpb=330, bsz=8, num_updates=39230, lr=6.14629e-05, gnorm=2.67, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=13411
2023-03-15 17:43:17 - progress_bar.py[line:272] - INFO: epoch 020:   1415 / 2004 loss=0.204, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=402.8, nsentences=8, sample_size=402.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1224.4, ups=3.04, wpb=402.8, bsz=8, num_updates=39240, lr=6.14529e-05, gnorm=2.747, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=13415
2023-03-15 17:43:20 - progress_bar.py[line:272] - INFO: epoch 020:   1425 / 2004 loss=0.181, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=286.3, nsentences=8, sample_size=286.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=915.4, ups=3.2, wpb=286.3, bsz=8, num_updates=39250, lr=6.14428e-05, gnorm=2.705, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=13418
2023-03-15 17:43:23 - progress_bar.py[line:272] - INFO: epoch 020:   1435 / 2004 loss=0.196, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=354.5, nsentences=8, sample_size=354.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1099.6, ups=3.1, wpb=354.5, bsz=8, num_updates=39260, lr=6.14327e-05, gnorm=2.582, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=13421
2023-03-15 17:43:27 - progress_bar.py[line:272] - INFO: epoch 020:   1445 / 2004 loss=0.211, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=330.5, nsentences=8, sample_size=330.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1047.5, ups=3.17, wpb=330.5, bsz=8, num_updates=39270, lr=6.14226e-05, gnorm=2.701, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=13424
2023-03-15 17:43:30 - progress_bar.py[line:272] - INFO: epoch 020:   1455 / 2004 loss=0.198, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=369.9, nsentences=8, sample_size=369.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1117.6, ups=3.02, wpb=369.9, bsz=8, num_updates=39280, lr=6.14125e-05, gnorm=2.675, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=13428
2023-03-15 17:43:33 - progress_bar.py[line:272] - INFO: epoch 020:   1465 / 2004 loss=0.199, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=395.3, nsentences=8, sample_size=395.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1132.3, ups=2.86, wpb=395.3, bsz=8, num_updates=39290, lr=6.14024e-05, gnorm=2.705, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=13431
2023-03-15 17:43:37 - progress_bar.py[line:272] - INFO: epoch 020:   1475 / 2004 loss=0.221, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=403.8, nsentences=8, sample_size=403.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1235.1, ups=3.06, wpb=403.8, bsz=8, num_updates=39300, lr=6.13924e-05, gnorm=2.703, clip=0, loss_scale=4096, train_wall=3, gb_free=14.5, wall=13434
2023-03-15 17:43:37 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 17:43:40 - progress_bar.py[line:272] - INFO: epoch 020:   1486 / 2004 loss=0.207, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=330.8, nsentences=7.8, sample_size=330.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=899.7, ups=2.72, wpb=330.8, bsz=7.8, num_updates=39310, lr=6.13823e-05, gnorm=2.627, clip=0, loss_scale=2048, train_wall=4, gb_free=15.1, wall=13438
2023-03-15 17:43:44 - progress_bar.py[line:272] - INFO: epoch 020:   1496 / 2004 loss=0.213, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=334, nsentences=8, sample_size=334, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=959, ups=2.87, wpb=334, bsz=8, num_updates=39320, lr=6.13722e-05, gnorm=2.503, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=13441
2023-03-15 17:43:47 - progress_bar.py[line:272] - INFO: epoch 020:   1506 / 2004 loss=0.206, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=318.9, nsentences=8, sample_size=318.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=933.3, ups=2.93, wpb=318.9, bsz=8, num_updates=39330, lr=6.13621e-05, gnorm=2.69, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=13445
2023-03-15 17:43:51 - progress_bar.py[line:272] - INFO: epoch 020:   1516 / 2004 loss=0.206, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=327.6, nsentences=8, sample_size=327.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=971.4, ups=2.97, wpb=327.6, bsz=8, num_updates=39340, lr=6.1352e-05, gnorm=2.617, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=13448
2023-03-15 17:43:54 - progress_bar.py[line:272] - INFO: epoch 020:   1526 / 2004 loss=0.198, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=330.1, nsentences=8, sample_size=330.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=966.2, ups=2.93, wpb=330.1, bsz=8, num_updates=39350, lr=6.1342e-05, gnorm=2.639, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=13452
2023-03-15 17:43:57 - progress_bar.py[line:272] - INFO: epoch 020:   1536 / 2004 loss=0.219, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=354.8, nsentences=8, sample_size=354.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1031.3, ups=2.91, wpb=354.8, bsz=8, num_updates=39360, lr=6.13319e-05, gnorm=2.608, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=13455
2023-03-15 17:44:01 - progress_bar.py[line:272] - INFO: epoch 020:   1546 / 2004 loss=0.213, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=324.7, nsentences=8, sample_size=324.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=937.6, ups=2.89, wpb=324.7, bsz=8, num_updates=39370, lr=6.13218e-05, gnorm=2.801, clip=0, loss_scale=2048, train_wall=3, gb_free=13.8, wall=13459
2023-03-15 17:44:04 - progress_bar.py[line:272] - INFO: epoch 020:   1556 / 2004 loss=0.199, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=339.6, nsentences=8, sample_size=339.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1000.7, ups=2.95, wpb=339.6, bsz=8, num_updates=39380, lr=6.13117e-05, gnorm=2.596, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=13462
2023-03-15 17:44:08 - progress_bar.py[line:272] - INFO: epoch 020:   1566 / 2004 loss=0.202, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=342.6, nsentences=8, sample_size=342.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1014, ups=2.96, wpb=342.6, bsz=8, num_updates=39390, lr=6.13016e-05, gnorm=2.492, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=13465
2023-03-15 17:44:11 - progress_bar.py[line:272] - INFO: epoch 020:   1576 / 2004 loss=0.204, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=351.2, nsentences=8, sample_size=351.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1031.9, ups=2.94, wpb=351.2, bsz=8, num_updates=39400, lr=6.12916e-05, gnorm=2.6, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=13469
2023-03-15 17:44:15 - progress_bar.py[line:272] - INFO: epoch 020:   1586 / 2004 loss=0.204, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=322, nsentences=8, sample_size=322, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=933, ups=2.9, wpb=322, bsz=8, num_updates=39410, lr=6.12815e-05, gnorm=2.725, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=13472
2023-03-15 17:44:18 - progress_bar.py[line:272] - INFO: epoch 020:   1596 / 2004 loss=0.189, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=353.3, nsentences=8, sample_size=353.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1004.2, ups=2.84, wpb=353.3, bsz=8, num_updates=39420, lr=6.12714e-05, gnorm=2.315, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=13476
2023-03-15 17:44:22 - progress_bar.py[line:272] - INFO: epoch 020:   1606 / 2004 loss=0.186, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=337.1, nsentences=8, sample_size=337.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=980.2, ups=2.91, wpb=337.1, bsz=8, num_updates=39430, lr=6.12613e-05, gnorm=2.285, clip=0, loss_scale=4096, train_wall=3, gb_free=15.2, wall=13479
2023-03-15 17:44:23 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 17:44:25 - progress_bar.py[line:272] - INFO: epoch 020:   1617 / 2004 loss=0.194, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=313.4, nsentences=8, sample_size=313.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=833.7, ups=2.66, wpb=313.4, bsz=8, num_updates=39440, lr=6.12512e-05, gnorm=2.342, clip=0, loss_scale=2048, train_wall=4, gb_free=15.3, wall=13483
2023-03-15 17:44:29 - progress_bar.py[line:272] - INFO: epoch 020:   1627 / 2004 loss=0.215, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=375.1, nsentences=8, sample_size=375.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1110.8, ups=2.96, wpb=375.1, bsz=8, num_updates=39450, lr=6.12412e-05, gnorm=2.528, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=13486
2023-03-15 17:44:32 - progress_bar.py[line:272] - INFO: epoch 020:   1637 / 2004 loss=0.207, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=328.2, nsentences=8, sample_size=328.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=939.9, ups=2.86, wpb=328.2, bsz=8, num_updates=39460, lr=6.12311e-05, gnorm=2.572, clip=0, loss_scale=2048, train_wall=3, gb_free=13.4, wall=13490
2023-03-15 17:44:36 - progress_bar.py[line:272] - INFO: epoch 020:   1647 / 2004 loss=0.194, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=307.9, nsentences=8, sample_size=307.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=881.9, ups=2.86, wpb=307.9, bsz=8, num_updates=39470, lr=6.1221e-05, gnorm=2.641, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=13493
2023-03-15 17:44:39 - progress_bar.py[line:272] - INFO: epoch 020:   1657 / 2004 loss=0.195, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=356.2, nsentences=8, sample_size=356.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1034.2, ups=2.9, wpb=356.2, bsz=8, num_updates=39480, lr=6.12109e-05, gnorm=2.47, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=13497
2023-03-15 17:44:43 - progress_bar.py[line:272] - INFO: epoch 020:   1667 / 2004 loss=0.213, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=339.4, nsentences=8, sample_size=339.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=969.9, ups=2.86, wpb=339.4, bsz=8, num_updates=39490, lr=6.12008e-05, gnorm=2.615, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=13500
2023-03-15 17:44:46 - progress_bar.py[line:272] - INFO: epoch 020:   1677 / 2004 loss=0.196, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=325.5, nsentences=8, sample_size=325.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=957.3, ups=2.94, wpb=325.5, bsz=8, num_updates=39500, lr=6.11907e-05, gnorm=2.52, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=13504
2023-03-15 17:44:49 - progress_bar.py[line:272] - INFO: epoch 020:   1687 / 2004 loss=0.196, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=332.1, nsentences=8, sample_size=332.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=945.6, ups=2.85, wpb=332.1, bsz=8, num_updates=39510, lr=6.11807e-05, gnorm=2.494, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=13507
2023-03-15 17:44:53 - progress_bar.py[line:272] - INFO: epoch 020:   1697 / 2004 loss=0.185, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=336.6, nsentences=8, sample_size=336.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=956.6, ups=2.84, wpb=336.6, bsz=8, num_updates=39520, lr=6.11706e-05, gnorm=2.246, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=13511
2023-03-15 17:44:56 - progress_bar.py[line:272] - INFO: epoch 020:   1707 / 2004 loss=0.195, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=349.1, nsentences=8, sample_size=349.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1010.9, ups=2.9, wpb=349.1, bsz=8, num_updates=39530, lr=6.11605e-05, gnorm=2.673, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=13514
2023-03-15 17:45:00 - progress_bar.py[line:272] - INFO: epoch 020:   1717 / 2004 loss=0.2, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=373.3, nsentences=8, sample_size=373.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1067.6, ups=2.86, wpb=373.3, bsz=8, num_updates=39540, lr=6.11504e-05, gnorm=2.635, clip=0, loss_scale=2048, train_wall=3, gb_free=14, wall=13518
2023-03-15 17:45:03 - progress_bar.py[line:272] - INFO: epoch 020:   1727 / 2004 loss=0.21, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=394.1, nsentences=8, sample_size=394.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1126, ups=2.86, wpb=394.1, bsz=8, num_updates=39550, lr=6.11403e-05, gnorm=2.514, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=13521
2023-03-15 17:45:07 - progress_bar.py[line:272] - INFO: epoch 020:   1737 / 2004 loss=0.185, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=332.4, nsentences=8, sample_size=332.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=961.3, ups=2.89, wpb=332.4, bsz=8, num_updates=39560, lr=6.11303e-05, gnorm=2.295, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=13525
2023-03-15 17:45:08 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 17:45:11 - progress_bar.py[line:272] - INFO: epoch 020:   1748 / 2004 loss=0.189, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=352.5, nsentences=8, sample_size=352.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=933, ups=2.65, wpb=352.5, bsz=8, num_updates=39570, lr=6.11202e-05, gnorm=2.501, clip=0, loss_scale=2048, train_wall=4, gb_free=14.7, wall=13528
2023-03-15 17:45:14 - progress_bar.py[line:272] - INFO: epoch 020:   1758 / 2004 loss=0.215, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=328, nsentences=8, sample_size=328, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=946.6, ups=2.89, wpb=328, bsz=8, num_updates=39580, lr=6.11101e-05, gnorm=2.632, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=13532
2023-03-15 17:45:18 - progress_bar.py[line:272] - INFO: epoch 020:   1768 / 2004 loss=0.188, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=323.1, nsentences=8, sample_size=323.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=944.9, ups=2.92, wpb=323.1, bsz=8, num_updates=39590, lr=6.11e-05, gnorm=2.511, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=13535
2023-03-15 17:45:21 - progress_bar.py[line:272] - INFO: epoch 020:   1778 / 2004 loss=0.233, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=347.6, nsentences=8, sample_size=347.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1062.2, ups=3.06, wpb=347.6, bsz=8, num_updates=39600, lr=6.10899e-05, gnorm=2.921, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=13538
2023-03-15 17:45:24 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 17:45:24 - progress_bar.py[line:272] - INFO: epoch 020:   1789 / 2004 loss=0.194, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=308.4, nsentences=8, sample_size=308.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=920.4, ups=2.98, wpb=308.4, bsz=8, num_updates=39610, lr=6.10799e-05, gnorm=2.517, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=13542
2023-03-15 17:45:27 - progress_bar.py[line:272] - INFO: epoch 020:   1799 / 2004 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=347.4, nsentences=8, sample_size=347.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1109.8, ups=3.19, wpb=347.4, bsz=8, num_updates=39620, lr=6.10698e-05, gnorm=2.635, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=13545
2023-03-15 17:45:31 - progress_bar.py[line:272] - INFO: epoch 020:   1809 / 2004 loss=0.185, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=347.7, nsentences=8, sample_size=347.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1078.8, ups=3.1, wpb=347.7, bsz=8, num_updates=39630, lr=6.10597e-05, gnorm=2.24, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=13548
2023-03-15 17:45:31 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-03-15 17:45:34 - progress_bar.py[line:272] - INFO: epoch 020:   1820 / 2004 loss=0.204, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=353.7, nsentences=8, sample_size=353.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1024.8, ups=2.9, wpb=353.7, bsz=8, num_updates=39640, lr=6.10496e-05, gnorm=2.607, clip=0, loss_scale=512, train_wall=3, gb_free=15.4, wall=13552
2023-03-15 17:45:37 - progress_bar.py[line:272] - INFO: epoch 020:   1830 / 2004 loss=0.192, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=347.9, nsentences=8, sample_size=347.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1093.2, ups=3.14, wpb=347.9, bsz=8, num_updates=39650, lr=6.10395e-05, gnorm=2.561, clip=0, loss_scale=512, train_wall=3, gb_free=14.1, wall=13555
2023-03-15 17:45:40 - progress_bar.py[line:272] - INFO: epoch 020:   1840 / 2004 loss=0.191, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=348.1, nsentences=8, sample_size=348.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1093.4, ups=3.14, wpb=348.1, bsz=8, num_updates=39660, lr=6.10295e-05, gnorm=2.442, clip=0, loss_scale=512, train_wall=3, gb_free=14.9, wall=13558
2023-03-15 17:45:44 - progress_bar.py[line:272] - INFO: epoch 020:   1850 / 2004 loss=0.219, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=338.2, nsentences=8, sample_size=338.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1079.6, ups=3.19, wpb=338.2, bsz=8, num_updates=39670, lr=6.10194e-05, gnorm=2.658, clip=0, loss_scale=512, train_wall=3, gb_free=15.2, wall=13561
2023-03-15 17:45:47 - progress_bar.py[line:272] - INFO: epoch 020:   1860 / 2004 loss=0.193, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=326.2, nsentences=8, sample_size=326.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1012.5, ups=3.1, wpb=326.2, bsz=8, num_updates=39680, lr=6.10093e-05, gnorm=2.459, clip=0, loss_scale=512, train_wall=3, gb_free=14.9, wall=13564
2023-03-15 17:45:50 - progress_bar.py[line:272] - INFO: epoch 020:   1870 / 2004 loss=0.188, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=343.6, nsentences=8, sample_size=343.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1032.4, ups=3, wpb=343.6, bsz=8, num_updates=39690, lr=6.09992e-05, gnorm=2.357, clip=0, loss_scale=512, train_wall=3, gb_free=14.7, wall=13568
2023-03-15 17:45:53 - progress_bar.py[line:272] - INFO: epoch 020:   1880 / 2004 loss=0.182, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=332, nsentences=8, sample_size=332, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=974.7, ups=2.94, wpb=332, bsz=8, num_updates=39700, lr=6.09891e-05, gnorm=2.471, clip=0, loss_scale=512, train_wall=3, gb_free=15.1, wall=13571
2023-03-15 17:45:57 - progress_bar.py[line:272] - INFO: epoch 020:   1890 / 2004 loss=0.193, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=323, nsentences=8, sample_size=323, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=955.7, ups=2.96, wpb=323, bsz=8, num_updates=39710, lr=6.09791e-05, gnorm=2.492, clip=0, loss_scale=512, train_wall=3, gb_free=14.6, wall=13574
2023-03-15 17:46:00 - progress_bar.py[line:272] - INFO: epoch 020:   1900 / 2004 loss=0.177, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=352.6, nsentences=8, sample_size=352.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1019.7, ups=2.89, wpb=352.6, bsz=8, num_updates=39720, lr=6.0969e-05, gnorm=2.305, clip=0, loss_scale=512, train_wall=3, gb_free=14.7, wall=13578
2023-03-15 17:46:04 - progress_bar.py[line:272] - INFO: epoch 020:   1910 / 2004 loss=0.203, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=339.3, nsentences=8, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=970.2, ups=2.86, wpb=339.3, bsz=8, num_updates=39730, lr=6.09589e-05, gnorm=2.38, clip=0, loss_scale=512, train_wall=3, gb_free=14.6, wall=13581
2023-03-15 17:46:07 - progress_bar.py[line:272] - INFO: epoch 020:   1920 / 2004 loss=0.188, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=330.2, nsentences=8, sample_size=330.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=956.7, ups=2.9, wpb=330.2, bsz=8, num_updates=39740, lr=6.09488e-05, gnorm=2.376, clip=0, loss_scale=512, train_wall=3, gb_free=15.4, wall=13585
2023-03-15 17:46:11 - progress_bar.py[line:272] - INFO: epoch 020:   1930 / 2004 loss=0.222, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=316.2, nsentences=8, sample_size=316.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=934.5, ups=2.96, wpb=316.2, bsz=8, num_updates=39750, lr=6.09387e-05, gnorm=2.658, clip=0, loss_scale=512, train_wall=3, gb_free=14.7, wall=13588
2023-03-15 17:46:14 - progress_bar.py[line:272] - INFO: epoch 020:   1940 / 2004 loss=0.195, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=349.9, nsentences=8, sample_size=349.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1019.4, ups=2.91, wpb=349.9, bsz=8, num_updates=39760, lr=6.09286e-05, gnorm=2.666, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=13592
2023-03-15 17:46:18 - progress_bar.py[line:272] - INFO: epoch 020:   1950 / 2004 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=337.9, nsentences=8, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=975.5, ups=2.89, wpb=337.9, bsz=8, num_updates=39770, lr=6.09186e-05, gnorm=2.204, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=13595
2023-03-15 17:46:21 - progress_bar.py[line:272] - INFO: epoch 020:   1960 / 2004 loss=0.181, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=365.6, nsentences=8, sample_size=365.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1033.6, ups=2.83, wpb=365.6, bsz=8, num_updates=39780, lr=6.09085e-05, gnorm=2.401, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=13599
2023-03-15 17:46:24 - progress_bar.py[line:272] - INFO: epoch 020:   1970 / 2004 loss=0.205, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=336.8, nsentences=8, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1004.9, ups=2.98, wpb=336.8, bsz=8, num_updates=39790, lr=6.08984e-05, gnorm=2.397, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=13602
2023-03-15 17:46:28 - progress_bar.py[line:272] - INFO: epoch 020:   1980 / 2004 loss=0.176, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=343.1, nsentences=8, sample_size=343.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=990.3, ups=2.89, wpb=343.1, bsz=8, num_updates=39800, lr=6.08883e-05, gnorm=2.407, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=13606
2023-03-15 17:46:31 - progress_bar.py[line:272] - INFO: epoch 020:   1990 / 2004 loss=0.213, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=355.1, nsentences=8, sample_size=355.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1009.2, ups=2.84, wpb=355.1, bsz=8, num_updates=39810, lr=6.08782e-05, gnorm=2.654, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=13609
2023-03-15 17:46:35 - progress_bar.py[line:272] - INFO: epoch 020:   2000 / 2004 loss=0.199, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=377.8, nsentences=8, sample_size=377.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1149.3, ups=3.04, wpb=377.8, bsz=8, num_updates=39820, lr=6.08682e-05, gnorm=2.678, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=13612
2023-03-15 17:46:36 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 20 @ 39824 updates
2023-03-15 17:46:36 - trainer.py[line:431] - INFO: Saving checkpoint to ./checkpoints/checkpoint20.pt
2023-03-15 17:46:43 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./checkpoints/checkpoint20.pt
2023-03-15 17:46:46 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./checkpoints/checkpoint20.pt (epoch 20 @ 39824 updates, score None) (writing took 9.792998576536775 seconds)
2023-03-15 17:46:46 - train.py[line:332] - INFO: end of epoch 20 (average epoch stats below)
2023-03-15 17:46:46 - progress_bar.py[line:282] - INFO: epoch 020 | loss 0.201 | loss_v1 0 | loss_v2 0 | nll_loss 0.201 | ntokens 345.337 | nsentences 7.999 | sample_size 345.337 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.15 | wps 988.5 | ups 2.86 | wpb 345.3 | bsz 8 | num_updates 39824 | lr 6.08641e-05 | gnorm 2.558 | clip 0 | loss_scale 1024 | train_wall 673 | gb_free 13.9 | wall 13624
2023-03-15 17:46:46 - trainer.py[line:639] - INFO: loading train data for epoch 21
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 row count 8015 total row count 8015
slice_id 0 seek offset 0
2023-03-15 17:46:47 - trainer.py[line:703] - INFO: begin training epoch 21
2023-03-15 17:46:47 - train.py[line:305] - INFO: Start iterating over samples
2023-03-15 17:46:49 - progress_bar.py[line:272] - INFO: epoch 021:      6 / 2004 loss=0.197, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=382.1, nsentences=8, sample_size=382.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=267, ups=0.7, wpb=382.1, bsz=8, num_updates=39830, lr=6.08581e-05, gnorm=2.65, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=13627
2023-03-15 17:46:52 - progress_bar.py[line:272] - INFO: epoch 021:     16 / 2004 loss=0.197, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=311.6, nsentences=8, sample_size=311.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=994.4, ups=3.19, wpb=311.6, bsz=8, num_updates=39840, lr=6.0848e-05, gnorm=2.417, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=13630
2023-03-15 17:46:56 - progress_bar.py[line:272] - INFO: epoch 021:     26 / 2004 loss=0.206, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=366.9, nsentences=8, sample_size=366.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1081.5, ups=2.95, wpb=366.9, bsz=8, num_updates=39850, lr=6.08379e-05, gnorm=2.827, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=13633
2023-03-15 17:46:59 - progress_bar.py[line:272] - INFO: epoch 021:     36 / 2004 loss=0.208, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=337.9, nsentences=8, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=975.1, ups=2.89, wpb=337.9, bsz=8, num_updates=39860, lr=6.08278e-05, gnorm=2.634, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=13637
2023-03-15 17:47:03 - progress_bar.py[line:272] - INFO: epoch 021:     46 / 2004 loss=0.186, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=362.6, nsentences=8, sample_size=362.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1022.7, ups=2.82, wpb=362.6, bsz=8, num_updates=39870, lr=6.08178e-05, gnorm=2.468, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=13640
2023-03-15 17:47:06 - progress_bar.py[line:272] - INFO: epoch 021:     56 / 2004 loss=0.215, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=343, nsentences=8, sample_size=343, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=960, ups=2.8, wpb=343, bsz=8, num_updates=39880, lr=6.08077e-05, gnorm=2.619, clip=0, loss_scale=1024, train_wall=4, gb_free=14.8, wall=13644
2023-03-15 17:47:10 - progress_bar.py[line:272] - INFO: epoch 021:     66 / 2004 loss=0.185, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=337.6, nsentences=8, sample_size=337.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=946.4, ups=2.8, wpb=337.6, bsz=8, num_updates=39890, lr=6.07976e-05, gnorm=2.401, clip=0, loss_scale=2048, train_wall=4, gb_free=15.3, wall=13647
2023-03-15 17:47:13 - progress_bar.py[line:272] - INFO: epoch 021:     76 / 2004 loss=0.205, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=343, nsentences=7.8, sample_size=343, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1009.1, ups=2.94, wpb=343, bsz=7.8, num_updates=39900, lr=6.07875e-05, gnorm=2.561, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=13651
2023-03-15 17:47:16 - progress_bar.py[line:272] - INFO: epoch 021:     86 / 2004 loss=0.202, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=344, nsentences=8, sample_size=344, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1075.8, ups=3.13, wpb=344, bsz=8, num_updates=39910, lr=6.07774e-05, gnorm=2.447, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=13654
2023-03-15 17:47:19 - progress_bar.py[line:272] - INFO: epoch 021:     96 / 2004 loss=0.207, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=357.6, nsentences=8, sample_size=357.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1127.5, ups=3.15, wpb=357.6, bsz=8, num_updates=39920, lr=6.07674e-05, gnorm=2.683, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=13657
2023-03-15 17:47:23 - progress_bar.py[line:272] - INFO: epoch 021:    106 / 2004 loss=0.196, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=376.3, nsentences=8, sample_size=376.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1150.9, ups=3.06, wpb=376.3, bsz=8, num_updates=39930, lr=6.07573e-05, gnorm=2.591, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=13660
2023-03-15 17:47:26 - progress_bar.py[line:272] - INFO: epoch 021:    116 / 2004 loss=0.211, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=335.3, nsentences=8, sample_size=335.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1001.2, ups=2.99, wpb=335.3, bsz=8, num_updates=39940, lr=6.07472e-05, gnorm=2.696, clip=0, loss_scale=2048, train_wall=3, gb_free=13.8, wall=13664
2023-03-15 17:47:30 - progress_bar.py[line:272] - INFO: epoch 021:    126 / 2004 loss=0.194, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=326.2, nsentences=8, sample_size=326.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=924.1, ups=2.83, wpb=326.2, bsz=8, num_updates=39950, lr=6.07371e-05, gnorm=2.486, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=13667
2023-03-15 17:47:33 - progress_bar.py[line:272] - INFO: epoch 021:    136 / 2004 loss=0.189, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=340, nsentences=8, sample_size=340, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=990, ups=2.91, wpb=340, bsz=8, num_updates=39960, lr=6.0727e-05, gnorm=2.675, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=13671
2023-03-15 17:47:36 - progress_bar.py[line:272] - INFO: epoch 021:    146 / 2004 loss=0.19, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=333.5, nsentences=8, sample_size=333.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=968.8, ups=2.9, wpb=333.5, bsz=8, num_updates=39970, lr=6.07169e-05, gnorm=2.383, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=13674
2023-03-15 17:47:40 - progress_bar.py[line:272] - INFO: epoch 021:    156 / 2004 loss=0.223, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=347.1, nsentences=8, sample_size=347.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=997, ups=2.87, wpb=347.1, bsz=8, num_updates=39980, lr=6.07069e-05, gnorm=2.834, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=13678
2023-03-15 17:47:43 - progress_bar.py[line:272] - INFO: epoch 021:    166 / 2004 loss=0.194, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=348.7, nsentences=8, sample_size=348.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1008.5, ups=2.89, wpb=348.7, bsz=8, num_updates=39990, lr=6.06968e-05, gnorm=2.505, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=13681
2023-03-15 17:47:47 - progress_bar.py[line:272] - INFO: epoch 021:    176 / 2004 loss=0.205, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=330.2, nsentences=8, sample_size=330.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=937.9, ups=2.84, wpb=330.2, bsz=8, num_updates=40000, lr=6.06867e-05, gnorm=2.571, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=13685
2023-03-15 17:47:50 - progress_bar.py[line:272] - INFO: epoch 021:    186 / 2004 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=334.4, nsentences=8, sample_size=334.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=942.7, ups=2.82, wpb=334.4, bsz=8, num_updates=40010, lr=6.06766e-05, gnorm=2.301, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=13688
2023-03-15 17:47:54 - progress_bar.py[line:272] - INFO: epoch 021:    196 / 2004 loss=0.188, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=322.4, nsentences=8, sample_size=322.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=941.3, ups=2.92, wpb=322.4, bsz=8, num_updates=40020, lr=6.06665e-05, gnorm=2.336, clip=0, loss_scale=4096, train_wall=3, gb_free=15.4, wall=13692
2023-03-15 17:47:55 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 17:47:58 - progress_bar.py[line:272] - INFO: epoch 021:    207 / 2004 loss=0.187, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=338, nsentences=8, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=880.7, ups=2.61, wpb=338, bsz=8, num_updates=40030, lr=6.06565e-05, gnorm=2.628, clip=0, loss_scale=2048, train_wall=4, gb_free=14.8, wall=13695
2023-03-15 17:48:01 - progress_bar.py[line:272] - INFO: epoch 021:    217 / 2004 loss=0.189, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=316.1, nsentences=8, sample_size=316.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=917.1, ups=2.9, wpb=316.1, bsz=8, num_updates=40040, lr=6.06464e-05, gnorm=2.508, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=13699
2023-03-15 17:48:04 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 17:48:05 - progress_bar.py[line:272] - INFO: epoch 021:    228 / 2004 loss=0.18, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=349.4, nsentences=8, sample_size=349.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=908.9, ups=2.6, wpb=349.4, bsz=8, num_updates=40050, lr=6.06363e-05, gnorm=2.437, clip=0, loss_scale=1024, train_wall=4, gb_free=14.4, wall=13703
2023-03-15 17:48:09 - progress_bar.py[line:272] - INFO: epoch 021:    238 / 2004 loss=0.192, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=372.1, nsentences=8, sample_size=372.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1055.2, ups=2.84, wpb=372.1, bsz=8, num_updates=40060, lr=6.06262e-05, gnorm=2.544, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=13706
2023-03-15 17:48:12 - progress_bar.py[line:272] - INFO: epoch 021:    248 / 2004 loss=0.195, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=353.4, nsentences=8, sample_size=353.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1008.3, ups=2.85, wpb=353.4, bsz=8, num_updates=40070, lr=6.06161e-05, gnorm=2.555, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=13710
2023-03-15 17:48:16 - progress_bar.py[line:272] - INFO: epoch 021:    258 / 2004 loss=0.182, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=336.8, nsentences=8, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=968.9, ups=2.88, wpb=336.8, bsz=8, num_updates=40080, lr=6.06061e-05, gnorm=2.405, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=13713
2023-03-15 17:48:19 - progress_bar.py[line:272] - INFO: epoch 021:    268 / 2004 loss=0.205, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=346, nsentences=8, sample_size=346, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=990.6, ups=2.86, wpb=346, bsz=8, num_updates=40090, lr=6.0596e-05, gnorm=2.733, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=13717
2023-03-15 17:48:23 - progress_bar.py[line:272] - INFO: epoch 021:    278 / 2004 loss=0.217, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=343.2, nsentences=8, sample_size=343.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=992.3, ups=2.89, wpb=343.2, bsz=8, num_updates=40100, lr=6.05859e-05, gnorm=2.676, clip=0, loss_scale=1024, train_wall=3, gb_free=15.7, wall=13720
2023-03-15 17:48:26 - progress_bar.py[line:272] - INFO: epoch 021:    288 / 2004 loss=0.187, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=357.9, nsentences=8, sample_size=357.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1002.8, ups=2.8, wpb=357.9, bsz=8, num_updates=40110, lr=6.05758e-05, gnorm=2.44, clip=0, loss_scale=1024, train_wall=4, gb_free=15.2, wall=13724
2023-03-15 17:48:30 - progress_bar.py[line:272] - INFO: epoch 021:    298 / 2004 loss=0.183, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=382.3, nsentences=8, sample_size=382.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1087.9, ups=2.85, wpb=382.3, bsz=8, num_updates=40120, lr=6.05657e-05, gnorm=2.499, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=13727
2023-03-15 17:48:33 - progress_bar.py[line:272] - INFO: epoch 021:    308 / 2004 loss=0.187, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=342.8, nsentences=8, sample_size=342.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=974.3, ups=2.84, wpb=342.8, bsz=8, num_updates=40130, lr=6.05557e-05, gnorm=2.517, clip=0, loss_scale=1024, train_wall=3, gb_free=14.1, wall=13731
2023-03-15 17:48:37 - progress_bar.py[line:272] - INFO: epoch 021:    318 / 2004 loss=0.205, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=335.3, nsentences=8, sample_size=335.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=954.4, ups=2.85, wpb=335.3, bsz=8, num_updates=40140, lr=6.05456e-05, gnorm=2.648, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=13734
2023-03-15 17:48:40 - progress_bar.py[line:272] - INFO: epoch 021:    328 / 2004 loss=0.188, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=330.5, nsentences=8, sample_size=330.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1069.8, ups=3.24, wpb=330.5, bsz=8, num_updates=40150, lr=6.05355e-05, gnorm=2.399, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=13737
2023-03-15 17:48:43 - progress_bar.py[line:272] - INFO: epoch 021:    338 / 2004 loss=0.197, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=343.6, nsentences=8, sample_size=343.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1077.1, ups=3.13, wpb=343.6, bsz=8, num_updates=40160, lr=6.05254e-05, gnorm=2.647, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=13741
2023-03-15 17:48:46 - progress_bar.py[line:272] - INFO: epoch 021:    348 / 2004 loss=0.204, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=370.8, nsentences=8, sample_size=370.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1162.1, ups=3.13, wpb=370.8, bsz=8, num_updates=40170, lr=6.05153e-05, gnorm=2.666, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=13744
2023-03-15 17:48:49 - progress_bar.py[line:272] - INFO: epoch 021:    358 / 2004 loss=0.207, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=340.2, nsentences=8, sample_size=340.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1068.9, ups=3.14, wpb=340.2, bsz=8, num_updates=40180, lr=6.05053e-05, gnorm=2.786, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=13747
2023-03-15 17:48:52 - progress_bar.py[line:272] - INFO: epoch 021:    368 / 2004 loss=0.183, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=363, nsentences=8, sample_size=363, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1143.3, ups=3.15, wpb=363, bsz=8, num_updates=40190, lr=6.04952e-05, gnorm=2.427, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=13750
2023-03-15 17:48:56 - progress_bar.py[line:272] - INFO: epoch 021:    378 / 2004 loss=0.194, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=295.3, nsentences=8, sample_size=295.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=938.3, ups=3.18, wpb=295.3, bsz=8, num_updates=40200, lr=6.04851e-05, gnorm=2.773, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=13753
2023-03-15 17:48:59 - progress_bar.py[line:272] - INFO: epoch 021:    388 / 2004 loss=0.202, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=348.3, nsentences=8, sample_size=348.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1085.6, ups=3.12, wpb=348.3, bsz=8, num_updates=40210, lr=6.0475e-05, gnorm=2.583, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=13756
2023-03-15 17:49:02 - progress_bar.py[line:272] - INFO: epoch 021:    398 / 2004 loss=0.199, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=341.8, nsentences=8, sample_size=341.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1087.7, ups=3.18, wpb=341.8, bsz=8, num_updates=40220, lr=6.04649e-05, gnorm=2.719, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=13760
2023-03-15 17:49:05 - progress_bar.py[line:272] - INFO: epoch 021:    408 / 2004 loss=0.183, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=376.2, nsentences=8, sample_size=376.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1185.3, ups=3.15, wpb=376.2, bsz=8, num_updates=40230, lr=6.04548e-05, gnorm=2.526, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=13763
2023-03-15 17:49:08 - progress_bar.py[line:272] - INFO: epoch 021:    418 / 2004 loss=0.175, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=343.4, nsentences=8, sample_size=343.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1063.5, ups=3.1, wpb=343.4, bsz=8, num_updates=40240, lr=6.04448e-05, gnorm=2.365, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=13766
2023-03-15 17:49:12 - progress_bar.py[line:272] - INFO: epoch 021:    428 / 2004 loss=0.203, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=332.9, nsentences=8, sample_size=332.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1036.6, ups=3.11, wpb=332.9, bsz=8, num_updates=40250, lr=6.04347e-05, gnorm=2.652, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=13769
2023-03-15 17:49:15 - progress_bar.py[line:272] - INFO: epoch 021:    438 / 2004 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=355.4, nsentences=8, sample_size=355.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1114.5, ups=3.14, wpb=355.4, bsz=8, num_updates=40260, lr=6.04246e-05, gnorm=2.395, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=13772
2023-03-15 17:49:18 - progress_bar.py[line:272] - INFO: epoch 021:    448 / 2004 loss=0.184, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=373.4, nsentences=8, sample_size=373.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1156.3, ups=3.1, wpb=373.4, bsz=8, num_updates=40270, lr=6.04145e-05, gnorm=2.418, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=13776
2023-03-15 17:49:21 - progress_bar.py[line:272] - INFO: epoch 021:    458 / 2004 loss=0.186, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=393.3, nsentences=8, sample_size=393.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1212.2, ups=3.08, wpb=393.3, bsz=8, num_updates=40280, lr=6.04044e-05, gnorm=2.416, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=13779
2023-03-15 17:49:24 - progress_bar.py[line:272] - INFO: epoch 021:    468 / 2004 loss=0.235, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=362.7, nsentences=8, sample_size=362.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1144.4, ups=3.16, wpb=362.7, bsz=8, num_updates=40290, lr=6.03944e-05, gnorm=2.991, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=13782
2023-03-15 17:49:28 - progress_bar.py[line:272] - INFO: epoch 021:    478 / 2004 loss=0.215, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=332.6, nsentences=8, sample_size=332.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1044.3, ups=3.14, wpb=332.6, bsz=8, num_updates=40300, lr=6.03843e-05, gnorm=2.474, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=13785
2023-03-15 17:49:29 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 17:49:31 - progress_bar.py[line:272] - INFO: epoch 021:    489 / 2004 loss=0.198, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=375.3, nsentences=8, sample_size=375.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1046.6, ups=2.79, wpb=375.3, bsz=8, num_updates=40310, lr=6.03742e-05, gnorm=2.67, clip=0, loss_scale=2048, train_wall=4, gb_free=14.7, wall=13789
2023-03-15 17:49:34 - progress_bar.py[line:272] - INFO: epoch 021:    499 / 2004 loss=0.197, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=356.9, nsentences=8, sample_size=356.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1112.7, ups=3.12, wpb=356.9, bsz=8, num_updates=40320, lr=6.03641e-05, gnorm=2.579, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=13792
2023-03-15 17:49:38 - progress_bar.py[line:272] - INFO: epoch 021:    509 / 2004 loss=0.196, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=354.5, nsentences=8, sample_size=354.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1097.8, ups=3.1, wpb=354.5, bsz=8, num_updates=40330, lr=6.0354e-05, gnorm=2.472, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=13795
2023-03-15 17:49:41 - progress_bar.py[line:272] - INFO: epoch 021:    519 / 2004 loss=0.197, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=357.2, nsentences=8, sample_size=357.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1048.9, ups=2.94, wpb=357.2, bsz=8, num_updates=40340, lr=6.0344e-05, gnorm=2.69, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=13799
2023-03-15 17:49:45 - progress_bar.py[line:272] - INFO: epoch 021:    529 / 2004 loss=0.211, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=399.8, nsentences=8, sample_size=399.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1141.8, ups=2.86, wpb=399.8, bsz=8, num_updates=40350, lr=6.03339e-05, gnorm=2.803, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=13802
2023-03-15 17:49:45 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 17:49:48 - progress_bar.py[line:272] - INFO: epoch 021:    540 / 2004 loss=0.205, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=392.2, nsentences=8, sample_size=392.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1009.1, ups=2.57, wpb=392.2, bsz=8, num_updates=40360, lr=6.03238e-05, gnorm=2.592, clip=0, loss_scale=1024, train_wall=4, gb_free=14.3, wall=13806
2023-03-15 17:49:52 - progress_bar.py[line:272] - INFO: epoch 021:    550 / 2004 loss=0.198, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=346.1, nsentences=8, sample_size=346.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=974.6, ups=2.82, wpb=346.1, bsz=8, num_updates=40370, lr=6.03137e-05, gnorm=2.622, clip=0, loss_scale=1024, train_wall=3, gb_free=14.2, wall=13810
2023-03-15 17:49:55 - progress_bar.py[line:272] - INFO: epoch 021:    560 / 2004 loss=0.185, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=361.8, nsentences=8, sample_size=361.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1034.1, ups=2.86, wpb=361.8, bsz=8, num_updates=40380, lr=6.03036e-05, gnorm=2.404, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=13813
2023-03-15 17:49:59 - progress_bar.py[line:272] - INFO: epoch 021:    570 / 2004 loss=0.178, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=383, nsentences=8, sample_size=383, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1079.2, ups=2.82, wpb=383, bsz=8, num_updates=40390, lr=6.02936e-05, gnorm=2.253, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=13817
2023-03-15 17:50:03 - progress_bar.py[line:272] - INFO: epoch 021:    580 / 2004 loss=0.217, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=320.9, nsentences=8, sample_size=320.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=910.5, ups=2.84, wpb=320.9, bsz=8, num_updates=40400, lr=6.02835e-05, gnorm=2.648, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=13820
2023-03-15 17:50:06 - progress_bar.py[line:272] - INFO: epoch 021:    590 / 2004 loss=0.199, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=376.7, nsentences=8, sample_size=376.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1083.1, ups=2.88, wpb=376.7, bsz=8, num_updates=40410, lr=6.02734e-05, gnorm=2.504, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=13824
2023-03-15 17:50:10 - progress_bar.py[line:272] - INFO: epoch 021:    600 / 2004 loss=0.185, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=354.5, nsentences=8, sample_size=354.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=999.5, ups=2.82, wpb=354.5, bsz=8, num_updates=40420, lr=6.02633e-05, gnorm=2.468, clip=0, loss_scale=1024, train_wall=3, gb_free=13.8, wall=13827
2023-03-15 17:50:13 - progress_bar.py[line:272] - INFO: epoch 021:    610 / 2004 loss=0.175, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=332.8, nsentences=8, sample_size=332.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=946.1, ups=2.84, wpb=332.8, bsz=8, num_updates=40430, lr=6.02532e-05, gnorm=2.304, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=13831
2023-03-15 17:50:17 - progress_bar.py[line:272] - INFO: epoch 021:    620 / 2004 loss=0.213, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=371, nsentences=8, sample_size=371, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1013.3, ups=2.73, wpb=371, bsz=8, num_updates=40440, lr=6.02432e-05, gnorm=2.857, clip=0, loss_scale=1024, train_wall=4, gb_free=15, wall=13834
2023-03-15 17:50:20 - progress_bar.py[line:272] - INFO: epoch 021:    630 / 2004 loss=0.191, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=352, nsentences=8, sample_size=352, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1024.5, ups=2.91, wpb=352, bsz=8, num_updates=40450, lr=6.02331e-05, gnorm=2.604, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=13838
2023-03-15 17:50:24 - progress_bar.py[line:272] - INFO: epoch 021:    640 / 2004 loss=0.184, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=339.7, nsentences=8, sample_size=339.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=977.6, ups=2.88, wpb=339.7, bsz=8, num_updates=40460, lr=6.0223e-05, gnorm=2.301, clip=0, loss_scale=1024, train_wall=3, gb_free=13.5, wall=13841
2023-03-15 17:50:27 - progress_bar.py[line:272] - INFO: epoch 021:    650 / 2004 loss=0.226, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=327, nsentences=8, sample_size=327, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=937.3, ups=2.87, wpb=327, bsz=8, num_updates=40470, lr=6.02129e-05, gnorm=2.676, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=13845
2023-03-15 17:50:31 - progress_bar.py[line:272] - INFO: epoch 021:    660 / 2004 loss=0.205, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=342.7, nsentences=8, sample_size=342.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=965.9, ups=2.82, wpb=342.7, bsz=8, num_updates=40480, lr=6.02028e-05, gnorm=2.597, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=13848
2023-03-15 17:50:34 - progress_bar.py[line:272] - INFO: epoch 021:    670 / 2004 loss=0.199, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=316.4, nsentences=8, sample_size=316.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=902.6, ups=2.85, wpb=316.4, bsz=8, num_updates=40490, lr=6.01927e-05, gnorm=2.394, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=13852
2023-03-15 17:50:38 - progress_bar.py[line:272] - INFO: epoch 021:    680 / 2004 loss=0.201, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=334.9, nsentences=8, sample_size=334.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=942.3, ups=2.81, wpb=334.9, bsz=8, num_updates=40500, lr=6.01827e-05, gnorm=2.618, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=13855
2023-03-15 17:50:41 - progress_bar.py[line:272] - INFO: epoch 021:    690 / 2004 loss=0.189, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=358, nsentences=8, sample_size=358, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1028.2, ups=2.87, wpb=358, bsz=8, num_updates=40510, lr=6.01726e-05, gnorm=2.429, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=13859
2023-03-15 17:50:45 - progress_bar.py[line:272] - INFO: epoch 021:    700 / 2004 loss=0.195, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=341.9, nsentences=8, sample_size=341.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=974.8, ups=2.85, wpb=341.9, bsz=8, num_updates=40520, lr=6.01625e-05, gnorm=2.503, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=13862
2023-03-15 17:50:48 - progress_bar.py[line:272] - INFO: epoch 021:    710 / 2004 loss=0.208, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=334.8, nsentences=8, sample_size=334.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=960.3, ups=2.87, wpb=334.8, bsz=8, num_updates=40530, lr=6.01524e-05, gnorm=2.673, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=13866
2023-03-15 17:50:52 - progress_bar.py[line:272] - INFO: epoch 021:    720 / 2004 loss=0.227, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=353, nsentences=8, sample_size=353, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1011.9, ups=2.87, wpb=353, bsz=8, num_updates=40540, lr=6.01423e-05, gnorm=2.891, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=13869
2023-03-15 17:50:55 - progress_bar.py[line:272] - INFO: epoch 021:    730 / 2004 loss=0.199, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=351.9, nsentences=8, sample_size=351.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1002, ups=2.85, wpb=351.9, bsz=8, num_updates=40550, lr=6.01323e-05, gnorm=2.584, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=13873
2023-03-15 17:50:59 - progress_bar.py[line:272] - INFO: epoch 021:    740 / 2004 loss=0.183, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=331.7, nsentences=8, sample_size=331.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=960.9, ups=2.9, wpb=331.7, bsz=8, num_updates=40560, lr=6.01222e-05, gnorm=2.345, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=13876
2023-03-15 17:51:02 - progress_bar.py[line:272] - INFO: epoch 021:    750 / 2004 loss=0.228, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=364.1, nsentences=8, sample_size=364.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1043.9, ups=2.87, wpb=364.1, bsz=8, num_updates=40570, lr=6.01121e-05, gnorm=2.971, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=13880
2023-03-15 17:51:06 - progress_bar.py[line:272] - INFO: epoch 021:    760 / 2004 loss=0.19, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=302.5, nsentences=8, sample_size=302.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=876.9, ups=2.9, wpb=302.5, bsz=8, num_updates=40580, lr=6.0102e-05, gnorm=2.728, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=13883
2023-03-15 17:51:09 - progress_bar.py[line:272] - INFO: epoch 021:    770 / 2004 loss=0.212, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=417.2, nsentences=8, sample_size=417.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1165, ups=2.79, wpb=417.2, bsz=8, num_updates=40590, lr=6.00919e-05, gnorm=2.735, clip=0, loss_scale=2048, train_wall=4, gb_free=14.7, wall=13887
2023-03-15 17:51:13 - progress_bar.py[line:272] - INFO: epoch 021:    780 / 2004 loss=0.198, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=326.7, nsentences=8, sample_size=326.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=938, ups=2.87, wpb=326.7, bsz=8, num_updates=40600, lr=6.00819e-05, gnorm=2.58, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=13890
2023-03-15 17:51:16 - progress_bar.py[line:272] - INFO: epoch 021:    790 / 2004 loss=0.186, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=353, nsentences=8, sample_size=353, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=992.3, ups=2.81, wpb=353, bsz=8, num_updates=40610, lr=6.00718e-05, gnorm=2.622, clip=0, loss_scale=4096, train_wall=3, gb_free=14.5, wall=13894
2023-03-15 17:51:19 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 17:51:20 - progress_bar.py[line:272] - INFO: epoch 021:    801 / 2004 loss=0.193, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=327.5, nsentences=8, sample_size=327.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=863.1, ups=2.64, wpb=327.5, bsz=8, num_updates=40620, lr=6.00617e-05, gnorm=2.421, clip=0, loss_scale=2048, train_wall=4, gb_free=15.1, wall=13898
2023-03-15 17:51:24 - progress_bar.py[line:272] - INFO: epoch 021:    811 / 2004 loss=0.184, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=352.5, nsentences=8, sample_size=352.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1011.7, ups=2.87, wpb=352.5, bsz=8, num_updates=40630, lr=6.00516e-05, gnorm=2.465, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=13901
2023-03-15 17:51:27 - progress_bar.py[line:272] - INFO: epoch 021:    821 / 2004 loss=0.194, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=321, nsentences=8, sample_size=321, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=909.6, ups=2.83, wpb=321, bsz=8, num_updates=40640, lr=6.00415e-05, gnorm=2.498, clip=0, loss_scale=2048, train_wall=3, gb_free=13.6, wall=13905
2023-03-15 17:51:31 - progress_bar.py[line:272] - INFO: epoch 021:    831 / 2004 loss=0.23, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=355.1, nsentences=8, sample_size=355.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=992.7, ups=2.8, wpb=355.1, bsz=8, num_updates=40650, lr=6.00315e-05, gnorm=2.918, clip=0, loss_scale=2048, train_wall=4, gb_free=14.4, wall=13908
2023-03-15 17:51:34 - progress_bar.py[line:272] - INFO: epoch 021:    841 / 2004 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=353.7, nsentences=8, sample_size=353.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=979.5, ups=2.77, wpb=353.7, bsz=8, num_updates=40660, lr=6.00214e-05, gnorm=2.282, clip=0, loss_scale=2048, train_wall=4, gb_free=14.8, wall=13912
2023-03-15 17:51:38 - progress_bar.py[line:272] - INFO: epoch 021:    851 / 2004 loss=0.198, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=358, nsentences=8, sample_size=358, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1018.3, ups=2.84, wpb=358, bsz=8, num_updates=40670, lr=6.00113e-05, gnorm=2.461, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=13915
2023-03-15 17:51:41 - progress_bar.py[line:272] - INFO: epoch 021:    861 / 2004 loss=0.186, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=345.4, nsentences=8, sample_size=345.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=989.7, ups=2.87, wpb=345.4, bsz=8, num_updates=40680, lr=6.00012e-05, gnorm=2.579, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=13919
2023-03-15 17:51:45 - progress_bar.py[line:272] - INFO: epoch 021:    871 / 2004 loss=0.211, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=379.1, nsentences=8, sample_size=379.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1088.3, ups=2.87, wpb=379.1, bsz=8, num_updates=40690, lr=5.99911e-05, gnorm=2.701, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=13922
2023-03-15 17:51:48 - progress_bar.py[line:272] - INFO: epoch 021:    881 / 2004 loss=0.198, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=314.8, nsentences=8, sample_size=314.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=926.5, ups=2.94, wpb=314.8, bsz=8, num_updates=40700, lr=5.9981e-05, gnorm=2.502, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=13926
2023-03-15 17:51:52 - progress_bar.py[line:272] - INFO: epoch 021:    891 / 2004 loss=0.189, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=319.1, nsentences=8, sample_size=319.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=916.6, ups=2.87, wpb=319.1, bsz=8, num_updates=40710, lr=5.9971e-05, gnorm=2.6, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=13929
2023-03-15 17:51:55 - progress_bar.py[line:272] - INFO: epoch 021:    901 / 2004 loss=0.205, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=360.1, nsentences=8, sample_size=360.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1025.8, ups=2.85, wpb=360.1, bsz=8, num_updates=40720, lr=5.99609e-05, gnorm=2.7, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=13933
2023-03-15 17:51:59 - progress_bar.py[line:272] - INFO: epoch 021:    911 / 2004 loss=0.195, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=354.9, nsentences=8, sample_size=354.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1016.6, ups=2.86, wpb=354.9, bsz=8, num_updates=40730, lr=5.99508e-05, gnorm=2.597, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=13936
2023-03-15 17:52:02 - progress_bar.py[line:272] - INFO: epoch 021:    921 / 2004 loss=0.199, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=346.2, nsentences=8, sample_size=346.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=999, ups=2.89, wpb=346.2, bsz=8, num_updates=40740, lr=5.99407e-05, gnorm=2.676, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=13940
2023-03-15 17:52:05 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 17:52:06 - progress_bar.py[line:272] - INFO: epoch 021:    932 / 2004 loss=0.195, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=330.1, nsentences=8, sample_size=330.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=885.7, ups=2.68, wpb=330.1, bsz=8, num_updates=40750, lr=5.99306e-05, gnorm=2.68, clip=0, loss_scale=2048, train_wall=4, gb_free=14.9, wall=13943
2023-03-15 17:52:09 - progress_bar.py[line:272] - INFO: epoch 021:    942 / 2004 loss=0.176, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=376.6, nsentences=8, sample_size=376.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1079.7, ups=2.87, wpb=376.6, bsz=8, num_updates=40760, lr=5.99206e-05, gnorm=2.272, clip=0, loss_scale=2048, train_wall=3, gb_free=13.9, wall=13947
2023-03-15 17:52:13 - progress_bar.py[line:272] - INFO: epoch 021:    952 / 2004 loss=0.19, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=343.4, nsentences=8, sample_size=343.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=983.5, ups=2.86, wpb=343.4, bsz=8, num_updates=40770, lr=5.99105e-05, gnorm=2.488, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=13950
2023-03-15 17:52:16 - progress_bar.py[line:272] - INFO: epoch 021:    962 / 2004 loss=0.202, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=381.7, nsentences=8, sample_size=381.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1058.2, ups=2.77, wpb=381.7, bsz=8, num_updates=40780, lr=5.99004e-05, gnorm=2.537, clip=0, loss_scale=2048, train_wall=4, gb_free=15.4, wall=13954
2023-03-15 17:52:20 - progress_bar.py[line:272] - INFO: epoch 021:    972 / 2004 loss=0.204, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=332.1, nsentences=8, sample_size=332.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=950.9, ups=2.86, wpb=332.1, bsz=8, num_updates=40790, lr=5.98903e-05, gnorm=2.473, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=13958
2023-03-15 17:52:23 - progress_bar.py[line:272] - INFO: epoch 021:    982 / 2004 loss=0.194, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=315.8, nsentences=8, sample_size=315.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=918.7, ups=2.91, wpb=315.8, bsz=8, num_updates=40800, lr=5.98802e-05, gnorm=2.572, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=13961
2023-03-15 17:52:27 - progress_bar.py[line:272] - INFO: epoch 021:    992 / 2004 loss=0.183, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=382.3, nsentences=8, sample_size=382.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1104.2, ups=2.89, wpb=382.3, bsz=8, num_updates=40810, lr=5.98702e-05, gnorm=2.383, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=13964
2023-03-15 17:52:30 - progress_bar.py[line:272] - INFO: epoch 021:   1002 / 2004 loss=0.186, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=329.7, nsentences=8, sample_size=329.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=953.4, ups=2.89, wpb=329.7, bsz=8, num_updates=40820, lr=5.98601e-05, gnorm=2.478, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=13968
2023-03-15 17:52:34 - progress_bar.py[line:272] - INFO: epoch 021:   1012 / 2004 loss=0.216, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=334.7, nsentences=8, sample_size=334.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=957.7, ups=2.86, wpb=334.7, bsz=8, num_updates=40830, lr=5.985e-05, gnorm=2.661, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=13971
2023-03-15 17:52:37 - progress_bar.py[line:272] - INFO: epoch 021:   1022 / 2004 loss=0.206, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=325.3, nsentences=8, sample_size=325.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=939.9, ups=2.89, wpb=325.3, bsz=8, num_updates=40840, lr=5.98399e-05, gnorm=2.563, clip=0, loss_scale=2048, train_wall=3, gb_free=15.8, wall=13975
2023-03-15 17:52:41 - progress_bar.py[line:272] - INFO: epoch 021:   1032 / 2004 loss=0.181, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=324.1, nsentences=8, sample_size=324.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=938.6, ups=2.9, wpb=324.1, bsz=8, num_updates=40850, lr=5.98298e-05, gnorm=2.341, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=13978
2023-03-15 17:52:44 - progress_bar.py[line:272] - INFO: epoch 021:   1042 / 2004 loss=0.203, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=342, nsentences=8, sample_size=342, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=983.6, ups=2.88, wpb=342, bsz=8, num_updates=40860, lr=5.98198e-05, gnorm=2.53, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=13982
2023-03-15 17:52:48 - progress_bar.py[line:272] - INFO: epoch 021:   1052 / 2004 loss=0.215, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=368.4, nsentences=8, sample_size=368.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1049.5, ups=2.85, wpb=368.4, bsz=8, num_updates=40870, lr=5.98097e-05, gnorm=2.695, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=13985
2023-03-15 17:52:51 - progress_bar.py[line:272] - INFO: epoch 021:   1062 / 2004 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=339.1, nsentences=8, sample_size=339.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=949.6, ups=2.8, wpb=339.1, bsz=8, num_updates=40880, lr=5.97996e-05, gnorm=2.34, clip=0, loss_scale=4096, train_wall=4, gb_free=15, wall=13989
2023-03-15 17:52:53 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 17:52:55 - progress_bar.py[line:272] - INFO: epoch 021:   1073 / 2004 loss=0.189, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=347, nsentences=8, sample_size=347, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=884.1, ups=2.55, wpb=347, bsz=8, num_updates=40890, lr=5.97895e-05, gnorm=2.446, clip=0, loss_scale=2048, train_wall=4, gb_free=15, wall=13993
2023-03-15 17:52:59 - progress_bar.py[line:272] - INFO: epoch 021:   1083 / 2004 loss=0.194, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=365.6, nsentences=8, sample_size=365.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1033.4, ups=2.83, wpb=365.6, bsz=8, num_updates=40900, lr=5.97794e-05, gnorm=2.456, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=13996
2023-03-15 17:53:02 - progress_bar.py[line:272] - INFO: epoch 021:   1093 / 2004 loss=0.189, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=336.9, nsentences=8, sample_size=336.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=969.6, ups=2.88, wpb=336.9, bsz=8, num_updates=40910, lr=5.97694e-05, gnorm=2.303, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=14000
2023-03-15 17:53:06 - progress_bar.py[line:272] - INFO: epoch 021:   1103 / 2004 loss=0.202, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=369, nsentences=8, sample_size=369, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1038.8, ups=2.82, wpb=369, bsz=8, num_updates=40920, lr=5.97593e-05, gnorm=2.854, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=14003
2023-03-15 17:53:09 - progress_bar.py[line:272] - INFO: epoch 021:   1113 / 2004 loss=0.218, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=345.6, nsentences=8, sample_size=345.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1017, ups=2.94, wpb=345.6, bsz=8, num_updates=40930, lr=5.97492e-05, gnorm=2.695, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=14007
2023-03-15 17:53:13 - progress_bar.py[line:272] - INFO: epoch 021:   1123 / 2004 loss=0.177, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=309.4, nsentences=8, sample_size=309.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=905.5, ups=2.93, wpb=309.4, bsz=8, num_updates=40940, lr=5.97391e-05, gnorm=2.504, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=14010
2023-03-15 17:53:13 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 17:53:16 - progress_bar.py[line:272] - INFO: epoch 021:   1134 / 2004 loss=0.2, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=394.4, nsentences=8, sample_size=394.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1101.2, ups=2.79, wpb=394.4, bsz=8, num_updates=40950, lr=5.9729e-05, gnorm=2.445, clip=0, loss_scale=1024, train_wall=4, gb_free=13.9, wall=14014
2023-03-15 17:53:19 - progress_bar.py[line:272] - INFO: epoch 021:   1144 / 2004 loss=0.193, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=338.3, nsentences=8, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1062.2, ups=3.14, wpb=338.3, bsz=8, num_updates=40960, lr=5.97189e-05, gnorm=2.401, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=14017
2023-03-15 17:53:22 - progress_bar.py[line:272] - INFO: epoch 021:   1154 / 2004 loss=0.221, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=391.1, nsentences=8, sample_size=391.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1239.2, ups=3.17, wpb=391.1, bsz=8, num_updates=40970, lr=5.97089e-05, gnorm=2.671, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=14020
2023-03-15 17:53:26 - progress_bar.py[line:272] - INFO: epoch 021:   1164 / 2004 loss=0.188, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=364.6, nsentences=8, sample_size=364.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1122.3, ups=3.08, wpb=364.6, bsz=8, num_updates=40980, lr=5.96988e-05, gnorm=2.588, clip=0, loss_scale=1024, train_wall=3, gb_free=13.9, wall=14023
2023-03-15 17:53:29 - progress_bar.py[line:272] - INFO: epoch 021:   1174 / 2004 loss=0.181, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=356.9, nsentences=8, sample_size=356.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1105.5, ups=3.1, wpb=356.9, bsz=8, num_updates=40990, lr=5.96887e-05, gnorm=2.348, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=14027
2023-03-15 17:53:32 - progress_bar.py[line:272] - INFO: epoch 021:   1184 / 2004 loss=0.178, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=328.1, nsentences=8, sample_size=328.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=940.8, ups=2.87, wpb=328.1, bsz=8, num_updates=41000, lr=5.96786e-05, gnorm=2.347, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=14030
2023-03-15 17:53:36 - progress_bar.py[line:272] - INFO: epoch 021:   1194 / 2004 loss=0.183, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=360.4, nsentences=8, sample_size=360.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1030.4, ups=2.86, wpb=360.4, bsz=8, num_updates=41010, lr=5.96685e-05, gnorm=2.472, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=14034
2023-03-15 17:53:39 - progress_bar.py[line:272] - INFO: epoch 021:   1204 / 2004 loss=0.194, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=313.8, nsentences=8, sample_size=313.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=907.7, ups=2.89, wpb=313.8, bsz=8, num_updates=41020, lr=5.96585e-05, gnorm=2.451, clip=0, loss_scale=1024, train_wall=3, gb_free=15.8, wall=14037
2023-03-15 17:53:43 - progress_bar.py[line:272] - INFO: epoch 021:   1214 / 2004 loss=0.2, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=308.1, nsentences=8, sample_size=308.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=892.6, ups=2.9, wpb=308.1, bsz=8, num_updates=41030, lr=5.96484e-05, gnorm=2.538, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=14040
2023-03-15 17:53:46 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-03-15 17:53:47 - progress_bar.py[line:272] - INFO: epoch 021:   1225 / 2004 loss=0.175, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=318.3, nsentences=8, sample_size=318.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=845.2, ups=2.66, wpb=318.3, bsz=8, num_updates=41040, lr=5.96383e-05, gnorm=2.221, clip=0, loss_scale=512, train_wall=4, gb_free=14.6, wall=14044
2023-03-15 17:53:50 - progress_bar.py[line:272] - INFO: epoch 021:   1235 / 2004 loss=0.189, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=344.5, nsentences=8, sample_size=344.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=988.8, ups=2.87, wpb=344.5, bsz=8, num_updates=41050, lr=5.96282e-05, gnorm=2.307, clip=0, loss_scale=512, train_wall=3, gb_free=14.1, wall=14048
2023-03-15 17:53:54 - progress_bar.py[line:272] - INFO: epoch 021:   1245 / 2004 loss=0.212, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=359.4, nsentences=8, sample_size=359.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1030.2, ups=2.87, wpb=359.4, bsz=8, num_updates=41060, lr=5.96181e-05, gnorm=2.808, clip=0, loss_scale=512, train_wall=3, gb_free=15.7, wall=14051
2023-03-15 17:53:57 - progress_bar.py[line:272] - INFO: epoch 021:   1255 / 2004 loss=0.195, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=347.9, nsentences=8, sample_size=347.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=986.8, ups=2.84, wpb=347.9, bsz=8, num_updates=41070, lr=5.96081e-05, gnorm=2.429, clip=0, loss_scale=512, train_wall=3, gb_free=15.1, wall=14055
2023-03-15 17:54:01 - progress_bar.py[line:272] - INFO: epoch 021:   1265 / 2004 loss=0.21, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=331.6, nsentences=8, sample_size=331.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=954.8, ups=2.88, wpb=331.6, bsz=8, num_updates=41080, lr=5.9598e-05, gnorm=2.919, clip=0, loss_scale=512, train_wall=3, gb_free=15.2, wall=14058
2023-03-15 17:54:04 - progress_bar.py[line:272] - INFO: epoch 021:   1275 / 2004 loss=0.171, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=356.3, nsentences=8, sample_size=356.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1022.4, ups=2.87, wpb=356.3, bsz=8, num_updates=41090, lr=5.95879e-05, gnorm=2.179, clip=0, loss_scale=512, train_wall=3, gb_free=14.6, wall=14062
2023-03-15 17:54:06 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-03-15 17:54:08 - progress_bar.py[line:272] - INFO: epoch 021:   1286 / 2004 loss=0.177, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=322.2, nsentences=8, sample_size=322.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=838.5, ups=2.6, wpb=322.2, bsz=8, num_updates=41100, lr=5.95778e-05, gnorm=2.409, clip=0, loss_scale=256, train_wall=4, gb_free=14.8, wall=14066
2023-03-15 17:54:11 - progress_bar.py[line:272] - INFO: epoch 021:   1296 / 2004 loss=0.183, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=317.6, nsentences=8, sample_size=317.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=930.9, ups=2.93, wpb=317.6, bsz=8, num_updates=41110, lr=5.95677e-05, gnorm=2.438, clip=0, loss_scale=256, train_wall=3, gb_free=15.3, wall=14069
2023-03-15 17:54:15 - progress_bar.py[line:272] - INFO: epoch 021:   1306 / 2004 loss=0.183, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=306.1, nsentences=8, sample_size=306.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=884.7, ups=2.89, wpb=306.1, bsz=8, num_updates=41120, lr=5.95577e-05, gnorm=2.179, clip=0, loss_scale=256, train_wall=3, gb_free=15.2, wall=14072
2023-03-15 17:54:18 - progress_bar.py[line:272] - INFO: epoch 021:   1316 / 2004 loss=0.19, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=349.7, nsentences=8, sample_size=349.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1010, ups=2.89, wpb=349.7, bsz=8, num_updates=41130, lr=5.95476e-05, gnorm=2.375, clip=0, loss_scale=256, train_wall=3, gb_free=14.7, wall=14076
2023-03-15 17:54:22 - progress_bar.py[line:272] - INFO: epoch 021:   1326 / 2004 loss=0.198, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=296, nsentences=8, sample_size=296, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=851.3, ups=2.88, wpb=296, bsz=8, num_updates=41140, lr=5.95375e-05, gnorm=2.721, clip=0, loss_scale=256, train_wall=3, gb_free=15.3, wall=14079
2023-03-15 17:54:25 - progress_bar.py[line:272] - INFO: epoch 021:   1336 / 2004 loss=0.19, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=361.4, nsentences=8, sample_size=361.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1021.4, ups=2.83, wpb=361.4, bsz=8, num_updates=41150, lr=5.95274e-05, gnorm=2.457, clip=0, loss_scale=256, train_wall=3, gb_free=14.9, wall=14083
2023-03-15 17:54:29 - progress_bar.py[line:272] - INFO: epoch 021:   1346 / 2004 loss=0.212, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=297.5, nsentences=8, sample_size=297.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=866.4, ups=2.91, wpb=297.5, bsz=8, num_updates=41160, lr=5.95173e-05, gnorm=2.959, clip=0, loss_scale=256, train_wall=3, gb_free=14.2, wall=14086
2023-03-15 17:54:32 - progress_bar.py[line:272] - INFO: epoch 021:   1356 / 2004 loss=0.192, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=327.6, nsentences=8, sample_size=327.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=956, ups=2.92, wpb=327.6, bsz=8, num_updates=41170, lr=5.95072e-05, gnorm=2.593, clip=0, loss_scale=256, train_wall=3, gb_free=14.9, wall=14090
2023-03-15 17:54:36 - progress_bar.py[line:272] - INFO: epoch 021:   1366 / 2004 loss=0.177, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=310.3, nsentences=8, sample_size=310.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=897.7, ups=2.89, wpb=310.3, bsz=8, num_updates=41180, lr=5.94972e-05, gnorm=2.368, clip=0, loss_scale=256, train_wall=3, gb_free=15.2, wall=14093
2023-03-15 17:54:39 - progress_bar.py[line:272] - INFO: epoch 021:   1376 / 2004 loss=0.188, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=329.6, nsentences=8, sample_size=329.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=953.1, ups=2.89, wpb=329.6, bsz=8, num_updates=41190, lr=5.94871e-05, gnorm=2.48, clip=0, loss_scale=256, train_wall=3, gb_free=13.9, wall=14097
2023-03-15 17:54:43 - progress_bar.py[line:272] - INFO: epoch 021:   1386 / 2004 loss=0.179, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=398.5, nsentences=8, sample_size=398.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1114.5, ups=2.8, wpb=398.5, bsz=8, num_updates=41200, lr=5.9477e-05, gnorm=2.541, clip=0, loss_scale=256, train_wall=4, gb_free=13.9, wall=14100
2023-03-15 17:54:46 - progress_bar.py[line:272] - INFO: epoch 021:   1396 / 2004 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=344.1, nsentences=8, sample_size=344.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=986.1, ups=2.87, wpb=344.1, bsz=8, num_updates=41210, lr=5.94669e-05, gnorm=2.269, clip=0, loss_scale=256, train_wall=3, gb_free=13.6, wall=14104
2023-03-15 17:54:50 - progress_bar.py[line:272] - INFO: epoch 021:   1406 / 2004 loss=0.19, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=335, nsentences=8, sample_size=335, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=964.4, ups=2.88, wpb=335, bsz=8, num_updates=41220, lr=5.94568e-05, gnorm=2.487, clip=0, loss_scale=256, train_wall=3, gb_free=15, wall=14107
2023-03-15 17:54:53 - progress_bar.py[line:272] - INFO: epoch 021:   1416 / 2004 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=394.7, nsentences=8, sample_size=394.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=1137.9, ups=2.88, wpb=394.7, bsz=8, num_updates=41230, lr=5.94468e-05, gnorm=2.938, clip=0, loss_scale=512, train_wall=3, gb_free=14.6, wall=14111
2023-03-15 17:54:56 - progress_bar.py[line:272] - INFO: epoch 021:   1426 / 2004 loss=0.182, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=282.6, nsentences=8, sample_size=282.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=827.2, ups=2.93, wpb=282.6, bsz=8, num_updates=41240, lr=5.94367e-05, gnorm=2.288, clip=0, loss_scale=512, train_wall=3, gb_free=14.8, wall=14114
2023-03-15 17:55:00 - progress_bar.py[line:272] - INFO: epoch 021:   1436 / 2004 loss=0.196, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=356.9, nsentences=8, sample_size=356.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1043.9, ups=2.92, wpb=356.9, bsz=8, num_updates=41250, lr=5.94266e-05, gnorm=2.641, clip=0, loss_scale=512, train_wall=3, gb_free=15.6, wall=14117
2023-03-15 17:55:03 - progress_bar.py[line:272] - INFO: epoch 021:   1446 / 2004 loss=0.195, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=340.3, nsentences=8, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=971.7, ups=2.86, wpb=340.3, bsz=8, num_updates=41260, lr=5.94165e-05, gnorm=2.545, clip=0, loss_scale=512, train_wall=3, gb_free=15.1, wall=14121
2023-03-15 17:55:07 - progress_bar.py[line:272] - INFO: epoch 021:   1456 / 2004 loss=0.203, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=369.2, nsentences=8, sample_size=369.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1032.3, ups=2.8, wpb=369.2, bsz=8, num_updates=41270, lr=5.94064e-05, gnorm=2.744, clip=0, loss_scale=512, train_wall=4, gb_free=14.1, wall=14125
2023-03-15 17:55:10 - progress_bar.py[line:272] - INFO: epoch 021:   1466 / 2004 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=393.9, nsentences=8, sample_size=393.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1116.7, ups=2.83, wpb=393.9, bsz=8, num_updates=41280, lr=5.93964e-05, gnorm=2.251, clip=0, loss_scale=512, train_wall=3, gb_free=14.5, wall=14128
2023-03-15 17:55:14 - progress_bar.py[line:272] - INFO: epoch 021:   1476 / 2004 loss=0.202, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=399.2, nsentences=8, sample_size=399.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1145.8, ups=2.87, wpb=399.2, bsz=8, num_updates=41290, lr=5.93863e-05, gnorm=2.595, clip=0, loss_scale=512, train_wall=3, gb_free=15.2, wall=14132
2023-03-15 17:55:17 - progress_bar.py[line:272] - INFO: epoch 021:   1486 / 2004 loss=0.186, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=351.9, nsentences=8, sample_size=351.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1020.7, ups=2.9, wpb=351.9, bsz=8, num_updates=41300, lr=5.93762e-05, gnorm=2.251, clip=0, loss_scale=512, train_wall=3, gb_free=15.6, wall=14135
2023-03-15 17:55:21 - progress_bar.py[line:272] - INFO: epoch 021:   1496 / 2004 loss=0.215, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=334, nsentences=8, sample_size=334, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=965.1, ups=2.89, wpb=334, bsz=8, num_updates=41310, lr=5.93661e-05, gnorm=2.443, clip=0, loss_scale=512, train_wall=3, gb_free=15, wall=14138
2023-03-15 17:55:24 - progress_bar.py[line:272] - INFO: epoch 021:   1506 / 2004 loss=0.186, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=318.9, nsentences=8, sample_size=318.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=975.1, ups=3.06, wpb=318.9, bsz=8, num_updates=41320, lr=5.9356e-05, gnorm=2.515, clip=0, loss_scale=512, train_wall=3, gb_free=14.9, wall=14142
2023-03-15 17:55:27 - progress_bar.py[line:272] - INFO: epoch 021:   1516 / 2004 loss=0.201, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=327.6, nsentences=8, sample_size=327.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1050.5, ups=3.21, wpb=327.6, bsz=8, num_updates=41330, lr=5.9346e-05, gnorm=2.498, clip=0, loss_scale=512, train_wall=3, gb_free=14.7, wall=14145
2023-03-15 17:55:30 - progress_bar.py[line:272] - INFO: epoch 021:   1526 / 2004 loss=0.195, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=330.1, nsentences=8, sample_size=330.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1038.3, ups=3.15, wpb=330.1, bsz=8, num_updates=41340, lr=5.93359e-05, gnorm=2.496, clip=0, loss_scale=512, train_wall=3, gb_free=14, wall=14148
2023-03-15 17:55:34 - progress_bar.py[line:272] - INFO: epoch 021:   1536 / 2004 loss=0.178, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=354.8, nsentences=8, sample_size=354.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1047.2, ups=2.95, wpb=354.8, bsz=8, num_updates=41350, lr=5.93258e-05, gnorm=2.264, clip=0, loss_scale=512, train_wall=3, gb_free=14.9, wall=14151
2023-03-15 17:55:37 - progress_bar.py[line:272] - INFO: epoch 021:   1546 / 2004 loss=0.18, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=324.7, nsentences=8, sample_size=324.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=946.2, ups=2.91, wpb=324.7, bsz=8, num_updates=41360, lr=5.93157e-05, gnorm=2.573, clip=0, loss_scale=1024, train_wall=3, gb_free=14.1, wall=14155
2023-03-15 17:55:41 - progress_bar.py[line:272] - INFO: epoch 021:   1556 / 2004 loss=0.195, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=339.6, nsentences=8, sample_size=339.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=998.2, ups=2.94, wpb=339.6, bsz=8, num_updates=41370, lr=5.93056e-05, gnorm=2.476, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=14158
2023-03-15 17:55:44 - progress_bar.py[line:272] - INFO: epoch 021:   1566 / 2004 loss=0.194, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=342.6, nsentences=8, sample_size=342.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=974.6, ups=2.84, wpb=342.6, bsz=8, num_updates=41380, lr=5.92956e-05, gnorm=2.541, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=14162
2023-03-15 17:55:48 - progress_bar.py[line:272] - INFO: epoch 021:   1576 / 2004 loss=0.199, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=351.2, nsentences=8, sample_size=351.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1009.4, ups=2.87, wpb=351.2, bsz=8, num_updates=41390, lr=5.92855e-05, gnorm=2.666, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=14165
2023-03-15 17:55:51 - progress_bar.py[line:272] - INFO: epoch 021:   1586 / 2004 loss=0.201, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=322, nsentences=8, sample_size=322, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=923, ups=2.87, wpb=322, bsz=8, num_updates=41400, lr=5.92754e-05, gnorm=2.662, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=14169
2023-03-15 17:55:55 - progress_bar.py[line:272] - INFO: epoch 021:   1596 / 2004 loss=0.208, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=353.3, nsentences=8, sample_size=353.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1012.1, ups=2.86, wpb=353.3, bsz=8, num_updates=41410, lr=5.92653e-05, gnorm=2.665, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=14172
2023-03-15 17:55:58 - progress_bar.py[line:272] - INFO: epoch 021:   1606 / 2004 loss=0.195, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=337.1, nsentences=8, sample_size=337.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=977.9, ups=2.9, wpb=337.1, bsz=8, num_updates=41420, lr=5.92552e-05, gnorm=2.542, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=14176
2023-03-15 17:56:02 - progress_bar.py[line:272] - INFO: epoch 021:   1616 / 2004 loss=0.205, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=332.6, nsentences=8, sample_size=332.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=947.3, ups=2.85, wpb=332.6, bsz=8, num_updates=41430, lr=5.92451e-05, gnorm=2.461, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=14179
2023-03-15 17:56:05 - progress_bar.py[line:272] - INFO: epoch 021:   1626 / 2004 loss=0.207, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=364.7, nsentences=8, sample_size=364.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1055.6, ups=2.89, wpb=364.7, bsz=8, num_updates=41440, lr=5.92351e-05, gnorm=2.547, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=14183
2023-03-15 17:56:09 - progress_bar.py[line:272] - INFO: epoch 021:   1636 / 2004 loss=0.179, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=324, nsentences=8, sample_size=324, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=937.8, ups=2.89, wpb=324, bsz=8, num_updates=41450, lr=5.9225e-05, gnorm=2.331, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=14186
2023-03-15 17:56:12 - progress_bar.py[line:272] - INFO: epoch 021:   1646 / 2004 loss=0.178, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=318.5, nsentences=8, sample_size=318.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=929.9, ups=2.92, wpb=318.5, bsz=8, num_updates=41460, lr=5.92149e-05, gnorm=2.228, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=14190
2023-03-15 17:56:16 - progress_bar.py[line:272] - INFO: epoch 021:   1656 / 2004 loss=0.186, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=358.1, nsentences=8, sample_size=358.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1004.5, ups=2.81, wpb=358.1, bsz=8, num_updates=41470, lr=5.92048e-05, gnorm=2.428, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=14193
2023-03-15 17:56:19 - progress_bar.py[line:272] - INFO: epoch 021:   1666 / 2004 loss=0.202, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=345.7, nsentences=8, sample_size=345.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=966.1, ups=2.79, wpb=345.7, bsz=8, num_updates=41480, lr=5.91947e-05, gnorm=2.594, clip=0, loss_scale=2048, train_wall=4, gb_free=14.1, wall=14197
2023-03-15 17:56:22 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 17:56:23 - progress_bar.py[line:272] - INFO: epoch 021:   1677 / 2004 loss=0.19, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=332.1, nsentences=8, sample_size=332.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=862.2, ups=2.6, wpb=332.1, bsz=8, num_updates=41490, lr=5.91847e-05, gnorm=2.471, clip=0, loss_scale=1024, train_wall=4, gb_free=15.2, wall=14201
2023-03-15 17:56:26 - progress_bar.py[line:272] - INFO: epoch 021:   1687 / 2004 loss=0.186, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=332.1, nsentences=8, sample_size=332.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=937.2, ups=2.82, wpb=332.1, bsz=8, num_updates=41500, lr=5.91746e-05, gnorm=2.412, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=14204
2023-03-15 17:56:30 - progress_bar.py[line:272] - INFO: epoch 021:   1697 / 2004 loss=0.177, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=336.6, nsentences=8, sample_size=336.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=966, ups=2.87, wpb=336.6, bsz=8, num_updates=41510, lr=5.91645e-05, gnorm=2.109, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=14208
2023-03-15 17:56:34 - progress_bar.py[line:272] - INFO: epoch 021:   1707 / 2004 loss=0.182, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=349.1, nsentences=8, sample_size=349.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=983.7, ups=2.82, wpb=349.1, bsz=8, num_updates=41520, lr=5.91544e-05, gnorm=2.424, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=14211
2023-03-15 17:56:37 - progress_bar.py[line:272] - INFO: epoch 021:   1717 / 2004 loss=0.199, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=373.3, nsentences=8, sample_size=373.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1065.8, ups=2.86, wpb=373.3, bsz=8, num_updates=41530, lr=5.91443e-05, gnorm=2.552, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=14215
2023-03-15 17:56:41 - progress_bar.py[line:272] - INFO: epoch 021:   1727 / 2004 loss=0.186, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=394.1, nsentences=8, sample_size=394.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1115.7, ups=2.83, wpb=394.1, bsz=8, num_updates=41540, lr=5.91343e-05, gnorm=2.503, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=14218
2023-03-15 17:56:44 - progress_bar.py[line:272] - INFO: epoch 021:   1737 / 2004 loss=0.177, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=332.4, nsentences=8, sample_size=332.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1033, ups=3.11, wpb=332.4, bsz=8, num_updates=41550, lr=5.91242e-05, gnorm=2.299, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=14221
2023-03-15 17:56:47 - progress_bar.py[line:272] - INFO: epoch 021:   1747 / 2004 loss=0.175, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=349.9, nsentences=8, sample_size=349.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1021.8, ups=2.92, wpb=349.9, bsz=8, num_updates=41560, lr=5.91141e-05, gnorm=2.218, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=14225
2023-03-15 17:56:51 - progress_bar.py[line:272] - INFO: epoch 021:   1757 / 2004 loss=0.196, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=328.9, nsentences=8, sample_size=328.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=953.2, ups=2.9, wpb=328.9, bsz=8, num_updates=41570, lr=5.9104e-05, gnorm=2.521, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=14228
2023-03-15 17:56:54 - progress_bar.py[line:272] - INFO: epoch 021:   1767 / 2004 loss=0.184, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=314.3, nsentences=8, sample_size=314.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=919.2, ups=2.92, wpb=314.3, bsz=8, num_updates=41580, lr=5.90939e-05, gnorm=2.666, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=14232
2023-03-15 17:56:58 - progress_bar.py[line:272] - INFO: epoch 021:   1777 / 2004 loss=0.19, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=350.3, nsentences=8, sample_size=350.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1006.7, ups=2.87, wpb=350.3, bsz=8, num_updates=41590, lr=5.90839e-05, gnorm=2.341, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=14235
2023-03-15 17:57:01 - progress_bar.py[line:272] - INFO: epoch 021:   1787 / 2004 loss=0.181, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=306.3, nsentences=8, sample_size=306.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=869.1, ups=2.84, wpb=306.3, bsz=8, num_updates=41600, lr=5.90738e-05, gnorm=2.367, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=14239
2023-03-15 17:57:05 - progress_bar.py[line:272] - INFO: epoch 021:   1797 / 2004 loss=0.183, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=349.8, nsentences=8, sample_size=349.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1004, ups=2.87, wpb=349.8, bsz=8, num_updates=41610, lr=5.90637e-05, gnorm=2.394, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=14242
2023-03-15 17:57:08 - progress_bar.py[line:272] - INFO: epoch 021:   1807 / 2004 loss=0.192, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=345.7, nsentences=8, sample_size=345.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1007.2, ups=2.91, wpb=345.7, bsz=8, num_updates=41620, lr=5.90536e-05, gnorm=2.652, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=14246
2023-03-15 17:57:11 - progress_bar.py[line:272] - INFO: epoch 021:   1817 / 2004 loss=0.197, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=339.3, nsentences=8, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=998, ups=2.94, wpb=339.3, bsz=8, num_updates=41630, lr=5.90435e-05, gnorm=2.505, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=14249
2023-03-15 17:57:15 - progress_bar.py[line:272] - INFO: epoch 021:   1827 / 2004 loss=0.192, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=357.3, nsentences=8, sample_size=357.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1022.8, ups=2.86, wpb=357.3, bsz=8, num_updates=41640, lr=5.90334e-05, gnorm=2.422, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=14252
2023-03-15 17:57:18 - progress_bar.py[line:272] - INFO: epoch 021:   1837 / 2004 loss=0.187, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=341.2, nsentences=8, sample_size=341.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=972.3, ups=2.85, wpb=341.2, bsz=8, num_updates=41650, lr=5.90234e-05, gnorm=2.459, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=14256
2023-03-15 17:57:22 - progress_bar.py[line:272] - INFO: epoch 021:   1847 / 2004 loss=0.186, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=355.5, nsentences=8, sample_size=355.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1030.4, ups=2.9, wpb=355.5, bsz=8, num_updates=41660, lr=5.90133e-05, gnorm=2.507, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=14259
2023-03-15 17:57:25 - progress_bar.py[line:272] - INFO: epoch 021:   1857 / 2004 loss=0.189, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=312.4, nsentences=8, sample_size=312.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=901.9, ups=2.89, wpb=312.4, bsz=8, num_updates=41670, lr=5.90032e-05, gnorm=2.627, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=14263
2023-03-15 17:57:29 - progress_bar.py[line:272] - INFO: epoch 021:   1867 / 2004 loss=0.196, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=352.6, nsentences=8, sample_size=352.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1001.4, ups=2.84, wpb=352.6, bsz=8, num_updates=41680, lr=5.89931e-05, gnorm=2.384, clip=0, loss_scale=2048, train_wall=3, gb_free=14, wall=14266
2023-03-15 17:57:30 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 17:57:33 - progress_bar.py[line:272] - INFO: epoch 021:   1878 / 2004 loss=0.19, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=328, nsentences=8, sample_size=328, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=856.8, ups=2.61, wpb=328, bsz=8, num_updates=41690, lr=5.8983e-05, gnorm=2.505, clip=0, loss_scale=1024, train_wall=4, gb_free=14.6, wall=14270
2023-03-15 17:57:37 - progress_bar.py[line:272] - INFO: epoch 021:   1888 / 2004 loss=0.187, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=320.3, nsentences=8, sample_size=320.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=731.5, ups=2.28, wpb=320.3, bsz=8, num_updates=41700, lr=5.8973e-05, gnorm=2.481, clip=0, loss_scale=1024, train_wall=4, gb_free=15.3, wall=14275
2023-03-15 17:57:41 - progress_bar.py[line:272] - INFO: epoch 021:   1898 / 2004 loss=0.193, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=347.2, nsentences=8, sample_size=347.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=992.8, ups=2.86, wpb=347.2, bsz=8, num_updates=41710, lr=5.89629e-05, gnorm=2.628, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=14278
2023-03-15 17:57:44 - progress_bar.py[line:272] - INFO: epoch 021:   1908 / 2004 loss=0.18, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=337.8, nsentences=8, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=967.8, ups=2.86, wpb=337.8, bsz=8, num_updates=41720, lr=5.89528e-05, gnorm=2.299, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=14282
2023-03-15 17:57:47 - progress_bar.py[line:272] - INFO: epoch 021:   1918 / 2004 loss=0.186, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=341.2, nsentences=8, sample_size=341.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=981.9, ups=2.88, wpb=341.2, bsz=8, num_updates=41730, lr=5.89427e-05, gnorm=2.314, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=14285
2023-03-15 17:57:51 - progress_bar.py[line:272] - INFO: epoch 021:   1928 / 2004 loss=0.192, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=313.1, nsentences=8, sample_size=313.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=906, ups=2.89, wpb=313.1, bsz=8, num_updates=41740, lr=5.89326e-05, gnorm=2.511, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=14289
2023-03-15 17:57:54 - progress_bar.py[line:272] - INFO: epoch 021:   1938 / 2004 loss=0.183, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=347.7, nsentences=8, sample_size=347.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1010.7, ups=2.91, wpb=347.7, bsz=8, num_updates=41750, lr=5.89226e-05, gnorm=2.301, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=14292
2023-03-15 17:57:58 - progress_bar.py[line:272] - INFO: epoch 021:   1948 / 2004 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=344.6, nsentences=8, sample_size=344.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=979.2, ups=2.84, wpb=344.6, bsz=8, num_updates=41760, lr=5.89125e-05, gnorm=2.181, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=14296
2023-03-15 17:58:00 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-03-15 17:58:02 - progress_bar.py[line:272] - INFO: epoch 021:   1959 / 2004 loss=0.176, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=360.2, nsentences=8, sample_size=360.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=942.3, ups=2.62, wpb=360.2, bsz=8, num_updates=41770, lr=5.89024e-05, gnorm=2.335, clip=0, loss_scale=512, train_wall=4, gb_free=15, wall=14299
2023-03-15 17:58:05 - progress_bar.py[line:272] - INFO: epoch 021:   1969 / 2004 loss=0.212, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=335.9, nsentences=8, sample_size=335.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=961.6, ups=2.86, wpb=335.9, bsz=8, num_updates=41780, lr=5.88923e-05, gnorm=2.596, clip=0, loss_scale=512, train_wall=3, gb_free=15, wall=14303
2023-03-15 17:58:09 - progress_bar.py[line:272] - INFO: epoch 021:   1979 / 2004 loss=0.183, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=350.5, nsentences=8, sample_size=350.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=995.6, ups=2.84, wpb=350.5, bsz=8, num_updates=41790, lr=5.88822e-05, gnorm=2.441, clip=0, loss_scale=512, train_wall=3, gb_free=14.9, wall=14306
2023-03-15 17:58:12 - progress_bar.py[line:272] - INFO: epoch 021:   1989 / 2004 loss=0.178, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=337.8, nsentences=8, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=954.2, ups=2.82, wpb=337.8, bsz=8, num_updates=41800, lr=5.88722e-05, gnorm=2.326, clip=0, loss_scale=512, train_wall=3, gb_free=14.4, wall=14310
2023-03-15 17:58:16 - progress_bar.py[line:272] - INFO: epoch 021:   1999 / 2004 loss=0.198, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=391.3, nsentences=8, sample_size=391.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1151.5, ups=2.94, wpb=391.3, bsz=8, num_updates=41810, lr=5.88621e-05, gnorm=2.66, clip=0, loss_scale=512, train_wall=3, gb_free=14.6, wall=14313
2023-03-15 17:58:17 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 21 @ 41815 updates
2023-03-15 17:58:17 - trainer.py[line:431] - INFO: Saving checkpoint to ./checkpoints/checkpoint21.pt
2023-03-15 17:58:25 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./checkpoints/checkpoint21.pt
2023-03-15 17:58:27 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./checkpoints/checkpoint21.pt (epoch 21 @ 41815 updates, score None) (writing took 10.182070516049862 seconds)
2023-03-15 17:58:28 - train.py[line:332] - INFO: end of epoch 21 (average epoch stats below)
2023-03-15 17:58:28 - progress_bar.py[line:282] - INFO: epoch 021 | loss 0.194 | loss_v1 0 | loss_v2 0 | nll_loss 0.194 | ntokens 345.506 | nsentences 7.999 | sample_size 345.506 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.14 | wps 980.5 | ups 2.84 | wpb 345.5 | bsz 8 | num_updates 41815 | lr 5.8857e-05 | gnorm 2.521 | clip 0 | loss_scale 512 | train_wall 678 | gb_free 14.4 | wall 14325
2023-03-15 17:58:28 - trainer.py[line:639] - INFO: loading train data for epoch 22
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 row count 8015 total row count 8015
slice_id 0 seek offset 0
2023-03-15 17:58:28 - trainer.py[line:703] - INFO: begin training epoch 22
2023-03-15 17:58:28 - train.py[line:305] - INFO: Start iterating over samples
2023-03-15 17:58:30 - progress_bar.py[line:272] - INFO: epoch 022:      5 / 2004 loss=0.204, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=375, nsentences=8, sample_size=375, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=257.7, ups=0.69, wpb=375, bsz=8, num_updates=41820, lr=5.8852e-05, gnorm=2.839, clip=0, loss_scale=512, train_wall=3, gb_free=15.2, wall=14328
2023-03-15 17:58:34 - progress_bar.py[line:272] - INFO: epoch 022:     15 / 2004 loss=0.204, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=323.5, nsentences=8, sample_size=323.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=970.9, ups=3, wpb=323.5, bsz=8, num_updates=41830, lr=5.88419e-05, gnorm=2.848, clip=0, loss_scale=512, train_wall=3, gb_free=14.3, wall=14331
2023-03-15 17:58:37 - progress_bar.py[line:272] - INFO: epoch 022:     25 / 2004 loss=0.184, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=358.1, nsentences=8, sample_size=358.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1040.7, ups=2.91, wpb=358.1, bsz=8, num_updates=41840, lr=5.88318e-05, gnorm=2.463, clip=0, loss_scale=512, train_wall=3, gb_free=14.5, wall=14335
2023-03-15 17:58:40 - progress_bar.py[line:272] - INFO: epoch 022:     35 / 2004 loss=0.189, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=346.3, nsentences=8, sample_size=346.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=998.8, ups=2.88, wpb=346.3, bsz=8, num_updates=41850, lr=5.88218e-05, gnorm=2.555, clip=0, loss_scale=512, train_wall=3, gb_free=15, wall=14338
2023-03-15 17:58:44 - progress_bar.py[line:272] - INFO: epoch 022:     45 / 2004 loss=0.202, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=354.5, nsentences=8, sample_size=354.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1024, ups=2.89, wpb=354.5, bsz=8, num_updates=41860, lr=5.88117e-05, gnorm=2.69, clip=0, loss_scale=512, train_wall=3, gb_free=14.6, wall=14342
2023-03-15 17:58:47 - progress_bar.py[line:272] - INFO: epoch 022:     55 / 2004 loss=0.18, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=341.4, nsentences=8, sample_size=341.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=981.4, ups=2.87, wpb=341.4, bsz=8, num_updates=41870, lr=5.88016e-05, gnorm=2.288, clip=0, loss_scale=512, train_wall=3, gb_free=15.2, wall=14345
2023-03-15 17:58:51 - progress_bar.py[line:272] - INFO: epoch 022:     65 / 2004 loss=0.193, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=344.9, nsentences=8, sample_size=344.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1000.4, ups=2.9, wpb=344.9, bsz=8, num_updates=41880, lr=5.87915e-05, gnorm=2.609, clip=0, loss_scale=512, train_wall=3, gb_free=14.1, wall=14348
2023-03-15 17:58:54 - progress_bar.py[line:272] - INFO: epoch 022:     75 / 2004 loss=0.185, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=347.6, nsentences=8, sample_size=347.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1008.8, ups=2.9, wpb=347.6, bsz=8, num_updates=41890, lr=5.87814e-05, gnorm=2.323, clip=0, loss_scale=512, train_wall=3, gb_free=15.1, wall=14352
2023-03-15 17:58:58 - progress_bar.py[line:272] - INFO: epoch 022:     85 / 2004 loss=0.209, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=338.9, nsentences=8, sample_size=338.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=980.2, ups=2.89, wpb=338.9, bsz=8, num_updates=41900, lr=5.87713e-05, gnorm=2.882, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=14355
2023-03-15 17:59:01 - progress_bar.py[line:272] - INFO: epoch 022:     95 / 2004 loss=0.198, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=356.7, nsentences=8, sample_size=356.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1036.4, ups=2.91, wpb=356.7, bsz=8, num_updates=41910, lr=5.87613e-05, gnorm=2.49, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=14359
2023-03-15 17:59:04 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-03-15 17:59:05 - progress_bar.py[line:272] - INFO: epoch 022:    106 / 2004 loss=0.177, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=367.6, nsentences=8, sample_size=367.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=987.6, ups=2.69, wpb=367.6, bsz=8, num_updates=41920, lr=5.87512e-05, gnorm=2.387, clip=0, loss_scale=512, train_wall=4, gb_free=14.8, wall=14363
2023-03-15 17:59:08 - progress_bar.py[line:272] - INFO: epoch 022:    116 / 2004 loss=0.207, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=336, nsentences=8, sample_size=336, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=980, ups=2.92, wpb=336, bsz=8, num_updates=41930, lr=5.87411e-05, gnorm=2.65, clip=0, loss_scale=512, train_wall=3, gb_free=15.3, wall=14366
2023-03-15 17:59:12 - progress_bar.py[line:272] - INFO: epoch 022:    126 / 2004 loss=0.187, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=332.7, nsentences=8, sample_size=332.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=963.2, ups=2.9, wpb=332.7, bsz=8, num_updates=41940, lr=5.8731e-05, gnorm=2.35, clip=0, loss_scale=512, train_wall=3, gb_free=14.4, wall=14369
2023-03-15 17:59:15 - progress_bar.py[line:272] - INFO: epoch 022:    136 / 2004 loss=0.178, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=333.1, nsentences=8, sample_size=333.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=956.7, ups=2.87, wpb=333.1, bsz=8, num_updates=41950, lr=5.87209e-05, gnorm=2.263, clip=0, loss_scale=512, train_wall=3, gb_free=15.1, wall=14373
2023-03-15 17:59:19 - progress_bar.py[line:272] - INFO: epoch 022:    146 / 2004 loss=0.195, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=333.7, nsentences=8, sample_size=333.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=964.1, ups=2.89, wpb=333.7, bsz=8, num_updates=41960, lr=5.87109e-05, gnorm=2.472, clip=0, loss_scale=512, train_wall=3, gb_free=15.2, wall=14376
2023-03-15 17:59:22 - progress_bar.py[line:272] - INFO: epoch 022:    156 / 2004 loss=0.21, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=344.1, nsentences=8, sample_size=344.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=983.1, ups=2.86, wpb=344.1, bsz=8, num_updates=41970, lr=5.87008e-05, gnorm=2.572, clip=0, loss_scale=512, train_wall=3, gb_free=14.9, wall=14380
2023-03-15 17:59:26 - progress_bar.py[line:272] - INFO: epoch 022:    166 / 2004 loss=0.189, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=351.8, nsentences=8, sample_size=351.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1022.6, ups=2.91, wpb=351.8, bsz=8, num_updates=41980, lr=5.86907e-05, gnorm=2.345, clip=0, loss_scale=512, train_wall=3, gb_free=15.2, wall=14383
2023-03-15 17:59:29 - progress_bar.py[line:272] - INFO: epoch 022:    176 / 2004 loss=0.186, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=333.7, nsentences=8, sample_size=333.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=949.2, ups=2.84, wpb=333.7, bsz=8, num_updates=41990, lr=5.86806e-05, gnorm=2.437, clip=0, loss_scale=512, train_wall=3, gb_free=14.9, wall=14387
2023-03-15 17:59:33 - progress_bar.py[line:272] - INFO: epoch 022:    186 / 2004 loss=0.192, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=332.7, nsentences=8, sample_size=332.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=952.1, ups=2.86, wpb=332.7, bsz=8, num_updates=42000, lr=5.86705e-05, gnorm=2.617, clip=0, loss_scale=512, train_wall=3, gb_free=15.3, wall=14390
2023-03-15 17:59:33 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 22 @ 42000 updates
2023-03-15 17:59:33 - trainer.py[line:431] - INFO: Saving checkpoint to ./checkpoints/checkpoint_22_42000.pt
2023-03-15 17:59:42 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./checkpoints/checkpoint_22_42000.pt
2023-03-15 17:59:44 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./checkpoints/checkpoint_22_42000.pt (epoch 22 @ 42000 updates, score None) (writing took 11.72220772691071 seconds)
2023-03-15 17:59:48 - progress_bar.py[line:272] - INFO: epoch 022:    196 / 2004 loss=0.177, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=321, nsentences=8, sample_size=321, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=215.6, ups=0.67, wpb=321, bsz=8, num_updates=42010, lr=5.86605e-05, gnorm=2.328, clip=0, loss_scale=512, train_wall=3, gb_free=15.3, wall=14405
2023-03-15 17:59:51 - progress_bar.py[line:272] - INFO: epoch 022:    206 / 2004 loss=0.188, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=341.7, nsentences=8, sample_size=341.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1073, ups=3.14, wpb=341.7, bsz=8, num_updates=42020, lr=5.86504e-05, gnorm=2.539, clip=0, loss_scale=512, train_wall=3, gb_free=14.6, wall=14408
2023-03-15 17:59:54 - progress_bar.py[line:272] - INFO: epoch 022:    216 / 2004 loss=0.186, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=319.7, nsentences=8, sample_size=319.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1011.7, ups=3.16, wpb=319.7, bsz=8, num_updates=42030, lr=5.86403e-05, gnorm=2.341, clip=0, loss_scale=512, train_wall=3, gb_free=15.4, wall=14412
2023-03-15 17:59:57 - progress_bar.py[line:272] - INFO: epoch 022:    226 / 2004 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=348.6, nsentences=8, sample_size=348.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1004.5, ups=2.88, wpb=348.6, bsz=8, num_updates=42040, lr=5.86302e-05, gnorm=2.256, clip=0, loss_scale=512, train_wall=3, gb_free=14.7, wall=14415
2023-03-15 18:00:01 - progress_bar.py[line:272] - INFO: epoch 022:    236 / 2004 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=378.5, nsentences=8, sample_size=378.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1086.2, ups=2.87, wpb=378.5, bsz=8, num_updates=42050, lr=5.86201e-05, gnorm=2.252, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=14419
2023-03-15 18:00:04 - progress_bar.py[line:272] - INFO: epoch 022:    246 / 2004 loss=0.191, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=352.2, nsentences=8, sample_size=352.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1012.7, ups=2.88, wpb=352.2, bsz=8, num_updates=42060, lr=5.86101e-05, gnorm=2.335, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=14422
2023-03-15 18:00:08 - progress_bar.py[line:272] - INFO: epoch 022:    256 / 2004 loss=0.197, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=329.3, nsentences=8, sample_size=329.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=957.2, ups=2.91, wpb=329.3, bsz=8, num_updates=42070, lr=5.86e-05, gnorm=2.62, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=14425
2023-03-15 18:00:11 - progress_bar.py[line:272] - INFO: epoch 022:    266 / 2004 loss=0.199, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=357, nsentences=8, sample_size=357, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1029.9, ups=2.88, wpb=357, bsz=8, num_updates=42080, lr=5.85899e-05, gnorm=2.534, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=14429
2023-03-15 18:00:15 - progress_bar.py[line:272] - INFO: epoch 022:    276 / 2004 loss=0.199, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=342.3, nsentences=8, sample_size=342.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=981.2, ups=2.87, wpb=342.3, bsz=8, num_updates=42090, lr=5.85798e-05, gnorm=2.522, clip=0, loss_scale=1024, train_wall=3, gb_free=13.7, wall=14432
2023-03-15 18:00:18 - progress_bar.py[line:272] - INFO: epoch 022:    286 / 2004 loss=0.183, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=366.8, nsentences=8, sample_size=366.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1044.1, ups=2.85, wpb=366.8, bsz=8, num_updates=42100, lr=5.85697e-05, gnorm=2.277, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=14436
2023-03-15 18:00:22 - progress_bar.py[line:272] - INFO: epoch 022:    296 / 2004 loss=0.187, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=352.6, nsentences=8, sample_size=352.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1026.7, ups=2.91, wpb=352.6, bsz=8, num_updates=42110, lr=5.85596e-05, gnorm=2.388, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=14439
2023-03-15 18:00:25 - progress_bar.py[line:272] - INFO: epoch 022:    306 / 2004 loss=0.187, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=340.2, nsentences=8, sample_size=340.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=978.1, ups=2.88, wpb=340.2, bsz=8, num_updates=42120, lr=5.85496e-05, gnorm=2.468, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=14443
2023-03-15 18:00:29 - progress_bar.py[line:272] - INFO: epoch 022:    316 / 2004 loss=0.188, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=362.2, nsentences=8, sample_size=362.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1054.9, ups=2.91, wpb=362.2, bsz=8, num_updates=42130, lr=5.85395e-05, gnorm=2.493, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=14446
2023-03-15 18:00:32 - progress_bar.py[line:272] - INFO: epoch 022:    326 / 2004 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=324.5, nsentences=8, sample_size=324.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1051.4, ups=3.24, wpb=324.5, bsz=8, num_updates=42140, lr=5.85294e-05, gnorm=2.375, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=14449
2023-03-15 18:00:35 - progress_bar.py[line:272] - INFO: epoch 022:    336 / 2004 loss=0.194, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=339, nsentences=8, sample_size=339, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1065.5, ups=3.14, wpb=339, bsz=8, num_updates=42150, lr=5.85193e-05, gnorm=2.479, clip=0, loss_scale=1024, train_wall=3, gb_free=13.9, wall=14453
2023-03-15 18:00:38 - progress_bar.py[line:272] - INFO: epoch 022:    346 / 2004 loss=0.192, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=374, nsentences=8, sample_size=374, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1155.7, ups=3.09, wpb=374, bsz=8, num_updates=42160, lr=5.85092e-05, gnorm=2.43, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=14456
2023-03-15 18:00:41 - progress_bar.py[line:272] - INFO: epoch 022:    356 / 2004 loss=0.195, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=335.2, nsentences=8, sample_size=335.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1064.2, ups=3.17, wpb=335.2, bsz=8, num_updates=42170, lr=5.84992e-05, gnorm=2.661, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=14459
2023-03-15 18:00:44 - progress_bar.py[line:272] - INFO: epoch 022:    366 / 2004 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=366.6, nsentences=8, sample_size=366.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1159.7, ups=3.16, wpb=366.6, bsz=8, num_updates=42180, lr=5.84891e-05, gnorm=2.041, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=14462
2023-03-15 18:00:45 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 18:00:48 - progress_bar.py[line:272] - INFO: epoch 022:    377 / 2004 loss=0.181, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=304, nsentences=8, sample_size=304, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=884.3, ups=2.91, wpb=304, bsz=8, num_updates=42190, lr=5.8479e-05, gnorm=2.342, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=14466
2023-03-15 18:00:51 - progress_bar.py[line:272] - INFO: epoch 022:    387 / 2004 loss=0.171, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=336.1, nsentences=8, sample_size=336.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1011.8, ups=3.01, wpb=336.1, bsz=8, num_updates=42200, lr=5.84689e-05, gnorm=2.285, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=14469
2023-03-15 18:00:55 - progress_bar.py[line:272] - INFO: epoch 022:    397 / 2004 loss=0.175, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=347, nsentences=8, sample_size=347, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=998.8, ups=2.88, wpb=347, bsz=8, num_updates=42210, lr=5.84588e-05, gnorm=2.236, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=14472
2023-03-15 18:00:58 - progress_bar.py[line:272] - INFO: epoch 022:    407 / 2004 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=382, nsentences=8, sample_size=382, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1113.6, ups=2.92, wpb=382, bsz=8, num_updates=42220, lr=5.84488e-05, gnorm=2.113, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=14476
2023-03-15 18:01:02 - progress_bar.py[line:272] - INFO: epoch 022:    417 / 2004 loss=0.193, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=337.8, nsentences=8, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=986.8, ups=2.92, wpb=337.8, bsz=8, num_updates=42230, lr=5.84387e-05, gnorm=2.533, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=14479
2023-03-15 18:01:05 - progress_bar.py[line:272] - INFO: epoch 022:    427 / 2004 loss=0.195, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=338.1, nsentences=8, sample_size=338.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=986.6, ups=2.92, wpb=338.1, bsz=8, num_updates=42240, lr=5.84286e-05, gnorm=2.64, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=14483
2023-03-15 18:01:08 - progress_bar.py[line:272] - INFO: epoch 022:    437 / 2004 loss=0.176, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=350.6, nsentences=8, sample_size=350.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1018.3, ups=2.9, wpb=350.6, bsz=8, num_updates=42250, lr=5.84185e-05, gnorm=2.451, clip=10, loss_scale=1024, train_wall=3, gb_free=15.6, wall=14486
2023-03-15 18:01:12 - progress_bar.py[line:272] - INFO: epoch 022:    447 / 2004 loss=0.191, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=374.5, nsentences=8, sample_size=374.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1177.3, ups=3.14, wpb=374.5, bsz=8, num_updates=42260, lr=5.84084e-05, gnorm=2.543, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=14489
2023-03-15 18:01:15 - progress_bar.py[line:272] - INFO: epoch 022:    457 / 2004 loss=0.191, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=390, nsentences=8, sample_size=390, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1227.4, ups=3.15, wpb=390, bsz=8, num_updates=42270, lr=5.83984e-05, gnorm=2.338, clip=0, loss_scale=1024, train_wall=3, gb_free=14.1, wall=14492
2023-03-15 18:01:18 - progress_bar.py[line:272] - INFO: epoch 022:    467 / 2004 loss=0.208, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=359.1, nsentences=8, sample_size=359.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1047.4, ups=2.92, wpb=359.1, bsz=8, num_updates=42280, lr=5.83883e-05, gnorm=2.59, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=14496
2023-03-15 18:01:22 - progress_bar.py[line:272] - INFO: epoch 022:    477 / 2004 loss=0.187, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=334.5, nsentences=8, sample_size=334.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=952, ups=2.85, wpb=334.5, bsz=8, num_updates=42290, lr=5.83782e-05, gnorm=2.494, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=14499
2023-03-15 18:01:25 - progress_bar.py[line:272] - INFO: epoch 022:    487 / 2004 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=391.9, nsentences=8, sample_size=391.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1120, ups=2.86, wpb=391.9, bsz=8, num_updates=42300, lr=5.83681e-05, gnorm=2.357, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=14503
2023-03-15 18:01:29 - progress_bar.py[line:272] - INFO: epoch 022:    497 / 2004 loss=0.187, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=371, nsentences=8, sample_size=371, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1056.9, ups=2.85, wpb=371, bsz=8, num_updates=42310, lr=5.8358e-05, gnorm=2.415, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=14506
2023-03-15 18:01:32 - progress_bar.py[line:272] - INFO: epoch 022:    507 / 2004 loss=0.196, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=341.1, nsentences=8, sample_size=341.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=975.2, ups=2.86, wpb=341.1, bsz=8, num_updates=42320, lr=5.8348e-05, gnorm=2.509, clip=0, loss_scale=2048, train_wall=3, gb_free=13.5, wall=14510
2023-03-15 18:01:36 - progress_bar.py[line:272] - INFO: epoch 022:    517 / 2004 loss=0.179, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=353.3, nsentences=8, sample_size=353.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1033.1, ups=2.92, wpb=353.3, bsz=8, num_updates=42330, lr=5.83379e-05, gnorm=2.418, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=14513
2023-03-15 18:01:38 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 18:01:40 - progress_bar.py[line:272] - INFO: epoch 022:    528 / 2004 loss=0.18, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=387.4, nsentences=8, sample_size=387.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=993.8, ups=2.57, wpb=387.4, bsz=8, num_updates=42340, lr=5.83278e-05, gnorm=2.446, clip=0, loss_scale=1024, train_wall=4, gb_free=15.3, wall=14517
2023-03-15 18:01:43 - progress_bar.py[line:272] - INFO: epoch 022:    538 / 2004 loss=0.185, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=385.5, nsentences=8, sample_size=385.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1097.2, ups=2.85, wpb=385.5, bsz=8, num_updates=42350, lr=5.83177e-05, gnorm=2.45, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=14521
2023-03-15 18:01:47 - progress_bar.py[line:272] - INFO: epoch 022:    548 / 2004 loss=0.191, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=350.6, nsentences=8, sample_size=350.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1008.9, ups=2.88, wpb=350.6, bsz=8, num_updates=42360, lr=5.83076e-05, gnorm=2.635, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=14524
2023-03-15 18:01:50 - progress_bar.py[line:272] - INFO: epoch 022:    558 / 2004 loss=0.197, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=378.2, nsentences=8, sample_size=378.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1090.5, ups=2.88, wpb=378.2, bsz=8, num_updates=42370, lr=5.82975e-05, gnorm=2.575, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=14528
2023-03-15 18:01:53 - progress_bar.py[line:272] - INFO: epoch 022:    568 / 2004 loss=0.181, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=377.4, nsentences=8, sample_size=377.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1103.4, ups=2.92, wpb=377.4, bsz=8, num_updates=42380, lr=5.82875e-05, gnorm=2.456, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=14531
2023-03-15 18:01:57 - progress_bar.py[line:272] - INFO: epoch 022:    578 / 2004 loss=0.182, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=329.9, nsentences=8, sample_size=329.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=951.4, ups=2.88, wpb=329.9, bsz=8, num_updates=42390, lr=5.82774e-05, gnorm=2.244, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=14535
2023-03-15 18:02:00 - progress_bar.py[line:272] - INFO: epoch 022:    588 / 2004 loss=0.198, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=372.9, nsentences=8, sample_size=372.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1054.4, ups=2.83, wpb=372.9, bsz=8, num_updates=42400, lr=5.82673e-05, gnorm=2.697, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=14538
2023-03-15 18:02:04 - progress_bar.py[line:272] - INFO: epoch 022:    598 / 2004 loss=0.19, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=334.5, nsentences=8, sample_size=334.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=975.5, ups=2.92, wpb=334.5, bsz=8, num_updates=42410, lr=5.82572e-05, gnorm=2.558, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=14541
2023-03-15 18:02:07 - progress_bar.py[line:272] - INFO: epoch 022:    608 / 2004 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=351.9, nsentences=8, sample_size=351.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1002.8, ups=2.85, wpb=351.9, bsz=8, num_updates=42420, lr=5.82471e-05, gnorm=2.282, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=14545
2023-03-15 18:02:11 - progress_bar.py[line:272] - INFO: epoch 022:    618 / 2004 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=354, nsentences=8, sample_size=354, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1019.6, ups=2.88, wpb=354, bsz=8, num_updates=42430, lr=5.82371e-05, gnorm=2.324, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=14548
2023-03-15 18:02:14 - progress_bar.py[line:272] - INFO: epoch 022:    628 / 2004 loss=0.192, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=368.7, nsentences=8, sample_size=368.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1073.8, ups=2.91, wpb=368.7, bsz=8, num_updates=42440, lr=5.8227e-05, gnorm=2.42, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=14552
2023-03-15 18:02:18 - progress_bar.py[line:272] - INFO: epoch 022:    638 / 2004 loss=0.193, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=331.9, nsentences=8, sample_size=331.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=959.2, ups=2.89, wpb=331.9, bsz=8, num_updates=42450, lr=5.82169e-05, gnorm=2.541, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=14555
2023-03-15 18:02:21 - progress_bar.py[line:272] - INFO: epoch 022:    648 / 2004 loss=0.183, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=330.7, nsentences=8, sample_size=330.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=930.8, ups=2.81, wpb=330.7, bsz=8, num_updates=42460, lr=5.82068e-05, gnorm=2.328, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=14559
2023-03-15 18:02:25 - progress_bar.py[line:272] - INFO: epoch 022:    658 / 2004 loss=0.188, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=352.5, nsentences=8, sample_size=352.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1010.6, ups=2.87, wpb=352.5, bsz=8, num_updates=42470, lr=5.81967e-05, gnorm=2.33, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=14562
2023-03-15 18:02:28 - progress_bar.py[line:272] - INFO: epoch 022:    668 / 2004 loss=0.18, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=299.1, nsentences=8, sample_size=299.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=870.7, ups=2.91, wpb=299.1, bsz=8, num_updates=42480, lr=5.81867e-05, gnorm=2.285, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=14566
2023-03-15 18:02:32 - progress_bar.py[line:272] - INFO: epoch 022:    678 / 2004 loss=0.193, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=343.8, nsentences=8, sample_size=343.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=996.8, ups=2.9, wpb=343.8, bsz=8, num_updates=42490, lr=5.81766e-05, gnorm=2.513, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=14569
2023-03-15 18:02:35 - progress_bar.py[line:272] - INFO: epoch 022:    688 / 2004 loss=0.196, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=355.9, nsentences=8, sample_size=355.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1035.8, ups=2.91, wpb=355.9, bsz=8, num_updates=42500, lr=5.81665e-05, gnorm=2.641, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=14573
2023-03-15 18:02:39 - progress_bar.py[line:272] - INFO: epoch 022:    698 / 2004 loss=0.192, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=354.1, nsentences=8, sample_size=354.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1020.7, ups=2.88, wpb=354.1, bsz=8, num_updates=42510, lr=5.81564e-05, gnorm=2.526, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=14576
2023-03-15 18:02:42 - progress_bar.py[line:272] - INFO: epoch 022:    708 / 2004 loss=0.187, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=324.6, nsentences=8, sample_size=324.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=948.8, ups=2.92, wpb=324.6, bsz=8, num_updates=42520, lr=5.81463e-05, gnorm=2.303, clip=0, loss_scale=2048, train_wall=3, gb_free=15.9, wall=14580
2023-03-15 18:02:45 - progress_bar.py[line:272] - INFO: epoch 022:    718 / 2004 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=336.8, nsentences=8, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=984.4, ups=2.92, wpb=336.8, bsz=8, num_updates=42530, lr=5.81363e-05, gnorm=2.292, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=14583
2023-03-15 18:02:49 - progress_bar.py[line:272] - INFO: epoch 022:    728 / 2004 loss=0.189, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=365.3, nsentences=8, sample_size=365.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1039.8, ups=2.85, wpb=365.3, bsz=8, num_updates=42540, lr=5.81262e-05, gnorm=2.754, clip=10, loss_scale=2048, train_wall=3, gb_free=14.7, wall=14587
2023-03-15 18:02:52 - progress_bar.py[line:272] - INFO: epoch 022:    738 / 2004 loss=0.193, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=331.6, nsentences=8, sample_size=331.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=943, ups=2.84, wpb=331.6, bsz=8, num_updates=42550, lr=5.81161e-05, gnorm=2.717, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=14590
2023-03-15 18:02:56 - progress_bar.py[line:272] - INFO: epoch 022:    748 / 2004 loss=0.199, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=375, nsentences=8, sample_size=375, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1095.3, ups=2.92, wpb=375, bsz=8, num_updates=42560, lr=5.8106e-05, gnorm=2.815, clip=0, loss_scale=2048, train_wall=3, gb_free=13.7, wall=14593
2023-03-15 18:02:59 - progress_bar.py[line:272] - INFO: epoch 022:    758 / 2004 loss=0.187, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=295.1, nsentences=8, sample_size=295.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=874.7, ups=2.96, wpb=295.1, bsz=8, num_updates=42570, lr=5.80959e-05, gnorm=2.667, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=14597
2023-03-15 18:03:03 - progress_bar.py[line:272] - INFO: epoch 022:    768 / 2004 loss=0.176, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=408.6, nsentences=8, sample_size=408.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1160, ups=2.84, wpb=408.6, bsz=8, num_updates=42580, lr=5.80858e-05, gnorm=2.283, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=14600
2023-03-15 18:03:06 - progress_bar.py[line:272] - INFO: epoch 022:    778 / 2004 loss=0.191, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=351.3, nsentences=8, sample_size=351.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1022.1, ups=2.91, wpb=351.3, bsz=8, num_updates=42590, lr=5.80758e-05, gnorm=2.557, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=14604
2023-03-15 18:03:10 - progress_bar.py[line:272] - INFO: epoch 022:    788 / 2004 loss=0.178, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=343.7, nsentences=8, sample_size=343.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1006.7, ups=2.93, wpb=343.7, bsz=8, num_updates=42600, lr=5.80657e-05, gnorm=2.311, clip=0, loss_scale=4096, train_wall=3, gb_free=14.8, wall=14607
2023-03-15 18:03:11 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 18:03:13 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 18:03:14 - progress_bar.py[line:272] - INFO: epoch 022:    800 / 2004 loss=0.176, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=323.2, nsentences=8, sample_size=323.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=786.1, ups=2.43, wpb=323.2, bsz=8, num_updates=42610, lr=5.80556e-05, gnorm=2.143, clip=0, loss_scale=1024, train_wall=4, gb_free=14.6, wall=14611
2023-03-15 18:03:17 - progress_bar.py[line:272] - INFO: epoch 022:    810 / 2004 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=352.2, nsentences=8, sample_size=352.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1018, ups=2.89, wpb=352.2, bsz=8, num_updates=42620, lr=5.80455e-05, gnorm=2.288, clip=0, loss_scale=1024, train_wall=3, gb_free=14.2, wall=14615
2023-03-15 18:03:21 - progress_bar.py[line:272] - INFO: epoch 022:    820 / 2004 loss=0.181, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=315.2, nsentences=8, sample_size=315.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=924.1, ups=2.93, wpb=315.2, bsz=8, num_updates=42630, lr=5.80354e-05, gnorm=2.509, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=14618
2023-03-15 18:03:24 - progress_bar.py[line:272] - INFO: epoch 022:    830 / 2004 loss=0.184, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=364.8, nsentences=8, sample_size=364.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1051.4, ups=2.88, wpb=364.8, bsz=8, num_updates=42640, lr=5.80254e-05, gnorm=2.594, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=14622
2023-03-15 18:03:28 - progress_bar.py[line:272] - INFO: epoch 022:    840 / 2004 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=347.7, nsentences=8, sample_size=347.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1000.3, ups=2.88, wpb=347.7, bsz=8, num_updates=42650, lr=5.80153e-05, gnorm=2.433, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=14625
2023-03-15 18:03:31 - progress_bar.py[line:272] - INFO: epoch 022:    850 / 2004 loss=0.178, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=360.7, nsentences=8, sample_size=360.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1021.4, ups=2.83, wpb=360.7, bsz=8, num_updates=42660, lr=5.80052e-05, gnorm=2.377, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=14629
2023-03-15 18:03:35 - progress_bar.py[line:272] - INFO: epoch 022:    860 / 2004 loss=0.175, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=346.4, nsentences=8, sample_size=346.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1011.3, ups=2.92, wpb=346.4, bsz=8, num_updates=42670, lr=5.79951e-05, gnorm=2.468, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=14632
2023-03-15 18:03:38 - progress_bar.py[line:272] - INFO: epoch 022:    870 / 2004 loss=0.183, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=371.3, nsentences=8, sample_size=371.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1101.2, ups=2.97, wpb=371.3, bsz=8, num_updates=42680, lr=5.7985e-05, gnorm=2.4, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=14636
2023-03-15 18:03:41 - progress_bar.py[line:272] - INFO: epoch 022:    880 / 2004 loss=0.183, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=323.1, nsentences=8, sample_size=323.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=936.6, ups=2.9, wpb=323.1, bsz=8, num_updates=42690, lr=5.7975e-05, gnorm=2.5, clip=0, loss_scale=1024, train_wall=3, gb_free=13.8, wall=14639
2023-03-15 18:03:45 - progress_bar.py[line:272] - INFO: epoch 022:    890 / 2004 loss=0.201, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=315, nsentences=8, sample_size=315, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=916, ups=2.91, wpb=315, bsz=8, num_updates=42700, lr=5.79649e-05, gnorm=2.676, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=14642
2023-03-15 18:03:48 - progress_bar.py[line:272] - INFO: epoch 022:    900 / 2004 loss=0.175, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=364.3, nsentences=8, sample_size=364.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1033.7, ups=2.84, wpb=364.3, bsz=8, num_updates=42710, lr=5.79548e-05, gnorm=2.487, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=14646
2023-03-15 18:03:52 - progress_bar.py[line:272] - INFO: epoch 022:    910 / 2004 loss=0.184, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=358, nsentences=8, sample_size=358, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1024.2, ups=2.86, wpb=358, bsz=8, num_updates=42720, lr=5.79447e-05, gnorm=2.506, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=14649
2023-03-15 18:03:55 - progress_bar.py[line:272] - INFO: epoch 022:    920 / 2004 loss=0.22, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=346, nsentences=8, sample_size=346, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=1002.9, ups=2.9, wpb=346, bsz=8, num_updates=42730, lr=5.79346e-05, gnorm=2.932, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=14653
2023-03-15 18:03:59 - progress_bar.py[line:272] - INFO: epoch 022:    930 / 2004 loss=0.175, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=329.5, nsentences=8, sample_size=329.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=967.6, ups=2.94, wpb=329.5, bsz=8, num_updates=42740, lr=5.79246e-05, gnorm=2.323, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=14656
2023-03-15 18:04:02 - progress_bar.py[line:272] - INFO: epoch 022:    940 / 2004 loss=0.198, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=367.4, nsentences=8, sample_size=367.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1056.1, ups=2.87, wpb=367.4, bsz=8, num_updates=42750, lr=5.79145e-05, gnorm=2.67, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=14660
2023-03-15 18:04:06 - progress_bar.py[line:272] - INFO: epoch 022:    950 / 2004 loss=0.185, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=356.9, nsentences=8, sample_size=356.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1023.1, ups=2.87, wpb=356.9, bsz=8, num_updates=42760, lr=5.79044e-05, gnorm=2.519, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=14663
2023-03-15 18:04:09 - progress_bar.py[line:272] - INFO: epoch 022:    960 / 2004 loss=0.182, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=359.5, nsentences=8, sample_size=359.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1012.8, ups=2.82, wpb=359.5, bsz=8, num_updates=42770, lr=5.78943e-05, gnorm=2.329, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=14667
2023-03-15 18:04:13 - progress_bar.py[line:272] - INFO: epoch 022:    970 / 2004 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=340.1, nsentences=8, sample_size=340.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=987.2, ups=2.9, wpb=340.1, bsz=8, num_updates=42780, lr=5.78842e-05, gnorm=2.102, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=14670
2023-03-15 18:04:16 - progress_bar.py[line:272] - INFO: epoch 022:    980 / 2004 loss=0.185, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=329.2, nsentences=8, sample_size=329.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=962.3, ups=2.92, wpb=329.2, bsz=8, num_updates=42790, lr=5.78742e-05, gnorm=2.53, clip=0, loss_scale=2048, train_wall=3, gb_free=15.8, wall=14674
2023-03-15 18:04:17 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 18:04:20 - progress_bar.py[line:272] - INFO: epoch 022:    991 / 2004 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=379.1, nsentences=8, sample_size=379.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1073.5, ups=2.83, wpb=379.1, bsz=8, num_updates=42800, lr=5.78641e-05, gnorm=2.241, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=14677
2023-03-15 18:04:23 - progress_bar.py[line:272] - INFO: epoch 022:   1001 / 2004 loss=0.185, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=332.3, nsentences=8, sample_size=332.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1051.5, ups=3.16, wpb=332.3, bsz=8, num_updates=42810, lr=5.7854e-05, gnorm=2.45, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=14680
2023-03-15 18:04:26 - progress_bar.py[line:272] - INFO: epoch 022:   1011 / 2004 loss=0.207, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=329.4, nsentences=8, sample_size=329.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1052.5, ups=3.2, wpb=329.4, bsz=8, num_updates=42820, lr=5.78439e-05, gnorm=2.513, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=14683
2023-03-15 18:04:29 - progress_bar.py[line:272] - INFO: epoch 022:   1021 / 2004 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=334.8, nsentences=8, sample_size=334.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1087.8, ups=3.25, wpb=334.8, bsz=8, num_updates=42830, lr=5.78338e-05, gnorm=2.323, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=14687
2023-03-15 18:04:29 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-03-15 18:04:32 - progress_bar.py[line:272] - INFO: epoch 022:   1032 / 2004 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=331, nsentences=8, sample_size=331, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=968, ups=2.92, wpb=331, bsz=8, num_updates=42840, lr=5.78237e-05, gnorm=2.37, clip=0, loss_scale=512, train_wall=3, gb_free=14.9, wall=14690
2023-03-15 18:04:35 - progress_bar.py[line:272] - INFO: epoch 022:   1042 / 2004 loss=0.201, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=338.7, nsentences=8, sample_size=338.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1092.1, ups=3.22, wpb=338.7, bsz=8, num_updates=42850, lr=5.78137e-05, gnorm=2.705, clip=0, loss_scale=512, train_wall=3, gb_free=15.4, wall=14693
2023-03-15 18:04:39 - progress_bar.py[line:272] - INFO: epoch 022:   1052 / 2004 loss=0.179, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=368, nsentences=8, sample_size=368, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1134.9, ups=3.08, wpb=368, bsz=8, num_updates=42860, lr=5.78036e-05, gnorm=2.351, clip=0, loss_scale=512, train_wall=3, gb_free=15.5, wall=14696
2023-03-15 18:04:42 - progress_bar.py[line:272] - INFO: epoch 022:   1062 / 2004 loss=0.188, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=338.8, nsentences=8, sample_size=338.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1077.5, ups=3.18, wpb=338.8, bsz=8, num_updates=42870, lr=5.77935e-05, gnorm=2.442, clip=0, loss_scale=512, train_wall=3, gb_free=15, wall=14699
2023-03-15 18:04:45 - progress_bar.py[line:272] - INFO: epoch 022:   1072 / 2004 loss=0.196, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=355.7, nsentences=8, sample_size=355.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1119.8, ups=3.15, wpb=355.7, bsz=8, num_updates=42880, lr=5.77834e-05, gnorm=2.73, clip=0, loss_scale=512, train_wall=3, gb_free=14.9, wall=14703
2023-03-15 18:04:48 - progress_bar.py[line:272] - INFO: epoch 022:   1082 / 2004 loss=0.183, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=368.8, nsentences=8, sample_size=368.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1145.2, ups=3.11, wpb=368.8, bsz=8, num_updates=42890, lr=5.77733e-05, gnorm=2.423, clip=0, loss_scale=512, train_wall=3, gb_free=14.4, wall=14706
2023-03-15 18:04:51 - progress_bar.py[line:272] - INFO: epoch 022:   1092 / 2004 loss=0.202, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=321.8, nsentences=7.8, sample_size=321.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1024.6, ups=3.18, wpb=321.8, bsz=7.8, num_updates=42900, lr=5.77633e-05, gnorm=2.592, clip=0, loss_scale=512, train_wall=3, gb_free=14.4, wall=14709
2023-03-15 18:04:52 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-03-15 18:04:55 - progress_bar.py[line:272] - INFO: epoch 022:   1103 / 2004 loss=0.191, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=369, nsentences=8, sample_size=369, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=990.3, ups=2.68, wpb=369, bsz=8, num_updates=42910, lr=5.77532e-05, gnorm=2.444, clip=0, loss_scale=256, train_wall=4, gb_free=14.2, wall=14713
2023-03-15 18:04:58 - progress_bar.py[line:272] - INFO: epoch 022:   1113 / 2004 loss=0.19, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=345.6, nsentences=8, sample_size=345.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1033.9, ups=2.99, wpb=345.6, bsz=8, num_updates=42920, lr=5.77431e-05, gnorm=2.509, clip=0, loss_scale=256, train_wall=3, gb_free=14.6, wall=14716
2023-03-15 18:05:02 - progress_bar.py[line:272] - INFO: epoch 022:   1123 / 2004 loss=0.187, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=309.4, nsentences=8, sample_size=309.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=904.7, ups=2.92, wpb=309.4, bsz=8, num_updates=42930, lr=5.7733e-05, gnorm=2.559, clip=0, loss_scale=256, train_wall=3, gb_free=14.9, wall=14719
2023-03-15 18:05:05 - progress_bar.py[line:272] - INFO: epoch 022:   1133 / 2004 loss=0.18, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=379.2, nsentences=8, sample_size=379.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1132, ups=2.99, wpb=379.2, bsz=8, num_updates=42940, lr=5.77229e-05, gnorm=2.314, clip=0, loss_scale=256, train_wall=3, gb_free=15.5, wall=14723
2023-03-15 18:05:09 - progress_bar.py[line:272] - INFO: epoch 022:   1143 / 2004 loss=0.182, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=365, nsentences=8, sample_size=365, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1051.5, ups=2.88, wpb=365, bsz=8, num_updates=42950, lr=5.77129e-05, gnorm=2.436, clip=0, loss_scale=256, train_wall=3, gb_free=15, wall=14726
2023-03-15 18:05:12 - progress_bar.py[line:272] - INFO: epoch 022:   1153 / 2004 loss=0.176, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=370.9, nsentences=8, sample_size=370.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1062, ups=2.86, wpb=370.9, bsz=8, num_updates=42960, lr=5.77028e-05, gnorm=2.386, clip=0, loss_scale=256, train_wall=3, gb_free=15.1, wall=14730
2023-03-15 18:05:16 - progress_bar.py[line:272] - INFO: epoch 022:   1163 / 2004 loss=0.179, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=376, nsentences=8, sample_size=376, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1068, ups=2.84, wpb=376, bsz=8, num_updates=42970, lr=5.76927e-05, gnorm=2.479, clip=0, loss_scale=256, train_wall=3, gb_free=15.4, wall=14733
2023-03-15 18:05:19 - progress_bar.py[line:272] - INFO: epoch 022:   1173 / 2004 loss=0.184, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=356.8, nsentences=8, sample_size=356.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1034.1, ups=2.9, wpb=356.8, bsz=8, num_updates=42980, lr=5.76826e-05, gnorm=2.362, clip=0, loss_scale=256, train_wall=3, gb_free=14.7, wall=14737
2023-03-15 18:05:23 - progress_bar.py[line:272] - INFO: epoch 022:   1183 / 2004 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=334.4, nsentences=8, sample_size=334.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=972.1, ups=2.91, wpb=334.4, bsz=8, num_updates=42990, lr=5.76725e-05, gnorm=2.197, clip=0, loss_scale=256, train_wall=3, gb_free=15.4, wall=14740
2023-03-15 18:05:26 - progress_bar.py[line:272] - INFO: epoch 022:   1193 / 2004 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=359.7, nsentences=8, sample_size=359.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1049.1, ups=2.92, wpb=359.7, bsz=8, num_updates=43000, lr=5.76625e-05, gnorm=2.236, clip=0, loss_scale=256, train_wall=3, gb_free=14.2, wall=14744
2023-03-15 18:05:29 - progress_bar.py[line:272] - INFO: epoch 022:   1203 / 2004 loss=0.198, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=325.9, nsentences=8, sample_size=325.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1053.6, ups=3.23, wpb=325.9, bsz=8, num_updates=43010, lr=5.76524e-05, gnorm=2.293, clip=0, loss_scale=256, train_wall=3, gb_free=15.1, wall=14747
2023-03-15 18:05:32 - progress_bar.py[line:272] - INFO: epoch 022:   1213 / 2004 loss=0.184, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=288.4, nsentences=8, sample_size=288.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=953.7, ups=3.31, wpb=288.4, bsz=8, num_updates=43020, lr=5.76423e-05, gnorm=2.477, clip=0, loss_scale=256, train_wall=3, gb_free=15.6, wall=14750
2023-03-15 18:05:35 - progress_bar.py[line:272] - INFO: epoch 022:   1223 / 2004 loss=0.2, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=339.3, nsentences=8, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1079.7, ups=3.18, wpb=339.3, bsz=8, num_updates=43030, lr=5.76322e-05, gnorm=2.549, clip=0, loss_scale=512, train_wall=3, gb_free=14.5, wall=14753
2023-03-15 18:05:38 - progress_bar.py[line:272] - INFO: epoch 022:   1233 / 2004 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=306.4, nsentences=8, sample_size=306.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=972.9, ups=3.18, wpb=306.4, bsz=8, num_updates=43040, lr=5.76221e-05, gnorm=2.161, clip=0, loss_scale=512, train_wall=3, gb_free=15, wall=14756
2023-03-15 18:05:42 - progress_bar.py[line:272] - INFO: epoch 022:   1243 / 2004 loss=0.178, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=392.9, nsentences=8, sample_size=392.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1099.3, ups=2.8, wpb=392.9, bsz=8, num_updates=43050, lr=5.7612e-05, gnorm=2.336, clip=0, loss_scale=512, train_wall=4, gb_free=14.3, wall=14760
2023-03-15 18:05:46 - progress_bar.py[line:272] - INFO: epoch 022:   1253 / 2004 loss=0.182, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=350.1, nsentences=8, sample_size=350.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1003.9, ups=2.87, wpb=350.1, bsz=8, num_updates=43060, lr=5.7602e-05, gnorm=2.331, clip=0, loss_scale=512, train_wall=3, gb_free=14.7, wall=14763
2023-03-15 18:05:49 - progress_bar.py[line:272] - INFO: epoch 022:   1263 / 2004 loss=0.191, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=326.6, nsentences=8, sample_size=326.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=936.7, ups=2.87, wpb=326.6, bsz=8, num_updates=43070, lr=5.75919e-05, gnorm=2.691, clip=0, loss_scale=512, train_wall=3, gb_free=15.4, wall=14767
2023-03-15 18:05:53 - progress_bar.py[line:272] - INFO: epoch 022:   1273 / 2004 loss=0.197, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=346.4, nsentences=8, sample_size=346.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=985.7, ups=2.85, wpb=346.4, bsz=8, num_updates=43080, lr=5.75818e-05, gnorm=2.524, clip=0, loss_scale=512, train_wall=3, gb_free=15.5, wall=14770
2023-03-15 18:05:56 - progress_bar.py[line:272] - INFO: epoch 022:   1283 / 2004 loss=0.182, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=343.9, nsentences=8, sample_size=343.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=986.9, ups=2.87, wpb=343.9, bsz=8, num_updates=43090, lr=5.75717e-05, gnorm=2.489, clip=0, loss_scale=512, train_wall=3, gb_free=14.3, wall=14774
2023-03-15 18:05:59 - progress_bar.py[line:272] - INFO: epoch 022:   1293 / 2004 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=300.6, nsentences=8, sample_size=300.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=896.1, ups=2.98, wpb=300.6, bsz=8, num_updates=43100, lr=5.75616e-05, gnorm=2.235, clip=0, loss_scale=512, train_wall=3, gb_free=15.2, wall=14777
2023-03-15 18:06:03 - progress_bar.py[line:272] - INFO: epoch 022:   1303 / 2004 loss=0.187, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=333.3, nsentences=8, sample_size=333.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=979.5, ups=2.94, wpb=333.3, bsz=8, num_updates=43110, lr=5.75516e-05, gnorm=2.347, clip=0, loss_scale=512, train_wall=3, gb_free=14.5, wall=14780
2023-03-15 18:06:06 - progress_bar.py[line:272] - INFO: epoch 022:   1313 / 2004 loss=0.175, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=323.2, nsentences=8, sample_size=323.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=952.3, ups=2.95, wpb=323.2, bsz=8, num_updates=43120, lr=5.75415e-05, gnorm=2.345, clip=0, loss_scale=512, train_wall=3, gb_free=15.1, wall=14784
2023-03-15 18:06:10 - progress_bar.py[line:272] - INFO: epoch 022:   1323 / 2004 loss=0.182, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=318.3, nsentences=8, sample_size=318.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=926.7, ups=2.91, wpb=318.3, bsz=8, num_updates=43130, lr=5.75314e-05, gnorm=2.352, clip=0, loss_scale=512, train_wall=3, gb_free=14.6, wall=14787
2023-03-15 18:06:13 - progress_bar.py[line:272] - INFO: epoch 022:   1333 / 2004 loss=0.192, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=333.2, nsentences=8, sample_size=333.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=955.5, ups=2.87, wpb=333.2, bsz=8, num_updates=43140, lr=5.75213e-05, gnorm=2.472, clip=0, loss_scale=512, train_wall=3, gb_free=14.6, wall=14791
2023-03-15 18:06:16 - progress_bar.py[line:272] - INFO: epoch 022:   1343 / 2004 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=321, nsentences=8, sample_size=321, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=943.9, ups=2.94, wpb=321, bsz=8, num_updates=43150, lr=5.75112e-05, gnorm=2.304, clip=0, loss_scale=512, train_wall=3, gb_free=14.2, wall=14794
2023-03-15 18:06:20 - progress_bar.py[line:272] - INFO: epoch 022:   1353 / 2004 loss=0.182, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=313, nsentences=8, sample_size=313, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=920.3, ups=2.94, wpb=313, bsz=8, num_updates=43160, lr=5.75012e-05, gnorm=2.528, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=14797
2023-03-15 18:06:23 - progress_bar.py[line:272] - INFO: epoch 022:   1363 / 2004 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=326.8, nsentences=8, sample_size=326.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=956.3, ups=2.93, wpb=326.8, bsz=8, num_updates=43170, lr=5.74911e-05, gnorm=2.257, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=14801
2023-03-15 18:06:27 - progress_bar.py[line:272] - INFO: epoch 022:   1373 / 2004 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=299.6, nsentences=8, sample_size=299.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=846.4, ups=2.83, wpb=299.6, bsz=8, num_updates=43180, lr=5.7481e-05, gnorm=2.197, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=14804
2023-03-15 18:06:30 - progress_bar.py[line:272] - INFO: epoch 022:   1383 / 2004 loss=0.183, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=384.6, nsentences=8, sample_size=384.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1098.1, ups=2.86, wpb=384.6, bsz=8, num_updates=43190, lr=5.74709e-05, gnorm=2.523, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=14808
2023-03-15 18:06:34 - progress_bar.py[line:272] - INFO: epoch 022:   1393 / 2004 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=362.5, nsentences=8, sample_size=362.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1049.8, ups=2.9, wpb=362.5, bsz=8, num_updates=43200, lr=5.74608e-05, gnorm=2.264, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=14811
2023-03-15 18:06:37 - progress_bar.py[line:272] - INFO: epoch 022:   1403 / 2004 loss=0.18, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=337.1, nsentences=8, sample_size=337.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=977.4, ups=2.9, wpb=337.1, bsz=8, num_updates=43210, lr=5.74508e-05, gnorm=2.236, clip=0, loss_scale=1024, train_wall=3, gb_free=15.7, wall=14815
2023-03-15 18:06:39 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-03-15 18:06:41 - progress_bar.py[line:272] - INFO: epoch 022:   1414 / 2004 loss=0.18, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=372.1, nsentences=8, sample_size=372.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=982.1, ups=2.64, wpb=372.1, bsz=8, num_updates=43220, lr=5.74407e-05, gnorm=2.455, clip=0, loss_scale=512, train_wall=4, gb_free=14.9, wall=14819
2023-03-15 18:06:45 - progress_bar.py[line:272] - INFO: epoch 022:   1424 / 2004 loss=0.179, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=297.9, nsentences=8, sample_size=297.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=855.8, ups=2.87, wpb=297.9, bsz=8, num_updates=43230, lr=5.74306e-05, gnorm=2.464, clip=0, loss_scale=512, train_wall=3, gb_free=15.4, wall=14822
2023-03-15 18:06:48 - progress_bar.py[line:272] - INFO: epoch 022:   1434 / 2004 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=368.1, nsentences=8, sample_size=368.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1061.3, ups=2.88, wpb=368.1, bsz=8, num_updates=43240, lr=5.74205e-05, gnorm=2.269, clip=0, loss_scale=512, train_wall=3, gb_free=14.2, wall=14826
2023-03-15 18:06:48 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-03-15 18:06:52 - progress_bar.py[line:272] - INFO: epoch 022:   1445 / 2004 loss=0.183, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=325.8, nsentences=8, sample_size=325.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=862.6, ups=2.65, wpb=325.8, bsz=8, num_updates=43250, lr=5.74104e-05, gnorm=2.291, clip=0, loss_scale=256, train_wall=4, gb_free=14.9, wall=14829
2023-03-15 18:06:55 - progress_bar.py[line:272] - INFO: epoch 022:   1455 / 2004 loss=0.193, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=370.5, nsentences=8, sample_size=370.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1052.9, ups=2.84, wpb=370.5, bsz=8, num_updates=43260, lr=5.74004e-05, gnorm=2.517, clip=0, loss_scale=256, train_wall=3, gb_free=15.1, wall=14833
2023-03-15 18:06:59 - progress_bar.py[line:272] - INFO: epoch 022:   1465 / 2004 loss=0.187, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=388.9, nsentences=8, sample_size=388.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1122, ups=2.89, wpb=388.9, bsz=8, num_updates=43270, lr=5.73903e-05, gnorm=2.602, clip=0, loss_scale=256, train_wall=3, gb_free=15, wall=14836
2023-03-15 18:07:02 - progress_bar.py[line:272] - INFO: epoch 022:   1475 / 2004 loss=0.201, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=411.5, nsentences=8, sample_size=411.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1179.3, ups=2.87, wpb=411.5, bsz=8, num_updates=43280, lr=5.73802e-05, gnorm=2.708, clip=0, loss_scale=256, train_wall=3, gb_free=14.3, wall=14840
2023-03-15 18:07:06 - progress_bar.py[line:272] - INFO: epoch 022:   1485 / 2004 loss=0.187, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=355.3, nsentences=8, sample_size=355.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1022.1, ups=2.88, wpb=355.3, bsz=8, num_updates=43290, lr=5.73701e-05, gnorm=2.482, clip=0, loss_scale=256, train_wall=3, gb_free=14.8, wall=14843
2023-03-15 18:07:09 - progress_bar.py[line:272] - INFO: epoch 022:   1495 / 2004 loss=0.199, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=323.5, nsentences=8, sample_size=323.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=937.6, ups=2.9, wpb=323.5, bsz=8, num_updates=43300, lr=5.736e-05, gnorm=2.832, clip=0, loss_scale=256, train_wall=3, gb_free=13.9, wall=14847
2023-03-15 18:07:12 - progress_bar.py[line:272] - INFO: epoch 022:   1505 / 2004 loss=0.188, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=329.6, nsentences=8, sample_size=329.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1031.3, ups=3.13, wpb=329.6, bsz=8, num_updates=43310, lr=5.73499e-05, gnorm=2.364, clip=0, loss_scale=256, train_wall=3, gb_free=14.9, wall=14850
2023-03-15 18:07:15 - progress_bar.py[line:272] - INFO: epoch 022:   1515 / 2004 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=322.3, nsentences=8, sample_size=322.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1027.2, ups=3.19, wpb=322.3, bsz=8, num_updates=43320, lr=5.73399e-05, gnorm=2.253, clip=0, loss_scale=256, train_wall=3, gb_free=14.9, wall=14853
2023-03-15 18:07:19 - progress_bar.py[line:272] - INFO: epoch 022:   1525 / 2004 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=327.9, nsentences=8, sample_size=327.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1029.7, ups=3.14, wpb=327.9, bsz=8, num_updates=43330, lr=5.73298e-05, gnorm=2.306, clip=0, loss_scale=256, train_wall=3, gb_free=14.8, wall=14856
2023-03-15 18:07:22 - progress_bar.py[line:272] - INFO: epoch 022:   1535 / 2004 loss=0.192, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=356.9, nsentences=8, sample_size=356.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1030.3, ups=2.89, wpb=356.9, bsz=8, num_updates=43340, lr=5.73197e-05, gnorm=2.54, clip=0, loss_scale=256, train_wall=3, gb_free=14.5, wall=14860
2023-03-15 18:07:26 - progress_bar.py[line:272] - INFO: epoch 022:   1545 / 2004 loss=0.175, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=309.5, nsentences=8, sample_size=309.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=896.5, ups=2.9, wpb=309.5, bsz=8, num_updates=43350, lr=5.73096e-05, gnorm=2.377, clip=0, loss_scale=256, train_wall=3, gb_free=15.5, wall=14863
2023-03-15 18:07:29 - progress_bar.py[line:272] - INFO: epoch 022:   1555 / 2004 loss=0.193, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=355.3, nsentences=8, sample_size=355.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1035.3, ups=2.91, wpb=355.3, bsz=8, num_updates=43360, lr=5.72995e-05, gnorm=2.443, clip=0, loss_scale=256, train_wall=3, gb_free=14, wall=14867
2023-03-15 18:07:33 - progress_bar.py[line:272] - INFO: epoch 022:   1565 / 2004 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=347, nsentences=8, sample_size=347, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=985.3, ups=2.84, wpb=347, bsz=8, num_updates=43370, lr=5.72895e-05, gnorm=2.287, clip=0, loss_scale=512, train_wall=3, gb_free=15.3, wall=14870
2023-03-15 18:07:36 - progress_bar.py[line:272] - INFO: epoch 022:   1575 / 2004 loss=0.179, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=336.5, nsentences=8, sample_size=336.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=983.3, ups=2.92, wpb=336.5, bsz=8, num_updates=43380, lr=5.72794e-05, gnorm=2.478, clip=0, loss_scale=512, train_wall=3, gb_free=15.1, wall=14874
2023-03-15 18:07:39 - progress_bar.py[line:272] - INFO: epoch 022:   1585 / 2004 loss=0.192, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=321.1, nsentences=8, sample_size=321.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=928.7, ups=2.89, wpb=321.1, bsz=8, num_updates=43390, lr=5.72693e-05, gnorm=2.527, clip=0, loss_scale=512, train_wall=3, gb_free=15.1, wall=14877
2023-03-15 18:07:43 - progress_bar.py[line:272] - INFO: epoch 022:   1595 / 2004 loss=0.179, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=362.8, nsentences=8, sample_size=362.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1035.6, ups=2.85, wpb=362.8, bsz=8, num_updates=43400, lr=5.72592e-05, gnorm=2.406, clip=0, loss_scale=512, train_wall=3, gb_free=14.8, wall=14881
2023-03-15 18:07:46 - progress_bar.py[line:272] - INFO: epoch 022:   1605 / 2004 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=337.9, nsentences=8, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=973, ups=2.88, wpb=337.9, bsz=8, num_updates=43410, lr=5.72491e-05, gnorm=2.437, clip=0, loss_scale=512, train_wall=3, gb_free=14.8, wall=14884
2023-03-15 18:07:50 - progress_bar.py[line:272] - INFO: epoch 022:   1615 / 2004 loss=0.19, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=341.2, nsentences=8, sample_size=341.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=976.6, ups=2.86, wpb=341.2, bsz=8, num_updates=43420, lr=5.72391e-05, gnorm=2.386, clip=0, loss_scale=512, train_wall=3, gb_free=15.5, wall=14888
2023-03-15 18:07:53 - progress_bar.py[line:272] - INFO: epoch 022:   1625 / 2004 loss=0.193, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=352.5, nsentences=8, sample_size=352.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1033.9, ups=2.93, wpb=352.5, bsz=8, num_updates=43430, lr=5.7229e-05, gnorm=2.485, clip=0, loss_scale=512, train_wall=3, gb_free=15.1, wall=14891
2023-03-15 18:07:56 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-03-15 18:07:57 - progress_bar.py[line:272] - INFO: epoch 022:   1636 / 2004 loss=0.183, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=324.3, nsentences=8, sample_size=324.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=870, ups=2.68, wpb=324.3, bsz=8, num_updates=43440, lr=5.72189e-05, gnorm=2.564, clip=0, loss_scale=256, train_wall=4, gb_free=15.1, wall=14895
2023-03-15 18:08:00 - progress_bar.py[line:272] - INFO: epoch 022:   1646 / 2004 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=318.5, nsentences=8, sample_size=318.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=924.1, ups=2.9, wpb=318.5, bsz=8, num_updates=43450, lr=5.72088e-05, gnorm=2.332, clip=0, loss_scale=256, train_wall=3, gb_free=14.5, wall=14898
2023-03-15 18:08:04 - progress_bar.py[line:272] - INFO: epoch 022:   1656 / 2004 loss=0.179, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=358.1, nsentences=8, sample_size=358.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1040.8, ups=2.91, wpb=358.1, bsz=8, num_updates=43460, lr=5.71987e-05, gnorm=2.344, clip=0, loss_scale=256, train_wall=3, gb_free=14.4, wall=14902
2023-03-15 18:08:07 - progress_bar.py[line:272] - INFO: epoch 022:   1666 / 2004 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=345.7, nsentences=8, sample_size=345.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1010.4, ups=2.92, wpb=345.7, bsz=8, num_updates=43470, lr=5.71887e-05, gnorm=2.475, clip=0, loss_scale=256, train_wall=3, gb_free=14.5, wall=14905
2023-03-15 18:08:11 - progress_bar.py[line:272] - INFO: epoch 022:   1676 / 2004 loss=0.181, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=320.2, nsentences=8, sample_size=320.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=935.7, ups=2.92, wpb=320.2, bsz=8, num_updates=43480, lr=5.71786e-05, gnorm=2.535, clip=0, loss_scale=256, train_wall=3, gb_free=14.9, wall=14908
2023-03-15 18:08:14 - progress_bar.py[line:272] - INFO: epoch 022:   1686 / 2004 loss=0.176, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=334, nsentences=8, sample_size=334, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=975.6, ups=2.92, wpb=334, bsz=8, num_updates=43490, lr=5.71685e-05, gnorm=2.269, clip=0, loss_scale=256, train_wall=3, gb_free=14.9, wall=14912
2023-03-15 18:08:18 - progress_bar.py[line:272] - INFO: epoch 022:   1696 / 2004 loss=0.185, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=337.7, nsentences=8, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=970.9, ups=2.87, wpb=337.7, bsz=8, num_updates=43500, lr=5.71584e-05, gnorm=2.472, clip=0, loss_scale=256, train_wall=3, gb_free=15.4, wall=14915
2023-03-15 18:08:21 - progress_bar.py[line:272] - INFO: epoch 022:   1706 / 2004 loss=0.175, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=348.9, nsentences=8, sample_size=348.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=997.5, ups=2.86, wpb=348.9, bsz=8, num_updates=43510, lr=5.71483e-05, gnorm=2.426, clip=0, loss_scale=256, train_wall=3, gb_free=13.9, wall=14919
2023-03-15 18:08:25 - progress_bar.py[line:272] - INFO: epoch 022:   1716 / 2004 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=356.2, nsentences=8, sample_size=356.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1027.2, ups=2.88, wpb=356.2, bsz=8, num_updates=43520, lr=5.71382e-05, gnorm=2.406, clip=0, loss_scale=256, train_wall=3, gb_free=15.1, wall=14922
2023-03-15 18:08:28 - progress_bar.py[line:272] - INFO: epoch 022:   1726 / 2004 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=396.6, nsentences=8, sample_size=396.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1142.4, ups=2.88, wpb=396.6, bsz=8, num_updates=43530, lr=5.71282e-05, gnorm=2.322, clip=0, loss_scale=256, train_wall=3, gb_free=15, wall=14926
2023-03-15 18:08:31 - progress_bar.py[line:272] - INFO: epoch 022:   1736 / 2004 loss=0.179, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=347.5, nsentences=8, sample_size=347.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1081.7, ups=3.11, wpb=347.5, bsz=8, num_updates=43540, lr=5.71181e-05, gnorm=2.554, clip=0, loss_scale=256, train_wall=3, gb_free=15, wall=14929
2023-03-15 18:08:35 - progress_bar.py[line:272] - INFO: epoch 022:   1746 / 2004 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=341.3, nsentences=8, sample_size=341.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1056.1, ups=3.09, wpb=341.3, bsz=8, num_updates=43550, lr=5.7108e-05, gnorm=2.505, clip=0, loss_scale=256, train_wall=3, gb_free=14.4, wall=14932
2023-03-15 18:08:38 - progress_bar.py[line:272] - INFO: epoch 022:   1756 / 2004 loss=0.181, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=328.1, nsentences=8, sample_size=328.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1050, ups=3.2, wpb=328.1, bsz=8, num_updates=43560, lr=5.70979e-05, gnorm=2.324, clip=0, loss_scale=256, train_wall=3, gb_free=16.2, wall=14935
2023-03-15 18:08:41 - progress_bar.py[line:272] - INFO: epoch 022:   1766 / 2004 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=318.3, nsentences=8, sample_size=318.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=928, ups=2.92, wpb=318.3, bsz=8, num_updates=43570, lr=5.70878e-05, gnorm=2.333, clip=0, loss_scale=512, train_wall=3, gb_free=15.4, wall=14939
2023-03-15 18:08:45 - progress_bar.py[line:272] - INFO: epoch 022:   1776 / 2004 loss=0.179, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=347.4, nsentences=8, sample_size=347.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=989.6, ups=2.85, wpb=347.4, bsz=8, num_updates=43580, lr=5.70778e-05, gnorm=2.33, clip=0, loss_scale=512, train_wall=3, gb_free=15.2, wall=14942
2023-03-15 18:08:48 - progress_bar.py[line:272] - INFO: epoch 022:   1786 / 2004 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=317, nsentences=8, sample_size=317, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=922.2, ups=2.91, wpb=317, bsz=8, num_updates=43590, lr=5.70677e-05, gnorm=2.058, clip=0, loss_scale=512, train_wall=3, gb_free=15.2, wall=14946
2023-03-15 18:08:52 - progress_bar.py[line:272] - INFO: epoch 022:   1796 / 2004 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=337.2, nsentences=8, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=978, ups=2.9, wpb=337.2, bsz=8, num_updates=43600, lr=5.70576e-05, gnorm=2.159, clip=0, loss_scale=512, train_wall=3, gb_free=14.5, wall=14949
2023-03-15 18:08:55 - progress_bar.py[line:272] - INFO: epoch 022:   1806 / 2004 loss=0.18, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=345.6, nsentences=8, sample_size=345.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=990, ups=2.86, wpb=345.6, bsz=8, num_updates=43610, lr=5.70475e-05, gnorm=2.626, clip=0, loss_scale=512, train_wall=3, gb_free=14.6, wall=14953
2023-03-15 18:08:58 - progress_bar.py[line:272] - INFO: epoch 022:   1816 / 2004 loss=0.194, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=347.7, nsentences=8, sample_size=347.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1006.1, ups=2.89, wpb=347.7, bsz=8, num_updates=43620, lr=5.70374e-05, gnorm=2.51, clip=0, loss_scale=512, train_wall=3, gb_free=15.2, wall=14956
2023-03-15 18:09:02 - progress_bar.py[line:272] - INFO: epoch 022:   1826 / 2004 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=365.7, nsentences=8, sample_size=365.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1047, ups=2.86, wpb=365.7, bsz=8, num_updates=43630, lr=5.70274e-05, gnorm=2.312, clip=0, loss_scale=512, train_wall=3, gb_free=15, wall=14960
2023-03-15 18:09:05 - progress_bar.py[line:272] - INFO: epoch 022:   1836 / 2004 loss=0.199, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=327.2, nsentences=8, sample_size=327.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=941.7, ups=2.88, wpb=327.2, bsz=8, num_updates=43640, lr=5.70173e-05, gnorm=2.695, clip=0, loss_scale=512, train_wall=3, gb_free=15.3, wall=14963
2023-03-15 18:09:09 - progress_bar.py[line:272] - INFO: epoch 022:   1846 / 2004 loss=0.177, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=360.5, nsentences=8, sample_size=360.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1035.9, ups=2.87, wpb=360.5, bsz=8, num_updates=43650, lr=5.70072e-05, gnorm=2.412, clip=0, loss_scale=512, train_wall=3, gb_free=14.6, wall=14967
2023-03-15 18:09:12 - progress_bar.py[line:272] - INFO: epoch 022:   1856 / 2004 loss=0.178, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=312.9, nsentences=8, sample_size=312.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=894.4, ups=2.86, wpb=312.9, bsz=8, num_updates=43660, lr=5.69971e-05, gnorm=2.366, clip=0, loss_scale=512, train_wall=3, gb_free=15.6, wall=14970
2023-03-15 18:09:16 - progress_bar.py[line:272] - INFO: epoch 022:   1866 / 2004 loss=0.171, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=343.7, nsentences=8, sample_size=343.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=993, ups=2.89, wpb=343.7, bsz=8, num_updates=43670, lr=5.6987e-05, gnorm=2.1, clip=0, loss_scale=512, train_wall=3, gb_free=15.3, wall=14973
2023-03-15 18:09:17 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-03-15 18:09:20 - progress_bar.py[line:272] - INFO: epoch 022:   1877 / 2004 loss=0.176, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=339.4, nsentences=8, sample_size=339.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=904.3, ups=2.66, wpb=339.4, bsz=8, num_updates=43680, lr=5.6977e-05, gnorm=2.427, clip=0, loss_scale=256, train_wall=4, gb_free=14.9, wall=14977
2023-03-15 18:09:23 - progress_bar.py[line:272] - INFO: epoch 022:   1887 / 2004 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=314.3, nsentences=8, sample_size=314.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=939, ups=2.99, wpb=314.3, bsz=8, num_updates=43690, lr=5.69669e-05, gnorm=2.372, clip=0, loss_scale=256, train_wall=3, gb_free=15.6, wall=14981
2023-03-15 18:09:26 - progress_bar.py[line:272] - INFO: epoch 022:   1897 / 2004 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=352.5, nsentences=8, sample_size=352.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1107.4, ups=3.14, wpb=352.5, bsz=8, num_updates=43700, lr=5.69568e-05, gnorm=2.353, clip=0, loss_scale=256, train_wall=3, gb_free=15.2, wall=14984
2023-03-15 18:09:29 - progress_bar.py[line:272] - INFO: epoch 022:   1907 / 2004 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=333.2, nsentences=8, sample_size=333.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1032.9, ups=3.1, wpb=333.2, bsz=8, num_updates=43710, lr=5.69467e-05, gnorm=1.998, clip=0, loss_scale=256, train_wall=3, gb_free=15.6, wall=14987
2023-03-15 18:09:33 - progress_bar.py[line:272] - INFO: epoch 022:   1917 / 2004 loss=0.185, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=332, nsentences=8, sample_size=332, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=981.8, ups=2.96, wpb=332, bsz=8, num_updates=43720, lr=5.69366e-05, gnorm=2.556, clip=0, loss_scale=256, train_wall=3, gb_free=15.4, wall=14990
2023-03-15 18:09:36 - progress_bar.py[line:272] - INFO: epoch 022:   1927 / 2004 loss=0.179, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=330.9, nsentences=8, sample_size=330.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=955.4, ups=2.89, wpb=330.9, bsz=8, num_updates=43730, lr=5.69266e-05, gnorm=2.29, clip=0, loss_scale=256, train_wall=3, gb_free=15.1, wall=14994
2023-03-15 18:09:40 - progress_bar.py[line:272] - INFO: epoch 022:   1937 / 2004 loss=0.196, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=337.9, nsentences=8, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=976.9, ups=2.89, wpb=337.9, bsz=8, num_updates=43740, lr=5.69165e-05, gnorm=2.526, clip=0, loss_scale=256, train_wall=3, gb_free=13.8, wall=14997
2023-03-15 18:09:43 - progress_bar.py[line:272] - INFO: epoch 022:   1947 / 2004 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=344.1, nsentences=8, sample_size=344.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=983, ups=2.86, wpb=344.1, bsz=8, num_updates=43750, lr=5.69064e-05, gnorm=2.312, clip=0, loss_scale=256, train_wall=3, gb_free=15.3, wall=15001
2023-03-15 18:09:47 - progress_bar.py[line:272] - INFO: epoch 022:   1957 / 2004 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=354.9, nsentences=8, sample_size=354.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1017.2, ups=2.87, wpb=354.9, bsz=8, num_updates=43760, lr=5.68963e-05, gnorm=2.225, clip=0, loss_scale=256, train_wall=3, gb_free=15.4, wall=15004
2023-03-15 18:09:50 - progress_bar.py[line:272] - INFO: epoch 022:   1967 / 2004 loss=0.178, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=352.3, nsentences=8, sample_size=352.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=980.3, ups=2.78, wpb=352.3, bsz=8, num_updates=43770, lr=5.68862e-05, gnorm=2.457, clip=0, loss_scale=256, train_wall=4, gb_free=15.5, wall=15008
2023-03-15 18:09:54 - progress_bar.py[line:272] - INFO: epoch 022:   1977 / 2004 loss=0.181, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=346.4, nsentences=8, sample_size=346.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1019.9, ups=2.94, wpb=346.4, bsz=8, num_updates=43780, lr=5.68761e-05, gnorm=2.541, clip=0, loss_scale=256, train_wall=3, gb_free=15.2, wall=15011
2023-03-15 18:09:57 - progress_bar.py[line:272] - INFO: epoch 022:   1987 / 2004 loss=0.177, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=323.2, nsentences=8, sample_size=323.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=941.8, ups=2.91, wpb=323.2, bsz=8, num_updates=43790, lr=5.68661e-05, gnorm=2.407, clip=0, loss_scale=256, train_wall=3, gb_free=13.8, wall=15015
2023-03-15 18:10:01 - progress_bar.py[line:272] - INFO: epoch 022:   1997 / 2004 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=398.1, nsentences=8, sample_size=398.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1156.3, ups=2.9, wpb=398.1, bsz=8, num_updates=43800, lr=5.6856e-05, gnorm=2.462, clip=0, loss_scale=256, train_wall=3, gb_free=14.1, wall=15018
2023-03-15 18:10:03 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 22 @ 43807 updates
2023-03-15 18:10:03 - trainer.py[line:431] - INFO: Saving checkpoint to ./checkpoints/checkpoint22.pt
2023-03-15 18:10:10 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./checkpoints/checkpoint22.pt
2023-03-15 18:10:13 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./checkpoints/checkpoint22.pt (epoch 22 @ 43807 updates, score None) (writing took 9.993638722226024 seconds)
2023-03-15 18:10:13 - train.py[line:332] - INFO: end of epoch 22 (average epoch stats below)
2023-03-15 18:10:13 - progress_bar.py[line:282] - INFO: epoch 022 | loss 0.184 | loss_v1 0 | loss_v2 0 | nll_loss 0.184 | ntokens 345.569 | nsentences 7.999 | sample_size 345.569 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.14 | wps 975.9 | ups 2.82 | wpb 345.6 | bsz 8 | num_updates 43807 | lr 5.68489e-05 | gnorm 2.435 | clip 0.1 | loss_scale 512 | train_wall 671 | gb_free 14.6 | wall 15031
2023-03-15 18:10:13 - trainer.py[line:639] - INFO: loading train data for epoch 23
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 row count 8015 total row count 8015
slice_id 0 seek offset 0
2023-03-15 18:10:14 - trainer.py[line:703] - INFO: begin training epoch 23
2023-03-15 18:10:14 - train.py[line:305] - INFO: Start iterating over samples
2023-03-15 18:10:15 - progress_bar.py[line:272] - INFO: epoch 023:      3 / 2004 loss=0.193, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=360.7, nsentences=8, sample_size=360.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=248.2, ups=0.69, wpb=360.7, bsz=8, num_updates=43810, lr=5.68459e-05, gnorm=2.474, clip=0, loss_scale=512, train_wall=3, gb_free=15.3, wall=15033
2023-03-15 18:10:19 - progress_bar.py[line:272] - INFO: epoch 023:     13 / 2004 loss=0.205, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=327, nsentences=8, sample_size=327, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=946.5, ups=2.89, wpb=327, bsz=8, num_updates=43820, lr=5.68358e-05, gnorm=2.572, clip=0, loss_scale=512, train_wall=3, gb_free=15.5, wall=15036
2023-03-15 18:10:22 - progress_bar.py[line:272] - INFO: epoch 023:     23 / 2004 loss=0.179, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=357.1, nsentences=8, sample_size=357.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1007.7, ups=2.82, wpb=357.1, bsz=8, num_updates=43830, lr=5.68257e-05, gnorm=2.405, clip=0, loss_scale=512, train_wall=3, gb_free=15.3, wall=15040
2023-03-15 18:10:26 - progress_bar.py[line:272] - INFO: epoch 023:     33 / 2004 loss=0.176, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=361.3, nsentences=8, sample_size=361.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1043.5, ups=2.89, wpb=361.3, bsz=8, num_updates=43840, lr=5.68157e-05, gnorm=2.466, clip=0, loss_scale=512, train_wall=3, gb_free=14.6, wall=15043
2023-03-15 18:10:29 - progress_bar.py[line:272] - INFO: epoch 023:     43 / 2004 loss=0.171, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=353.2, nsentences=8, sample_size=353.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1035.7, ups=2.93, wpb=353.2, bsz=8, num_updates=43850, lr=5.68056e-05, gnorm=2.221, clip=0, loss_scale=512, train_wall=3, gb_free=15.2, wall=15047
2023-03-15 18:10:32 - progress_bar.py[line:272] - INFO: epoch 023:     53 / 2004 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=344.3, nsentences=8, sample_size=344.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1006.8, ups=2.92, wpb=344.3, bsz=8, num_updates=43860, lr=5.67955e-05, gnorm=2.185, clip=0, loss_scale=512, train_wall=3, gb_free=14.8, wall=15050
2023-03-15 18:10:36 - progress_bar.py[line:272] - INFO: epoch 023:     63 / 2004 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=338.5, nsentences=8, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=979.8, ups=2.89, wpb=338.5, bsz=8, num_updates=43870, lr=5.67854e-05, gnorm=2.244, clip=0, loss_scale=512, train_wall=3, gb_free=13.8, wall=15053
2023-03-15 18:10:39 - progress_bar.py[line:272] - INFO: epoch 023:     73 / 2004 loss=0.175, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=348.7, nsentences=8, sample_size=348.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1003.1, ups=2.88, wpb=348.7, bsz=8, num_updates=43880, lr=5.67753e-05, gnorm=2.364, clip=0, loss_scale=512, train_wall=3, gb_free=14.9, wall=15057
2023-03-15 18:10:43 - progress_bar.py[line:272] - INFO: epoch 023:     83 / 2004 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=328.5, nsentences=8, sample_size=328.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=945, ups=2.88, wpb=328.5, bsz=8, num_updates=43890, lr=5.67653e-05, gnorm=2.326, clip=0, loss_scale=512, train_wall=3, gb_free=15, wall=15060
2023-03-15 18:10:46 - progress_bar.py[line:272] - INFO: epoch 023:     93 / 2004 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=369.6, nsentences=8, sample_size=369.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1051.1, ups=2.84, wpb=369.6, bsz=8, num_updates=43900, lr=5.67552e-05, gnorm=2.332, clip=0, loss_scale=512, train_wall=3, gb_free=12.9, wall=15064
2023-03-15 18:10:50 - progress_bar.py[line:272] - INFO: epoch 023:    103 / 2004 loss=0.178, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=367.3, nsentences=8, sample_size=367.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1056.9, ups=2.88, wpb=367.3, bsz=8, num_updates=43910, lr=5.67451e-05, gnorm=2.421, clip=0, loss_scale=512, train_wall=3, gb_free=15, wall=15067
2023-03-15 18:10:53 - progress_bar.py[line:272] - INFO: epoch 023:    113 / 2004 loss=0.177, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=339.8, nsentences=8, sample_size=339.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=993.1, ups=2.92, wpb=339.8, bsz=8, num_updates=43920, lr=5.6735e-05, gnorm=2.421, clip=0, loss_scale=512, train_wall=3, gb_free=14.4, wall=15071
2023-03-15 18:10:57 - progress_bar.py[line:272] - INFO: epoch 023:    123 / 2004 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=349.4, nsentences=8, sample_size=349.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=998.2, ups=2.86, wpb=349.4, bsz=8, num_updates=43930, lr=5.67249e-05, gnorm=2.249, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=15074
2023-03-15 18:11:00 - progress_bar.py[line:272] - INFO: epoch 023:    133 / 2004 loss=0.192, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=316.1, nsentences=8, sample_size=316.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=929, ups=2.94, wpb=316.1, bsz=8, num_updates=43940, lr=5.67149e-05, gnorm=2.552, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=15078
2023-03-15 18:11:04 - progress_bar.py[line:272] - INFO: epoch 023:    143 / 2004 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=348.9, nsentences=8, sample_size=348.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1007.8, ups=2.89, wpb=348.9, bsz=8, num_updates=43950, lr=5.67048e-05, gnorm=2.298, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=15081
2023-03-15 18:11:07 - progress_bar.py[line:272] - INFO: epoch 023:    153 / 2004 loss=0.18, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=323, nsentences=8, sample_size=323, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=945.9, ups=2.93, wpb=323, bsz=8, num_updates=43960, lr=5.66947e-05, gnorm=2.617, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=15085
2023-03-15 18:11:10 - progress_bar.py[line:272] - INFO: epoch 023:    163 / 2004 loss=0.187, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=369.2, nsentences=8, sample_size=369.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1063.4, ups=2.88, wpb=369.2, bsz=8, num_updates=43970, lr=5.66846e-05, gnorm=2.478, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=15088
2023-03-15 18:11:14 - progress_bar.py[line:272] - INFO: epoch 023:    173 / 2004 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=335, nsentences=8, sample_size=335, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1001.5, ups=2.99, wpb=335, bsz=8, num_updates=43980, lr=5.66745e-05, gnorm=2.247, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=15091
2023-03-15 18:11:17 - progress_bar.py[line:272] - INFO: epoch 023:    183 / 2004 loss=0.185, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=322.9, nsentences=8, sample_size=322.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=928.7, ups=2.88, wpb=322.9, bsz=8, num_updates=43990, lr=5.66644e-05, gnorm=2.479, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=15095
2023-03-15 18:11:21 - progress_bar.py[line:272] - INFO: epoch 023:    193 / 2004 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=334.5, nsentences=8, sample_size=334.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=954.8, ups=2.85, wpb=334.5, bsz=8, num_updates=44000, lr=5.66544e-05, gnorm=2.222, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=15098
2023-03-15 18:11:24 - progress_bar.py[line:272] - INFO: epoch 023:    203 / 2004 loss=0.176, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=335.4, nsentences=8, sample_size=335.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=964.2, ups=2.87, wpb=335.4, bsz=8, num_updates=44010, lr=5.66443e-05, gnorm=2.475, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=15102
2023-03-15 18:11:28 - progress_bar.py[line:272] - INFO: epoch 023:    213 / 2004 loss=0.18, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=328.1, nsentences=8, sample_size=328.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=936.6, ups=2.85, wpb=328.1, bsz=8, num_updates=44020, lr=5.66342e-05, gnorm=2.323, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=15105
2023-03-15 18:11:31 - progress_bar.py[line:272] - INFO: epoch 023:    223 / 2004 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=331.8, nsentences=8, sample_size=331.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=948.1, ups=2.86, wpb=331.8, bsz=8, num_updates=44030, lr=5.66241e-05, gnorm=2.196, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=15109
2023-03-15 18:11:35 - progress_bar.py[line:272] - INFO: epoch 023:    233 / 2004 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=370.2, nsentences=8, sample_size=370.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1048.1, ups=2.83, wpb=370.2, bsz=8, num_updates=44040, lr=5.6614e-05, gnorm=2.039, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=15112
2023-03-15 18:11:38 - progress_bar.py[line:272] - INFO: epoch 023:    243 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=361, nsentences=8, sample_size=361, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1039.4, ups=2.88, wpb=361, bsz=8, num_updates=44050, lr=5.6604e-05, gnorm=2.053, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=15116
2023-03-15 18:11:42 - progress_bar.py[line:272] - INFO: epoch 023:    253 / 2004 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=342.6, nsentences=8, sample_size=342.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=981.2, ups=2.86, wpb=342.6, bsz=8, num_updates=44060, lr=5.65939e-05, gnorm=2.115, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=15119
2023-03-15 18:11:45 - progress_bar.py[line:272] - INFO: epoch 023:    263 / 2004 loss=0.181, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=332.9, nsentences=8, sample_size=332.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=957.4, ups=2.88, wpb=332.9, bsz=8, num_updates=44070, lr=5.65838e-05, gnorm=2.287, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=15123
2023-03-15 18:11:49 - progress_bar.py[line:272] - INFO: epoch 023:    273 / 2004 loss=0.178, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=344.7, nsentences=8, sample_size=344.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=998.3, ups=2.9, wpb=344.7, bsz=8, num_updates=44080, lr=5.65737e-05, gnorm=2.304, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=15126
2023-03-15 18:11:52 - progress_bar.py[line:272] - INFO: epoch 023:    283 / 2004 loss=0.185, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=369.4, nsentences=8, sample_size=369.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1056.5, ups=2.86, wpb=369.4, bsz=8, num_updates=44090, lr=5.65636e-05, gnorm=2.538, clip=0, loss_scale=2048, train_wall=3, gb_free=13.8, wall=15130
2023-03-15 18:11:56 - progress_bar.py[line:272] - INFO: epoch 023:    293 / 2004 loss=0.178, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=356.2, nsentences=8, sample_size=356.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1015.4, ups=2.85, wpb=356.2, bsz=8, num_updates=44100, lr=5.65536e-05, gnorm=2.408, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=15133
2023-03-15 18:11:59 - progress_bar.py[line:272] - INFO: epoch 023:    303 / 2004 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=354.3, nsentences=8, sample_size=354.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1030, ups=2.91, wpb=354.3, bsz=8, num_updates=44110, lr=5.65435e-05, gnorm=2.117, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=15137
2023-03-15 18:12:03 - progress_bar.py[line:272] - INFO: epoch 023:    313 / 2004 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=356.8, nsentences=8, sample_size=356.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1032.2, ups=2.89, wpb=356.8, bsz=8, num_updates=44120, lr=5.65334e-05, gnorm=2.352, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=15140
2023-03-15 18:12:06 - progress_bar.py[line:272] - INFO: epoch 023:    323 / 2004 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=330.4, nsentences=8, sample_size=330.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=954, ups=2.89, wpb=330.4, bsz=8, num_updates=44130, lr=5.65233e-05, gnorm=2.109, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=15144
2023-03-15 18:12:10 - progress_bar.py[line:272] - INFO: epoch 023:    333 / 2004 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=318.4, nsentences=8, sample_size=318.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=900, ups=2.83, wpb=318.4, bsz=8, num_updates=44140, lr=5.65132e-05, gnorm=2.252, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=15147
2023-03-15 18:12:13 - progress_bar.py[line:272] - INFO: epoch 023:    343 / 2004 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=372.8, nsentences=8, sample_size=372.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1054.7, ups=2.83, wpb=372.8, bsz=8, num_updates=44150, lr=5.65032e-05, gnorm=2.305, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=15151
2023-03-15 18:12:17 - progress_bar.py[line:272] - INFO: epoch 023:    353 / 2004 loss=0.18, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=345.9, nsentences=8, sample_size=345.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=997.9, ups=2.88, wpb=345.9, bsz=8, num_updates=44160, lr=5.64931e-05, gnorm=2.476, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=15154
2023-03-15 18:12:20 - progress_bar.py[line:272] - INFO: epoch 023:    363 / 2004 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=370.3, nsentences=8, sample_size=370.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1054.2, ups=2.85, wpb=370.3, bsz=8, num_updates=44170, lr=5.6483e-05, gnorm=2.248, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=15158
2023-03-15 18:12:24 - progress_bar.py[line:272] - INFO: epoch 023:    373 / 2004 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=317.4, nsentences=8, sample_size=317.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=923.9, ups=2.91, wpb=317.4, bsz=8, num_updates=44180, lr=5.64729e-05, gnorm=2.135, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=15161
2023-03-15 18:12:27 - progress_bar.py[line:272] - INFO: epoch 023:    383 / 2004 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=318.9, nsentences=8, sample_size=318.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=923, ups=2.89, wpb=318.9, bsz=8, num_updates=44190, lr=5.64628e-05, gnorm=2.333, clip=0, loss_scale=4096, train_wall=3, gb_free=14.7, wall=15165
2023-03-15 18:12:28 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 18:12:31 - progress_bar.py[line:272] - INFO: epoch 023:    394 / 2004 loss=0.179, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=368.5, nsentences=8, sample_size=368.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=963.7, ups=2.62, wpb=368.5, bsz=8, num_updates=44200, lr=5.64528e-05, gnorm=2.378, clip=0, loss_scale=2048, train_wall=4, gb_free=14.6, wall=15168
2023-03-15 18:12:33 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 18:12:35 - progress_bar.py[line:272] - INFO: epoch 023:    405 / 2004 loss=0.192, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=345.5, nsentences=8, sample_size=345.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=914, ups=2.65, wpb=345.5, bsz=8, num_updates=44210, lr=5.64427e-05, gnorm=2.617, clip=0, loss_scale=1024, train_wall=4, gb_free=15.4, wall=15172
2023-03-15 18:12:38 - progress_bar.py[line:272] - INFO: epoch 023:    415 / 2004 loss=0.171, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=351.8, nsentences=8, sample_size=351.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1026.4, ups=2.92, wpb=351.8, bsz=8, num_updates=44220, lr=5.64326e-05, gnorm=2.271, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=15176
2023-03-15 18:12:42 - progress_bar.py[line:272] - INFO: epoch 023:    425 / 2004 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=331.5, nsentences=8, sample_size=331.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=942.7, ups=2.84, wpb=331.5, bsz=8, num_updates=44230, lr=5.64225e-05, gnorm=2.138, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=15179
2023-03-15 18:12:45 - progress_bar.py[line:272] - INFO: epoch 023:    435 / 2004 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=363.6, nsentences=8, sample_size=363.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1012.1, ups=2.78, wpb=363.6, bsz=8, num_updates=44240, lr=5.64124e-05, gnorm=2.471, clip=0, loss_scale=1024, train_wall=4, gb_free=15.4, wall=15183
2023-03-15 18:12:49 - progress_bar.py[line:272] - INFO: epoch 023:    445 / 2004 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=366.6, nsentences=8, sample_size=366.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1034.3, ups=2.82, wpb=366.6, bsz=8, num_updates=44250, lr=5.64023e-05, gnorm=2.308, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=15186
2023-03-15 18:12:52 - progress_bar.py[line:272] - INFO: epoch 023:    455 / 2004 loss=0.188, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=380.2, nsentences=8, sample_size=380.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1074.7, ups=2.83, wpb=380.2, bsz=8, num_updates=44260, lr=5.63923e-05, gnorm=2.427, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=15190
2023-03-15 18:12:56 - progress_bar.py[line:272] - INFO: epoch 023:    465 / 2004 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=338.9, nsentences=8, sample_size=338.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=972.4, ups=2.87, wpb=338.9, bsz=8, num_updates=44270, lr=5.63822e-05, gnorm=2.295, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=15193
2023-03-15 18:12:59 - progress_bar.py[line:272] - INFO: epoch 023:    475 / 2004 loss=0.188, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=379.1, nsentences=8, sample_size=379.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1075.3, ups=2.84, wpb=379.1, bsz=8, num_updates=44280, lr=5.63721e-05, gnorm=2.351, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=15197
2023-03-15 18:13:03 - progress_bar.py[line:272] - INFO: epoch 023:    485 / 2004 loss=0.176, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=366.1, nsentences=8, sample_size=366.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1050.9, ups=2.87, wpb=366.1, bsz=8, num_updates=44290, lr=5.6362e-05, gnorm=2.297, clip=0, loss_scale=1024, train_wall=3, gb_free=15.7, wall=15200
2023-03-15 18:13:06 - progress_bar.py[line:272] - INFO: epoch 023:    495 / 2004 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=359.9, nsentences=8, sample_size=359.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=986.9, ups=2.74, wpb=359.9, bsz=8, num_updates=44300, lr=5.63519e-05, gnorm=2.237, clip=0, loss_scale=1024, train_wall=4, gb_free=15.3, wall=15204
2023-03-15 18:13:10 - progress_bar.py[line:272] - INFO: epoch 023:    505 / 2004 loss=0.196, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=353.8, nsentences=8, sample_size=353.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1033.2, ups=2.92, wpb=353.8, bsz=8, num_updates=44310, lr=5.63419e-05, gnorm=2.523, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=15207
2023-03-15 18:13:13 - progress_bar.py[line:272] - INFO: epoch 023:    515 / 2004 loss=0.19, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=359, nsentences=8, sample_size=359, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1005.2, ups=2.8, wpb=359, bsz=8, num_updates=44320, lr=5.63318e-05, gnorm=2.503, clip=0, loss_scale=1024, train_wall=4, gb_free=15.7, wall=15211
2023-03-15 18:13:18 - progress_bar.py[line:272] - INFO: epoch 023:    525 / 2004 loss=0.185, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=386.6, nsentences=8, sample_size=386.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=855.8, ups=2.21, wpb=386.6, bsz=8, num_updates=44330, lr=5.63217e-05, gnorm=2.527, clip=0, loss_scale=1024, train_wall=4, gb_free=14.4, wall=15215
2023-03-15 18:13:21 - progress_bar.py[line:272] - INFO: epoch 023:    535 / 2004 loss=0.187, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=382.7, nsentences=8, sample_size=382.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1086, ups=2.84, wpb=382.7, bsz=8, num_updates=44340, lr=5.63116e-05, gnorm=2.617, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=15219
2023-03-15 18:13:25 - progress_bar.py[line:272] - INFO: epoch 023:    545 / 2004 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=359, nsentences=8, sample_size=359, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1042.2, ups=2.9, wpb=359, bsz=8, num_updates=44350, lr=5.63015e-05, gnorm=2.233, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=15222
2023-03-15 18:13:28 - progress_bar.py[line:272] - INFO: epoch 023:    555 / 2004 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=383.6, nsentences=8, sample_size=383.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1089.3, ups=2.84, wpb=383.6, bsz=8, num_updates=44360, lr=5.62915e-05, gnorm=2.291, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=15226
2023-03-15 18:13:32 - progress_bar.py[line:272] - INFO: epoch 023:    565 / 2004 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=370.2, nsentences=8, sample_size=370.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1073.3, ups=2.9, wpb=370.2, bsz=8, num_updates=44370, lr=5.62814e-05, gnorm=2.394, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=15229
2023-03-15 18:13:35 - progress_bar.py[line:272] - INFO: epoch 023:    575 / 2004 loss=0.178, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=359.6, nsentences=8, sample_size=359.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1044.6, ups=2.9, wpb=359.6, bsz=8, num_updates=44380, lr=5.62713e-05, gnorm=2.282, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=15233
2023-03-15 18:13:39 - progress_bar.py[line:272] - INFO: epoch 023:    585 / 2004 loss=0.19, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=343.8, nsentences=8, sample_size=343.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=994.7, ups=2.89, wpb=343.8, bsz=8, num_updates=44390, lr=5.62612e-05, gnorm=2.531, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=15236
2023-03-15 18:13:42 - progress_bar.py[line:272] - INFO: epoch 023:    595 / 2004 loss=0.181, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=350.9, nsentences=8, sample_size=350.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1007.9, ups=2.87, wpb=350.9, bsz=8, num_updates=44400, lr=5.62511e-05, gnorm=2.225, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=15240
2023-03-15 18:13:44 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 18:13:46 - progress_bar.py[line:272] - INFO: epoch 023:    606 / 2004 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=339.6, nsentences=8, sample_size=339.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=884, ups=2.6, wpb=339.6, bsz=8, num_updates=44410, lr=5.62411e-05, gnorm=2.326, clip=0, loss_scale=1024, train_wall=4, gb_free=14.8, wall=15244
2023-03-15 18:13:50 - progress_bar.py[line:272] - INFO: epoch 023:    616 / 2004 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=360.8, nsentences=8, sample_size=360.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1020.9, ups=2.83, wpb=360.8, bsz=8, num_updates=44420, lr=5.6231e-05, gnorm=2.234, clip=0, loss_scale=1024, train_wall=3, gb_free=13.4, wall=15247
2023-03-15 18:13:53 - progress_bar.py[line:272] - INFO: epoch 023:    626 / 2004 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=360.5, nsentences=8, sample_size=360.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1042.5, ups=2.89, wpb=360.5, bsz=8, num_updates=44430, lr=5.62209e-05, gnorm=2.25, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=15251
2023-03-15 18:13:56 - progress_bar.py[line:272] - INFO: epoch 023:    636 / 2004 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=339.4, nsentences=8, sample_size=339.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=990.1, ups=2.92, wpb=339.4, bsz=8, num_updates=44440, lr=5.62108e-05, gnorm=2.229, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=15254
2023-03-15 18:14:00 - progress_bar.py[line:272] - INFO: epoch 023:    646 / 2004 loss=0.191, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=327.6, nsentences=8, sample_size=327.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=957.7, ups=2.92, wpb=327.6, bsz=8, num_updates=44450, lr=5.62007e-05, gnorm=2.519, clip=0, loss_scale=1024, train_wall=3, gb_free=15.7, wall=15258
2023-03-15 18:14:03 - progress_bar.py[line:272] - INFO: epoch 023:    656 / 2004 loss=0.18, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=355.7, nsentences=8, sample_size=355.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1038.5, ups=2.92, wpb=355.7, bsz=8, num_updates=44460, lr=5.61906e-05, gnorm=2.378, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=15261
2023-03-15 18:14:07 - progress_bar.py[line:272] - INFO: epoch 023:    666 / 2004 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=289.7, nsentences=8, sample_size=289.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=855, ups=2.95, wpb=289.7, bsz=8, num_updates=44470, lr=5.61806e-05, gnorm=2.444, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=15264
2023-03-15 18:14:10 - progress_bar.py[line:272] - INFO: epoch 023:    676 / 2004 loss=0.191, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=342.5, nsentences=8, sample_size=342.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1031.7, ups=3.01, wpb=342.5, bsz=8, num_updates=44480, lr=5.61705e-05, gnorm=2.515, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=15268
2023-03-15 18:14:13 - progress_bar.py[line:272] - INFO: epoch 023:    686 / 2004 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=363.1, nsentences=8, sample_size=363.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1082, ups=2.98, wpb=363.1, bsz=8, num_updates=44490, lr=5.61604e-05, gnorm=2.391, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=15271
2023-03-15 18:14:17 - progress_bar.py[line:272] - INFO: epoch 023:    696 / 2004 loss=0.199, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=341.4, nsentences=8, sample_size=341.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1000.3, ups=2.93, wpb=341.4, bsz=8, num_updates=44500, lr=5.61503e-05, gnorm=2.531, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=15274
2023-03-15 18:14:20 - progress_bar.py[line:272] - INFO: epoch 023:    706 / 2004 loss=0.175, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=346.8, nsentences=8, sample_size=346.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1013.5, ups=2.92, wpb=346.8, bsz=8, num_updates=44510, lr=5.61402e-05, gnorm=2.402, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=15278
2023-03-15 18:14:24 - progress_bar.py[line:272] - INFO: epoch 023:    716 / 2004 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=333.6, nsentences=8, sample_size=333.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=981, ups=2.94, wpb=333.6, bsz=8, num_updates=44520, lr=5.61302e-05, gnorm=2.329, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=15281
2023-03-15 18:14:24 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-03-15 18:14:28 - progress_bar.py[line:272] - INFO: epoch 023:    727 / 2004 loss=0.177, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=364.2, nsentences=8, sample_size=364.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=936, ups=2.57, wpb=364.2, bsz=8, num_updates=44530, lr=5.61201e-05, gnorm=2.317, clip=0, loss_scale=512, train_wall=4, gb_free=15, wall=15285
2023-03-15 18:14:31 - progress_bar.py[line:272] - INFO: epoch 023:    737 / 2004 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=344.2, nsentences=8, sample_size=344.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=997.9, ups=2.9, wpb=344.2, bsz=8, num_updates=44540, lr=5.611e-05, gnorm=2.203, clip=0, loss_scale=512, train_wall=3, gb_free=15.4, wall=15289
2023-03-15 18:14:34 - progress_bar.py[line:272] - INFO: epoch 023:    747 / 2004 loss=0.197, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=358.9, nsentences=8, sample_size=358.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1048.5, ups=2.92, wpb=358.9, bsz=8, num_updates=44550, lr=5.60999e-05, gnorm=2.581, clip=0, loss_scale=512, train_wall=3, gb_free=14.4, wall=15292
2023-03-15 18:14:38 - progress_bar.py[line:272] - INFO: epoch 023:    757 / 2004 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=310.2, nsentences=8, sample_size=310.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=923.9, ups=2.98, wpb=310.2, bsz=8, num_updates=44560, lr=5.60898e-05, gnorm=1.992, clip=0, loss_scale=512, train_wall=3, gb_free=14.8, wall=15295
2023-03-15 18:14:41 - progress_bar.py[line:272] - INFO: epoch 023:    767 / 2004 loss=0.184, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=390.8, nsentences=8, sample_size=390.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1214.8, ups=3.11, wpb=390.8, bsz=8, num_updates=44570, lr=5.60798e-05, gnorm=2.644, clip=0, loss_scale=512, train_wall=3, gb_free=14.2, wall=15299
2023-03-15 18:14:44 - progress_bar.py[line:272] - INFO: epoch 023:    777 / 2004 loss=0.206, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=371.6, nsentences=8, sample_size=371.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1070.7, ups=2.88, wpb=371.6, bsz=8, num_updates=44580, lr=5.60697e-05, gnorm=2.656, clip=0, loss_scale=512, train_wall=3, gb_free=14.4, wall=15302
2023-03-15 18:14:48 - progress_bar.py[line:272] - INFO: epoch 023:    787 / 2004 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=331.4, nsentences=8, sample_size=331.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=969.8, ups=2.93, wpb=331.4, bsz=8, num_updates=44590, lr=5.60596e-05, gnorm=2.255, clip=0, loss_scale=512, train_wall=3, gb_free=15.8, wall=15305
2023-03-15 18:14:51 - progress_bar.py[line:272] - INFO: epoch 023:    797 / 2004 loss=0.184, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=319.8, nsentences=8, sample_size=319.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=922.8, ups=2.89, wpb=319.8, bsz=8, num_updates=44600, lr=5.60495e-05, gnorm=2.347, clip=0, loss_scale=512, train_wall=3, gb_free=15.3, wall=15309
2023-03-15 18:14:55 - progress_bar.py[line:272] - INFO: epoch 023:    807 / 2004 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=346.2, nsentences=8, sample_size=346.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=994, ups=2.87, wpb=346.2, bsz=8, num_updates=44610, lr=5.60394e-05, gnorm=2.285, clip=0, loss_scale=512, train_wall=3, gb_free=15.1, wall=15312
2023-03-15 18:14:58 - progress_bar.py[line:272] - INFO: epoch 023:    817 / 2004 loss=0.176, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=326.3, nsentences=8, sample_size=326.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=963.3, ups=2.95, wpb=326.3, bsz=8, num_updates=44620, lr=5.60294e-05, gnorm=2.313, clip=0, loss_scale=512, train_wall=3, gb_free=14.5, wall=15316
2023-03-15 18:15:02 - progress_bar.py[line:272] - INFO: epoch 023:    827 / 2004 loss=0.182, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=374.4, nsentences=8, sample_size=374.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1059.9, ups=2.83, wpb=374.4, bsz=8, num_updates=44630, lr=5.60193e-05, gnorm=2.443, clip=0, loss_scale=512, train_wall=3, gb_free=14.9, wall=15319
2023-03-15 18:15:05 - progress_bar.py[line:272] - INFO: epoch 023:    837 / 2004 loss=0.191, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=317.4, nsentences=8, sample_size=317.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=920.1, ups=2.9, wpb=317.4, bsz=8, num_updates=44640, lr=5.60092e-05, gnorm=2.797, clip=0, loss_scale=512, train_wall=3, gb_free=15, wall=15323
2023-03-15 18:15:09 - progress_bar.py[line:272] - INFO: epoch 023:    847 / 2004 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=363.7, nsentences=8, sample_size=363.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1045.5, ups=2.87, wpb=363.7, bsz=8, num_updates=44650, lr=5.59991e-05, gnorm=2.142, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=15326
2023-03-15 18:15:12 - progress_bar.py[line:272] - INFO: epoch 023:    857 / 2004 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=364.2, nsentences=8, sample_size=364.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1054.6, ups=2.9, wpb=364.2, bsz=8, num_updates=44660, lr=5.5989e-05, gnorm=2.36, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=15330
2023-03-15 18:15:16 - progress_bar.py[line:272] - INFO: epoch 023:    867 / 2004 loss=0.18, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=363.7, nsentences=8, sample_size=363.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1054.5, ups=2.9, wpb=363.7, bsz=8, num_updates=44670, lr=5.5979e-05, gnorm=2.205, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=15333
2023-03-15 18:15:19 - progress_bar.py[line:272] - INFO: epoch 023:    877 / 2004 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=331.4, nsentences=8, sample_size=331.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=968.5, ups=2.92, wpb=331.4, bsz=8, num_updates=44680, lr=5.59689e-05, gnorm=2.169, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=15337
2023-03-15 18:15:22 - progress_bar.py[line:272] - INFO: epoch 023:    887 / 2004 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=315.9, nsentences=8, sample_size=315.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=901.6, ups=2.85, wpb=315.9, bsz=8, num_updates=44690, lr=5.59588e-05, gnorm=2.362, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=15340
2023-03-15 18:15:26 - progress_bar.py[line:272] - INFO: epoch 023:    897 / 2004 loss=0.186, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=343.3, nsentences=8, sample_size=343.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=980.2, ups=2.86, wpb=343.3, bsz=8, num_updates=44700, lr=5.59487e-05, gnorm=2.596, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=15344
2023-03-15 18:15:30 - progress_bar.py[line:272] - INFO: epoch 023:    907 / 2004 loss=0.171, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=358.2, nsentences=8, sample_size=358.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1014.2, ups=2.83, wpb=358.2, bsz=8, num_updates=44710, lr=5.59386e-05, gnorm=2.334, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=15347
2023-03-15 18:15:33 - progress_bar.py[line:272] - INFO: epoch 023:    917 / 2004 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=368.8, nsentences=8, sample_size=368.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1059, ups=2.87, wpb=368.8, bsz=8, num_updates=44720, lr=5.59285e-05, gnorm=2.081, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=15351
2023-03-15 18:15:36 - progress_bar.py[line:272] - INFO: epoch 023:    927 / 2004 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=332.1, nsentences=8, sample_size=332.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=955.3, ups=2.88, wpb=332.1, bsz=8, num_updates=44730, lr=5.59185e-05, gnorm=2.409, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=15354
2023-03-15 18:15:40 - progress_bar.py[line:272] - INFO: epoch 023:    937 / 2004 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=362.7, nsentences=8, sample_size=362.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1092.9, ups=3.01, wpb=362.7, bsz=8, num_updates=44740, lr=5.59084e-05, gnorm=2.297, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=15357
2023-03-15 18:15:43 - progress_bar.py[line:272] - INFO: epoch 023:    947 / 2004 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=351, nsentences=8, sample_size=351, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1120.4, ups=3.19, wpb=351, bsz=8, num_updates=44750, lr=5.58983e-05, gnorm=2.267, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=15361
2023-03-15 18:15:46 - progress_bar.py[line:272] - INFO: epoch 023:    957 / 2004 loss=0.171, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=336.5, nsentences=8, sample_size=336.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1073.6, ups=3.19, wpb=336.5, bsz=8, num_updates=44760, lr=5.58882e-05, gnorm=2.199, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=15364
2023-03-15 18:15:49 - progress_bar.py[line:272] - INFO: epoch 023:    967 / 2004 loss=0.188, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=372.4, nsentences=8, sample_size=372.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1167.5, ups=3.13, wpb=372.4, bsz=8, num_updates=44770, lr=5.58781e-05, gnorm=2.383, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=15367
2023-03-15 18:15:52 - progress_bar.py[line:272] - INFO: epoch 023:    977 / 2004 loss=0.193, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=335.1, nsentences=8, sample_size=335.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1037.8, ups=3.1, wpb=335.1, bsz=8, num_updates=44780, lr=5.58681e-05, gnorm=2.596, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=15370
2023-03-15 18:15:53 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 18:15:56 - progress_bar.py[line:272] - INFO: epoch 023:    988 / 2004 loss=0.184, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=356, nsentences=8, sample_size=356, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=969.3, ups=2.72, wpb=356, bsz=8, num_updates=44790, lr=5.5858e-05, gnorm=2.697, clip=0, loss_scale=1024, train_wall=4, gb_free=14.7, wall=15374
2023-03-15 18:15:57 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-03-15 18:16:00 - progress_bar.py[line:272] - INFO: epoch 023:    999 / 2004 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=358.5, nsentences=8, sample_size=358.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=946.3, ups=2.64, wpb=358.5, bsz=8, num_updates=44800, lr=5.58479e-05, gnorm=2.482, clip=0, loss_scale=512, train_wall=4, gb_free=15, wall=15378
2023-03-15 18:16:03 - progress_bar.py[line:272] - INFO: epoch 023:   1009 / 2004 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=306.3, nsentences=8, sample_size=306.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=904.7, ups=2.95, wpb=306.3, bsz=8, num_updates=44810, lr=5.58378e-05, gnorm=2.342, clip=0, loss_scale=512, train_wall=3, gb_free=14.5, wall=15381
2023-03-15 18:16:07 - progress_bar.py[line:272] - INFO: epoch 023:   1019 / 2004 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=335.3, nsentences=8, sample_size=335.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=983.7, ups=2.93, wpb=335.3, bsz=8, num_updates=44820, lr=5.58277e-05, gnorm=2.137, clip=0, loss_scale=512, train_wall=3, gb_free=15.3, wall=15384
2023-03-15 18:16:10 - progress_bar.py[line:272] - INFO: epoch 023:   1029 / 2004 loss=0.185, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=326.1, nsentences=8, sample_size=326.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=958.1, ups=2.94, wpb=326.1, bsz=8, num_updates=44830, lr=5.58177e-05, gnorm=2.512, clip=0, loss_scale=512, train_wall=3, gb_free=14.9, wall=15388
2023-03-15 18:16:14 - progress_bar.py[line:272] - INFO: epoch 023:   1039 / 2004 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=315.2, nsentences=8, sample_size=315.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=932.5, ups=2.96, wpb=315.2, bsz=8, num_updates=44840, lr=5.58076e-05, gnorm=2.122, clip=0, loss_scale=512, train_wall=3, gb_free=15.2, wall=15391
2023-03-15 18:16:17 - progress_bar.py[line:272] - INFO: epoch 023:   1049 / 2004 loss=0.191, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=390.3, nsentences=8, sample_size=390.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1112.3, ups=2.85, wpb=390.3, bsz=8, num_updates=44850, lr=5.57975e-05, gnorm=2.514, clip=0, loss_scale=512, train_wall=3, gb_free=14.8, wall=15395
2023-03-15 18:16:20 - progress_bar.py[line:272] - INFO: epoch 023:   1059 / 2004 loss=0.187, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=346.4, nsentences=8, sample_size=346.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1013, ups=2.92, wpb=346.4, bsz=8, num_updates=44860, lr=5.57874e-05, gnorm=2.449, clip=0, loss_scale=512, train_wall=3, gb_free=14.9, wall=15398
2023-03-15 18:16:24 - progress_bar.py[line:272] - INFO: epoch 023:   1069 / 2004 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=339.8, nsentences=8, sample_size=339.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=986.8, ups=2.9, wpb=339.8, bsz=8, num_updates=44870, lr=5.57773e-05, gnorm=2.338, clip=0, loss_scale=512, train_wall=3, gb_free=14.2, wall=15402
2023-03-15 18:16:27 - progress_bar.py[line:272] - INFO: epoch 023:   1079 / 2004 loss=0.176, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=361.9, nsentences=8, sample_size=361.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1091.3, ups=3.02, wpb=361.9, bsz=8, num_updates=44880, lr=5.57673e-05, gnorm=2.384, clip=0, loss_scale=512, train_wall=3, gb_free=14.1, wall=15405
2023-03-15 18:16:31 - progress_bar.py[line:272] - INFO: epoch 023:   1089 / 2004 loss=0.189, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=367.3, nsentences=8, sample_size=367.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1059.4, ups=2.88, wpb=367.3, bsz=8, num_updates=44890, lr=5.57572e-05, gnorm=2.451, clip=0, loss_scale=512, train_wall=3, gb_free=14.5, wall=15408
2023-03-15 18:16:34 - progress_bar.py[line:272] - INFO: epoch 023:   1099 / 2004 loss=0.186, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=331.9, nsentences=8, sample_size=331.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=952, ups=2.87, wpb=331.9, bsz=8, num_updates=44900, lr=5.57471e-05, gnorm=2.3, clip=0, loss_scale=512, train_wall=3, gb_free=15.3, wall=15412
2023-03-15 18:16:38 - progress_bar.py[line:272] - INFO: epoch 023:   1109 / 2004 loss=0.178, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=362.8, nsentences=7.8, sample_size=362.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1045.7, ups=2.88, wpb=362.8, bsz=7.8, num_updates=44910, lr=5.5737e-05, gnorm=2.33, clip=0, loss_scale=512, train_wall=3, gb_free=14.6, wall=15415
2023-03-15 18:16:41 - progress_bar.py[line:272] - INFO: epoch 023:   1119 / 2004 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=327.8, nsentences=8, sample_size=327.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=939.9, ups=2.87, wpb=327.8, bsz=8, num_updates=44920, lr=5.57269e-05, gnorm=2.182, clip=0, loss_scale=1024, train_wall=3, gb_free=14.1, wall=15419
2023-03-15 18:16:44 - progress_bar.py[line:272] - INFO: epoch 023:   1129 / 2004 loss=0.188, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=343.2, nsentences=8, sample_size=343.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1038.6, ups=3.03, wpb=343.2, bsz=8, num_updates=44930, lr=5.57168e-05, gnorm=2.57, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=15422
2023-03-15 18:16:48 - progress_bar.py[line:272] - INFO: epoch 023:   1139 / 2004 loss=0.18, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=379, nsentences=8, sample_size=379, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1107.8, ups=2.92, wpb=379, bsz=8, num_updates=44940, lr=5.57068e-05, gnorm=2.305, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=15425
2023-03-15 18:16:51 - progress_bar.py[line:272] - INFO: epoch 023:   1149 / 2004 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=352.7, nsentences=8, sample_size=352.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1003.1, ups=2.84, wpb=352.7, bsz=8, num_updates=44950, lr=5.56967e-05, gnorm=2.226, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=15429
2023-03-15 18:16:55 - progress_bar.py[line:272] - INFO: epoch 023:   1159 / 2004 loss=0.176, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=407.1, nsentences=8, sample_size=407.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1144.2, ups=2.81, wpb=407.1, bsz=8, num_updates=44960, lr=5.56866e-05, gnorm=2.323, clip=0, loss_scale=1024, train_wall=4, gb_free=14.5, wall=15433
2023-03-15 18:16:58 - progress_bar.py[line:272] - INFO: epoch 023:   1169 / 2004 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=320.5, nsentences=8, sample_size=320.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=928.5, ups=2.9, wpb=320.5, bsz=8, num_updates=44970, lr=5.56765e-05, gnorm=2.363, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=15436
2023-03-15 18:17:02 - progress_bar.py[line:272] - INFO: epoch 023:   1179 / 2004 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=355.8, nsentences=8, sample_size=355.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1002.5, ups=2.82, wpb=355.8, bsz=8, num_updates=44980, lr=5.56664e-05, gnorm=2.053, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=15440
2023-03-15 18:17:05 - progress_bar.py[line:272] - INFO: epoch 023:   1189 / 2004 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=339.9, nsentences=8, sample_size=339.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=988.2, ups=2.91, wpb=339.9, bsz=8, num_updates=44990, lr=5.56564e-05, gnorm=2.001, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=15443
2023-03-15 18:17:09 - progress_bar.py[line:272] - INFO: epoch 023:   1199 / 2004 loss=0.18, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=354.4, nsentences=8, sample_size=354.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1031.9, ups=2.91, wpb=354.4, bsz=8, num_updates=45000, lr=5.56463e-05, gnorm=2.316, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=15446
2023-03-15 18:17:12 - progress_bar.py[line:272] - INFO: epoch 023:   1209 / 2004 loss=0.196, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=286.6, nsentences=8, sample_size=286.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=843.9, ups=2.94, wpb=286.6, bsz=8, num_updates=45010, lr=5.56362e-05, gnorm=2.446, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=15450
2023-03-15 18:17:16 - progress_bar.py[line:272] - INFO: epoch 023:   1219 / 2004 loss=0.178, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=333.3, nsentences=8, sample_size=333.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=963.2, ups=2.89, wpb=333.3, bsz=8, num_updates=45020, lr=5.56261e-05, gnorm=2.39, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=15453
2023-03-15 18:17:19 - progress_bar.py[line:272] - INFO: epoch 023:   1229 / 2004 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=307, nsentences=8, sample_size=307, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=973.8, ups=3.17, wpb=307, bsz=8, num_updates=45030, lr=5.5616e-05, gnorm=2.003, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=15456
2023-03-15 18:17:22 - progress_bar.py[line:272] - INFO: epoch 023:   1239 / 2004 loss=0.184, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=382.6, nsentences=8, sample_size=382.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1172.3, ups=3.06, wpb=382.6, bsz=8, num_updates=45040, lr=5.5606e-05, gnorm=2.386, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=15460
2023-03-15 18:17:25 - progress_bar.py[line:272] - INFO: epoch 023:   1249 / 2004 loss=0.182, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=338.6, nsentences=8, sample_size=338.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1047.2, ups=3.09, wpb=338.6, bsz=8, num_updates=45050, lr=5.55959e-05, gnorm=2.303, clip=0, loss_scale=2048, train_wall=3, gb_free=13.1, wall=15463
2023-03-15 18:17:29 - progress_bar.py[line:272] - INFO: epoch 023:   1259 / 2004 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=348.2, nsentences=8, sample_size=348.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1036.1, ups=2.98, wpb=348.2, bsz=8, num_updates=45060, lr=5.55858e-05, gnorm=2.08, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=15466
2023-03-15 18:17:32 - progress_bar.py[line:272] - INFO: epoch 023:   1269 / 2004 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=346.7, nsentences=8, sample_size=346.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=999.7, ups=2.88, wpb=346.7, bsz=8, num_updates=45070, lr=5.55757e-05, gnorm=2.249, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=15470
2023-03-15 18:17:36 - progress_bar.py[line:272] - INFO: epoch 023:   1279 / 2004 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=343.5, nsentences=8, sample_size=343.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=993.4, ups=2.89, wpb=343.5, bsz=8, num_updates=45080, lr=5.55656e-05, gnorm=2.152, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=15473
2023-03-15 18:17:39 - progress_bar.py[line:272] - INFO: epoch 023:   1289 / 2004 loss=0.19, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=310.5, nsentences=8, sample_size=310.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=876.2, ups=2.82, wpb=310.5, bsz=8, num_updates=45090, lr=5.55556e-05, gnorm=2.63, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=15477
2023-03-15 18:17:43 - progress_bar.py[line:272] - INFO: epoch 023:   1299 / 2004 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=309.4, nsentences=8, sample_size=309.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=897.1, ups=2.9, wpb=309.4, bsz=8, num_updates=45100, lr=5.55455e-05, gnorm=2.174, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=15480
2023-03-15 18:17:46 - progress_bar.py[line:272] - INFO: epoch 023:   1309 / 2004 loss=0.177, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=332.4, nsentences=8, sample_size=332.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=969.2, ups=2.92, wpb=332.4, bsz=8, num_updates=45110, lr=5.55354e-05, gnorm=2.252, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=15484
2023-03-15 18:17:49 - progress_bar.py[line:272] - INFO: epoch 023:   1319 / 2004 loss=0.18, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=338.5, nsentences=8, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=985.8, ups=2.91, wpb=338.5, bsz=8, num_updates=45120, lr=5.55253e-05, gnorm=2.503, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=15487
2023-03-15 18:17:53 - progress_bar.py[line:272] - INFO: epoch 023:   1329 / 2004 loss=0.179, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=294.3, nsentences=8, sample_size=294.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=847.3, ups=2.88, wpb=294.3, bsz=8, num_updates=45130, lr=5.55152e-05, gnorm=2.587, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=15491
2023-03-15 18:17:56 - progress_bar.py[line:272] - INFO: epoch 023:   1339 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=360.4, nsentences=8, sample_size=360.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1020.5, ups=2.83, wpb=360.4, bsz=8, num_updates=45140, lr=5.55052e-05, gnorm=2.179, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=15494
2023-03-15 18:18:00 - progress_bar.py[line:272] - INFO: epoch 023:   1349 / 2004 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=300.2, nsentences=8, sample_size=300.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=894.4, ups=2.98, wpb=300.2, bsz=8, num_updates=45150, lr=5.54951e-05, gnorm=2.301, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=15497
2023-03-15 18:18:00 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 18:18:04 - progress_bar.py[line:272] - INFO: epoch 023:   1360 / 2004 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=322.5, nsentences=8, sample_size=322.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=864.4, ups=2.68, wpb=322.5, bsz=8, num_updates=45160, lr=5.5485e-05, gnorm=2.368, clip=0, loss_scale=1024, train_wall=4, gb_free=15.5, wall=15501
2023-03-15 18:18:07 - progress_bar.py[line:272] - INFO: epoch 023:   1370 / 2004 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=311.4, nsentences=8, sample_size=311.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=892.8, ups=2.87, wpb=311.4, bsz=8, num_updates=45170, lr=5.54749e-05, gnorm=2.231, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=15505
2023-03-15 18:18:10 - progress_bar.py[line:272] - INFO: epoch 023:   1380 / 2004 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=352.8, nsentences=8, sample_size=352.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1056.9, ups=3, wpb=352.8, bsz=8, num_updates=45180, lr=5.54648e-05, gnorm=2.303, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=15508
2023-03-15 18:18:14 - progress_bar.py[line:272] - INFO: epoch 023:   1390 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=375.5, nsentences=8, sample_size=375.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1068.7, ups=2.85, wpb=375.5, bsz=8, num_updates=45190, lr=5.54547e-05, gnorm=2.042, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=15512
2023-03-15 18:18:17 - progress_bar.py[line:272] - INFO: epoch 023:   1400 / 2004 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=339.1, nsentences=8, sample_size=339.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=976.8, ups=2.88, wpb=339.1, bsz=8, num_updates=45200, lr=5.54447e-05, gnorm=2.289, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=15515
2023-03-15 18:18:20 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-03-15 18:18:21 - progress_bar.py[line:272] - INFO: epoch 023:   1411 / 2004 loss=0.183, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=366.3, nsentences=8, sample_size=366.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=957.1, ups=2.61, wpb=366.3, bsz=8, num_updates=45210, lr=5.54346e-05, gnorm=2.706, clip=0, loss_scale=512, train_wall=4, gb_free=14.3, wall=15519
2023-03-15 18:18:24 - progress_bar.py[line:272] - INFO: epoch 023:   1421 / 2004 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=342.3, nsentences=8, sample_size=342.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1057.3, ups=3.09, wpb=342.3, bsz=8, num_updates=45220, lr=5.54245e-05, gnorm=2.402, clip=0, loss_scale=512, train_wall=3, gb_free=15.1, wall=15522
2023-03-15 18:18:28 - progress_bar.py[line:272] - INFO: epoch 023:   1431 / 2004 loss=0.171, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=323.8, nsentences=8, sample_size=323.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1035.9, ups=3.2, wpb=323.8, bsz=8, num_updates=45230, lr=5.54144e-05, gnorm=2.245, clip=0, loss_scale=512, train_wall=3, gb_free=14.6, wall=15525
2023-03-15 18:18:29 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-03-15 18:18:31 - progress_bar.py[line:272] - INFO: epoch 023:   1442 / 2004 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=356.2, nsentences=8, sample_size=356.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=981.5, ups=2.76, wpb=356.2, bsz=8, num_updates=45240, lr=5.54043e-05, gnorm=2.414, clip=0, loss_scale=256, train_wall=4, gb_free=15.1, wall=15529
2023-03-15 18:18:35 - progress_bar.py[line:272] - INFO: epoch 023:   1452 / 2004 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=326.8, nsentences=8, sample_size=326.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=937.2, ups=2.87, wpb=326.8, bsz=8, num_updates=45250, lr=5.53943e-05, gnorm=2.111, clip=0, loss_scale=256, train_wall=3, gb_free=14.7, wall=15532
2023-03-15 18:18:38 - progress_bar.py[line:272] - INFO: epoch 023:   1462 / 2004 loss=0.171, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=391.4, nsentences=8, sample_size=391.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1096.5, ups=2.8, wpb=391.4, bsz=8, num_updates=45260, lr=5.53842e-05, gnorm=2.276, clip=0, loss_scale=256, train_wall=4, gb_free=14.8, wall=15536
2023-03-15 18:18:42 - progress_bar.py[line:272] - INFO: epoch 023:   1472 / 2004 loss=0.175, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=393.9, nsentences=8, sample_size=393.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1142, ups=2.9, wpb=393.9, bsz=8, num_updates=45270, lr=5.53741e-05, gnorm=2.442, clip=0, loss_scale=256, train_wall=3, gb_free=14.3, wall=15539
2023-03-15 18:18:45 - progress_bar.py[line:272] - INFO: epoch 023:   1482 / 2004 loss=0.18, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=391.7, nsentences=8, sample_size=391.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1103.2, ups=2.82, wpb=391.7, bsz=8, num_updates=45280, lr=5.5364e-05, gnorm=2.409, clip=0, loss_scale=256, train_wall=3, gb_free=14.7, wall=15543
2023-03-15 18:18:49 - progress_bar.py[line:272] - INFO: epoch 023:   1492 / 2004 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=315.7, nsentences=8, sample_size=315.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=928.5, ups=2.94, wpb=315.7, bsz=8, num_updates=45290, lr=5.53539e-05, gnorm=2.064, clip=0, loss_scale=256, train_wall=3, gb_free=14.1, wall=15546
2023-03-15 18:18:52 - progress_bar.py[line:272] - INFO: epoch 023:   1502 / 2004 loss=0.181, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=336, nsentences=8, sample_size=336, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1010, ups=3.01, wpb=336, bsz=8, num_updates=45300, lr=5.53439e-05, gnorm=2.452, clip=0, loss_scale=256, train_wall=3, gb_free=15.7, wall=15550
2023-03-15 18:18:55 - progress_bar.py[line:272] - INFO: epoch 023:   1512 / 2004 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=328.1, nsentences=8, sample_size=328.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=972.3, ups=2.96, wpb=328.1, bsz=8, num_updates=45310, lr=5.53338e-05, gnorm=2.168, clip=0, loss_scale=256, train_wall=3, gb_free=14.7, wall=15553
2023-03-15 18:18:59 - progress_bar.py[line:272] - INFO: epoch 023:   1522 / 2004 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=324.5, nsentences=8, sample_size=324.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=945.1, ups=2.91, wpb=324.5, bsz=8, num_updates=45320, lr=5.53237e-05, gnorm=2.42, clip=0, loss_scale=256, train_wall=3, gb_free=15.2, wall=15556
2023-03-15 18:19:02 - progress_bar.py[line:272] - INFO: epoch 023:   1532 / 2004 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=351.8, nsentences=8, sample_size=351.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1020.7, ups=2.9, wpb=351.8, bsz=8, num_updates=45330, lr=5.53136e-05, gnorm=2.324, clip=0, loss_scale=256, train_wall=3, gb_free=15.1, wall=15560
2023-03-15 18:19:06 - progress_bar.py[line:272] - INFO: epoch 023:   1542 / 2004 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=320.5, nsentences=8, sample_size=320.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=916, ups=2.86, wpb=320.5, bsz=8, num_updates=45340, lr=5.53035e-05, gnorm=1.958, clip=0, loss_scale=256, train_wall=3, gb_free=14.7, wall=15563
2023-03-15 18:19:09 - progress_bar.py[line:272] - INFO: epoch 023:   1552 / 2004 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=330.6, nsentences=8, sample_size=330.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=964.9, ups=2.92, wpb=330.6, bsz=8, num_updates=45350, lr=5.52935e-05, gnorm=2.141, clip=0, loss_scale=256, train_wall=3, gb_free=14.8, wall=15567
2023-03-15 18:19:13 - progress_bar.py[line:272] - INFO: epoch 023:   1562 / 2004 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=363.1, nsentences=8, sample_size=363.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1061.3, ups=2.92, wpb=363.1, bsz=8, num_updates=45360, lr=5.52834e-05, gnorm=2.131, clip=0, loss_scale=256, train_wall=3, gb_free=14.6, wall=15570
2023-03-15 18:19:16 - progress_bar.py[line:272] - INFO: epoch 023:   1572 / 2004 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=321.9, nsentences=8, sample_size=321.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=960.2, ups=2.98, wpb=321.9, bsz=8, num_updates=45370, lr=5.52733e-05, gnorm=2.107, clip=0, loss_scale=512, train_wall=3, gb_free=14.5, wall=15574
2023-03-15 18:19:19 - progress_bar.py[line:272] - INFO: epoch 023:   1582 / 2004 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=349.2, nsentences=8, sample_size=349.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1016, ups=2.91, wpb=349.2, bsz=8, num_updates=45380, lr=5.52632e-05, gnorm=2.285, clip=0, loss_scale=512, train_wall=3, gb_free=15.2, wall=15577
2023-03-15 18:19:23 - progress_bar.py[line:272] - INFO: epoch 023:   1592 / 2004 loss=0.191, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=340, nsentences=8, sample_size=340, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=979.2, ups=2.88, wpb=340, bsz=8, num_updates=45390, lr=5.52531e-05, gnorm=2.531, clip=0, loss_scale=512, train_wall=3, gb_free=14.7, wall=15580
2023-03-15 18:19:26 - progress_bar.py[line:272] - INFO: epoch 023:   1602 / 2004 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=337.7, nsentences=8, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=963.6, ups=2.85, wpb=337.7, bsz=8, num_updates=45400, lr=5.5243e-05, gnorm=2.368, clip=0, loss_scale=512, train_wall=3, gb_free=14.6, wall=15584
2023-03-15 18:19:30 - progress_bar.py[line:272] - INFO: epoch 023:   1612 / 2004 loss=0.182, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=359, nsentences=8, sample_size=359, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1008, ups=2.81, wpb=359, bsz=8, num_updates=45410, lr=5.5233e-05, gnorm=2.454, clip=0, loss_scale=512, train_wall=3, gb_free=14.4, wall=15588
2023-03-15 18:19:33 - progress_bar.py[line:272] - INFO: epoch 023:   1622 / 2004 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=351, nsentences=8, sample_size=351, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1009.4, ups=2.88, wpb=351, bsz=8, num_updates=45420, lr=5.52229e-05, gnorm=2.176, clip=0, loss_scale=512, train_wall=3, gb_free=14.5, wall=15591
2023-03-15 18:19:37 - progress_bar.py[line:272] - INFO: epoch 023:   1632 / 2004 loss=0.185, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=336.9, nsentences=8, sample_size=336.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=962.5, ups=2.86, wpb=336.9, bsz=8, num_updates=45430, lr=5.52128e-05, gnorm=2.551, clip=0, loss_scale=512, train_wall=3, gb_free=15.5, wall=15594
2023-03-15 18:19:40 - progress_bar.py[line:272] - INFO: epoch 023:   1642 / 2004 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=310.1, nsentences=8, sample_size=310.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=891, ups=2.87, wpb=310.1, bsz=8, num_updates=45440, lr=5.52027e-05, gnorm=2.225, clip=0, loss_scale=512, train_wall=3, gb_free=15.4, wall=15598
2023-03-15 18:19:44 - progress_bar.py[line:272] - INFO: epoch 023:   1652 / 2004 loss=0.178, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=327.8, nsentences=8, sample_size=327.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=952.2, ups=2.9, wpb=327.8, bsz=8, num_updates=45450, lr=5.51926e-05, gnorm=2.322, clip=0, loss_scale=512, train_wall=3, gb_free=15.5, wall=15601
2023-03-15 18:19:47 - progress_bar.py[line:272] - INFO: epoch 023:   1662 / 2004 loss=0.171, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=366.9, nsentences=8, sample_size=366.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1117.7, ups=3.05, wpb=366.9, bsz=8, num_updates=45460, lr=5.51826e-05, gnorm=2.47, clip=0, loss_scale=512, train_wall=3, gb_free=14.8, wall=15605
2023-03-15 18:19:50 - progress_bar.py[line:272] - INFO: epoch 023:   1672 / 2004 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=334.6, nsentences=8, sample_size=334.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1098.8, ups=3.28, wpb=334.6, bsz=8, num_updates=45470, lr=5.51725e-05, gnorm=2.353, clip=0, loss_scale=512, train_wall=3, gb_free=15.7, wall=15608
2023-03-15 18:19:53 - progress_bar.py[line:272] - INFO: epoch 023:   1682 / 2004 loss=0.178, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=332.8, nsentences=8, sample_size=332.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1000.6, ups=3.01, wpb=332.8, bsz=8, num_updates=45480, lr=5.51624e-05, gnorm=2.509, clip=0, loss_scale=512, train_wall=3, gb_free=15.1, wall=15611
2023-03-15 18:19:57 - progress_bar.py[line:272] - INFO: epoch 023:   1692 / 2004 loss=0.18, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=337.2, nsentences=8, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=966.7, ups=2.87, wpb=337.2, bsz=8, num_updates=45490, lr=5.51523e-05, gnorm=2.371, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=15615
2023-03-15 18:20:00 - progress_bar.py[line:272] - INFO: epoch 023:   1702 / 2004 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=327.4, nsentences=8, sample_size=327.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=947.6, ups=2.89, wpb=327.4, bsz=8, num_updates=45500, lr=5.51422e-05, gnorm=2.319, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=15618
2023-03-15 18:20:04 - progress_bar.py[line:272] - INFO: epoch 023:   1712 / 2004 loss=0.18, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=358.5, nsentences=8, sample_size=358.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1007, ups=2.81, wpb=358.5, bsz=8, num_updates=45510, lr=5.51322e-05, gnorm=2.497, clip=0, loss_scale=1024, train_wall=4, gb_free=14.9, wall=15622
2023-03-15 18:20:08 - progress_bar.py[line:272] - INFO: epoch 023:   1722 / 2004 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=389.8, nsentences=8, sample_size=389.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1093.4, ups=2.8, wpb=389.8, bsz=8, num_updates=45520, lr=5.51221e-05, gnorm=2.43, clip=0, loss_scale=1024, train_wall=4, gb_free=14.7, wall=15625
2023-03-15 18:20:11 - progress_bar.py[line:272] - INFO: epoch 023:   1732 / 2004 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=358, nsentences=8, sample_size=358, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1029.4, ups=2.88, wpb=358, bsz=8, num_updates=45530, lr=5.5112e-05, gnorm=2.075, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=15629
2023-03-15 18:20:14 - progress_bar.py[line:272] - INFO: epoch 023:   1742 / 2004 loss=0.178, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=325.7, nsentences=8, sample_size=325.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=957.5, ups=2.94, wpb=325.7, bsz=8, num_updates=45540, lr=5.51019e-05, gnorm=2.495, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=15632
2023-03-15 18:20:18 - progress_bar.py[line:272] - INFO: epoch 023:   1752 / 2004 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=361.1, nsentences=8, sample_size=361.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1043, ups=2.89, wpb=361.1, bsz=8, num_updates=45550, lr=5.50918e-05, gnorm=2.188, clip=0, loss_scale=1024, train_wall=3, gb_free=14.2, wall=15635
2023-03-15 18:20:21 - progress_bar.py[line:272] - INFO: epoch 023:   1762 / 2004 loss=0.179, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=314.7, nsentences=8, sample_size=314.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=915.9, ups=2.91, wpb=314.7, bsz=8, num_updates=45560, lr=5.50818e-05, gnorm=2.294, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=15639
2023-03-15 18:20:25 - progress_bar.py[line:272] - INFO: epoch 023:   1772 / 2004 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=336, nsentences=8, sample_size=336, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=976.9, ups=2.91, wpb=336, bsz=8, num_updates=45570, lr=5.50717e-05, gnorm=2.329, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=15642
2023-03-15 18:20:28 - progress_bar.py[line:272] - INFO: epoch 023:   1782 / 2004 loss=0.181, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=340.3, nsentences=8, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=982, ups=2.89, wpb=340.3, bsz=8, num_updates=45580, lr=5.50616e-05, gnorm=2.378, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=15646
2023-03-15 18:20:32 - progress_bar.py[line:272] - INFO: epoch 023:   1792 / 2004 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=291.2, nsentences=8, sample_size=291.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=855, ups=2.94, wpb=291.2, bsz=8, num_updates=45590, lr=5.50515e-05, gnorm=2.198, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=15649
2023-03-15 18:20:35 - progress_bar.py[line:272] - INFO: epoch 023:   1802 / 2004 loss=0.185, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=368.2, nsentences=8, sample_size=368.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1054.8, ups=2.86, wpb=368.2, bsz=8, num_updates=45600, lr=5.50414e-05, gnorm=2.51, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=15653
2023-03-15 18:20:39 - progress_bar.py[line:272] - INFO: epoch 023:   1812 / 2004 loss=0.177, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=337.3, nsentences=8, sample_size=337.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=953.5, ups=2.83, wpb=337.3, bsz=8, num_updates=45610, lr=5.50314e-05, gnorm=2.497, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=15656
2023-03-15 18:20:42 - progress_bar.py[line:272] - INFO: epoch 023:   1822 / 2004 loss=0.176, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=362.8, nsentences=8, sample_size=362.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1056.8, ups=2.91, wpb=362.8, bsz=8, num_updates=45620, lr=5.50213e-05, gnorm=2.376, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=15660
2023-03-15 18:20:46 - progress_bar.py[line:272] - INFO: epoch 023:   1832 / 2004 loss=0.202, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=356.5, nsentences=8, sample_size=356.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1021.8, ups=2.87, wpb=356.5, bsz=8, num_updates=45630, lr=5.50112e-05, gnorm=2.631, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=15663
2023-03-15 18:20:49 - progress_bar.py[line:272] - INFO: epoch 023:   1842 / 2004 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=330.6, nsentences=8, sample_size=330.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=946.2, ups=2.86, wpb=330.6, bsz=8, num_updates=45640, lr=5.50011e-05, gnorm=2.352, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=15667
2023-03-15 18:20:53 - progress_bar.py[line:272] - INFO: epoch 023:   1852 / 2004 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=336.3, nsentences=8, sample_size=336.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=977.1, ups=2.91, wpb=336.3, bsz=8, num_updates=45650, lr=5.4991e-05, gnorm=2.153, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=15670
2023-03-15 18:20:56 - progress_bar.py[line:272] - INFO: epoch 023:   1862 / 2004 loss=0.18, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=358.2, nsentences=8, sample_size=358.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1028.4, ups=2.87, wpb=358.2, bsz=8, num_updates=45660, lr=5.49809e-05, gnorm=2.376, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=15674
2023-03-15 18:21:00 - progress_bar.py[line:272] - INFO: epoch 023:   1872 / 2004 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=309.9, nsentences=8, sample_size=309.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=881.9, ups=2.85, wpb=309.9, bsz=8, num_updates=45670, lr=5.49709e-05, gnorm=2.027, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=15677
2023-03-15 18:21:03 - progress_bar.py[line:272] - INFO: epoch 023:   1882 / 2004 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=345.5, nsentences=8, sample_size=345.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1016.6, ups=2.94, wpb=345.5, bsz=8, num_updates=45680, lr=5.49608e-05, gnorm=2.377, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=15681
2023-03-15 18:21:06 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 18:21:07 - progress_bar.py[line:272] - INFO: epoch 023:   1893 / 2004 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=315.5, nsentences=8, sample_size=315.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=827.3, ups=2.62, wpb=315.5, bsz=8, num_updates=45690, lr=5.49507e-05, gnorm=2.13, clip=0, loss_scale=1024, train_wall=4, gb_free=14.6, wall=15684
2023-03-15 18:21:10 - progress_bar.py[line:272] - INFO: epoch 023:   1903 / 2004 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=356.7, nsentences=8, sample_size=356.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1033.1, ups=2.9, wpb=356.7, bsz=8, num_updates=45700, lr=5.49406e-05, gnorm=2.228, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=15688
2023-03-15 18:21:14 - progress_bar.py[line:272] - INFO: epoch 023:   1913 / 2004 loss=0.185, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=303, nsentences=8, sample_size=303, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=905.8, ups=2.99, wpb=303, bsz=8, num_updates=45710, lr=5.49305e-05, gnorm=2.458, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=15691
2023-03-15 18:21:17 - progress_bar.py[line:272] - INFO: epoch 023:   1923 / 2004 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=335.9, nsentences=8, sample_size=335.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=980.6, ups=2.92, wpb=335.9, bsz=8, num_updates=45720, lr=5.49205e-05, gnorm=2.252, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=15695
2023-03-15 18:21:20 - progress_bar.py[line:272] - INFO: epoch 023:   1933 / 2004 loss=0.186, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=327.4, nsentences=8, sample_size=327.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=928.5, ups=2.84, wpb=327.4, bsz=8, num_updates=45730, lr=5.49104e-05, gnorm=2.384, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=15698
2023-03-15 18:21:24 - progress_bar.py[line:272] - INFO: epoch 023:   1943 / 2004 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=352.8, nsentences=8, sample_size=352.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1018.5, ups=2.89, wpb=352.8, bsz=8, num_updates=45740, lr=5.49003e-05, gnorm=2.142, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=15702
2023-03-15 18:21:27 - progress_bar.py[line:272] - INFO: epoch 023:   1953 / 2004 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=345.8, nsentences=8, sample_size=345.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=994.5, ups=2.88, wpb=345.8, bsz=8, num_updates=45750, lr=5.48902e-05, gnorm=2.268, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=15705
2023-03-15 18:21:31 - progress_bar.py[line:272] - INFO: epoch 023:   1963 / 2004 loss=0.193, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=355.3, nsentences=8, sample_size=355.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1031.7, ups=2.9, wpb=355.3, bsz=8, num_updates=45760, lr=5.48801e-05, gnorm=2.557, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=15708
2023-03-15 18:21:34 - progress_bar.py[line:272] - INFO: epoch 023:   1973 / 2004 loss=0.18, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=351.9, nsentences=8, sample_size=351.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=998.2, ups=2.84, wpb=351.9, bsz=8, num_updates=45770, lr=5.48701e-05, gnorm=2.324, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=15712
2023-03-15 18:21:38 - progress_bar.py[line:272] - INFO: epoch 023:   1983 / 2004 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=321, nsentences=8, sample_size=321, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=923.2, ups=2.88, wpb=321, bsz=8, num_updates=45780, lr=5.486e-05, gnorm=2.092, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=15715
2023-03-15 18:21:41 - progress_bar.py[line:272] - INFO: epoch 023:   1993 / 2004 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=370, nsentences=8, sample_size=370, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1033.5, ups=2.79, wpb=370, bsz=8, num_updates=45790, lr=5.48499e-05, gnorm=2.168, clip=0, loss_scale=1024, train_wall=4, gb_free=15.2, wall=15719
2023-03-15 18:21:45 - progress_bar.py[line:272] - INFO: epoch 023:   2003 / 2004 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=383.1, nsentences=8, sample_size=383.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1158.6, ups=3.02, wpb=383.1, bsz=8, num_updates=45800, lr=5.48398e-05, gnorm=2.402, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=15722
2023-03-15 18:21:45 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 23 @ 45801 updates
2023-03-15 18:21:45 - trainer.py[line:431] - INFO: Saving checkpoint to ./checkpoints/checkpoint23.pt
2023-03-15 18:21:52 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./checkpoints/checkpoint23.pt
2023-03-15 18:21:55 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./checkpoints/checkpoint23.pt (epoch 23 @ 45801 updates, score None) (writing took 9.911025676876307 seconds)
2023-03-15 18:21:55 - train.py[line:332] - INFO: end of epoch 23 (average epoch stats below)
2023-03-15 18:21:55 - progress_bar.py[line:282] - INFO: epoch 023 | loss 0.175 | loss_v1 0 | loss_v2 0 | nll_loss 0.175 | ntokens 345.54 | nsentences 7.999 | sample_size 345.54 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.13 | wps 981.2 | ups 2.84 | wpb 345.5 | bsz 8 | num_updates 45801 | lr 5.48388e-05 | gnorm 2.334 | clip 0 | loss_scale 1024 | train_wall 679 | gb_free 14.4 | wall 15733
2023-03-15 18:21:55 - trainer.py[line:639] - INFO: loading train data for epoch 24
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 row count 8015 total row count 8015
slice_id 0 seek offset 0
2023-03-15 18:21:56 - trainer.py[line:703] - INFO: begin training epoch 24
2023-03-15 18:21:56 - train.py[line:305] - INFO: Start iterating over samples
2023-03-15 18:21:59 - progress_bar.py[line:272] - INFO: epoch 024:      9 / 2004 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=373.8, nsentences=8, sample_size=373.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=264.3, ups=0.71, wpb=373.8, bsz=8, num_updates=45810, lr=5.48297e-05, gnorm=2.377, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=15737
2023-03-15 18:22:02 - progress_bar.py[line:272] - INFO: epoch 024:     19 / 2004 loss=0.19, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=323.5, nsentences=8, sample_size=323.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1010.8, ups=3.12, wpb=323.5, bsz=8, num_updates=45820, lr=5.48197e-05, gnorm=2.394, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=15740
2023-03-15 18:22:06 - progress_bar.py[line:272] - INFO: epoch 024:     29 / 2004 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=350, nsentences=8, sample_size=350, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1019, ups=2.91, wpb=350, bsz=8, num_updates=45830, lr=5.48096e-05, gnorm=2.267, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=15743
2023-03-15 18:22:09 - progress_bar.py[line:272] - INFO: epoch 024:     39 / 2004 loss=0.175, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=353.7, nsentences=8, sample_size=353.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1023.9, ups=2.89, wpb=353.7, bsz=8, num_updates=45840, lr=5.47995e-05, gnorm=2.405, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=15747
2023-03-15 18:22:12 - progress_bar.py[line:272] - INFO: epoch 024:     49 / 2004 loss=0.187, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=338.5, nsentences=8, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=994.7, ups=2.94, wpb=338.5, bsz=8, num_updates=45850, lr=5.47894e-05, gnorm=2.486, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=15750
2023-03-15 18:22:16 - progress_bar.py[line:272] - INFO: epoch 024:     59 / 2004 loss=0.192, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=357.9, nsentences=8, sample_size=357.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1033.4, ups=2.89, wpb=357.9, bsz=8, num_updates=45860, lr=5.47793e-05, gnorm=2.423, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=15753
2023-03-15 18:22:19 - progress_bar.py[line:272] - INFO: epoch 024:     69 / 2004 loss=0.18, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=341, nsentences=8, sample_size=341, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=990.3, ups=2.9, wpb=341, bsz=8, num_updates=45870, lr=5.47692e-05, gnorm=2.343, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=15757
2023-03-15 18:22:23 - progress_bar.py[line:272] - INFO: epoch 024:     79 / 2004 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=322.9, nsentences=8, sample_size=322.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=964.8, ups=2.99, wpb=322.9, bsz=8, num_updates=45880, lr=5.47592e-05, gnorm=2.336, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=15760
2023-03-15 18:22:26 - progress_bar.py[line:272] - INFO: epoch 024:     89 / 2004 loss=0.175, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=364.2, nsentences=8, sample_size=364.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1068.1, ups=2.93, wpb=364.2, bsz=8, num_updates=45890, lr=5.47491e-05, gnorm=2.33, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=15764
2023-03-15 18:22:27 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 18:22:30 - progress_bar.py[line:272] - INFO: epoch 024:    100 / 2004 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=371.2, nsentences=8, sample_size=371.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1010.6, ups=2.72, wpb=371.2, bsz=8, num_updates=45900, lr=5.4739e-05, gnorm=2.563, clip=0, loss_scale=1024, train_wall=4, gb_free=14.9, wall=15767
2023-03-15 18:22:33 - progress_bar.py[line:272] - INFO: epoch 024:    110 / 2004 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=340.3, nsentences=8, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1080.3, ups=3.17, wpb=340.3, bsz=8, num_updates=45910, lr=5.47289e-05, gnorm=2.421, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=15770
2023-03-15 18:22:36 - progress_bar.py[line:272] - INFO: epoch 024:    120 / 2004 loss=0.176, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=353, nsentences=8, sample_size=353, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1086.6, ups=3.08, wpb=353, bsz=8, num_updates=45920, lr=5.47188e-05, gnorm=2.528, clip=0, loss_scale=1024, train_wall=3, gb_free=14.2, wall=15774
2023-03-15 18:22:39 - progress_bar.py[line:272] - INFO: epoch 024:    130 / 2004 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=315.3, nsentences=8, sample_size=315.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1012.8, ups=3.21, wpb=315.3, bsz=8, num_updates=45930, lr=5.47088e-05, gnorm=2.274, clip=0, loss_scale=1024, train_wall=3, gb_free=15.9, wall=15777
2023-03-15 18:22:42 - progress_bar.py[line:272] - INFO: epoch 024:    140 / 2004 loss=0.189, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=349.5, nsentences=8, sample_size=349.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1081.1, ups=3.09, wpb=349.5, bsz=8, num_updates=45940, lr=5.46987e-05, gnorm=2.515, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=15780
2023-03-15 18:22:46 - progress_bar.py[line:272] - INFO: epoch 024:    150 / 2004 loss=0.176, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=322.7, nsentences=8, sample_size=322.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1031.3, ups=3.2, wpb=322.7, bsz=8, num_updates=45950, lr=5.46886e-05, gnorm=2.601, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=15783
2023-03-15 18:22:49 - progress_bar.py[line:272] - INFO: epoch 024:    160 / 2004 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=368.3, nsentences=8, sample_size=368.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1156.6, ups=3.14, wpb=368.3, bsz=8, num_updates=45960, lr=5.46785e-05, gnorm=2.361, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=15786
2023-03-15 18:22:52 - progress_bar.py[line:272] - INFO: epoch 024:    170 / 2004 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=335.2, nsentences=8, sample_size=335.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1050.2, ups=3.13, wpb=335.2, bsz=8, num_updates=45970, lr=5.46684e-05, gnorm=2.267, clip=0, loss_scale=1024, train_wall=3, gb_free=14.2, wall=15790
2023-03-15 18:22:55 - progress_bar.py[line:272] - INFO: epoch 024:    180 / 2004 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=332.1, nsentences=8, sample_size=332.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1052, ups=3.17, wpb=332.1, bsz=8, num_updates=45980, lr=5.46584e-05, gnorm=2.368, clip=0, loss_scale=1024, train_wall=3, gb_free=14.2, wall=15793
2023-03-15 18:22:58 - progress_bar.py[line:272] - INFO: epoch 024:    190 / 2004 loss=0.182, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=322.8, nsentences=8, sample_size=322.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1020, ups=3.16, wpb=322.8, bsz=8, num_updates=45990, lr=5.46483e-05, gnorm=2.43, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=15796
2023-03-15 18:23:02 - progress_bar.py[line:272] - INFO: epoch 024:    200 / 2004 loss=0.194, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=329.6, nsentences=8, sample_size=329.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=973, ups=2.95, wpb=329.6, bsz=8, num_updates=46000, lr=5.46382e-05, gnorm=2.856, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=15799
2023-03-15 18:23:05 - progress_bar.py[line:272] - INFO: epoch 024:    210 / 2004 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=335.4, nsentences=8, sample_size=335.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=973.1, ups=2.9, wpb=335.4, bsz=8, num_updates=46010, lr=5.46281e-05, gnorm=2.167, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=15803
2023-03-15 18:23:09 - progress_bar.py[line:272] - INFO: epoch 024:    220 / 2004 loss=0.175, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=338.8, nsentences=8, sample_size=338.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=981.9, ups=2.9, wpb=338.8, bsz=8, num_updates=46020, lr=5.4618e-05, gnorm=2.498, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=15806
2023-03-15 18:23:12 - progress_bar.py[line:272] - INFO: epoch 024:    230 / 2004 loss=0.176, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=320.9, nsentences=8, sample_size=320.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=927.9, ups=2.89, wpb=320.9, bsz=8, num_updates=46030, lr=5.4608e-05, gnorm=2.414, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=15810
2023-03-15 18:23:16 - progress_bar.py[line:272] - INFO: epoch 024:    240 / 2004 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=403.2, nsentences=8, sample_size=403.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1133.8, ups=2.81, wpb=403.2, bsz=8, num_updates=46040, lr=5.45979e-05, gnorm=2.121, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=15813
2023-03-15 18:23:19 - progress_bar.py[line:272] - INFO: epoch 024:    250 / 2004 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=346.3, nsentences=8, sample_size=346.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1012.5, ups=2.92, wpb=346.3, bsz=8, num_updates=46050, lr=5.45878e-05, gnorm=2.255, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=15817
2023-03-15 18:23:22 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 18:23:23 - progress_bar.py[line:272] - INFO: epoch 024:    261 / 2004 loss=0.182, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=333.6, nsentences=8, sample_size=333.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=883, ups=2.65, wpb=333.6, bsz=8, num_updates=46060, lr=5.45777e-05, gnorm=2.415, clip=0, loss_scale=1024, train_wall=4, gb_free=14.8, wall=15820
2023-03-15 18:23:26 - progress_bar.py[line:272] - INFO: epoch 024:    271 / 2004 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=342, nsentences=8, sample_size=342, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=978.5, ups=2.86, wpb=342, bsz=8, num_updates=46070, lr=5.45676e-05, gnorm=2.283, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=15824
2023-03-15 18:23:30 - progress_bar.py[line:272] - INFO: epoch 024:    281 / 2004 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=328.4, nsentences=8, sample_size=328.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=949.2, ups=2.89, wpb=328.4, bsz=8, num_updates=46080, lr=5.45576e-05, gnorm=2.266, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=15827
2023-03-15 18:23:33 - progress_bar.py[line:272] - INFO: epoch 024:    291 / 2004 loss=0.177, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=396.7, nsentences=8, sample_size=396.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1125.8, ups=2.84, wpb=396.7, bsz=8, num_updates=46090, lr=5.45475e-05, gnorm=2.341, clip=0, loss_scale=1024, train_wall=3, gb_free=14, wall=15831
2023-03-15 18:23:37 - progress_bar.py[line:272] - INFO: epoch 024:    301 / 2004 loss=0.171, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=346.9, nsentences=8, sample_size=346.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1005.8, ups=2.9, wpb=346.9, bsz=8, num_updates=46100, lr=5.45374e-05, gnorm=2.385, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=15834
2023-03-15 18:23:40 - progress_bar.py[line:272] - INFO: epoch 024:    311 / 2004 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=352.9, nsentences=8, sample_size=352.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1027.5, ups=2.91, wpb=352.9, bsz=8, num_updates=46110, lr=5.45273e-05, gnorm=2.362, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=15838
2023-03-15 18:23:44 - progress_bar.py[line:272] - INFO: epoch 024:    321 / 2004 loss=0.186, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=330, nsentences=8, sample_size=330, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=946.1, ups=2.87, wpb=330, bsz=8, num_updates=46120, lr=5.45172e-05, gnorm=2.628, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=15841
2023-03-15 18:23:47 - progress_bar.py[line:272] - INFO: epoch 024:    331 / 2004 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=337.6, nsentences=8, sample_size=337.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=973.8, ups=2.88, wpb=337.6, bsz=8, num_updates=46130, lr=5.45071e-05, gnorm=2.069, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=15845
2023-03-15 18:23:51 - progress_bar.py[line:272] - INFO: epoch 024:    341 / 2004 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=349.5, nsentences=8, sample_size=349.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1021.4, ups=2.92, wpb=349.5, bsz=8, num_updates=46140, lr=5.44971e-05, gnorm=2.216, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=15848
2023-03-15 18:23:54 - progress_bar.py[line:272] - INFO: epoch 024:    351 / 2004 loss=0.177, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=359.7, nsentences=8, sample_size=359.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1085.7, ups=3.02, wpb=359.7, bsz=8, num_updates=46150, lr=5.4487e-05, gnorm=2.44, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=15851
2023-03-15 18:23:57 - progress_bar.py[line:272] - INFO: epoch 024:    361 / 2004 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=355.6, nsentences=8, sample_size=355.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1130.6, ups=3.18, wpb=355.6, bsz=8, num_updates=46160, lr=5.44769e-05, gnorm=2.326, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=15855
2023-03-15 18:24:00 - progress_bar.py[line:272] - INFO: epoch 024:    371 / 2004 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=330.2, nsentences=8, sample_size=330.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1050.9, ups=3.18, wpb=330.2, bsz=8, num_updates=46170, lr=5.44668e-05, gnorm=2.237, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=15858
2023-03-15 18:24:03 - progress_bar.py[line:272] - INFO: epoch 024:    381 / 2004 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=314.1, nsentences=8, sample_size=314.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=997.5, ups=3.18, wpb=314.1, bsz=8, num_updates=46180, lr=5.44567e-05, gnorm=2.202, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=15861
2023-03-15 18:24:07 - progress_bar.py[line:272] - INFO: epoch 024:    391 / 2004 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=351.6, nsentences=8, sample_size=351.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1040.5, ups=2.96, wpb=351.6, bsz=8, num_updates=46190, lr=5.44467e-05, gnorm=2.219, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=15864
2023-03-15 18:24:10 - progress_bar.py[line:272] - INFO: epoch 024:    401 / 2004 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=371, nsentences=8, sample_size=371, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1070.8, ups=2.89, wpb=371, bsz=8, num_updates=46200, lr=5.44366e-05, gnorm=2.148, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=15868
2023-03-15 18:24:14 - progress_bar.py[line:272] - INFO: epoch 024:    411 / 2004 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=349.1, nsentences=8, sample_size=349.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1028, ups=2.94, wpb=349.1, bsz=8, num_updates=46210, lr=5.44265e-05, gnorm=2.269, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=15871
2023-03-15 18:24:17 - progress_bar.py[line:272] - INFO: epoch 024:    421 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=344.5, nsentences=8, sample_size=344.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1058.9, ups=3.07, wpb=344.5, bsz=8, num_updates=46220, lr=5.44164e-05, gnorm=1.953, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=15874
2023-03-15 18:24:20 - progress_bar.py[line:272] - INFO: epoch 024:    431 / 2004 loss=0.177, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=329.9, nsentences=8, sample_size=329.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1056.2, ups=3.2, wpb=329.9, bsz=8, num_updates=46230, lr=5.44063e-05, gnorm=2.415, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=15878
2023-03-15 18:24:23 - progress_bar.py[line:272] - INFO: epoch 024:    441 / 2004 loss=0.18, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=370.9, nsentences=8, sample_size=370.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1147, ups=3.09, wpb=370.9, bsz=8, num_updates=46240, lr=5.43963e-05, gnorm=2.693, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=15881
2023-03-15 18:24:26 - progress_bar.py[line:272] - INFO: epoch 024:    451 / 2004 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=369.6, nsentences=8, sample_size=369.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1130.4, ups=3.06, wpb=369.6, bsz=8, num_updates=46250, lr=5.43862e-05, gnorm=2.35, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=15884
2023-03-15 18:24:30 - progress_bar.py[line:272] - INFO: epoch 024:    461 / 2004 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=379.4, nsentences=8, sample_size=379.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1185.6, ups=3.13, wpb=379.4, bsz=8, num_updates=46260, lr=5.43761e-05, gnorm=2.248, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=15887
2023-03-15 18:24:33 - progress_bar.py[line:272] - INFO: epoch 024:    471 / 2004 loss=0.195, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=356.9, nsentences=8, sample_size=356.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1137, ups=3.19, wpb=356.9, bsz=8, num_updates=46270, lr=5.4366e-05, gnorm=2.729, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=15890
2023-03-15 18:24:36 - progress_bar.py[line:272] - INFO: epoch 024:    481 / 2004 loss=0.191, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=358.2, nsentences=8, sample_size=358.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1137.8, ups=3.18, wpb=358.2, bsz=8, num_updates=46280, lr=5.43559e-05, gnorm=2.642, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=15894
2023-03-15 18:24:39 - progress_bar.py[line:272] - INFO: epoch 024:    491 / 2004 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=372.5, nsentences=8, sample_size=372.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1174.2, ups=3.15, wpb=372.5, bsz=8, num_updates=46290, lr=5.43459e-05, gnorm=2.234, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=15897
2023-03-15 18:24:42 - progress_bar.py[line:272] - INFO: epoch 024:    501 / 2004 loss=0.18, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=364.5, nsentences=8, sample_size=364.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1145.7, ups=3.14, wpb=364.5, bsz=8, num_updates=46300, lr=5.43358e-05, gnorm=2.373, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=15900
2023-03-15 18:24:46 - progress_bar.py[line:272] - INFO: epoch 024:    511 / 2004 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=351.3, nsentences=8, sample_size=351.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1058.2, ups=3.01, wpb=351.3, bsz=8, num_updates=46310, lr=5.43257e-05, gnorm=2.248, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=15903
2023-03-15 18:24:48 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 18:24:49 - progress_bar.py[line:272] - INFO: epoch 024:    522 / 2004 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=371.3, nsentences=8, sample_size=371.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1002.1, ups=2.7, wpb=371.3, bsz=8, num_updates=46320, lr=5.43156e-05, gnorm=2.206, clip=0, loss_scale=2048, train_wall=4, gb_free=14.7, wall=15907
2023-03-15 18:24:53 - progress_bar.py[line:272] - INFO: epoch 024:    532 / 2004 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=385.3, nsentences=8, sample_size=385.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1129, ups=2.93, wpb=385.3, bsz=8, num_updates=46330, lr=5.43055e-05, gnorm=2.211, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=15910
2023-03-15 18:24:56 - progress_bar.py[line:272] - INFO: epoch 024:    542 / 2004 loss=0.176, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=374.1, nsentences=8, sample_size=374.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1092.7, ups=2.92, wpb=374.1, bsz=8, num_updates=46340, lr=5.42954e-05, gnorm=2.423, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=15914
2023-03-15 18:25:00 - progress_bar.py[line:272] - INFO: epoch 024:    552 / 2004 loss=0.184, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=362.2, nsentences=8, sample_size=362.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1046.1, ups=2.89, wpb=362.2, bsz=8, num_updates=46350, lr=5.42854e-05, gnorm=2.415, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=15917
2023-03-15 18:25:03 - progress_bar.py[line:272] - INFO: epoch 024:    562 / 2004 loss=0.188, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=370.4, nsentences=8, sample_size=370.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1068.1, ups=2.88, wpb=370.4, bsz=8, num_updates=46360, lr=5.42753e-05, gnorm=2.789, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=15921
2023-03-15 18:25:07 - progress_bar.py[line:272] - INFO: epoch 024:    572 / 2004 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=367.1, nsentences=8, sample_size=367.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1064.6, ups=2.9, wpb=367.1, bsz=8, num_updates=46370, lr=5.42652e-05, gnorm=2.304, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=15924
2023-03-15 18:25:10 - progress_bar.py[line:272] - INFO: epoch 024:    582 / 2004 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=355.9, nsentences=8, sample_size=355.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1003.4, ups=2.82, wpb=355.9, bsz=8, num_updates=46380, lr=5.42551e-05, gnorm=2.077, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=15928
2023-03-15 18:25:14 - progress_bar.py[line:272] - INFO: epoch 024:    592 / 2004 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=338.3, nsentences=8, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=977.7, ups=2.89, wpb=338.3, bsz=8, num_updates=46390, lr=5.4245e-05, gnorm=2.075, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=15931
2023-03-15 18:25:17 - progress_bar.py[line:272] - INFO: epoch 024:    602 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=358.5, nsentences=8, sample_size=358.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1009.9, ups=2.82, wpb=358.5, bsz=8, num_updates=46400, lr=5.4235e-05, gnorm=2.204, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=15935
2023-03-15 18:25:20 - progress_bar.py[line:272] - INFO: epoch 024:    612 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=356.4, nsentences=8, sample_size=356.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1043.2, ups=2.93, wpb=356.4, bsz=8, num_updates=46410, lr=5.42249e-05, gnorm=2.157, clip=0, loss_scale=2048, train_wall=3, gb_free=13.9, wall=15938
2023-03-15 18:25:24 - progress_bar.py[line:272] - INFO: epoch 024:    622 / 2004 loss=0.186, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=357.3, nsentences=8, sample_size=357.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1019.7, ups=2.85, wpb=357.3, bsz=8, num_updates=46420, lr=5.42148e-05, gnorm=2.802, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=15942
2023-03-15 18:25:27 - progress_bar.py[line:272] - INFO: epoch 024:    632 / 2004 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=342.4, nsentences=8, sample_size=342.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=999.2, ups=2.92, wpb=342.4, bsz=8, num_updates=46430, lr=5.42047e-05, gnorm=2.19, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=15945
2023-03-15 18:25:31 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 18:25:31 - progress_bar.py[line:272] - INFO: epoch 024:    643 / 2004 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=338.6, nsentences=8, sample_size=338.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=895.9, ups=2.65, wpb=338.6, bsz=8, num_updates=46440, lr=5.41946e-05, gnorm=2.342, clip=0, loss_scale=1024, train_wall=4, gb_free=15, wall=15949
2023-03-15 18:25:34 - progress_bar.py[line:272] - INFO: epoch 024:    653 / 2004 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=321.6, nsentences=8, sample_size=321.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=977.8, ups=3.04, wpb=321.6, bsz=8, num_updates=46450, lr=5.41846e-05, gnorm=2.143, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=15952
2023-03-15 18:25:38 - progress_bar.py[line:272] - INFO: epoch 024:    663 / 2004 loss=0.182, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=321.2, nsentences=8, sample_size=321.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=912.8, ups=2.84, wpb=321.2, bsz=8, num_updates=46460, lr=5.41745e-05, gnorm=2.507, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=15956
2023-03-15 18:25:41 - progress_bar.py[line:272] - INFO: epoch 024:    673 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=341.2, nsentences=8, sample_size=341.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=978.8, ups=2.87, wpb=341.2, bsz=8, num_updates=46470, lr=5.41644e-05, gnorm=2.016, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=15959
2023-03-15 18:25:45 - progress_bar.py[line:272] - INFO: epoch 024:    683 / 2004 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=345.5, nsentences=8, sample_size=345.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=996.3, ups=2.88, wpb=345.5, bsz=8, num_updates=46480, lr=5.41543e-05, gnorm=2.325, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=15963
2023-03-15 18:25:48 - progress_bar.py[line:272] - INFO: epoch 024:    693 / 2004 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=350.8, nsentences=8, sample_size=350.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1023.8, ups=2.92, wpb=350.8, bsz=8, num_updates=46490, lr=5.41442e-05, gnorm=2.379, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=15966
2023-03-15 18:25:52 - progress_bar.py[line:272] - INFO: epoch 024:    703 / 2004 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=324.2, nsentences=8, sample_size=324.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=943.4, ups=2.91, wpb=324.2, bsz=8, num_updates=46500, lr=5.41342e-05, gnorm=2.069, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=15969
2023-03-15 18:25:55 - progress_bar.py[line:272] - INFO: epoch 024:    713 / 2004 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=335.3, nsentences=8, sample_size=335.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=964.6, ups=2.88, wpb=335.3, bsz=8, num_updates=46510, lr=5.41241e-05, gnorm=2.211, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=15973
2023-03-15 18:25:59 - progress_bar.py[line:272] - INFO: epoch 024:    723 / 2004 loss=0.176, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=357.8, nsentences=8, sample_size=357.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1018, ups=2.85, wpb=357.8, bsz=8, num_updates=46520, lr=5.4114e-05, gnorm=2.486, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=15976
2023-03-15 18:26:02 - progress_bar.py[line:272] - INFO: epoch 024:    733 / 2004 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=352.7, nsentences=8, sample_size=352.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1029.9, ups=2.92, wpb=352.7, bsz=8, num_updates=46530, lr=5.41039e-05, gnorm=2.259, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=15980
2023-03-15 18:26:06 - progress_bar.py[line:272] - INFO: epoch 024:    743 / 2004 loss=0.194, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=348.7, nsentences=8, sample_size=348.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1038.4, ups=2.98, wpb=348.7, bsz=8, num_updates=46540, lr=5.40938e-05, gnorm=2.694, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=15983
2023-03-15 18:26:09 - progress_bar.py[line:272] - INFO: epoch 024:    753 / 2004 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=338.2, nsentences=8, sample_size=338.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=980.7, ups=2.9, wpb=338.2, bsz=8, num_updates=46550, lr=5.40838e-05, gnorm=2.394, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=15987
2023-03-15 18:26:13 - progress_bar.py[line:272] - INFO: epoch 024:    763 / 2004 loss=0.18, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=353.4, nsentences=8, sample_size=353.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1011.9, ups=2.86, wpb=353.4, bsz=8, num_updates=46560, lr=5.40737e-05, gnorm=2.651, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=15990
2023-03-15 18:26:16 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 18:26:16 - progress_bar.py[line:272] - INFO: epoch 024:    774 / 2004 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=386.8, nsentences=8, sample_size=386.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1019.9, ups=2.64, wpb=386.8, bsz=8, num_updates=46570, lr=5.40636e-05, gnorm=2.418, clip=0, loss_scale=1024, train_wall=4, gb_free=15.2, wall=15994
2023-03-15 18:26:20 - progress_bar.py[line:272] - INFO: epoch 024:    784 / 2004 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=335.1, nsentences=8, sample_size=335.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1014.3, ups=3.03, wpb=335.1, bsz=8, num_updates=46580, lr=5.40535e-05, gnorm=2.234, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=15997
2023-03-15 18:26:23 - progress_bar.py[line:272] - INFO: epoch 024:    794 / 2004 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=334.2, nsentences=8, sample_size=334.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1061, ups=3.17, wpb=334.2, bsz=8, num_updates=46590, lr=5.40434e-05, gnorm=2.098, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=16000
2023-03-15 18:26:26 - progress_bar.py[line:272] - INFO: epoch 024:    804 / 2004 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=320.2, nsentences=8, sample_size=320.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=978.6, ups=3.06, wpb=320.2, bsz=8, num_updates=46600, lr=5.40333e-05, gnorm=2.347, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=16004
2023-03-15 18:26:29 - progress_bar.py[line:272] - INFO: epoch 024:    814 / 2004 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=343.8, nsentences=8, sample_size=343.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1007.9, ups=2.93, wpb=343.8, bsz=8, num_updates=46610, lr=5.40233e-05, gnorm=2.423, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=16007
2023-03-15 18:26:33 - progress_bar.py[line:272] - INFO: epoch 024:    824 / 2004 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=355.7, nsentences=8, sample_size=355.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1047.7, ups=2.95, wpb=355.7, bsz=8, num_updates=46620, lr=5.40132e-05, gnorm=2.349, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=16010
2023-03-15 18:26:36 - progress_bar.py[line:272] - INFO: epoch 024:    834 / 2004 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=341.1, nsentences=8, sample_size=341.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1001.1, ups=2.94, wpb=341.1, bsz=8, num_updates=46630, lr=5.40031e-05, gnorm=2.212, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=16014
2023-03-15 18:26:40 - progress_bar.py[line:272] - INFO: epoch 024:    844 / 2004 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=358.9, nsentences=8, sample_size=358.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1045, ups=2.91, wpb=358.9, bsz=8, num_updates=46640, lr=5.3993e-05, gnorm=2.211, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=16017
2023-03-15 18:26:43 - progress_bar.py[line:272] - INFO: epoch 024:    854 / 2004 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=359.8, nsentences=8, sample_size=359.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1044, ups=2.9, wpb=359.8, bsz=8, num_updates=46650, lr=5.39829e-05, gnorm=2.336, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=16021
2023-03-15 18:26:47 - progress_bar.py[line:272] - INFO: epoch 024:    864 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=350.1, nsentences=8, sample_size=350.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1006.2, ups=2.87, wpb=350.1, bsz=8, num_updates=46660, lr=5.39729e-05, gnorm=2.086, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=16024
2023-03-15 18:26:50 - progress_bar.py[line:272] - INFO: epoch 024:    874 / 2004 loss=0.184, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=355.6, nsentences=8, sample_size=355.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1018.2, ups=2.86, wpb=355.6, bsz=8, num_updates=46670, lr=5.39628e-05, gnorm=2.715, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=16028
2023-03-15 18:26:54 - progress_bar.py[line:272] - INFO: epoch 024:    884 / 2004 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=316.2, nsentences=8, sample_size=316.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=918.5, ups=2.9, wpb=316.2, bsz=8, num_updates=46680, lr=5.39527e-05, gnorm=2.145, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=16031
2023-03-15 18:26:57 - progress_bar.py[line:272] - INFO: epoch 024:    894 / 2004 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=312, nsentences=8, sample_size=312, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=909.3, ups=2.91, wpb=312, bsz=8, num_updates=46690, lr=5.39426e-05, gnorm=2.233, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=16035
2023-03-15 18:27:01 - progress_bar.py[line:272] - INFO: epoch 024:    904 / 2004 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=377.7, nsentences=8, sample_size=377.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1068.8, ups=2.83, wpb=377.7, bsz=8, num_updates=46700, lr=5.39325e-05, gnorm=2.223, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=16038
2023-03-15 18:27:04 - progress_bar.py[line:272] - INFO: epoch 024:    914 / 2004 loss=0.175, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=374.9, nsentences=8, sample_size=374.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1069, ups=2.85, wpb=374.9, bsz=8, num_updates=46710, lr=5.39225e-05, gnorm=2.412, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=16042
2023-03-15 18:27:07 - progress_bar.py[line:272] - INFO: epoch 024:    924 / 2004 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=318.5, nsentences=7.8, sample_size=318.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=949.6, ups=2.98, wpb=318.5, bsz=7.8, num_updates=46720, lr=5.39124e-05, gnorm=2.352, clip=0, loss_scale=2048, train_wall=3, gb_free=15.8, wall=16045
2023-03-15 18:27:11 - progress_bar.py[line:272] - INFO: epoch 024:    934 / 2004 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=339.1, nsentences=8, sample_size=339.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1005.1, ups=2.96, wpb=339.1, bsz=8, num_updates=46730, lr=5.39023e-05, gnorm=2.234, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=16048
2023-03-15 18:27:11 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 18:27:15 - progress_bar.py[line:272] - INFO: epoch 024:    945 / 2004 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=364, nsentences=8, sample_size=364, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=973.7, ups=2.68, wpb=364, bsz=8, num_updates=46740, lr=5.38922e-05, gnorm=2.453, clip=0, loss_scale=1024, train_wall=4, gb_free=14.9, wall=16052
2023-03-15 18:27:18 - progress_bar.py[line:272] - INFO: epoch 024:    955 / 2004 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=342, nsentences=8, sample_size=342, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=994.2, ups=2.91, wpb=342, bsz=8, num_updates=46750, lr=5.38821e-05, gnorm=2.238, clip=0, loss_scale=1024, train_wall=3, gb_free=13.8, wall=16056
2023-03-15 18:27:21 - progress_bar.py[line:272] - INFO: epoch 024:    965 / 2004 loss=0.181, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=374, nsentences=8, sample_size=374, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1086.6, ups=2.91, wpb=374, bsz=8, num_updates=46760, lr=5.38721e-05, gnorm=2.544, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=16059
2023-03-15 18:27:25 - progress_bar.py[line:272] - INFO: epoch 024:    975 / 2004 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=324.9, nsentences=8, sample_size=324.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=964.1, ups=2.97, wpb=324.9, bsz=8, num_updates=46770, lr=5.3862e-05, gnorm=2.246, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=16062
2023-03-15 18:27:28 - progress_bar.py[line:272] - INFO: epoch 024:    985 / 2004 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=323.1, nsentences=8, sample_size=323.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=936.6, ups=2.9, wpb=323.1, bsz=8, num_updates=46780, lr=5.38519e-05, gnorm=2.495, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=16066
2023-03-15 18:27:32 - progress_bar.py[line:272] - INFO: epoch 024:    995 / 2004 loss=0.178, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=389.9, nsentences=8, sample_size=389.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1126.4, ups=2.89, wpb=389.9, bsz=8, num_updates=46790, lr=5.38418e-05, gnorm=2.56, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=16069
2023-03-15 18:27:35 - progress_bar.py[line:272] - INFO: epoch 024:   1005 / 2004 loss=0.178, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=312.5, nsentences=8, sample_size=312.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=936.4, ups=3, wpb=312.5, bsz=8, num_updates=46800, lr=5.38317e-05, gnorm=2.464, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=16073
2023-03-15 18:27:38 - progress_bar.py[line:272] - INFO: epoch 024:   1015 / 2004 loss=0.184, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=343.4, nsentences=8, sample_size=343.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1009.5, ups=2.94, wpb=343.4, bsz=8, num_updates=46810, lr=5.38216e-05, gnorm=2.665, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=16076
2023-03-15 18:27:42 - progress_bar.py[line:272] - INFO: epoch 024:   1025 / 2004 loss=0.177, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=325, nsentences=8, sample_size=325, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=918.4, ups=2.83, wpb=325, bsz=8, num_updates=46820, lr=5.38116e-05, gnorm=2.451, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=16080
2023-03-15 18:27:45 - progress_bar.py[line:272] - INFO: epoch 024:   1035 / 2004 loss=0.202, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=316.9, nsentences=8, sample_size=316.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=944.1, ups=2.98, wpb=316.9, bsz=8, num_updates=46830, lr=5.38015e-05, gnorm=2.708, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=16083
2023-03-15 18:27:49 - progress_bar.py[line:272] - INFO: epoch 024:   1045 / 2004 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=360.4, nsentences=8, sample_size=360.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1015.9, ups=2.82, wpb=360.4, bsz=8, num_updates=46840, lr=5.37914e-05, gnorm=2.377, clip=0, loss_scale=1024, train_wall=3, gb_free=14.1, wall=16086
2023-03-15 18:27:52 - progress_bar.py[line:272] - INFO: epoch 024:   1055 / 2004 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=372.2, nsentences=8, sample_size=372.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1079.2, ups=2.9, wpb=372.2, bsz=8, num_updates=46850, lr=5.37813e-05, gnorm=2.252, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=16090
2023-03-15 18:27:56 - progress_bar.py[line:272] - INFO: epoch 024:   1065 / 2004 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=329.5, nsentences=8, sample_size=329.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=948.2, ups=2.88, wpb=329.5, bsz=8, num_updates=46860, lr=5.37712e-05, gnorm=2.433, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=16093
2023-03-15 18:27:59 - progress_bar.py[line:272] - INFO: epoch 024:   1075 / 2004 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=361.8, nsentences=8, sample_size=361.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1045.9, ups=2.89, wpb=361.8, bsz=8, num_updates=46870, lr=5.37612e-05, gnorm=2.43, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=16097
2023-03-15 18:28:03 - progress_bar.py[line:272] - INFO: epoch 024:   1085 / 2004 loss=0.18, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=369, nsentences=8, sample_size=369, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1048.9, ups=2.84, wpb=369, bsz=8, num_updates=46880, lr=5.37511e-05, gnorm=2.347, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=16100
2023-03-15 18:28:06 - progress_bar.py[line:272] - INFO: epoch 024:   1095 / 2004 loss=0.178, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=323.9, nsentences=8, sample_size=323.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=978.8, ups=3.02, wpb=323.9, bsz=8, num_updates=46890, lr=5.3741e-05, gnorm=2.27, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=16104
2023-03-15 18:28:10 - progress_bar.py[line:272] - INFO: epoch 024:   1105 / 2004 loss=0.175, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=375, nsentences=8, sample_size=375, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1066.9, ups=2.84, wpb=375, bsz=8, num_updates=46900, lr=5.37309e-05, gnorm=2.484, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=16107
2023-03-15 18:28:13 - progress_bar.py[line:272] - INFO: epoch 024:   1115 / 2004 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=341.2, nsentences=8, sample_size=341.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=979.3, ups=2.87, wpb=341.2, bsz=8, num_updates=46910, lr=5.37208e-05, gnorm=2.271, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=16111
2023-03-15 18:28:17 - progress_bar.py[line:272] - INFO: epoch 024:   1125 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=321, nsentences=8, sample_size=321, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=910.5, ups=2.84, wpb=321, bsz=8, num_updates=46920, lr=5.37108e-05, gnorm=2.058, clip=0, loss_scale=2048, train_wall=3, gb_free=13.8, wall=16114
2023-03-15 18:28:20 - progress_bar.py[line:272] - INFO: epoch 024:   1135 / 2004 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=388.3, nsentences=8, sample_size=388.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1111.7, ups=2.86, wpb=388.3, bsz=8, num_updates=46930, lr=5.37007e-05, gnorm=2.128, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=16118
2023-03-15 18:28:24 - progress_bar.py[line:272] - INFO: epoch 024:   1145 / 2004 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=335.4, nsentences=8, sample_size=335.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=977.2, ups=2.91, wpb=335.4, bsz=8, num_updates=46940, lr=5.36906e-05, gnorm=2.167, clip=0, loss_scale=2048, train_wall=3, gb_free=13.9, wall=16121
2023-03-15 18:28:27 - progress_bar.py[line:272] - INFO: epoch 024:   1155 / 2004 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=395.1, nsentences=8, sample_size=395.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1126.3, ups=2.85, wpb=395.1, bsz=8, num_updates=46950, lr=5.36805e-05, gnorm=2.242, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=16125
2023-03-15 18:28:31 - progress_bar.py[line:272] - INFO: epoch 024:   1165 / 2004 loss=0.186, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=358.4, nsentences=8, sample_size=358.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1024.6, ups=2.86, wpb=358.4, bsz=8, num_updates=46960, lr=5.36704e-05, gnorm=2.548, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=16128
2023-03-15 18:28:34 - progress_bar.py[line:272] - INFO: epoch 024:   1175 / 2004 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=364.5, nsentences=8, sample_size=364.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1051.3, ups=2.88, wpb=364.5, bsz=8, num_updates=46970, lr=5.36604e-05, gnorm=2.181, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=16132
2023-03-15 18:28:37 - progress_bar.py[line:272] - INFO: epoch 024:   1185 / 2004 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=339.9, nsentences=8, sample_size=339.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=988.4, ups=2.91, wpb=339.9, bsz=8, num_updates=46980, lr=5.36503e-05, gnorm=2.204, clip=0, loss_scale=2048, train_wall=3, gb_free=13.6, wall=16135
2023-03-15 18:28:40 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 18:28:41 - progress_bar.py[line:272] - INFO: epoch 024:   1196 / 2004 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=350.4, nsentences=8, sample_size=350.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=911.8, ups=2.6, wpb=350.4, bsz=8, num_updates=46990, lr=5.36402e-05, gnorm=2.239, clip=0, loss_scale=2048, train_wall=4, gb_free=13.5, wall=16139
2023-03-15 18:28:45 - progress_bar.py[line:272] - INFO: epoch 024:   1206 / 2004 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=291.8, nsentences=8, sample_size=291.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=860.4, ups=2.95, wpb=291.8, bsz=8, num_updates=47000, lr=5.36301e-05, gnorm=2.278, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=16142
2023-03-15 18:28:48 - progress_bar.py[line:272] - INFO: epoch 024:   1216 / 2004 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=322.4, nsentences=8, sample_size=322.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=955.9, ups=2.96, wpb=322.4, bsz=8, num_updates=47010, lr=5.362e-05, gnorm=2.118, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=16146
2023-03-15 18:28:52 - progress_bar.py[line:272] - INFO: epoch 024:   1226 / 2004 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=306.6, nsentences=8, sample_size=306.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=882.6, ups=2.88, wpb=306.6, bsz=8, num_updates=47020, lr=5.361e-05, gnorm=2.012, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=16149
2023-03-15 18:28:55 - progress_bar.py[line:272] - INFO: epoch 024:   1236 / 2004 loss=0.175, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=357.7, nsentences=8, sample_size=357.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1015.9, ups=2.84, wpb=357.7, bsz=8, num_updates=47030, lr=5.35999e-05, gnorm=2.146, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=16153
2023-03-15 18:28:59 - progress_bar.py[line:272] - INFO: epoch 024:   1246 / 2004 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=355.5, nsentences=8, sample_size=355.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1027.5, ups=2.89, wpb=355.5, bsz=8, num_updates=47040, lr=5.35898e-05, gnorm=2.14, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=16156
2023-03-15 18:29:02 - progress_bar.py[line:272] - INFO: epoch 024:   1256 / 2004 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=353.5, nsentences=8, sample_size=353.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1003, ups=2.84, wpb=353.5, bsz=8, num_updates=47050, lr=5.35797e-05, gnorm=2.18, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=16160
2023-03-15 18:29:05 - progress_bar.py[line:272] - INFO: epoch 024:   1266 / 2004 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=337.8, nsentences=8, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=996.3, ups=2.95, wpb=337.8, bsz=8, num_updates=47060, lr=5.35696e-05, gnorm=2.393, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=16163
2023-03-15 18:29:09 - progress_bar.py[line:272] - INFO: epoch 024:   1276 / 2004 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=348.6, nsentences=8, sample_size=348.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1020.2, ups=2.93, wpb=348.6, bsz=8, num_updates=47070, lr=5.35595e-05, gnorm=2.383, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=16166
2023-03-15 18:29:12 - progress_bar.py[line:272] - INFO: epoch 024:   1286 / 2004 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=320.2, nsentences=8, sample_size=320.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=926.5, ups=2.89, wpb=320.2, bsz=8, num_updates=47080, lr=5.35495e-05, gnorm=2.014, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=16170
2023-03-15 18:29:17 - progress_bar.py[line:272] - INFO: epoch 024:   1296 / 2004 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=317.6, nsentences=8, sample_size=317.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=724.8, ups=2.28, wpb=317.6, bsz=8, num_updates=47090, lr=5.35394e-05, gnorm=2.411, clip=0, loss_scale=2048, train_wall=4, gb_free=15.1, wall=16174
2023-03-15 18:29:20 - progress_bar.py[line:272] - INFO: epoch 024:   1306 / 2004 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=306.1, nsentences=8, sample_size=306.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=889.6, ups=2.91, wpb=306.1, bsz=8, num_updates=47100, lr=5.35293e-05, gnorm=2.191, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=16178
2023-03-15 18:29:24 - progress_bar.py[line:272] - INFO: epoch 024:   1316 / 2004 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=349.7, nsentences=8, sample_size=349.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=980.1, ups=2.8, wpb=349.7, bsz=8, num_updates=47110, lr=5.35192e-05, gnorm=2.294, clip=0, loss_scale=2048, train_wall=4, gb_free=14.7, wall=16181
2023-03-15 18:29:27 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 18:29:27 - progress_bar.py[line:272] - INFO: epoch 024:   1327 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=305, nsentences=8, sample_size=305, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=809.4, ups=2.65, wpb=305, bsz=8, num_updates=47120, lr=5.35091e-05, gnorm=2.17, clip=0, loss_scale=2048, train_wall=4, gb_free=15.4, wall=16185
2023-03-15 18:29:31 - progress_bar.py[line:272] - INFO: epoch 024:   1337 / 2004 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=371.2, nsentences=8, sample_size=371.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1060.2, ups=2.86, wpb=371.2, bsz=8, num_updates=47130, lr=5.34991e-05, gnorm=2.262, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=16189
2023-03-15 18:29:34 - progress_bar.py[line:272] - INFO: epoch 024:   1347 / 2004 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=298.5, nsentences=8, sample_size=298.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=872.4, ups=2.92, wpb=298.5, bsz=8, num_updates=47140, lr=5.3489e-05, gnorm=2.102, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=16192
2023-03-15 18:29:38 - progress_bar.py[line:272] - INFO: epoch 024:   1357 / 2004 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=321, nsentences=8, sample_size=321, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=927.5, ups=2.89, wpb=321, bsz=8, num_updates=47150, lr=5.34789e-05, gnorm=2.464, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=16195
2023-03-15 18:29:41 - progress_bar.py[line:272] - INFO: epoch 024:   1367 / 2004 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=314.9, nsentences=8, sample_size=314.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=924.2, ups=2.93, wpb=314.9, bsz=8, num_updates=47160, lr=5.34688e-05, gnorm=2.342, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=16199
2023-03-15 18:29:45 - progress_bar.py[line:272] - INFO: epoch 024:   1377 / 2004 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=326, nsentences=8, sample_size=326, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=984.6, ups=3.02, wpb=326, bsz=8, num_updates=47170, lr=5.34587e-05, gnorm=2.291, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=16202
2023-03-15 18:29:48 - progress_bar.py[line:272] - INFO: epoch 024:   1387 / 2004 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=400.3, nsentences=8, sample_size=400.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1232.6, ups=3.08, wpb=400.3, bsz=8, num_updates=47180, lr=5.34487e-05, gnorm=2.169, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=16205
2023-03-15 18:29:51 - progress_bar.py[line:272] - INFO: epoch 024:   1397 / 2004 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=339.6, nsentences=8, sample_size=339.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1037.4, ups=3.05, wpb=339.6, bsz=8, num_updates=47190, lr=5.34386e-05, gnorm=2.12, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=16209
2023-03-15 18:29:55 - progress_bar.py[line:272] - INFO: epoch 024:   1407 / 2004 loss=0.181, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=348.2, nsentences=8, sample_size=348.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1014.8, ups=2.91, wpb=348.2, bsz=8, num_updates=47200, lr=5.34285e-05, gnorm=2.536, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=16212
2023-03-15 18:29:58 - progress_bar.py[line:272] - INFO: epoch 024:   1417 / 2004 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=382.3, nsentences=8, sample_size=382.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1075.2, ups=2.81, wpb=382.3, bsz=8, num_updates=47210, lr=5.34184e-05, gnorm=2.412, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=16216
2023-03-15 18:30:02 - progress_bar.py[line:272] - INFO: epoch 024:   1427 / 2004 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=289.4, nsentences=8, sample_size=289.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=838.9, ups=2.9, wpb=289.4, bsz=8, num_updates=47220, lr=5.34083e-05, gnorm=2.22, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=16219
2023-03-15 18:30:05 - progress_bar.py[line:272] - INFO: epoch 024:   1437 / 2004 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=366.3, nsentences=8, sample_size=366.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1045.2, ups=2.85, wpb=366.3, bsz=8, num_updates=47230, lr=5.33983e-05, gnorm=2.163, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=16223
2023-03-15 18:30:08 - progress_bar.py[line:272] - INFO: epoch 024:   1447 / 2004 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=329.8, nsentences=8, sample_size=329.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=958.2, ups=2.91, wpb=329.8, bsz=8, num_updates=47240, lr=5.33882e-05, gnorm=2.265, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=16226
2023-03-15 18:30:12 - progress_bar.py[line:272] - INFO: epoch 024:   1457 / 2004 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=358.2, nsentences=8, sample_size=358.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1012.2, ups=2.83, wpb=358.2, bsz=8, num_updates=47250, lr=5.33781e-05, gnorm=2.238, clip=0, loss_scale=4096, train_wall=3, gb_free=15.6, wall=16230
2023-03-15 18:30:12 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 18:30:16 - progress_bar.py[line:272] - INFO: epoch 024:   1468 / 2004 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=394.2, nsentences=8, sample_size=394.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1046.7, ups=2.66, wpb=394.2, bsz=8, num_updates=47260, lr=5.3368e-05, gnorm=2.145, clip=0, loss_scale=2048, train_wall=4, gb_free=14.9, wall=16233
2023-03-15 18:30:19 - progress_bar.py[line:272] - INFO: epoch 024:   1478 / 2004 loss=0.178, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=404.3, nsentences=8, sample_size=404.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1180.8, ups=2.92, wpb=404.3, bsz=8, num_updates=47270, lr=5.33579e-05, gnorm=2.64, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=16237
2023-03-15 18:30:23 - progress_bar.py[line:272] - INFO: epoch 024:   1488 / 2004 loss=0.187, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=320.4, nsentences=8, sample_size=320.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=930.2, ups=2.9, wpb=320.4, bsz=8, num_updates=47280, lr=5.33478e-05, gnorm=2.526, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=16240
2023-03-15 18:30:26 - progress_bar.py[line:272] - INFO: epoch 024:   1498 / 2004 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=342.5, nsentences=8, sample_size=342.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=999.3, ups=2.92, wpb=342.5, bsz=8, num_updates=47290, lr=5.33378e-05, gnorm=2.33, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=16244
2023-03-15 18:30:30 - progress_bar.py[line:272] - INFO: epoch 024:   1508 / 2004 loss=0.176, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=329, nsentences=8, sample_size=329, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=959.9, ups=2.92, wpb=329, bsz=8, num_updates=47300, lr=5.33277e-05, gnorm=2.343, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=16247
2023-03-15 18:30:33 - progress_bar.py[line:272] - INFO: epoch 024:   1518 / 2004 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=328.3, nsentences=8, sample_size=328.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=958, ups=2.92, wpb=328.3, bsz=8, num_updates=47310, lr=5.33176e-05, gnorm=2.335, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=16251
2023-03-15 18:30:36 - progress_bar.py[line:272] - INFO: epoch 024:   1528 / 2004 loss=0.176, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=321.6, nsentences=8, sample_size=321.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=956.8, ups=2.98, wpb=321.6, bsz=8, num_updates=47320, lr=5.33075e-05, gnorm=2.426, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=16254
2023-03-15 18:30:40 - progress_bar.py[line:272] - INFO: epoch 024:   1538 / 2004 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=359.2, nsentences=8, sample_size=359.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1052.8, ups=2.93, wpb=359.2, bsz=8, num_updates=47330, lr=5.32974e-05, gnorm=2.247, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=16257
2023-03-15 18:30:43 - progress_bar.py[line:272] - INFO: epoch 024:   1548 / 2004 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=310, nsentences=8, sample_size=310, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=909.4, ups=2.93, wpb=310, bsz=8, num_updates=47340, lr=5.32874e-05, gnorm=2.181, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=16261
2023-03-15 18:30:47 - progress_bar.py[line:272] - INFO: epoch 024:   1558 / 2004 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=354.8, nsentences=8, sample_size=354.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1029.1, ups=2.9, wpb=354.8, bsz=8, num_updates=47350, lr=5.32773e-05, gnorm=1.951, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=16264
2023-03-15 18:30:50 - progress_bar.py[line:272] - INFO: epoch 024:   1568 / 2004 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=328.6, nsentences=8, sample_size=328.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=953, ups=2.9, wpb=328.6, bsz=8, num_updates=47360, lr=5.32672e-05, gnorm=2.505, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=16268
2023-03-15 18:30:53 - progress_bar.py[line:272] - INFO: epoch 024:   1578 / 2004 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=359.8, nsentences=8, sample_size=359.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1064.1, ups=2.96, wpb=359.8, bsz=8, num_updates=47370, lr=5.32571e-05, gnorm=2.315, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=16271
2023-03-15 18:30:57 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 18:30:57 - progress_bar.py[line:272] - INFO: epoch 024:   1589 / 2004 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=313.8, nsentences=8, sample_size=313.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=818.4, ups=2.61, wpb=313.8, bsz=8, num_updates=47380, lr=5.3247e-05, gnorm=2.068, clip=0, loss_scale=2048, train_wall=4, gb_free=14.3, wall=16275
2023-03-15 18:31:01 - progress_bar.py[line:272] - INFO: epoch 024:   1599 / 2004 loss=0.175, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=345.9, nsentences=8, sample_size=345.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=982.2, ups=2.84, wpb=345.9, bsz=8, num_updates=47390, lr=5.3237e-05, gnorm=2.452, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=16278
2023-03-15 18:31:04 - progress_bar.py[line:272] - INFO: epoch 024:   1609 / 2004 loss=0.181, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=336.5, nsentences=8, sample_size=336.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=989.7, ups=2.94, wpb=336.5, bsz=8, num_updates=47400, lr=5.32269e-05, gnorm=2.527, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=16282
2023-03-15 18:31:08 - progress_bar.py[line:272] - INFO: epoch 024:   1619 / 2004 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=342.5, nsentences=8, sample_size=342.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=985.1, ups=2.88, wpb=342.5, bsz=8, num_updates=47410, lr=5.32168e-05, gnorm=2.11, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=16285
2023-03-15 18:31:11 - progress_bar.py[line:272] - INFO: epoch 024:   1629 / 2004 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=362.5, nsentences=8, sample_size=362.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1049.8, ups=2.9, wpb=362.5, bsz=8, num_updates=47420, lr=5.32067e-05, gnorm=2.336, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=16289
2023-03-15 18:31:14 - progress_bar.py[line:272] - INFO: epoch 024:   1639 / 2004 loss=0.171, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=328.8, nsentences=8, sample_size=328.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=983.1, ups=2.99, wpb=328.8, bsz=8, num_updates=47430, lr=5.31966e-05, gnorm=2.296, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=16292
2023-03-15 18:31:18 - progress_bar.py[line:272] - INFO: epoch 024:   1649 / 2004 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=315, nsentences=8, sample_size=315, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=985.8, ups=3.13, wpb=315, bsz=8, num_updates=47440, lr=5.31866e-05, gnorm=2.042, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=16295
2023-03-15 18:31:21 - progress_bar.py[line:272] - INFO: epoch 024:   1659 / 2004 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=348.3, nsentences=8, sample_size=348.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1108.4, ups=3.18, wpb=348.3, bsz=8, num_updates=47450, lr=5.31765e-05, gnorm=2.609, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=16298
2023-03-15 18:31:24 - progress_bar.py[line:272] - INFO: epoch 024:   1669 / 2004 loss=0.193, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=359.3, nsentences=8, sample_size=359.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1024.8, ups=2.85, wpb=359.3, bsz=8, num_updates=47460, lr=5.31664e-05, gnorm=2.627, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=16302
2023-03-15 18:31:27 - progress_bar.py[line:272] - INFO: epoch 024:   1679 / 2004 loss=0.188, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=315.7, nsentences=8, sample_size=315.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=999.4, ups=3.17, wpb=315.7, bsz=8, num_updates=47470, lr=5.31563e-05, gnorm=2.521, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=16305
2023-03-15 18:31:31 - progress_bar.py[line:272] - INFO: epoch 024:   1689 / 2004 loss=0.181, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=349.9, nsentences=8, sample_size=349.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1086.9, ups=3.11, wpb=349.9, bsz=8, num_updates=47480, lr=5.31462e-05, gnorm=2.435, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=16308
2023-03-15 18:31:34 - progress_bar.py[line:272] - INFO: epoch 024:   1699 / 2004 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=331.1, nsentences=8, sample_size=331.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1032.7, ups=3.12, wpb=331.1, bsz=8, num_updates=47490, lr=5.31362e-05, gnorm=2.278, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=16311
2023-03-15 18:31:37 - progress_bar.py[line:272] - INFO: epoch 024:   1709 / 2004 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=346, nsentences=8, sample_size=346, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1099.8, ups=3.18, wpb=346, bsz=8, num_updates=47500, lr=5.31261e-05, gnorm=2.337, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=16315
2023-03-15 18:31:40 - progress_bar.py[line:272] - INFO: epoch 024:   1719 / 2004 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=370.1, nsentences=8, sample_size=370.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1143.3, ups=3.09, wpb=370.1, bsz=8, num_updates=47510, lr=5.3116e-05, gnorm=2.223, clip=0, loss_scale=4096, train_wall=3, gb_free=15.4, wall=16318
2023-03-15 18:31:41 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 18:31:44 - progress_bar.py[line:272] - INFO: epoch 024:   1730 / 2004 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=379.3, nsentences=8, sample_size=379.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1018.2, ups=2.68, wpb=379.3, bsz=8, num_updates=47520, lr=5.31059e-05, gnorm=1.907, clip=0, loss_scale=2048, train_wall=4, gb_free=15, wall=16322
2023-03-15 18:31:47 - progress_bar.py[line:272] - INFO: epoch 024:   1740 / 2004 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=314.8, nsentences=8, sample_size=314.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=913.4, ups=2.9, wpb=314.8, bsz=8, num_updates=47530, lr=5.30958e-05, gnorm=2.546, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=16325
2023-03-15 18:31:48 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 18:31:51 - progress_bar.py[line:272] - INFO: epoch 024:   1751 / 2004 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=354, nsentences=8, sample_size=354, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=954.6, ups=2.7, wpb=354, bsz=8, num_updates=47540, lr=5.30857e-05, gnorm=2.425, clip=0, loss_scale=1024, train_wall=4, gb_free=14.6, wall=16329
2023-03-15 18:31:55 - progress_bar.py[line:272] - INFO: epoch 024:   1761 / 2004 loss=0.185, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=324.6, nsentences=8, sample_size=324.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=931.5, ups=2.87, wpb=324.6, bsz=8, num_updates=47550, lr=5.30757e-05, gnorm=2.622, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=16332
2023-03-15 18:31:58 - progress_bar.py[line:272] - INFO: epoch 024:   1771 / 2004 loss=0.182, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=332.3, nsentences=8, sample_size=332.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=968.2, ups=2.91, wpb=332.3, bsz=8, num_updates=47560, lr=5.30656e-05, gnorm=2.457, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=16336
2023-03-15 18:32:01 - progress_bar.py[line:272] - INFO: epoch 024:   1781 / 2004 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=345.2, nsentences=8, sample_size=345.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1007.2, ups=2.92, wpb=345.2, bsz=8, num_updates=47570, lr=5.30555e-05, gnorm=2.071, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=16339
2023-03-15 18:32:05 - progress_bar.py[line:272] - INFO: epoch 024:   1791 / 2004 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=285.3, nsentences=8, sample_size=285.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=846.7, ups=2.97, wpb=285.3, bsz=8, num_updates=47580, lr=5.30454e-05, gnorm=2.256, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=16342
2023-03-15 18:32:08 - progress_bar.py[line:272] - INFO: epoch 024:   1801 / 2004 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=373.8, nsentences=8, sample_size=373.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1102.1, ups=2.95, wpb=373.8, bsz=8, num_updates=47590, lr=5.30353e-05, gnorm=2.145, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=16346
2023-03-15 18:32:12 - progress_bar.py[line:272] - INFO: epoch 024:   1811 / 2004 loss=0.171, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=339.5, nsentences=8, sample_size=339.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=993.1, ups=2.93, wpb=339.5, bsz=8, num_updates=47600, lr=5.30253e-05, gnorm=2.362, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=16349
2023-03-15 18:32:15 - progress_bar.py[line:272] - INFO: epoch 024:   1821 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=356.6, nsentences=8, sample_size=356.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1035.1, ups=2.9, wpb=356.6, bsz=8, num_updates=47610, lr=5.30152e-05, gnorm=2.193, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=16353
2023-03-15 18:32:19 - progress_bar.py[line:272] - INFO: epoch 024:   1831 / 2004 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=357, nsentences=8, sample_size=357, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1006.2, ups=2.82, wpb=357, bsz=8, num_updates=47620, lr=5.30051e-05, gnorm=2.243, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=16356
2023-03-15 18:32:22 - progress_bar.py[line:272] - INFO: epoch 024:   1841 / 2004 loss=0.178, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=331.9, nsentences=8, sample_size=331.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=965, ups=2.91, wpb=331.9, bsz=8, num_updates=47630, lr=5.2995e-05, gnorm=2.213, clip=0, loss_scale=1024, train_wall=3, gb_free=15.7, wall=16360
2023-03-15 18:32:26 - progress_bar.py[line:272] - INFO: epoch 024:   1851 / 2004 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=339.1, nsentences=8, sample_size=339.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=977.4, ups=2.88, wpb=339.1, bsz=8, num_updates=47640, lr=5.29849e-05, gnorm=2.003, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=16363
2023-03-15 18:32:29 - progress_bar.py[line:272] - INFO: epoch 024:   1861 / 2004 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=338, nsentences=8, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=970.5, ups=2.87, wpb=338, bsz=8, num_updates=47650, lr=5.29749e-05, gnorm=2.266, clip=0, loss_scale=1024, train_wall=3, gb_free=14.2, wall=16367
2023-03-15 18:32:33 - progress_bar.py[line:272] - INFO: epoch 024:   1871 / 2004 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=331.6, nsentences=8, sample_size=331.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=951.1, ups=2.87, wpb=331.6, bsz=8, num_updates=47660, lr=5.29648e-05, gnorm=2.356, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=16370
2023-03-15 18:32:36 - progress_bar.py[line:272] - INFO: epoch 024:   1881 / 2004 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=329.2, nsentences=8, sample_size=329.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=956.4, ups=2.91, wpb=329.2, bsz=8, num_updates=47670, lr=5.29547e-05, gnorm=2.405, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=16374
2023-03-15 18:32:39 - progress_bar.py[line:272] - INFO: epoch 024:   1891 / 2004 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=337.8, nsentences=8, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1000, ups=2.96, wpb=337.8, bsz=8, num_updates=47680, lr=5.29446e-05, gnorm=2.026, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=16377
2023-03-15 18:32:43 - progress_bar.py[line:272] - INFO: epoch 024:   1901 / 2004 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=346.1, nsentences=8, sample_size=346.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=986.7, ups=2.85, wpb=346.1, bsz=8, num_updates=47690, lr=5.29345e-05, gnorm=2.07, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=16380
2023-03-15 18:32:46 - progress_bar.py[line:272] - INFO: epoch 024:   1911 / 2004 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=334.7, nsentences=8, sample_size=334.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=971.7, ups=2.9, wpb=334.7, bsz=8, num_updates=47700, lr=5.29245e-05, gnorm=2.404, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=16384
2023-03-15 18:32:50 - progress_bar.py[line:272] - INFO: epoch 024:   1921 / 2004 loss=0.177, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=323.1, nsentences=8, sample_size=323.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=951.8, ups=2.95, wpb=323.1, bsz=8, num_updates=47710, lr=5.29144e-05, gnorm=2.164, clip=0, loss_scale=2048, train_wall=3, gb_free=15.9, wall=16387
2023-03-15 18:32:53 - progress_bar.py[line:272] - INFO: epoch 024:   1931 / 2004 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=326.7, nsentences=8, sample_size=326.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=959.7, ups=2.94, wpb=326.7, bsz=8, num_updates=47720, lr=5.29043e-05, gnorm=2.293, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=16391
2023-03-15 18:32:56 - progress_bar.py[line:272] - INFO: epoch 024:   1941 / 2004 loss=0.175, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=341.3, nsentences=8, sample_size=341.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1013.7, ups=2.97, wpb=341.3, bsz=8, num_updates=47730, lr=5.28942e-05, gnorm=2.298, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=16394
2023-03-15 18:33:00 - progress_bar.py[line:272] - INFO: epoch 024:   1951 / 2004 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=340.2, nsentences=8, sample_size=340.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=993.3, ups=2.92, wpb=340.2, bsz=8, num_updates=47740, lr=5.28841e-05, gnorm=2.201, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=16398
2023-03-15 18:33:03 - progress_bar.py[line:272] - INFO: epoch 024:   1961 / 2004 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=363.8, nsentences=8, sample_size=363.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1012.5, ups=2.78, wpb=363.8, bsz=8, num_updates=47750, lr=5.2874e-05, gnorm=2.658, clip=0, loss_scale=2048, train_wall=4, gb_free=15.3, wall=16401
2023-03-15 18:33:07 - progress_bar.py[line:272] - INFO: epoch 024:   1971 / 2004 loss=0.187, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=357.7, nsentences=8, sample_size=357.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1028.4, ups=2.88, wpb=357.7, bsz=8, num_updates=47760, lr=5.2864e-05, gnorm=2.535, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=16405
2023-03-15 18:33:10 - progress_bar.py[line:272] - INFO: epoch 024:   1981 / 2004 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=321.6, nsentences=8, sample_size=321.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=921.6, ups=2.87, wpb=321.6, bsz=8, num_updates=47770, lr=5.28539e-05, gnorm=2.376, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=16408
2023-03-15 18:33:14 - progress_bar.py[line:272] - INFO: epoch 024:   1991 / 2004 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=360.9, nsentences=8, sample_size=360.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1046.2, ups=2.9, wpb=360.9, bsz=8, num_updates=47780, lr=5.28438e-05, gnorm=2.235, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=16412
2023-03-15 18:33:17 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 18:33:18 - progress_bar.py[line:272] - INFO: epoch 024:   2002 / 2004 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=374.4, nsentences=8, sample_size=374.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1034.5, ups=2.76, wpb=374.4, bsz=8, num_updates=47790, lr=5.28337e-05, gnorm=2.255, clip=0, loss_scale=2048, train_wall=4, gb_free=14.4, wall=16415
2023-03-15 18:33:18 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 24 @ 47792 updates
2023-03-15 18:33:18 - trainer.py[line:431] - INFO: Saving checkpoint to ./checkpoints/checkpoint24.pt
2023-03-15 18:33:25 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./checkpoints/checkpoint24.pt
2023-03-15 18:33:28 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./checkpoints/checkpoint24.pt (epoch 24 @ 47792 updates, score None) (writing took 9.505821783095598 seconds)
2023-03-15 18:33:28 - train.py[line:332] - INFO: end of epoch 24 (average epoch stats below)
2023-03-15 18:33:28 - progress_bar.py[line:282] - INFO: epoch 024 | loss 0.169 | loss_v1 0 | loss_v2 0 | nll_loss 0.169 | ntokens 345.29 | nsentences 7.999 | sample_size 345.29 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.12 | wps 992.5 | ups 2.87 | wpb 345.3 | bsz 8 | num_updates 47792 | lr 5.28317e-05 | gnorm 2.325 | clip 0 | loss_scale 2048 | train_wall 670 | gb_free 14.4 | wall 16425
2023-03-15 18:33:28 - trainer.py[line:639] - INFO: loading train data for epoch 25
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 row count 8015 total row count 8015
slice_id 0 seek offset 0
2023-03-15 18:33:29 - trainer.py[line:703] - INFO: begin training epoch 25
2023-03-15 18:33:29 - train.py[line:305] - INFO: Start iterating over samples
2023-03-15 18:33:32 - progress_bar.py[line:272] - INFO: epoch 025:      8 / 2004 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=379.4, nsentences=8, sample_size=379.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=267.2, ups=0.7, wpb=379.4, bsz=8, num_updates=47800, lr=5.28236e-05, gnorm=2.413, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=16429
2023-03-15 18:33:35 - progress_bar.py[line:272] - INFO: epoch 025:     18 / 2004 loss=0.178, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=330.2, nsentences=8, sample_size=330.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=952.1, ups=2.88, wpb=330.2, bsz=8, num_updates=47810, lr=5.28136e-05, gnorm=2.505, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=16433
2023-03-15 18:33:37 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 18:33:39 - progress_bar.py[line:272] - INFO: epoch 025:     29 / 2004 loss=0.171, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=358.3, nsentences=8, sample_size=358.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=955.1, ups=2.67, wpb=358.3, bsz=8, num_updates=47820, lr=5.28035e-05, gnorm=2.447, clip=0, loss_scale=1024, train_wall=4, gb_free=15, wall=16437
2023-03-15 18:33:43 - progress_bar.py[line:272] - INFO: epoch 025:     39 / 2004 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=353.7, nsentences=8, sample_size=353.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=989.4, ups=2.8, wpb=353.7, bsz=8, num_updates=47830, lr=5.27934e-05, gnorm=2.436, clip=0, loss_scale=1024, train_wall=4, gb_free=14.6, wall=16440
2023-03-15 18:33:46 - progress_bar.py[line:272] - INFO: epoch 025:     49 / 2004 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=338.5, nsentences=8, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=965.9, ups=2.85, wpb=338.5, bsz=8, num_updates=47840, lr=5.27833e-05, gnorm=2.412, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=16444
2023-03-15 18:33:50 - progress_bar.py[line:272] - INFO: epoch 025:     59 / 2004 loss=0.175, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=357.9, nsentences=8, sample_size=357.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=971.6, ups=2.71, wpb=357.9, bsz=8, num_updates=47850, lr=5.27732e-05, gnorm=2.458, clip=0, loss_scale=1024, train_wall=4, gb_free=15.5, wall=16447
2023-03-15 18:33:53 - progress_bar.py[line:272] - INFO: epoch 025:     69 / 2004 loss=0.177, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=341, nsentences=8, sample_size=341, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=974.6, ups=2.86, wpb=341, bsz=8, num_updates=47860, lr=5.27632e-05, gnorm=2.543, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=16451
2023-03-15 18:33:57 - progress_bar.py[line:272] - INFO: epoch 025:     79 / 2004 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=322.9, nsentences=8, sample_size=322.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=934.4, ups=2.89, wpb=322.9, bsz=8, num_updates=47870, lr=5.27531e-05, gnorm=1.961, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=16454
2023-03-15 18:33:59 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-03-15 18:34:00 - progress_bar.py[line:272] - INFO: epoch 025:     90 / 2004 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=361.7, nsentences=8, sample_size=361.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=960.8, ups=2.66, wpb=361.7, bsz=8, num_updates=47880, lr=5.2743e-05, gnorm=2.276, clip=0, loss_scale=512, train_wall=4, gb_free=15.1, wall=16458
2023-03-15 18:34:04 - progress_bar.py[line:272] - INFO: epoch 025:    100 / 2004 loss=0.193, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=385.5, nsentences=8, sample_size=385.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1101.7, ups=2.86, wpb=385.5, bsz=8, num_updates=47890, lr=5.27329e-05, gnorm=2.649, clip=0, loss_scale=512, train_wall=3, gb_free=14.9, wall=16462
2023-03-15 18:34:07 - progress_bar.py[line:272] - INFO: epoch 025:    110 / 2004 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=340.3, nsentences=8, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=981.3, ups=2.88, wpb=340.3, bsz=8, num_updates=47900, lr=5.27228e-05, gnorm=2.381, clip=0, loss_scale=512, train_wall=3, gb_free=15, wall=16465
2023-03-15 18:34:11 - progress_bar.py[line:272] - INFO: epoch 025:    120 / 2004 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=353, nsentences=8, sample_size=353, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=999.9, ups=2.83, wpb=353, bsz=8, num_updates=47910, lr=5.27128e-05, gnorm=2.144, clip=0, loss_scale=512, train_wall=3, gb_free=14.4, wall=16469
2023-03-15 18:34:14 - progress_bar.py[line:272] - INFO: epoch 025:    130 / 2004 loss=0.183, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=315.3, nsentences=8, sample_size=315.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=907.5, ups=2.88, wpb=315.3, bsz=8, num_updates=47920, lr=5.27027e-05, gnorm=2.672, clip=0, loss_scale=512, train_wall=3, gb_free=15.8, wall=16472
2023-03-15 18:34:18 - progress_bar.py[line:272] - INFO: epoch 025:    140 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=349.5, nsentences=8, sample_size=349.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=992.9, ups=2.84, wpb=349.5, bsz=8, num_updates=47930, lr=5.26926e-05, gnorm=2.106, clip=0, loss_scale=512, train_wall=3, gb_free=14.3, wall=16476
2023-03-15 18:34:21 - progress_bar.py[line:272] - INFO: epoch 025:    150 / 2004 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=322.7, nsentences=8, sample_size=322.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=932.9, ups=2.89, wpb=322.7, bsz=8, num_updates=47940, lr=5.26825e-05, gnorm=2.351, clip=0, loss_scale=512, train_wall=3, gb_free=14.6, wall=16479
2023-03-15 18:34:25 - progress_bar.py[line:272] - INFO: epoch 025:    160 / 2004 loss=0.171, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=368.3, nsentences=8, sample_size=368.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1039.7, ups=2.82, wpb=368.3, bsz=8, num_updates=47950, lr=5.26724e-05, gnorm=2.282, clip=0, loss_scale=512, train_wall=3, gb_free=15, wall=16483
2023-03-15 18:34:28 - progress_bar.py[line:272] - INFO: epoch 025:    170 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=335.2, nsentences=8, sample_size=335.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=951.6, ups=2.84, wpb=335.2, bsz=8, num_updates=47960, lr=5.26624e-05, gnorm=2.088, clip=0, loss_scale=512, train_wall=3, gb_free=14.8, wall=16486
2023-03-15 18:34:32 - progress_bar.py[line:272] - INFO: epoch 025:    180 / 2004 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=332.1, nsentences=8, sample_size=332.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=964.4, ups=2.9, wpb=332.1, bsz=8, num_updates=47970, lr=5.26523e-05, gnorm=2.282, clip=0, loss_scale=512, train_wall=3, gb_free=14.2, wall=16490
2023-03-15 18:34:33 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-03-15 18:34:36 - progress_bar.py[line:272] - INFO: epoch 025:    191 / 2004 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=320.6, nsentences=8, sample_size=320.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=865.8, ups=2.7, wpb=320.6, bsz=8, num_updates=47980, lr=5.26422e-05, gnorm=2.307, clip=0, loss_scale=256, train_wall=4, gb_free=15.4, wall=16493
2023-03-15 18:34:39 - progress_bar.py[line:272] - INFO: epoch 025:    201 / 2004 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=345.5, nsentences=8, sample_size=345.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=974.9, ups=2.82, wpb=345.5, bsz=8, num_updates=47990, lr=5.26321e-05, gnorm=2.214, clip=0, loss_scale=256, train_wall=3, gb_free=14.5, wall=16497
2023-03-15 18:34:43 - progress_bar.py[line:272] - INFO: epoch 025:    211 / 2004 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=324.4, nsentences=8, sample_size=324.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=957.5, ups=2.95, wpb=324.4, bsz=8, num_updates=48000, lr=5.2622e-05, gnorm=2.221, clip=0, loss_scale=256, train_wall=3, gb_free=15.1, wall=16500
2023-03-15 18:34:43 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 25 @ 48000 updates
2023-03-15 18:34:43 - trainer.py[line:431] - INFO: Saving checkpoint to ./checkpoints/checkpoint_25_48000.pt
2023-03-15 18:34:50 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./checkpoints/checkpoint_25_48000.pt
2023-03-15 18:34:53 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./checkpoints/checkpoint_25_48000.pt (epoch 25 @ 48000 updates, score None) (writing took 10.77359139546752 seconds)
2023-03-15 18:34:57 - progress_bar.py[line:272] - INFO: epoch 025:    221 / 2004 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=329.2, nsentences=8, sample_size=329.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=231.3, ups=0.7, wpb=329.2, bsz=8, num_updates=48010, lr=5.26119e-05, gnorm=2.525, clip=0, loss_scale=256, train_wall=3, gb_free=15.5, wall=16514
2023-03-15 18:35:00 - progress_bar.py[line:272] - INFO: epoch 025:    231 / 2004 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=348.8, nsentences=8, sample_size=348.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=985.2, ups=2.82, wpb=348.8, bsz=8, num_updates=48020, lr=5.26019e-05, gnorm=2.41, clip=0, loss_scale=256, train_wall=3, gb_free=14.1, wall=16518
2023-03-15 18:35:04 - progress_bar.py[line:272] - INFO: epoch 025:    241 / 2004 loss=0.175, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=375.9, nsentences=8, sample_size=375.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1068.2, ups=2.84, wpb=375.9, bsz=8, num_updates=48030, lr=5.25918e-05, gnorm=2.371, clip=0, loss_scale=256, train_wall=3, gb_free=15.8, wall=16521
2023-03-15 18:35:07 - progress_bar.py[line:272] - INFO: epoch 025:    251 / 2004 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=344.3, nsentences=8, sample_size=344.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=968.4, ups=2.81, wpb=344.3, bsz=8, num_updates=48040, lr=5.25817e-05, gnorm=2.245, clip=0, loss_scale=256, train_wall=3, gb_free=15.9, wall=16525
2023-03-15 18:35:11 - progress_bar.py[line:272] - INFO: epoch 025:    261 / 2004 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=348.2, nsentences=8, sample_size=348.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=999.7, ups=2.87, wpb=348.2, bsz=8, num_updates=48050, lr=5.25716e-05, gnorm=2.074, clip=0, loss_scale=256, train_wall=3, gb_free=14.8, wall=16528
2023-03-15 18:35:14 - progress_bar.py[line:272] - INFO: epoch 025:    271 / 2004 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=342, nsentences=8, sample_size=342, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=968.7, ups=2.83, wpb=342, bsz=8, num_updates=48060, lr=5.25615e-05, gnorm=2.191, clip=0, loss_scale=256, train_wall=3, gb_free=15.6, wall=16532
2023-03-15 18:35:18 - progress_bar.py[line:272] - INFO: epoch 025:    281 / 2004 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=328.4, nsentences=8, sample_size=328.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=958.2, ups=2.92, wpb=328.4, bsz=8, num_updates=48070, lr=5.25515e-05, gnorm=2.152, clip=0, loss_scale=256, train_wall=3, gb_free=15.4, wall=16535
2023-03-15 18:35:21 - progress_bar.py[line:272] - INFO: epoch 025:    291 / 2004 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=396.7, nsentences=8, sample_size=396.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1128.9, ups=2.85, wpb=396.7, bsz=8, num_updates=48080, lr=5.25414e-05, gnorm=2.167, clip=0, loss_scale=256, train_wall=3, gb_free=14.3, wall=16539
2023-03-15 18:35:25 - progress_bar.py[line:272] - INFO: epoch 025:    301 / 2004 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=346.9, nsentences=8, sample_size=346.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=985.4, ups=2.84, wpb=346.9, bsz=8, num_updates=48090, lr=5.25313e-05, gnorm=2.277, clip=0, loss_scale=256, train_wall=3, gb_free=15.2, wall=16542
2023-03-15 18:35:28 - progress_bar.py[line:272] - INFO: epoch 025:    311 / 2004 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=352.9, nsentences=8, sample_size=352.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=996.9, ups=2.82, wpb=352.9, bsz=8, num_updates=48100, lr=5.25212e-05, gnorm=2.444, clip=0, loss_scale=512, train_wall=3, gb_free=14.1, wall=16546
2023-03-15 18:35:32 - progress_bar.py[line:272] - INFO: epoch 025:    321 / 2004 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=330, nsentences=8, sample_size=330, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=959.1, ups=2.91, wpb=330, bsz=8, num_updates=48110, lr=5.25111e-05, gnorm=2.061, clip=0, loss_scale=512, train_wall=3, gb_free=15.5, wall=16549
2023-03-15 18:35:35 - progress_bar.py[line:272] - INFO: epoch 025:    331 / 2004 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=337.6, nsentences=8, sample_size=337.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=975.2, ups=2.89, wpb=337.6, bsz=8, num_updates=48120, lr=5.25011e-05, gnorm=2.174, clip=0, loss_scale=512, train_wall=3, gb_free=15.4, wall=16553
2023-03-15 18:35:39 - progress_bar.py[line:272] - INFO: epoch 025:    341 / 2004 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=349.5, nsentences=8, sample_size=349.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=979.2, ups=2.8, wpb=349.5, bsz=8, num_updates=48130, lr=5.2491e-05, gnorm=2.502, clip=0, loss_scale=512, train_wall=4, gb_free=14.4, wall=16556
2023-03-15 18:35:42 - progress_bar.py[line:272] - INFO: epoch 025:    351 / 2004 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=359.7, nsentences=8, sample_size=359.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1088.2, ups=3.03, wpb=359.7, bsz=8, num_updates=48140, lr=5.24809e-05, gnorm=2.332, clip=0, loss_scale=512, train_wall=3, gb_free=15, wall=16560
2023-03-15 18:35:46 - progress_bar.py[line:272] - INFO: epoch 025:    361 / 2004 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=355.6, nsentences=8, sample_size=355.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1017.4, ups=2.86, wpb=355.6, bsz=8, num_updates=48150, lr=5.24708e-05, gnorm=2.076, clip=0, loss_scale=512, train_wall=3, gb_free=14.9, wall=16563
2023-03-15 18:35:49 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-03-15 18:35:49 - progress_bar.py[line:272] - INFO: epoch 025:    372 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=330.1, nsentences=8, sample_size=330.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=867.9, ups=2.63, wpb=330.1, bsz=8, num_updates=48160, lr=5.24607e-05, gnorm=2.127, clip=0, loss_scale=256, train_wall=4, gb_free=15.1, wall=16567
2023-03-15 18:35:53 - progress_bar.py[line:272] - INFO: epoch 025:    382 / 2004 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=316.6, nsentences=8, sample_size=316.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=910.3, ups=2.88, wpb=316.6, bsz=8, num_updates=48170, lr=5.24507e-05, gnorm=2.261, clip=0, loss_scale=256, train_wall=3, gb_free=15.4, wall=16571
2023-03-15 18:35:56 - progress_bar.py[line:272] - INFO: epoch 025:    392 / 2004 loss=0.171, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=352.6, nsentences=8, sample_size=352.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1010, ups=2.86, wpb=352.6, bsz=8, num_updates=48180, lr=5.24406e-05, gnorm=2.42, clip=0, loss_scale=256, train_wall=3, gb_free=14.6, wall=16574
2023-03-15 18:36:00 - progress_bar.py[line:272] - INFO: epoch 025:    402 / 2004 loss=0.192, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=376.4, nsentences=8, sample_size=376.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1100.4, ups=2.92, wpb=376.4, bsz=8, num_updates=48190, lr=5.24305e-05, gnorm=2.744, clip=0, loss_scale=256, train_wall=3, gb_free=14.6, wall=16577
2023-03-15 18:36:03 - progress_bar.py[line:272] - INFO: epoch 025:    412 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=342.2, nsentences=8, sample_size=342.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=998.1, ups=2.92, wpb=342.2, bsz=8, num_updates=48200, lr=5.24204e-05, gnorm=2.466, clip=0, loss_scale=256, train_wall=3, gb_free=15.1, wall=16581
2023-03-15 18:36:07 - progress_bar.py[line:272] - INFO: epoch 025:    422 / 2004 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=338.9, nsentences=8, sample_size=338.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=952.4, ups=2.81, wpb=338.9, bsz=8, num_updates=48210, lr=5.24103e-05, gnorm=2.231, clip=0, loss_scale=256, train_wall=3, gb_free=15.2, wall=16584
2023-03-15 18:36:10 - progress_bar.py[line:272] - INFO: epoch 025:    432 / 2004 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=345, nsentences=8, sample_size=345, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=984.7, ups=2.85, wpb=345, bsz=8, num_updates=48220, lr=5.24003e-05, gnorm=2.442, clip=0, loss_scale=256, train_wall=3, gb_free=14.4, wall=16588
2023-03-15 18:36:14 - progress_bar.py[line:272] - INFO: epoch 025:    442 / 2004 loss=0.188, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=372.3, nsentences=8, sample_size=372.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1050.1, ups=2.82, wpb=372.3, bsz=8, num_updates=48230, lr=5.23902e-05, gnorm=2.608, clip=0, loss_scale=256, train_wall=3, gb_free=13.6, wall=16592
2023-03-15 18:36:17 - progress_bar.py[line:272] - INFO: epoch 025:    452 / 2004 loss=0.186, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=349, nsentences=8, sample_size=349, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1000.3, ups=2.87, wpb=349, bsz=8, num_updates=48240, lr=5.23801e-05, gnorm=2.501, clip=0, loss_scale=256, train_wall=3, gb_free=15.4, wall=16595
2023-03-15 18:36:21 - progress_bar.py[line:272] - INFO: epoch 025:    462 / 2004 loss=0.178, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=390.3, nsentences=8, sample_size=390.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1086.2, ups=2.78, wpb=390.3, bsz=8, num_updates=48250, lr=5.237e-05, gnorm=2.442, clip=0, loss_scale=256, train_wall=4, gb_free=14.2, wall=16599
2023-03-15 18:36:25 - progress_bar.py[line:272] - INFO: epoch 025:    472 / 2004 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=348.9, nsentences=8, sample_size=348.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=957, ups=2.74, wpb=348.9, bsz=8, num_updates=48260, lr=5.23599e-05, gnorm=2.294, clip=0, loss_scale=256, train_wall=4, gb_free=14.9, wall=16602
2023-03-15 18:36:28 - progress_bar.py[line:272] - INFO: epoch 025:    482 / 2004 loss=0.193, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=364.5, nsentences=8, sample_size=364.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1027.5, ups=2.82, wpb=364.5, bsz=8, num_updates=48270, lr=5.23498e-05, gnorm=2.482, clip=0, loss_scale=256, train_wall=3, gb_free=14.8, wall=16606
2023-03-15 18:36:32 - progress_bar.py[line:272] - INFO: epoch 025:    492 / 2004 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=376.1, nsentences=8, sample_size=376.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1054.3, ups=2.8, wpb=376.1, bsz=8, num_updates=48280, lr=5.23398e-05, gnorm=2.211, clip=0, loss_scale=256, train_wall=4, gb_free=14.5, wall=16609
2023-03-15 18:36:35 - progress_bar.py[line:272] - INFO: epoch 025:    502 / 2004 loss=0.171, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=362.2, nsentences=8, sample_size=362.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1054.5, ups=2.91, wpb=362.2, bsz=8, num_updates=48290, lr=5.23297e-05, gnorm=2.508, clip=0, loss_scale=512, train_wall=3, gb_free=15, wall=16613
2023-03-15 18:36:39 - progress_bar.py[line:272] - INFO: epoch 025:    512 / 2004 loss=0.191, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=347.2, nsentences=8, sample_size=347.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=976.2, ups=2.81, wpb=347.2, bsz=8, num_updates=48300, lr=5.23196e-05, gnorm=2.554, clip=0, loss_scale=512, train_wall=3, gb_free=14.6, wall=16616
2023-03-15 18:36:42 - progress_bar.py[line:272] - INFO: epoch 025:    522 / 2004 loss=0.18, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=377.6, nsentences=8, sample_size=377.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1090, ups=2.89, wpb=377.6, bsz=8, num_updates=48310, lr=5.23095e-05, gnorm=2.575, clip=0, loss_scale=512, train_wall=3, gb_free=14.9, wall=16620
2023-03-15 18:36:46 - progress_bar.py[line:272] - INFO: epoch 025:    532 / 2004 loss=0.181, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=385.3, nsentences=8, sample_size=385.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1095.3, ups=2.84, wpb=385.3, bsz=8, num_updates=48320, lr=5.22994e-05, gnorm=2.605, clip=0, loss_scale=512, train_wall=3, gb_free=14.7, wall=16623
2023-03-15 18:36:49 - progress_bar.py[line:272] - INFO: epoch 025:    542 / 2004 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=374.1, nsentences=8, sample_size=374.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1058.6, ups=2.83, wpb=374.1, bsz=8, num_updates=48330, lr=5.22894e-05, gnorm=2.421, clip=0, loss_scale=512, train_wall=3, gb_free=14.3, wall=16627
2023-03-15 18:36:53 - progress_bar.py[line:272] - INFO: epoch 025:    552 / 2004 loss=0.176, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=362.2, nsentences=8, sample_size=362.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1033.2, ups=2.85, wpb=362.2, bsz=8, num_updates=48340, lr=5.22793e-05, gnorm=2.397, clip=0, loss_scale=512, train_wall=3, gb_free=15.2, wall=16630
2023-03-15 18:36:56 - progress_bar.py[line:272] - INFO: epoch 025:    562 / 2004 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=370.4, nsentences=8, sample_size=370.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1079.5, ups=2.91, wpb=370.4, bsz=8, num_updates=48350, lr=5.22692e-05, gnorm=2.19, clip=0, loss_scale=512, train_wall=3, gb_free=14.7, wall=16634
2023-03-15 18:37:00 - progress_bar.py[line:272] - INFO: epoch 025:    572 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=367.1, nsentences=8, sample_size=367.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1049.6, ups=2.86, wpb=367.1, bsz=8, num_updates=48360, lr=5.22591e-05, gnorm=1.981, clip=0, loss_scale=512, train_wall=3, gb_free=14.9, wall=16637
2023-03-15 18:37:03 - progress_bar.py[line:272] - INFO: epoch 025:    582 / 2004 loss=0.177, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=355.9, nsentences=8, sample_size=355.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=999.7, ups=2.81, wpb=355.9, bsz=8, num_updates=48370, lr=5.2249e-05, gnorm=2.285, clip=0, loss_scale=512, train_wall=4, gb_free=14.4, wall=16641
2023-03-15 18:37:07 - progress_bar.py[line:272] - INFO: epoch 025:    592 / 2004 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=338.3, nsentences=8, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=988.2, ups=2.92, wpb=338.3, bsz=8, num_updates=48380, lr=5.2239e-05, gnorm=2.056, clip=0, loss_scale=512, train_wall=3, gb_free=15.5, wall=16644
2023-03-15 18:37:10 - progress_bar.py[line:272] - INFO: epoch 025:    602 / 2004 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=358.5, nsentences=8, sample_size=358.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=999.1, ups=2.79, wpb=358.5, bsz=8, num_updates=48390, lr=5.22289e-05, gnorm=2.147, clip=0, loss_scale=512, train_wall=4, gb_free=15, wall=16648
2023-03-15 18:37:14 - progress_bar.py[line:272] - INFO: epoch 025:    612 / 2004 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=356.4, nsentences=8, sample_size=356.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=989.7, ups=2.78, wpb=356.4, bsz=8, num_updates=48400, lr=5.22188e-05, gnorm=2.362, clip=0, loss_scale=512, train_wall=4, gb_free=13.9, wall=16651
2023-03-15 18:37:17 - progress_bar.py[line:272] - INFO: epoch 025:    622 / 2004 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=357.3, nsentences=8, sample_size=357.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1012.1, ups=2.83, wpb=357.3, bsz=8, num_updates=48410, lr=5.22087e-05, gnorm=2.302, clip=0, loss_scale=512, train_wall=3, gb_free=15.2, wall=16655
2023-03-15 18:37:21 - progress_bar.py[line:272] - INFO: epoch 025:    632 / 2004 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=342.4, nsentences=8, sample_size=342.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1002.1, ups=2.93, wpb=342.4, bsz=8, num_updates=48420, lr=5.21986e-05, gnorm=2.048, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=16658
2023-03-15 18:37:22 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-03-15 18:37:24 - progress_bar.py[line:272] - INFO: epoch 025:    643 / 2004 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=342.8, nsentences=8, sample_size=342.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=943, ups=2.75, wpb=342.8, bsz=8, num_updates=48430, lr=5.21886e-05, gnorm=2.291, clip=0, loss_scale=512, train_wall=4, gb_free=15, wall=16662
2023-03-15 18:37:28 - progress_bar.py[line:272] - INFO: epoch 025:    653 / 2004 loss=0.193, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=321.6, nsentences=8, sample_size=321.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1042.2, ups=3.24, wpb=321.6, bsz=8, num_updates=48440, lr=5.21785e-05, gnorm=2.417, clip=0, loss_scale=512, train_wall=3, gb_free=15, wall=16665
2023-03-15 18:37:31 - progress_bar.py[line:272] - INFO: epoch 025:    663 / 2004 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=321.2, nsentences=8, sample_size=321.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=990.5, ups=3.08, wpb=321.2, bsz=8, num_updates=48450, lr=5.21684e-05, gnorm=2.091, clip=0, loss_scale=512, train_wall=3, gb_free=15.2, wall=16668
2023-03-15 18:37:34 - progress_bar.py[line:272] - INFO: epoch 025:    673 / 2004 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=341.2, nsentences=8, sample_size=341.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1076.9, ups=3.16, wpb=341.2, bsz=8, num_updates=48460, lr=5.21583e-05, gnorm=2.05, clip=0, loss_scale=512, train_wall=3, gb_free=15, wall=16672
2023-03-15 18:37:37 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-03-15 18:37:38 - progress_bar.py[line:272] - INFO: epoch 025:    684 / 2004 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=339.7, nsentences=8, sample_size=339.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=906.5, ups=2.67, wpb=339.7, bsz=8, num_updates=48470, lr=5.21482e-05, gnorm=2.128, clip=0, loss_scale=256, train_wall=4, gb_free=15.1, wall=16675
2023-03-15 18:37:41 - progress_bar.py[line:272] - INFO: epoch 025:    694 / 2004 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=354.2, nsentences=8, sample_size=354.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1020.8, ups=2.88, wpb=354.2, bsz=8, num_updates=48480, lr=5.21381e-05, gnorm=2.273, clip=0, loss_scale=256, train_wall=3, gb_free=14.6, wall=16679
2023-03-15 18:37:45 - progress_bar.py[line:272] - INFO: epoch 025:    704 / 2004 loss=0.188, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=321, nsentences=8, sample_size=321, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=924.9, ups=2.88, wpb=321, bsz=8, num_updates=48490, lr=5.21281e-05, gnorm=2.434, clip=0, loss_scale=256, train_wall=3, gb_free=14.8, wall=16682
2023-03-15 18:37:48 - progress_bar.py[line:272] - INFO: epoch 025:    714 / 2004 loss=0.197, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=331.7, nsentences=8, sample_size=331.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=1044.4, ups=3.15, wpb=331.7, bsz=8, num_updates=48500, lr=5.2118e-05, gnorm=2.49, clip=0, loss_scale=256, train_wall=3, gb_free=15.3, wall=16685
2023-03-15 18:37:51 - progress_bar.py[line:272] - INFO: epoch 025:    724 / 2004 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=364.1, nsentences=8, sample_size=364.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1147.4, ups=3.15, wpb=364.1, bsz=8, num_updates=48510, lr=5.21079e-05, gnorm=2.358, clip=0, loss_scale=256, train_wall=3, gb_free=15, wall=16689
2023-03-15 18:37:54 - progress_bar.py[line:272] - INFO: epoch 025:    734 / 2004 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=352.1, nsentences=8, sample_size=352.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1102.6, ups=3.13, wpb=352.1, bsz=8, num_updates=48520, lr=5.20978e-05, gnorm=2.073, clip=0, loss_scale=256, train_wall=3, gb_free=14.9, wall=16692
2023-03-15 18:37:57 - progress_bar.py[line:272] - INFO: epoch 025:    744 / 2004 loss=0.179, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=346.6, nsentences=8, sample_size=346.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1104.6, ups=3.19, wpb=346.6, bsz=8, num_updates=48530, lr=5.20877e-05, gnorm=2.381, clip=0, loss_scale=256, train_wall=3, gb_free=14.6, wall=16695
2023-03-15 18:38:01 - progress_bar.py[line:272] - INFO: epoch 025:    754 / 2004 loss=0.181, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=344.4, nsentences=8, sample_size=344.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1085.7, ups=3.15, wpb=344.4, bsz=8, num_updates=48540, lr=5.20777e-05, gnorm=2.76, clip=0, loss_scale=256, train_wall=3, gb_free=14.9, wall=16698
2023-03-15 18:38:04 - progress_bar.py[line:272] - INFO: epoch 025:    764 / 2004 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=359.2, nsentences=8, sample_size=359.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1090, ups=3.03, wpb=359.2, bsz=8, num_updates=48550, lr=5.20676e-05, gnorm=2.129, clip=0, loss_scale=256, train_wall=3, gb_free=14.4, wall=16701
2023-03-15 18:38:07 - progress_bar.py[line:272] - INFO: epoch 025:    774 / 2004 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=380.6, nsentences=8, sample_size=380.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1105.6, ups=2.9, wpb=380.6, bsz=8, num_updates=48560, lr=5.20575e-05, gnorm=2.087, clip=0, loss_scale=256, train_wall=3, gb_free=15.2, wall=16705
2023-03-15 18:38:11 - progress_bar.py[line:272] - INFO: epoch 025:    784 / 2004 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=335.1, nsentences=8, sample_size=335.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=959.8, ups=2.86, wpb=335.1, bsz=8, num_updates=48570, lr=5.20474e-05, gnorm=2.33, clip=0, loss_scale=256, train_wall=3, gb_free=14.9, wall=16708
2023-03-15 18:38:14 - progress_bar.py[line:272] - INFO: epoch 025:    794 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=334.2, nsentences=8, sample_size=334.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=961.4, ups=2.88, wpb=334.2, bsz=8, num_updates=48580, lr=5.20373e-05, gnorm=2.043, clip=0, loss_scale=256, train_wall=3, gb_free=14.8, wall=16712
2023-03-15 18:38:18 - progress_bar.py[line:272] - INFO: epoch 025:    804 / 2004 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=320.2, nsentences=8, sample_size=320.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=926.4, ups=2.89, wpb=320.2, bsz=8, num_updates=48590, lr=5.20273e-05, gnorm=2.143, clip=0, loss_scale=256, train_wall=3, gb_free=15.3, wall=16715
2023-03-15 18:38:21 - progress_bar.py[line:272] - INFO: epoch 025:    814 / 2004 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=343.8, nsentences=8, sample_size=343.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=970.2, ups=2.82, wpb=343.8, bsz=8, num_updates=48600, lr=5.20172e-05, gnorm=2.059, clip=0, loss_scale=512, train_wall=3, gb_free=15.3, wall=16719
2023-03-15 18:38:25 - progress_bar.py[line:272] - INFO: epoch 025:    824 / 2004 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=355.7, nsentences=8, sample_size=355.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1018.9, ups=2.86, wpb=355.7, bsz=8, num_updates=48610, lr=5.20071e-05, gnorm=2.125, clip=0, loss_scale=512, train_wall=3, gb_free=15.1, wall=16722
2023-03-15 18:38:26 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-03-15 18:38:29 - progress_bar.py[line:272] - INFO: epoch 025:    835 / 2004 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=336.1, nsentences=8, sample_size=336.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=885.6, ups=2.64, wpb=336.1, bsz=8, num_updates=48620, lr=5.1997e-05, gnorm=2.344, clip=0, loss_scale=256, train_wall=4, gb_free=14.9, wall=16726
2023-03-15 18:38:32 - progress_bar.py[line:272] - INFO: epoch 025:    845 / 2004 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=362.7, nsentences=8, sample_size=362.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1014.8, ups=2.8, wpb=362.7, bsz=8, num_updates=48630, lr=5.19869e-05, gnorm=2.336, clip=0, loss_scale=256, train_wall=4, gb_free=15, wall=16730
2023-03-15 18:38:36 - progress_bar.py[line:272] - INFO: epoch 025:    855 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=348.9, nsentences=8, sample_size=348.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=988.1, ups=2.83, wpb=348.9, bsz=8, num_updates=48640, lr=5.19769e-05, gnorm=2.336, clip=0, loss_scale=256, train_wall=3, gb_free=15.6, wall=16733
2023-03-15 18:38:39 - progress_bar.py[line:272] - INFO: epoch 025:    865 / 2004 loss=0.179, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=375.2, nsentences=8, sample_size=375.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1082.2, ups=2.88, wpb=375.2, bsz=8, num_updates=48650, lr=5.19668e-05, gnorm=2.6, clip=0, loss_scale=256, train_wall=3, gb_free=14.6, wall=16737
2023-03-15 18:38:43 - progress_bar.py[line:272] - INFO: epoch 025:    875 / 2004 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=339.5, nsentences=8, sample_size=339.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=984.5, ups=2.9, wpb=339.5, bsz=8, num_updates=48660, lr=5.19567e-05, gnorm=2.467, clip=0, loss_scale=256, train_wall=3, gb_free=15.3, wall=16740
2023-03-15 18:38:46 - progress_bar.py[line:272] - INFO: epoch 025:    885 / 2004 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=317.6, nsentences=8, sample_size=317.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=999.1, ups=3.15, wpb=317.6, bsz=8, num_updates=48670, lr=5.19466e-05, gnorm=2.143, clip=0, loss_scale=256, train_wall=3, gb_free=15.4, wall=16743
2023-03-15 18:38:49 - progress_bar.py[line:272] - INFO: epoch 025:    895 / 2004 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=337.2, nsentences=8, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1052.6, ups=3.12, wpb=337.2, bsz=8, num_updates=48680, lr=5.19365e-05, gnorm=2.081, clip=0, loss_scale=256, train_wall=3, gb_free=13.7, wall=16747
2023-03-15 18:38:52 - progress_bar.py[line:272] - INFO: epoch 025:    905 / 2004 loss=0.178, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=352.4, nsentences=8, sample_size=352.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1075.8, ups=3.05, wpb=352.4, bsz=8, num_updates=48690, lr=5.19265e-05, gnorm=2.474, clip=0, loss_scale=256, train_wall=3, gb_free=14.8, wall=16750
2023-03-15 18:38:56 - progress_bar.py[line:272] - INFO: epoch 025:    915 / 2004 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=371.7, nsentences=8, sample_size=371.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1066.3, ups=2.87, wpb=371.7, bsz=8, num_updates=48700, lr=5.19164e-05, gnorm=2.036, clip=0, loss_scale=256, train_wall=3, gb_free=15.2, wall=16753
2023-03-15 18:38:59 - progress_bar.py[line:272] - INFO: epoch 025:    925 / 2004 loss=0.178, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=338.7, nsentences=8, sample_size=338.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=963.3, ups=2.84, wpb=338.7, bsz=8, num_updates=48710, lr=5.19063e-05, gnorm=2.565, clip=0, loss_scale=256, train_wall=3, gb_free=14.6, wall=16757
2023-03-15 18:39:03 - progress_bar.py[line:272] - INFO: epoch 025:    935 / 2004 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=342, nsentences=8, sample_size=342, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=976.9, ups=2.86, wpb=342, bsz=8, num_updates=48720, lr=5.18962e-05, gnorm=2.174, clip=0, loss_scale=256, train_wall=3, gb_free=14.3, wall=16760
2023-03-15 18:39:06 - progress_bar.py[line:272] - INFO: epoch 025:    945 / 2004 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=357.1, nsentences=8, sample_size=357.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1002.6, ups=2.81, wpb=357.1, bsz=8, num_updates=48730, lr=5.18861e-05, gnorm=2.278, clip=0, loss_scale=256, train_wall=3, gb_free=14.3, wall=16764
2023-03-15 18:39:10 - progress_bar.py[line:272] - INFO: epoch 025:    955 / 2004 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=345.1, nsentences=8, sample_size=345.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=989.7, ups=2.87, wpb=345.1, bsz=8, num_updates=48740, lr=5.1876e-05, gnorm=2.008, clip=0, loss_scale=256, train_wall=3, gb_free=14.1, wall=16767
2023-03-15 18:39:13 - progress_bar.py[line:272] - INFO: epoch 025:    965 / 2004 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=372.9, nsentences=8, sample_size=372.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1059.7, ups=2.84, wpb=372.9, bsz=8, num_updates=48750, lr=5.1866e-05, gnorm=2.062, clip=0, loss_scale=512, train_wall=3, gb_free=15.2, wall=16771
2023-03-15 18:39:17 - progress_bar.py[line:272] - INFO: epoch 025:    975 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=329, nsentences=8, sample_size=329, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=937.8, ups=2.85, wpb=329, bsz=8, num_updates=48760, lr=5.18559e-05, gnorm=1.919, clip=0, loss_scale=512, train_wall=3, gb_free=14.7, wall=16774
2023-03-15 18:39:20 - progress_bar.py[line:272] - INFO: epoch 025:    985 / 2004 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=321.4, nsentences=8, sample_size=321.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=926.1, ups=2.88, wpb=321.4, bsz=8, num_updates=48770, lr=5.18458e-05, gnorm=2.174, clip=0, loss_scale=512, train_wall=3, gb_free=14.8, wall=16778
2023-03-15 18:39:22 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-03-15 18:39:24 - progress_bar.py[line:272] - INFO: epoch 025:    996 / 2004 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=387.6, nsentences=8, sample_size=387.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1002.5, ups=2.59, wpb=387.6, bsz=8, num_updates=48780, lr=5.18357e-05, gnorm=2.236, clip=0, loss_scale=256, train_wall=4, gb_free=14.7, wall=16782
2023-03-15 18:39:28 - progress_bar.py[line:272] - INFO: epoch 025:   1006 / 2004 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=300.6, nsentences=8, sample_size=300.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=861.5, ups=2.87, wpb=300.6, bsz=8, num_updates=48790, lr=5.18256e-05, gnorm=2.381, clip=0, loss_scale=256, train_wall=3, gb_free=15.4, wall=16785
2023-03-15 18:39:31 - progress_bar.py[line:272] - INFO: epoch 025:   1016 / 2004 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=347.9, nsentences=8, sample_size=347.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1002.4, ups=2.88, wpb=347.9, bsz=8, num_updates=48800, lr=5.18156e-05, gnorm=2.276, clip=0, loss_scale=256, train_wall=3, gb_free=15.6, wall=16789
2023-03-15 18:39:34 - progress_bar.py[line:272] - INFO: epoch 025:   1026 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=318.7, nsentences=7.8, sample_size=318.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=938.8, ups=2.95, wpb=318.7, bsz=7.8, num_updates=48810, lr=5.18055e-05, gnorm=2.29, clip=0, loss_scale=256, train_wall=3, gb_free=15.3, wall=16792
2023-03-15 18:39:38 - progress_bar.py[line:272] - INFO: epoch 025:   1036 / 2004 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=319.1, nsentences=8, sample_size=319.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=915.4, ups=2.87, wpb=319.1, bsz=8, num_updates=48820, lr=5.17954e-05, gnorm=2.208, clip=0, loss_scale=256, train_wall=3, gb_free=15.1, wall=16796
2023-03-15 18:39:41 - progress_bar.py[line:272] - INFO: epoch 025:   1046 / 2004 loss=0.171, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=379.8, nsentences=8, sample_size=379.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1101.3, ups=2.9, wpb=379.8, bsz=8, num_updates=48830, lr=5.17853e-05, gnorm=2.285, clip=0, loss_scale=256, train_wall=3, gb_free=14.3, wall=16799
2023-03-15 18:39:45 - progress_bar.py[line:272] - INFO: epoch 025:   1056 / 2004 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=349.5, nsentences=8, sample_size=349.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1005.4, ups=2.88, wpb=349.5, bsz=8, num_updates=48840, lr=5.17752e-05, gnorm=2.196, clip=0, loss_scale=256, train_wall=3, gb_free=15.3, wall=16802
2023-03-15 18:39:48 - progress_bar.py[line:272] - INFO: epoch 025:   1066 / 2004 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=340.9, nsentences=8, sample_size=340.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1078.9, ups=3.16, wpb=340.9, bsz=8, num_updates=48850, lr=5.17652e-05, gnorm=2.237, clip=0, loss_scale=256, train_wall=3, gb_free=14.5, wall=16806
2023-03-15 18:39:51 - progress_bar.py[line:272] - INFO: epoch 025:   1076 / 2004 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=354.1, nsentences=8, sample_size=354.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1093.8, ups=3.09, wpb=354.1, bsz=8, num_updates=48860, lr=5.17551e-05, gnorm=2.408, clip=0, loss_scale=256, train_wall=3, gb_free=14.7, wall=16809
2023-03-15 18:39:54 - progress_bar.py[line:272] - INFO: epoch 025:   1086 / 2004 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=377.6, nsentences=8, sample_size=377.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1186.3, ups=3.14, wpb=377.6, bsz=8, num_updates=48870, lr=5.1745e-05, gnorm=2.172, clip=0, loss_scale=256, train_wall=3, gb_free=14.9, wall=16812
2023-03-15 18:39:58 - progress_bar.py[line:272] - INFO: epoch 025:   1096 / 2004 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=322.8, nsentences=8, sample_size=322.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1039.1, ups=3.22, wpb=322.8, bsz=8, num_updates=48880, lr=5.17349e-05, gnorm=2.139, clip=0, loss_scale=256, train_wall=3, gb_free=14.2, wall=16815
2023-03-15 18:40:01 - progress_bar.py[line:272] - INFO: epoch 025:   1106 / 2004 loss=0.18, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=378.9, nsentences=8, sample_size=378.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1181.5, ups=3.12, wpb=378.9, bsz=8, num_updates=48890, lr=5.17248e-05, gnorm=2.531, clip=0, loss_scale=256, train_wall=3, gb_free=14.2, wall=16818
2023-03-15 18:40:04 - progress_bar.py[line:272] - INFO: epoch 025:   1116 / 2004 loss=0.18, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=336.3, nsentences=8, sample_size=336.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1070.1, ups=3.18, wpb=336.3, bsz=8, num_updates=48900, lr=5.17148e-05, gnorm=2.298, clip=0, loss_scale=256, train_wall=3, gb_free=14.8, wall=16822
2023-03-15 18:40:05 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-03-15 18:40:07 - progress_bar.py[line:272] - INFO: epoch 025:   1127 / 2004 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=328.4, nsentences=8, sample_size=328.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=962.6, ups=2.93, wpb=328.4, bsz=8, num_updates=48910, lr=5.17047e-05, gnorm=2.201, clip=0, loss_scale=256, train_wall=3, gb_free=14.7, wall=16825
2023-03-15 18:40:11 - progress_bar.py[line:272] - INFO: epoch 025:   1137 / 2004 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=389.6, nsentences=8, sample_size=389.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1193.8, ups=3.06, wpb=389.6, bsz=8, num_updates=48920, lr=5.16946e-05, gnorm=2.085, clip=0, loss_scale=256, train_wall=3, gb_free=14.1, wall=16828
2023-03-15 18:40:14 - progress_bar.py[line:272] - INFO: epoch 025:   1147 / 2004 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=343.7, nsentences=8, sample_size=343.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=985.5, ups=2.87, wpb=343.7, bsz=8, num_updates=48930, lr=5.16845e-05, gnorm=2.4, clip=0, loss_scale=256, train_wall=3, gb_free=13.8, wall=16832
2023-03-15 18:40:18 - progress_bar.py[line:272] - INFO: epoch 025:   1157 / 2004 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=401.4, nsentences=8, sample_size=401.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1146.5, ups=2.86, wpb=401.4, bsz=8, num_updates=48940, lr=5.16744e-05, gnorm=2.114, clip=0, loss_scale=256, train_wall=3, gb_free=14.2, wall=16835
2023-03-15 18:40:21 - progress_bar.py[line:272] - INFO: epoch 025:   1167 / 2004 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=332.3, nsentences=8, sample_size=332.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=991.7, ups=2.98, wpb=332.3, bsz=8, num_updates=48950, lr=5.16643e-05, gnorm=2.081, clip=0, loss_scale=256, train_wall=3, gb_free=14.7, wall=16839
2023-03-15 18:40:24 - progress_bar.py[line:272] - INFO: epoch 025:   1177 / 2004 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=370.3, nsentences=8, sample_size=370.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1211.9, ups=3.27, wpb=370.3, bsz=8, num_updates=48960, lr=5.16543e-05, gnorm=2.274, clip=0, loss_scale=256, train_wall=3, gb_free=15, wall=16842
2023-03-15 18:40:27 - progress_bar.py[line:272] - INFO: epoch 025:   1187 / 2004 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=327.9, nsentences=8, sample_size=327.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1064.5, ups=3.25, wpb=327.9, bsz=8, num_updates=48970, lr=5.16442e-05, gnorm=2.352, clip=0, loss_scale=256, train_wall=3, gb_free=15.2, wall=16845
2023-03-15 18:40:30 - progress_bar.py[line:272] - INFO: epoch 025:   1197 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=364.3, nsentences=8, sample_size=364.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1150.4, ups=3.16, wpb=364.3, bsz=8, num_updates=48980, lr=5.16341e-05, gnorm=2.11, clip=0, loss_scale=256, train_wall=3, gb_free=14.8, wall=16848
2023-03-15 18:40:33 - progress_bar.py[line:272] - INFO: epoch 025:   1207 / 2004 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=289.7, nsentences=8, sample_size=289.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=887, ups=3.06, wpb=289.7, bsz=8, num_updates=48990, lr=5.1624e-05, gnorm=2.156, clip=0, loss_scale=256, train_wall=3, gb_free=15, wall=16851
2023-03-15 18:40:37 - progress_bar.py[line:272] - INFO: epoch 025:   1217 / 2004 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=312.2, nsentences=8, sample_size=312.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=998.4, ups=3.2, wpb=312.2, bsz=8, num_updates=49000, lr=5.16139e-05, gnorm=2.402, clip=0, loss_scale=256, train_wall=3, gb_free=15.9, wall=16854
2023-03-15 18:40:40 - progress_bar.py[line:272] - INFO: epoch 025:   1227 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=321.7, nsentences=8, sample_size=321.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1002.5, ups=3.12, wpb=321.7, bsz=8, num_updates=49010, lr=5.16039e-05, gnorm=2.014, clip=0, loss_scale=256, train_wall=3, gb_free=14.6, wall=16857
2023-03-15 18:40:42 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-03-15 18:40:44 - progress_bar.py[line:272] - INFO: epoch 025:   1238 / 2004 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=366.3, nsentences=8, sample_size=366.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=959.5, ups=2.62, wpb=366.3, bsz=8, num_updates=49020, lr=5.15938e-05, gnorm=2.019, clip=0, loss_scale=128, train_wall=4, gb_free=14.6, wall=16861
2023-03-15 18:40:47 - progress_bar.py[line:272] - INFO: epoch 025:   1248 / 2004 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=346.1, nsentences=8, sample_size=346.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=998, ups=2.88, wpb=346.1, bsz=8, num_updates=49030, lr=5.15837e-05, gnorm=2.235, clip=0, loss_scale=128, train_wall=3, gb_free=15.4, wall=16865
2023-03-15 18:40:51 - progress_bar.py[line:272] - INFO: epoch 025:   1258 / 2004 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=352.3, nsentences=8, sample_size=352.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1008.9, ups=2.86, wpb=352.3, bsz=8, num_updates=49040, lr=5.15736e-05, gnorm=2.039, clip=0, loss_scale=128, train_wall=3, gb_free=14.8, wall=16868
2023-03-15 18:40:54 - progress_bar.py[line:272] - INFO: epoch 025:   1268 / 2004 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=344.3, nsentences=8, sample_size=344.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=965.1, ups=2.8, wpb=344.3, bsz=8, num_updates=49050, lr=5.15635e-05, gnorm=2.321, clip=0, loss_scale=128, train_wall=4, gb_free=13.6, wall=16872
2023-03-15 18:40:58 - progress_bar.py[line:272] - INFO: epoch 025:   1278 / 2004 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=346, nsentences=8, sample_size=346, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=969.9, ups=2.8, wpb=346, bsz=8, num_updates=49060, lr=5.15535e-05, gnorm=1.971, clip=0, loss_scale=128, train_wall=4, gb_free=14.6, wall=16875
2023-03-15 18:41:01 - progress_bar.py[line:272] - INFO: epoch 025:   1288 / 2004 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=312.4, nsentences=8, sample_size=312.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=902.3, ups=2.89, wpb=312.4, bsz=8, num_updates=49070, lr=5.15434e-05, gnorm=2.224, clip=0, loss_scale=128, train_wall=3, gb_free=15, wall=16879
2023-03-15 18:41:05 - progress_bar.py[line:272] - INFO: epoch 025:   1298 / 2004 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=308.6, nsentences=8, sample_size=308.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=879.3, ups=2.85, wpb=308.6, bsz=8, num_updates=49080, lr=5.15333e-05, gnorm=2.35, clip=0, loss_scale=128, train_wall=3, gb_free=14.9, wall=16882
2023-03-15 18:41:08 - progress_bar.py[line:272] - INFO: epoch 025:   1308 / 2004 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=321.5, nsentences=8, sample_size=321.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=940.2, ups=2.92, wpb=321.5, bsz=8, num_updates=49090, lr=5.15232e-05, gnorm=2.155, clip=0, loss_scale=128, train_wall=3, gb_free=15, wall=16886
2023-03-15 18:41:12 - progress_bar.py[line:272] - INFO: epoch 025:   1318 / 2004 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=345.9, nsentences=8, sample_size=345.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=986.2, ups=2.85, wpb=345.9, bsz=8, num_updates=49100, lr=5.15131e-05, gnorm=2.445, clip=0, loss_scale=128, train_wall=3, gb_free=15.4, wall=16889
2023-03-15 18:41:15 - progress_bar.py[line:272] - INFO: epoch 025:   1328 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=292.4, nsentences=8, sample_size=292.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=877.1, ups=3, wpb=292.4, bsz=8, num_updates=49110, lr=5.15031e-05, gnorm=2.159, clip=0, loss_scale=128, train_wall=3, gb_free=14.8, wall=16893
2023-03-15 18:41:18 - progress_bar.py[line:272] - INFO: epoch 025:   1338 / 2004 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=365.9, nsentences=8, sample_size=365.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1128.2, ups=3.08, wpb=365.9, bsz=8, num_updates=49120, lr=5.1493e-05, gnorm=2.292, clip=0, loss_scale=128, train_wall=3, gb_free=15.1, wall=16896
2023-03-15 18:41:22 - progress_bar.py[line:272] - INFO: epoch 025:   1348 / 2004 loss=0.175, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=302.1, nsentences=8, sample_size=302.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=886.4, ups=2.93, wpb=302.1, bsz=8, num_updates=49130, lr=5.14829e-05, gnorm=2.376, clip=0, loss_scale=128, train_wall=3, gb_free=15.2, wall=16899
2023-03-15 18:41:25 - progress_bar.py[line:272] - INFO: epoch 025:   1358 / 2004 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=317.5, nsentences=8, sample_size=317.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=935.8, ups=2.95, wpb=317.5, bsz=8, num_updates=49140, lr=5.14728e-05, gnorm=2.53, clip=0, loss_scale=128, train_wall=3, gb_free=15.4, wall=16903
2023-03-15 18:41:29 - progress_bar.py[line:272] - INFO: epoch 025:   1368 / 2004 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=319.2, nsentences=8, sample_size=319.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=897.9, ups=2.81, wpb=319.2, bsz=8, num_updates=49150, lr=5.14627e-05, gnorm=2.405, clip=0, loss_scale=256, train_wall=3, gb_free=14.1, wall=16906
2023-03-15 18:41:32 - progress_bar.py[line:272] - INFO: epoch 025:   1378 / 2004 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=328, nsentences=8, sample_size=328, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=937.1, ups=2.86, wpb=328, bsz=8, num_updates=49160, lr=5.14527e-05, gnorm=2.344, clip=0, loss_scale=256, train_wall=3, gb_free=14.9, wall=16910
2023-03-15 18:41:36 - progress_bar.py[line:272] - INFO: epoch 025:   1388 / 2004 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=394.4, nsentences=8, sample_size=394.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1122.1, ups=2.85, wpb=394.4, bsz=8, num_updates=49170, lr=5.14426e-05, gnorm=2.189, clip=0, loss_scale=256, train_wall=3, gb_free=14.9, wall=16913
2023-03-15 18:41:39 - progress_bar.py[line:272] - INFO: epoch 025:   1398 / 2004 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=348.6, nsentences=8, sample_size=348.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1023.4, ups=2.94, wpb=348.6, bsz=8, num_updates=49180, lr=5.14325e-05, gnorm=2.242, clip=0, loss_scale=256, train_wall=3, gb_free=14.4, wall=16917
2023-03-15 18:41:43 - progress_bar.py[line:272] - INFO: epoch 025:   1408 / 2004 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=346, nsentences=8, sample_size=346, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=987.6, ups=2.85, wpb=346, bsz=8, num_updates=49190, lr=5.14224e-05, gnorm=2.386, clip=0, loss_scale=256, train_wall=3, gb_free=14.6, wall=16920
2023-03-15 18:41:46 - progress_bar.py[line:272] - INFO: epoch 025:   1418 / 2004 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=372.2, nsentences=8, sample_size=372.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1071.8, ups=2.88, wpb=372.2, bsz=8, num_updates=49200, lr=5.14123e-05, gnorm=2.566, clip=0, loss_scale=256, train_wall=3, gb_free=15.4, wall=16924
2023-03-15 18:41:49 - progress_bar.py[line:272] - INFO: epoch 025:   1428 / 2004 loss=0.18, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=309.5, nsentences=8, sample_size=309.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=888.2, ups=2.87, wpb=309.5, bsz=8, num_updates=49210, lr=5.14022e-05, gnorm=2.345, clip=0, loss_scale=256, train_wall=3, gb_free=13.8, wall=16927
2023-03-15 18:41:53 - progress_bar.py[line:272] - INFO: epoch 025:   1438 / 2004 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=359.9, nsentences=8, sample_size=359.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1030.4, ups=2.86, wpb=359.9, bsz=8, num_updates=49220, lr=5.13922e-05, gnorm=2.556, clip=0, loss_scale=256, train_wall=3, gb_free=14.7, wall=16931
2023-03-15 18:41:56 - progress_bar.py[line:272] - INFO: epoch 025:   1448 / 2004 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=317.7, nsentences=8, sample_size=317.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=914.5, ups=2.88, wpb=317.7, bsz=8, num_updates=49230, lr=5.13821e-05, gnorm=2.409, clip=0, loss_scale=256, train_wall=3, gb_free=15.3, wall=16934
2023-03-15 18:42:00 - progress_bar.py[line:272] - INFO: epoch 025:   1458 / 2004 loss=0.188, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=382.4, nsentences=8, sample_size=382.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1087.5, ups=2.84, wpb=382.4, bsz=8, num_updates=49240, lr=5.1372e-05, gnorm=2.519, clip=0, loss_scale=256, train_wall=3, gb_free=14.8, wall=16938
2023-03-15 18:42:02 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-03-15 18:42:04 - progress_bar.py[line:272] - INFO: epoch 025:   1469 / 2004 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=394.3, nsentences=8, sample_size=394.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1024.4, ups=2.6, wpb=394.3, bsz=8, num_updates=49250, lr=5.13619e-05, gnorm=2.178, clip=0, loss_scale=128, train_wall=4, gb_free=14.8, wall=16941
2023-03-15 18:42:07 - progress_bar.py[line:272] - INFO: epoch 025:   1479 / 2004 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=404.4, nsentences=8, sample_size=404.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1161.4, ups=2.87, wpb=404.4, bsz=8, num_updates=49260, lr=5.13518e-05, gnorm=2.042, clip=0, loss_scale=128, train_wall=3, gb_free=14.4, wall=16945
2023-03-15 18:42:11 - progress_bar.py[line:272] - INFO: epoch 025:   1489 / 2004 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=309.1, nsentences=8, sample_size=309.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=897, ups=2.9, wpb=309.1, bsz=8, num_updates=49270, lr=5.13418e-05, gnorm=2.35, clip=0, loss_scale=128, train_wall=3, gb_free=14.8, wall=16948
2023-03-15 18:42:14 - progress_bar.py[line:272] - INFO: epoch 025:   1499 / 2004 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=344.8, nsentences=8, sample_size=344.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=977.2, ups=2.83, wpb=344.8, bsz=8, num_updates=49280, lr=5.13317e-05, gnorm=2.212, clip=0, loss_scale=128, train_wall=3, gb_free=15.2, wall=16952
2023-03-15 18:42:18 - progress_bar.py[line:272] - INFO: epoch 025:   1509 / 2004 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=328.7, nsentences=8, sample_size=328.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=941.1, ups=2.86, wpb=328.7, bsz=8, num_updates=49290, lr=5.13216e-05, gnorm=2.184, clip=0, loss_scale=128, train_wall=3, gb_free=15.5, wall=16955
2023-03-15 18:42:21 - progress_bar.py[line:272] - INFO: epoch 025:   1519 / 2004 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=327.1, nsentences=8, sample_size=327.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=933.6, ups=2.85, wpb=327.1, bsz=8, num_updates=49300, lr=5.13115e-05, gnorm=2.096, clip=0, loss_scale=128, train_wall=3, gb_free=15.5, wall=16959
2023-03-15 18:42:25 - progress_bar.py[line:272] - INFO: epoch 025:   1529 / 2004 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=335.7, nsentences=8, sample_size=335.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=971, ups=2.89, wpb=335.7, bsz=8, num_updates=49310, lr=5.13014e-05, gnorm=2.221, clip=0, loss_scale=128, train_wall=3, gb_free=13.9, wall=16962
2023-03-15 18:42:28 - progress_bar.py[line:272] - INFO: epoch 025:   1539 / 2004 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=346.3, nsentences=8, sample_size=346.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1092.6, ups=3.15, wpb=346.3, bsz=8, num_updates=49320, lr=5.12914e-05, gnorm=2.056, clip=0, loss_scale=128, train_wall=3, gb_free=15, wall=16965
2023-03-15 18:42:31 - progress_bar.py[line:272] - INFO: epoch 025:   1549 / 2004 loss=0.182, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=317.1, nsentences=8, sample_size=317.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1017.3, ups=3.21, wpb=317.1, bsz=8, num_updates=49330, lr=5.12813e-05, gnorm=2.511, clip=0, loss_scale=128, train_wall=3, gb_free=14.9, wall=16969
2023-03-15 18:42:34 - progress_bar.py[line:272] - INFO: epoch 025:   1559 / 2004 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=353.3, nsentences=8, sample_size=353.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1136.4, ups=3.22, wpb=353.3, bsz=8, num_updates=49340, lr=5.12712e-05, gnorm=2.016, clip=0, loss_scale=128, train_wall=3, gb_free=15, wall=16972
2023-03-15 18:42:37 - progress_bar.py[line:272] - INFO: epoch 025:   1569 / 2004 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=325.9, nsentences=8, sample_size=325.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1039.2, ups=3.19, wpb=325.9, bsz=8, num_updates=49350, lr=5.12611e-05, gnorm=2.259, clip=0, loss_scale=128, train_wall=3, gb_free=15.1, wall=16975
2023-03-15 18:42:40 - progress_bar.py[line:272] - INFO: epoch 025:   1579 / 2004 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=354, nsentences=8, sample_size=354, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1159.3, ups=3.27, wpb=354, bsz=8, num_updates=49360, lr=5.1251e-05, gnorm=2.044, clip=0, loss_scale=128, train_wall=3, gb_free=15.3, wall=16978
2023-03-15 18:42:43 - progress_bar.py[line:272] - INFO: epoch 025:   1589 / 2004 loss=0.171, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=328.2, nsentences=8, sample_size=328.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1067.5, ups=3.25, wpb=328.2, bsz=8, num_updates=49370, lr=5.1241e-05, gnorm=2.041, clip=0, loss_scale=128, train_wall=3, gb_free=14.8, wall=16981
2023-03-15 18:42:47 - progress_bar.py[line:272] - INFO: epoch 025:   1599 / 2004 loss=0.171, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=345.9, nsentences=8, sample_size=345.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1096.1, ups=3.17, wpb=345.9, bsz=8, num_updates=49380, lr=5.12309e-05, gnorm=2.239, clip=0, loss_scale=256, train_wall=3, gb_free=15.3, wall=16984
2023-03-15 18:42:50 - progress_bar.py[line:272] - INFO: epoch 025:   1609 / 2004 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=336.5, nsentences=8, sample_size=336.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1065.4, ups=3.17, wpb=336.5, bsz=8, num_updates=49390, lr=5.12208e-05, gnorm=2.156, clip=0, loss_scale=256, train_wall=3, gb_free=15.1, wall=16987
2023-03-15 18:42:53 - progress_bar.py[line:272] - INFO: epoch 025:   1619 / 2004 loss=0.179, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=342.5, nsentences=8, sample_size=342.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1086.3, ups=3.17, wpb=342.5, bsz=8, num_updates=49400, lr=5.12107e-05, gnorm=2.374, clip=0, loss_scale=256, train_wall=3, gb_free=14.9, wall=16990
2023-03-15 18:42:56 - progress_bar.py[line:272] - INFO: epoch 025:   1629 / 2004 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=362.5, nsentences=8, sample_size=362.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1132.2, ups=3.12, wpb=362.5, bsz=8, num_updates=49410, lr=5.12006e-05, gnorm=1.905, clip=0, loss_scale=256, train_wall=3, gb_free=15.5, wall=16994
2023-03-15 18:42:59 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-03-15 18:43:00 - progress_bar.py[line:272] - INFO: epoch 025:   1640 / 2004 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=314.6, nsentences=8, sample_size=314.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=894.1, ups=2.84, wpb=314.6, bsz=8, num_updates=49420, lr=5.11905e-05, gnorm=2.416, clip=0, loss_scale=128, train_wall=3, gb_free=14.9, wall=16997
2023-03-15 18:43:03 - progress_bar.py[line:272] - INFO: epoch 025:   1650 / 2004 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=327.5, nsentences=8, sample_size=327.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1008.2, ups=3.08, wpb=327.5, bsz=8, num_updates=49430, lr=5.11805e-05, gnorm=2.226, clip=0, loss_scale=128, train_wall=3, gb_free=14.5, wall=17000
2023-03-15 18:43:06 - progress_bar.py[line:272] - INFO: epoch 025:   1660 / 2004 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=346.7, nsentences=8, sample_size=346.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1087, ups=3.14, wpb=346.7, bsz=8, num_updates=49440, lr=5.11704e-05, gnorm=2.26, clip=0, loss_scale=128, train_wall=3, gb_free=13.9, wall=17004
2023-03-15 18:43:09 - progress_bar.py[line:272] - INFO: epoch 025:   1670 / 2004 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=352.2, nsentences=8, sample_size=352.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1117.3, ups=3.17, wpb=352.2, bsz=8, num_updates=49450, lr=5.11603e-05, gnorm=2.422, clip=0, loss_scale=128, train_wall=3, gb_free=15, wall=17007
2023-03-15 18:43:12 - progress_bar.py[line:272] - INFO: epoch 025:   1680 / 2004 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=314, nsentences=8, sample_size=314, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1000.1, ups=3.19, wpb=314, bsz=8, num_updates=49460, lr=5.11502e-05, gnorm=2.324, clip=0, loss_scale=128, train_wall=3, gb_free=14.7, wall=17010
2023-03-15 18:43:15 - progress_bar.py[line:272] - INFO: epoch 025:   1690 / 2004 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=347.7, nsentences=8, sample_size=347.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1132.4, ups=3.26, wpb=347.7, bsz=8, num_updates=49470, lr=5.11401e-05, gnorm=2.063, clip=0, loss_scale=128, train_wall=3, gb_free=14.6, wall=17013
2023-03-15 18:43:19 - progress_bar.py[line:272] - INFO: epoch 025:   1700 / 2004 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=335.8, nsentences=8, sample_size=335.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1004.3, ups=2.99, wpb=335.8, bsz=8, num_updates=49480, lr=5.11301e-05, gnorm=2.351, clip=0, loss_scale=128, train_wall=3, gb_free=14.9, wall=17016
2023-03-15 18:43:22 - progress_bar.py[line:272] - INFO: epoch 025:   1710 / 2004 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=346.6, nsentences=8, sample_size=346.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=978.8, ups=2.82, wpb=346.6, bsz=8, num_updates=49490, lr=5.112e-05, gnorm=2.135, clip=0, loss_scale=128, train_wall=3, gb_free=14.8, wall=17020
2023-03-15 18:43:26 - progress_bar.py[line:272] - INFO: epoch 025:   1720 / 2004 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=379, nsentences=8, sample_size=379, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1081.4, ups=2.85, wpb=379, bsz=8, num_updates=49500, lr=5.11099e-05, gnorm=2.204, clip=0, loss_scale=128, train_wall=3, gb_free=14.8, wall=17023
2023-03-15 18:43:29 - progress_bar.py[line:272] - INFO: epoch 025:   1730 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=379.3, nsentences=8, sample_size=379.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1068.7, ups=2.82, wpb=379.3, bsz=8, num_updates=49510, lr=5.10998e-05, gnorm=2.097, clip=0, loss_scale=128, train_wall=3, gb_free=15, wall=17027
2023-03-15 18:43:33 - progress_bar.py[line:272] - INFO: epoch 025:   1740 / 2004 loss=0.171, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=314.8, nsentences=8, sample_size=314.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=917, ups=2.91, wpb=314.8, bsz=8, num_updates=49520, lr=5.10897e-05, gnorm=2.421, clip=0, loss_scale=128, train_wall=3, gb_free=15.2, wall=17030
2023-03-15 18:43:36 - progress_bar.py[line:272] - INFO: epoch 025:   1750 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=357.9, nsentences=8, sample_size=357.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1043.3, ups=2.92, wpb=357.9, bsz=8, num_updates=49530, lr=5.10797e-05, gnorm=2.02, clip=0, loss_scale=128, train_wall=3, gb_free=15.8, wall=17034
2023-03-15 18:43:40 - progress_bar.py[line:272] - INFO: epoch 025:   1760 / 2004 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=325.3, nsentences=8, sample_size=325.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=923, ups=2.84, wpb=325.3, bsz=8, num_updates=49540, lr=5.10696e-05, gnorm=2.249, clip=0, loss_scale=128, train_wall=3, gb_free=15.2, wall=17037
2023-03-15 18:43:43 - progress_bar.py[line:272] - INFO: epoch 025:   1770 / 2004 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=339.2, nsentences=8, sample_size=339.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=959, ups=2.83, wpb=339.2, bsz=8, num_updates=49550, lr=5.10595e-05, gnorm=2.314, clip=0, loss_scale=256, train_wall=3, gb_free=15.3, wall=17041
2023-03-15 18:43:47 - progress_bar.py[line:272] - INFO: epoch 025:   1780 / 2004 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=330.8, nsentences=8, sample_size=330.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=935.1, ups=2.83, wpb=330.8, bsz=8, num_updates=49560, lr=5.10494e-05, gnorm=2.156, clip=0, loss_scale=256, train_wall=3, gb_free=15, wall=17044
2023-03-15 18:43:50 - progress_bar.py[line:272] - INFO: epoch 025:   1790 / 2004 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=306.4, nsentences=8, sample_size=306.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=885.9, ups=2.89, wpb=306.4, bsz=8, num_updates=49570, lr=5.10393e-05, gnorm=2.146, clip=0, loss_scale=256, train_wall=3, gb_free=15.1, wall=17048
2023-03-15 18:43:54 - progress_bar.py[line:272] - INFO: epoch 025:   1800 / 2004 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=355.2, nsentences=8, sample_size=355.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1037.3, ups=2.92, wpb=355.2, bsz=8, num_updates=49580, lr=5.10293e-05, gnorm=2.348, clip=0, loss_scale=256, train_wall=3, gb_free=15.2, wall=17051
2023-03-15 18:43:57 - progress_bar.py[line:272] - INFO: epoch 025:   1810 / 2004 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=343.4, nsentences=8, sample_size=343.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=972.2, ups=2.83, wpb=343.4, bsz=8, num_updates=49590, lr=5.10192e-05, gnorm=2.319, clip=0, loss_scale=256, train_wall=3, gb_free=15, wall=17055
2023-03-15 18:44:01 - progress_bar.py[line:272] - INFO: epoch 025:   1820 / 2004 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=350.1, nsentences=8, sample_size=350.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1022.3, ups=2.92, wpb=350.1, bsz=8, num_updates=49600, lr=5.10091e-05, gnorm=2.189, clip=0, loss_scale=256, train_wall=3, gb_free=15.4, wall=17058
2023-03-15 18:44:04 - progress_bar.py[line:272] - INFO: epoch 025:   1830 / 2004 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=347.9, nsentences=8, sample_size=347.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=991.1, ups=2.85, wpb=347.9, bsz=8, num_updates=49610, lr=5.0999e-05, gnorm=2.195, clip=0, loss_scale=256, train_wall=3, gb_free=14.1, wall=17062
2023-03-15 18:44:08 - progress_bar.py[line:272] - INFO: epoch 025:   1840 / 2004 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=348.1, nsentences=8, sample_size=348.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1030.3, ups=2.96, wpb=348.1, bsz=8, num_updates=49620, lr=5.09889e-05, gnorm=2.117, clip=0, loss_scale=256, train_wall=3, gb_free=15.3, wall=17065
2023-03-15 18:44:11 - progress_bar.py[line:272] - INFO: epoch 025:   1850 / 2004 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=338.2, nsentences=8, sample_size=338.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=994.4, ups=2.94, wpb=338.2, bsz=8, num_updates=49630, lr=5.09789e-05, gnorm=2.184, clip=0, loss_scale=256, train_wall=3, gb_free=15.6, wall=17069
2023-03-15 18:44:14 - progress_bar.py[line:272] - INFO: epoch 025:   1860 / 2004 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=326.2, nsentences=8, sample_size=326.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=947.5, ups=2.9, wpb=326.2, bsz=8, num_updates=49640, lr=5.09688e-05, gnorm=2.078, clip=0, loss_scale=256, train_wall=3, gb_free=14.9, wall=17072
2023-03-15 18:44:18 - progress_bar.py[line:272] - INFO: epoch 025:   1870 / 2004 loss=0.18, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=343.6, nsentences=8, sample_size=343.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=972.7, ups=2.83, wpb=343.6, bsz=8, num_updates=49650, lr=5.09587e-05, gnorm=2.502, clip=0, loss_scale=256, train_wall=3, gb_free=14.5, wall=17075
2023-03-15 18:44:21 - progress_bar.py[line:272] - INFO: epoch 025:   1880 / 2004 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=332, nsentences=8, sample_size=332, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=948.6, ups=2.86, wpb=332, bsz=8, num_updates=49660, lr=5.09486e-05, gnorm=2.188, clip=0, loss_scale=256, train_wall=3, gb_free=15.3, wall=17079
2023-03-15 18:44:25 - progress_bar.py[line:272] - INFO: epoch 025:   1890 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=323, nsentences=8, sample_size=323, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=919.3, ups=2.85, wpb=323, bsz=8, num_updates=49670, lr=5.09385e-05, gnorm=2.207, clip=0, loss_scale=256, train_wall=3, gb_free=14.6, wall=17083
2023-03-15 18:44:28 - progress_bar.py[line:272] - INFO: epoch 025:   1900 / 2004 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=352.6, nsentences=8, sample_size=352.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1019.1, ups=2.89, wpb=352.6, bsz=8, num_updates=49680, lr=5.09284e-05, gnorm=2.109, clip=0, loss_scale=512, train_wall=3, gb_free=14.5, wall=17086
2023-03-15 18:44:32 - progress_bar.py[line:272] - INFO: epoch 025:   1910 / 2004 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=339.3, nsentences=8, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1013.1, ups=2.99, wpb=339.3, bsz=8, num_updates=49690, lr=5.09184e-05, gnorm=2.179, clip=0, loss_scale=512, train_wall=3, gb_free=14.6, wall=17089
2023-03-15 18:44:35 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-03-15 18:44:35 - progress_bar.py[line:272] - INFO: epoch 025:   1921 / 2004 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=326.3, nsentences=8, sample_size=326.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=894.2, ups=2.74, wpb=326.3, bsz=8, num_updates=49700, lr=5.09083e-05, gnorm=2.303, clip=0, loss_scale=256, train_wall=4, gb_free=15.4, wall=17093
2023-03-15 18:44:39 - progress_bar.py[line:272] - INFO: epoch 025:   1931 / 2004 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=326.7, nsentences=8, sample_size=326.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=953.7, ups=2.92, wpb=326.7, bsz=8, num_updates=49710, lr=5.08982e-05, gnorm=2.382, clip=0, loss_scale=256, train_wall=3, gb_free=14.9, wall=17096
2023-03-15 18:44:42 - progress_bar.py[line:272] - INFO: epoch 025:   1941 / 2004 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=341.3, nsentences=8, sample_size=341.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=960.7, ups=2.81, wpb=341.3, bsz=8, num_updates=49720, lr=5.08881e-05, gnorm=2.06, clip=0, loss_scale=256, train_wall=3, gb_free=14.8, wall=17100
2023-03-15 18:44:46 - progress_bar.py[line:272] - INFO: epoch 025:   1951 / 2004 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=340.2, nsentences=8, sample_size=340.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=976.1, ups=2.87, wpb=340.2, bsz=8, num_updates=49730, lr=5.0878e-05, gnorm=2.141, clip=0, loss_scale=256, train_wall=3, gb_free=15.2, wall=17103
2023-03-15 18:44:49 - progress_bar.py[line:272] - INFO: epoch 025:   1961 / 2004 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=363.8, nsentences=8, sample_size=363.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1029.7, ups=2.83, wpb=363.8, bsz=8, num_updates=49740, lr=5.0868e-05, gnorm=2.212, clip=0, loss_scale=256, train_wall=3, gb_free=15.4, wall=17107
2023-03-15 18:44:53 - progress_bar.py[line:272] - INFO: epoch 025:   1971 / 2004 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=357.7, nsentences=8, sample_size=357.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1015.7, ups=2.84, wpb=357.7, bsz=8, num_updates=49750, lr=5.08579e-05, gnorm=2.335, clip=0, loss_scale=256, train_wall=3, gb_free=14.1, wall=17110
2023-03-15 18:44:57 - progress_bar.py[line:272] - INFO: epoch 025:   1981 / 2004 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=321.6, nsentences=8, sample_size=321.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=721.9, ups=2.24, wpb=321.6, bsz=8, num_updates=49760, lr=5.08478e-05, gnorm=2.432, clip=0, loss_scale=256, train_wall=4, gb_free=15.4, wall=17115
2023-03-15 18:45:01 - progress_bar.py[line:272] - INFO: epoch 025:   1991 / 2004 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=360.9, nsentences=8, sample_size=360.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1023.2, ups=2.84, wpb=360.9, bsz=8, num_updates=49770, lr=5.08377e-05, gnorm=2.042, clip=0, loss_scale=256, train_wall=3, gb_free=14.9, wall=17118
2023-03-15 18:45:04 - progress_bar.py[line:272] - INFO: epoch 025:   2001 / 2004 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=370.4, nsentences=8, sample_size=370.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1107.9, ups=2.99, wpb=370.4, bsz=8, num_updates=49780, lr=5.08276e-05, gnorm=2.171, clip=0, loss_scale=256, train_wall=3, gb_free=14.8, wall=17122
2023-03-15 18:45:05 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 25 @ 49783 updates
2023-03-15 18:45:05 - trainer.py[line:431] - INFO: Saving checkpoint to ./checkpoints/checkpoint25.pt
2023-03-15 18:45:12 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./checkpoints/checkpoint25.pt
2023-03-15 18:45:13 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./checkpoints/checkpoint25.pt (epoch 25 @ 49783 updates, score None) (writing took 8.16251564398408 seconds)
2023-03-15 18:45:14 - train.py[line:332] - INFO: end of epoch 25 (average epoch stats below)
2023-03-15 18:45:14 - progress_bar.py[line:282] - INFO: epoch 025 | loss 0.165 | loss_v1 0 | loss_v2 0 | nll_loss 0.165 | ntokens 345.633 | nsentences 7.999 | sample_size 345.633 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.12 | wps 975.2 | ups 2.82 | wpb 345.6 | bsz 8 | num_updates 49783 | lr 5.08246e-05 | gnorm 2.27 | clip 0 | loss_scale 256 | train_wall 673 | gb_free 13.9 | wall 17131
2023-03-15 18:45:14 - trainer.py[line:639] - INFO: loading train data for epoch 26
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 row count 8015 total row count 8015
slice_id 0 seek offset 0
2023-03-15 18:45:14 - trainer.py[line:703] - INFO: begin training epoch 26
2023-03-15 18:45:14 - train.py[line:305] - INFO: Start iterating over samples
2023-03-15 18:45:17 - progress_bar.py[line:272] - INFO: epoch 026:      7 / 2004 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=384.9, nsentences=8, sample_size=384.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=304.6, ups=0.79, wpb=384.9, bsz=8, num_updates=49790, lr=5.08176e-05, gnorm=2.253, clip=0, loss_scale=256, train_wall=3, gb_free=15.7, wall=17134
2023-03-15 18:45:20 - progress_bar.py[line:272] - INFO: epoch 026:     17 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=320.8, nsentences=8, sample_size=320.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=923, ups=2.88, wpb=320.8, bsz=8, num_updates=49800, lr=5.08075e-05, gnorm=2.259, clip=0, loss_scale=256, train_wall=3, gb_free=14.6, wall=17138
2023-03-15 18:45:24 - progress_bar.py[line:272] - INFO: epoch 026:     27 / 2004 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=357.9, nsentences=8, sample_size=357.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1031.4, ups=2.88, wpb=357.9, bsz=8, num_updates=49810, lr=5.07974e-05, gnorm=2.313, clip=0, loss_scale=256, train_wall=3, gb_free=15, wall=17141
2023-03-15 18:45:27 - progress_bar.py[line:272] - INFO: epoch 026:     37 / 2004 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=347.8, nsentences=8, sample_size=347.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1000.9, ups=2.88, wpb=347.8, bsz=8, num_updates=49820, lr=5.07873e-05, gnorm=1.939, clip=0, loss_scale=256, train_wall=3, gb_free=14.8, wall=17145
2023-03-15 18:45:31 - progress_bar.py[line:272] - INFO: epoch 026:     47 / 2004 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=350.5, nsentences=8, sample_size=350.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1006.5, ups=2.87, wpb=350.5, bsz=8, num_updates=49830, lr=5.07772e-05, gnorm=1.943, clip=0, loss_scale=512, train_wall=3, gb_free=15.5, wall=17148
2023-03-15 18:45:34 - progress_bar.py[line:272] - INFO: epoch 026:     57 / 2004 loss=0.175, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=360.4, nsentences=8, sample_size=360.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1053, ups=2.92, wpb=360.4, bsz=8, num_updates=49840, lr=5.07672e-05, gnorm=2.311, clip=0, loss_scale=512, train_wall=3, gb_free=15.3, wall=17152
2023-03-15 18:45:38 - progress_bar.py[line:272] - INFO: epoch 026:     67 / 2004 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=328.9, nsentences=8, sample_size=328.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=957, ups=2.91, wpb=328.9, bsz=8, num_updates=49850, lr=5.07571e-05, gnorm=1.89, clip=0, loss_scale=512, train_wall=3, gb_free=14.9, wall=17155
2023-03-15 18:45:41 - progress_bar.py[line:272] - INFO: epoch 026:     77 / 2004 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=336.2, nsentences=8, sample_size=336.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=995.4, ups=2.96, wpb=336.2, bsz=8, num_updates=49860, lr=5.0747e-05, gnorm=2.17, clip=0, loss_scale=512, train_wall=3, gb_free=15, wall=17159
2023-03-15 18:45:44 - progress_bar.py[line:272] - INFO: epoch 026:     87 / 2004 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=353.6, nsentences=8, sample_size=353.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1019.7, ups=2.88, wpb=353.6, bsz=8, num_updates=49870, lr=5.07369e-05, gnorm=2.141, clip=0, loss_scale=512, train_wall=3, gb_free=14.9, wall=17162
2023-03-15 18:45:48 - progress_bar.py[line:272] - INFO: epoch 026:     97 / 2004 loss=0.189, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=371.5, nsentences=8, sample_size=371.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=1064.7, ups=2.87, wpb=371.5, bsz=8, num_updates=49880, lr=5.07268e-05, gnorm=2.608, clip=10, loss_scale=512, train_wall=3, gb_free=14.9, wall=17166
2023-03-15 18:45:51 - progress_bar.py[line:272] - INFO: epoch 026:    107 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=363.5, nsentences=8, sample_size=363.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1038.8, ups=2.86, wpb=363.5, bsz=8, num_updates=49890, lr=5.07167e-05, gnorm=2.247, clip=0, loss_scale=512, train_wall=3, gb_free=14.7, wall=17169
2023-03-15 18:45:55 - progress_bar.py[line:272] - INFO: epoch 026:    117 / 2004 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=328.6, nsentences=8, sample_size=328.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1038.4, ups=3.16, wpb=328.6, bsz=8, num_updates=49900, lr=5.07067e-05, gnorm=2.152, clip=0, loss_scale=512, train_wall=3, gb_free=15.6, wall=17172
2023-03-15 18:45:58 - progress_bar.py[line:272] - INFO: epoch 026:    127 / 2004 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=344.5, nsentences=8, sample_size=344.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1064.6, ups=3.09, wpb=344.5, bsz=8, num_updates=49910, lr=5.06966e-05, gnorm=2.264, clip=0, loss_scale=512, train_wall=3, gb_free=14.9, wall=17175
2023-03-15 18:46:01 - progress_bar.py[line:272] - INFO: epoch 026:    137 / 2004 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=325.1, nsentences=8, sample_size=325.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=991, ups=3.05, wpb=325.1, bsz=8, num_updates=49920, lr=5.06865e-05, gnorm=2.199, clip=0, loss_scale=512, train_wall=3, gb_free=14.8, wall=17179
2023-03-15 18:46:05 - progress_bar.py[line:272] - INFO: epoch 026:    147 / 2004 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=336.8, nsentences=8, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=983.1, ups=2.92, wpb=336.8, bsz=8, num_updates=49930, lr=5.06764e-05, gnorm=2.016, clip=0, loss_scale=512, train_wall=3, gb_free=14.7, wall=17182
2023-03-15 18:46:08 - progress_bar.py[line:272] - INFO: epoch 026:    157 / 2004 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=342.5, nsentences=8, sample_size=342.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=988.3, ups=2.89, wpb=342.5, bsz=8, num_updates=49940, lr=5.06663e-05, gnorm=1.86, clip=0, loss_scale=512, train_wall=3, gb_free=15.3, wall=17186
2023-03-15 18:46:11 - progress_bar.py[line:272] - INFO: epoch 026:    167 / 2004 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=351.3, nsentences=8, sample_size=351.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1036.3, ups=2.95, wpb=351.3, bsz=8, num_updates=49950, lr=5.06563e-05, gnorm=2.11, clip=0, loss_scale=512, train_wall=3, gb_free=15.2, wall=17189
2023-03-15 18:46:15 - progress_bar.py[line:272] - INFO: epoch 026:    177 / 2004 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=336.2, nsentences=8, sample_size=336.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=989.4, ups=2.94, wpb=336.2, bsz=8, num_updates=49960, lr=5.06462e-05, gnorm=2.297, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=17192
2023-03-15 18:46:18 - progress_bar.py[line:272] - INFO: epoch 026:    187 / 2004 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=330.2, nsentences=8, sample_size=330.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=976.2, ups=2.96, wpb=330.2, bsz=8, num_updates=49970, lr=5.06361e-05, gnorm=1.892, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=17196
2023-03-15 18:46:22 - progress_bar.py[line:272] - INFO: epoch 026:    197 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=319.2, nsentences=8, sample_size=319.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=941.4, ups=2.95, wpb=319.2, bsz=8, num_updates=49980, lr=5.0626e-05, gnorm=2.194, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=17199
2023-03-15 18:46:25 - progress_bar.py[line:272] - INFO: epoch 026:    207 / 2004 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=346.4, nsentences=8, sample_size=346.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1116.1, ups=3.22, wpb=346.4, bsz=8, num_updates=49990, lr=5.06159e-05, gnorm=2.272, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=17202
2023-03-15 18:46:28 - progress_bar.py[line:272] - INFO: epoch 026:    217 / 2004 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=321.6, nsentences=8, sample_size=321.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1039.8, ups=3.23, wpb=321.6, bsz=8, num_updates=50000, lr=5.06059e-05, gnorm=2.101, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=17205
2023-03-15 18:46:31 - progress_bar.py[line:272] - INFO: epoch 026:    227 / 2004 loss=0.132, loss_v1=0, loss_v2=0, nll_loss=0.132, ntokens=347.8, nsentences=8, sample_size=347.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1118, ups=3.21, wpb=347.8, bsz=8, num_updates=50010, lr=5.05958e-05, gnorm=1.856, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=17209
2023-03-15 18:46:34 - progress_bar.py[line:272] - INFO: epoch 026:    237 / 2004 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=375.8, nsentences=8, sample_size=375.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1155.1, ups=3.07, wpb=375.8, bsz=8, num_updates=50020, lr=5.05857e-05, gnorm=2.085, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=17212
2023-03-15 18:46:37 - progress_bar.py[line:272] - INFO: epoch 026:    247 / 2004 loss=0.21, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=347.4, nsentences=8, sample_size=347.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=1092.7, ups=3.15, wpb=347.4, bsz=8, num_updates=50030, lr=5.05756e-05, gnorm=2.87, clip=10, loss_scale=1024, train_wall=3, gb_free=15.1, wall=17215
2023-03-15 18:46:41 - progress_bar.py[line:272] - INFO: epoch 026:    257 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=336.8, nsentences=8, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1058.9, ups=3.14, wpb=336.8, bsz=8, num_updates=50040, lr=5.05655e-05, gnorm=2.054, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=17218
2023-03-15 18:46:44 - progress_bar.py[line:272] - INFO: epoch 026:    267 / 2004 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=352.4, nsentences=8, sample_size=352.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1076.7, ups=3.06, wpb=352.4, bsz=8, num_updates=50050, lr=5.05555e-05, gnorm=2.293, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=17221
2023-03-15 18:46:47 - progress_bar.py[line:272] - INFO: epoch 026:    277 / 2004 loss=0.171, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=345.8, nsentences=8, sample_size=345.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=991.5, ups=2.87, wpb=345.8, bsz=8, num_updates=50060, lr=5.05454e-05, gnorm=2.175, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=17225
2023-03-15 18:46:51 - progress_bar.py[line:272] - INFO: epoch 026:    287 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=357.4, nsentences=8, sample_size=357.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1036, ups=2.9, wpb=357.4, bsz=8, num_updates=50070, lr=5.05353e-05, gnorm=2.099, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=17228
2023-03-15 18:46:54 - progress_bar.py[line:272] - INFO: epoch 026:    297 / 2004 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=374.1, nsentences=8, sample_size=374.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1062.3, ups=2.84, wpb=374.1, bsz=8, num_updates=50080, lr=5.05252e-05, gnorm=2.321, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=17232
2023-03-15 18:46:58 - progress_bar.py[line:272] - INFO: epoch 026:    307 / 2004 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=336, nsentences=8, sample_size=336, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=984, ups=2.93, wpb=336, bsz=8, num_updates=50090, lr=5.05151e-05, gnorm=2.061, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=17235
2023-03-15 18:47:01 - progress_bar.py[line:272] - INFO: epoch 026:    317 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=348, nsentences=8, sample_size=348, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1020.7, ups=2.93, wpb=348, bsz=8, num_updates=50100, lr=5.05051e-05, gnorm=2.283, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=17239
2023-03-15 18:47:04 - progress_bar.py[line:272] - INFO: epoch 026:    327 / 2004 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=323.6, nsentences=8, sample_size=323.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=946.3, ups=2.92, wpb=323.6, bsz=8, num_updates=50110, lr=5.0495e-05, gnorm=2.069, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=17242
2023-03-15 18:47:08 - progress_bar.py[line:272] - INFO: epoch 026:    337 / 2004 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=342.5, nsentences=8, sample_size=342.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=995.1, ups=2.91, wpb=342.5, bsz=8, num_updates=50120, lr=5.04849e-05, gnorm=2.109, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=17246
2023-03-15 18:47:11 - progress_bar.py[line:272] - INFO: epoch 026:    347 / 2004 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=374.8, nsentences=8, sample_size=374.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1076.1, ups=2.87, wpb=374.8, bsz=8, num_updates=50130, lr=5.04748e-05, gnorm=2.326, clip=10, loss_scale=2048, train_wall=3, gb_free=15, wall=17249
2023-03-15 18:47:15 - progress_bar.py[line:272] - INFO: epoch 026:    357 / 2004 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=353.3, nsentences=8, sample_size=353.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1007.1, ups=2.85, wpb=353.3, bsz=8, num_updates=50140, lr=5.04647e-05, gnorm=2.021, clip=0, loss_scale=2048, train_wall=3, gb_free=13.8, wall=17253
2023-03-15 18:47:18 - progress_bar.py[line:272] - INFO: epoch 026:    367 / 2004 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=351.7, nsentences=8, sample_size=351.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1081.5, ups=3.08, wpb=351.7, bsz=8, num_updates=50150, lr=5.04546e-05, gnorm=2.131, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=17256
2023-03-15 18:47:21 - progress_bar.py[line:272] - INFO: epoch 026:    377 / 2004 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=302.3, nsentences=8, sample_size=302.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=952.8, ups=3.15, wpb=302.3, bsz=8, num_updates=50160, lr=5.04446e-05, gnorm=2.08, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=17259
2023-03-15 18:47:25 - progress_bar.py[line:272] - INFO: epoch 026:    387 / 2004 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=336.1, nsentences=8, sample_size=336.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1045.8, ups=3.11, wpb=336.1, bsz=8, num_updates=50170, lr=5.04345e-05, gnorm=2.254, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=17262
2023-03-15 18:47:28 - progress_bar.py[line:272] - INFO: epoch 026:    397 / 2004 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=347, nsentences=8, sample_size=347, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1102.3, ups=3.18, wpb=347, bsz=8, num_updates=50180, lr=5.04244e-05, gnorm=2.191, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=17265
2023-03-15 18:47:31 - progress_bar.py[line:272] - INFO: epoch 026:    407 / 2004 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=382, nsentences=8, sample_size=382, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1166.7, ups=3.05, wpb=382, bsz=8, num_updates=50190, lr=5.04143e-05, gnorm=2.059, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=17269
2023-03-15 18:47:34 - progress_bar.py[line:272] - INFO: epoch 026:    417 / 2004 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=337.8, nsentences=8, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1072.2, ups=3.17, wpb=337.8, bsz=8, num_updates=50200, lr=5.04042e-05, gnorm=2.216, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=17272
2023-03-15 18:47:37 - progress_bar.py[line:272] - INFO: epoch 026:    427 / 2004 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=338.1, nsentences=8, sample_size=338.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1084.4, ups=3.21, wpb=338.1, bsz=8, num_updates=50210, lr=5.03942e-05, gnorm=2.257, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=17275
2023-03-15 18:47:39 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 18:47:41 - progress_bar.py[line:272] - INFO: epoch 026:    438 / 2004 loss=0.134, loss_v1=0, loss_v2=0, nll_loss=0.134, ntokens=337.9, nsentences=8, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=987.2, ups=2.92, wpb=337.9, bsz=8, num_updates=50220, lr=5.03841e-05, gnorm=1.845, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=17278
2023-03-15 18:47:44 - progress_bar.py[line:272] - INFO: epoch 026:    448 / 2004 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=377.2, nsentences=8, sample_size=377.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1146, ups=3.04, wpb=377.2, bsz=8, num_updates=50230, lr=5.0374e-05, gnorm=2.147, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=17282
2023-03-15 18:47:47 - progress_bar.py[line:272] - INFO: epoch 026:    458 / 2004 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=394, nsentences=8, sample_size=394, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1235.6, ups=3.14, wpb=394, bsz=8, num_updates=50240, lr=5.03639e-05, gnorm=2.24, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=17285
2023-03-15 18:47:50 - progress_bar.py[line:272] - INFO: epoch 026:    468 / 2004 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=358.4, nsentences=8, sample_size=358.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1112.9, ups=3.11, wpb=358.4, bsz=8, num_updates=50250, lr=5.03538e-05, gnorm=2.279, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=17288
2023-03-15 18:47:54 - progress_bar.py[line:272] - INFO: epoch 026:    478 / 2004 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=338.3, nsentences=8, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1070.5, ups=3.16, wpb=338.3, bsz=8, num_updates=50260, lr=5.03438e-05, gnorm=2.13, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=17291
2023-03-15 18:47:57 - progress_bar.py[line:272] - INFO: epoch 026:    488 / 2004 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=375.5, nsentences=8, sample_size=375.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1180.7, ups=3.14, wpb=375.5, bsz=8, num_updates=50270, lr=5.03337e-05, gnorm=2.429, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=17294
2023-03-15 18:48:00 - progress_bar.py[line:272] - INFO: epoch 026:    498 / 2004 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=365.1, nsentences=8, sample_size=365.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1152.5, ups=3.16, wpb=365.1, bsz=8, num_updates=50280, lr=5.03236e-05, gnorm=2.27, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=17298
2023-03-15 18:48:03 - progress_bar.py[line:272] - INFO: epoch 026:    508 / 2004 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=352.5, nsentences=8, sample_size=352.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1118.7, ups=3.17, wpb=352.5, bsz=8, num_updates=50290, lr=5.03135e-05, gnorm=2.404, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=17301
2023-03-15 18:48:06 - progress_bar.py[line:272] - INFO: epoch 026:    518 / 2004 loss=0.178, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=351.6, nsentences=8, sample_size=351.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1091.8, ups=3.11, wpb=351.6, bsz=8, num_updates=50300, lr=5.03034e-05, gnorm=2.655, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=17304
2023-03-15 18:48:09 - progress_bar.py[line:272] - INFO: epoch 026:    528 / 2004 loss=0.171, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=402.8, nsentences=8, sample_size=402.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1248.1, ups=3.1, wpb=402.8, bsz=8, num_updates=50310, lr=5.02934e-05, gnorm=2.534, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=17307
2023-03-15 18:48:13 - progress_bar.py[line:272] - INFO: epoch 026:    538 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=385.5, nsentences=8, sample_size=385.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1214.2, ups=3.15, wpb=385.5, bsz=8, num_updates=50320, lr=5.02833e-05, gnorm=2.365, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=17310
2023-03-15 18:48:16 - progress_bar.py[line:272] - INFO: epoch 026:    548 / 2004 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=350.6, nsentences=8, sample_size=350.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1126.6, ups=3.21, wpb=350.6, bsz=8, num_updates=50330, lr=5.02732e-05, gnorm=2.206, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=17313
2023-03-15 18:48:19 - progress_bar.py[line:272] - INFO: epoch 026:    558 / 2004 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=378.2, nsentences=8, sample_size=378.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1215.8, ups=3.21, wpb=378.2, bsz=8, num_updates=50340, lr=5.02631e-05, gnorm=2.233, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=17316
2023-03-15 18:48:21 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 18:48:22 - progress_bar.py[line:272] - INFO: epoch 026:    569 / 2004 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=355.4, nsentences=8, sample_size=355.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1025.8, ups=2.89, wpb=355.4, bsz=8, num_updates=50350, lr=5.0253e-05, gnorm=1.973, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=17320
2023-03-15 18:48:26 - progress_bar.py[line:272] - INFO: epoch 026:    579 / 2004 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=322.4, nsentences=8, sample_size=322.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1015.7, ups=3.15, wpb=322.4, bsz=8, num_updates=50360, lr=5.02429e-05, gnorm=2.046, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=17323
2023-03-15 18:48:27 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 18:48:29 - progress_bar.py[line:272] - INFO: epoch 026:    590 / 2004 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=375.5, nsentences=8, sample_size=375.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1077.6, ups=2.87, wpb=375.5, bsz=8, num_updates=50370, lr=5.02329e-05, gnorm=2.234, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=17327
2023-03-15 18:48:32 - progress_bar.py[line:272] - INFO: epoch 026:    600 / 2004 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=349.1, nsentences=8, sample_size=349.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1088.1, ups=3.12, wpb=349.1, bsz=8, num_updates=50380, lr=5.02228e-05, gnorm=2.003, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=17330
2023-03-15 18:48:35 - progress_bar.py[line:272] - INFO: epoch 026:    610 / 2004 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=335.9, nsentences=8, sample_size=335.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1064.4, ups=3.17, wpb=335.9, bsz=8, num_updates=50390, lr=5.02127e-05, gnorm=2.283, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=17333
2023-03-15 18:48:39 - progress_bar.py[line:272] - INFO: epoch 026:    620 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=370.2, nsentences=8, sample_size=370.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1177.4, ups=3.18, wpb=370.2, bsz=8, num_updates=50400, lr=5.02026e-05, gnorm=2.401, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=17336
2023-03-15 18:48:42 - progress_bar.py[line:272] - INFO: epoch 026:    630 / 2004 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=347.8, nsentences=8, sample_size=347.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1097.2, ups=3.15, wpb=347.8, bsz=8, num_updates=50410, lr=5.01925e-05, gnorm=2.254, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=17339
2023-03-15 18:48:45 - progress_bar.py[line:272] - INFO: epoch 026:    640 / 2004 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=347.1, nsentences=8, sample_size=347.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1100.8, ups=3.17, wpb=347.1, bsz=8, num_updates=50420, lr=5.01825e-05, gnorm=2.104, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=17342
2023-03-15 18:48:48 - progress_bar.py[line:272] - INFO: epoch 026:    650 / 2004 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=321.3, nsentences=8, sample_size=321.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1026, ups=3.19, wpb=321.3, bsz=8, num_updates=50430, lr=5.01724e-05, gnorm=1.967, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=17346
2023-03-15 18:48:51 - progress_bar.py[line:272] - INFO: epoch 026:    660 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=341.3, nsentences=8, sample_size=341.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1080.6, ups=3.17, wpb=341.3, bsz=8, num_updates=50440, lr=5.01623e-05, gnorm=2.036, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=17349
2023-03-15 18:48:54 - progress_bar.py[line:272] - INFO: epoch 026:    670 / 2004 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=323.1, nsentences=8, sample_size=323.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1049.7, ups=3.25, wpb=323.1, bsz=8, num_updates=50450, lr=5.01522e-05, gnorm=2.23, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=17352
2023-03-15 18:48:57 - progress_bar.py[line:272] - INFO: epoch 026:    680 / 2004 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=332.9, nsentences=8, sample_size=332.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1038.8, ups=3.12, wpb=332.9, bsz=8, num_updates=50460, lr=5.01421e-05, gnorm=2.181, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=17355
2023-03-15 18:49:01 - progress_bar.py[line:272] - INFO: epoch 026:    690 / 2004 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=355.4, nsentences=8, sample_size=355.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1128.6, ups=3.18, wpb=355.4, bsz=8, num_updates=50470, lr=5.01321e-05, gnorm=2.375, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=17358
2023-03-15 18:49:04 - progress_bar.py[line:272] - INFO: epoch 026:    700 / 2004 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=341, nsentences=8, sample_size=341, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1083, ups=3.18, wpb=341, bsz=8, num_updates=50480, lr=5.0122e-05, gnorm=2.36, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=17361
2023-03-15 18:49:07 - progress_bar.py[line:272] - INFO: epoch 026:    710 / 2004 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=334.2, nsentences=8, sample_size=334.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1058, ups=3.17, wpb=334.2, bsz=8, num_updates=50490, lr=5.01119e-05, gnorm=2.236, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=17364
2023-03-15 18:49:10 - progress_bar.py[line:272] - INFO: epoch 026:    720 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=351.7, nsentences=8, sample_size=351.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1128.5, ups=3.21, wpb=351.7, bsz=8, num_updates=50500, lr=5.01018e-05, gnorm=2.114, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=17368
2023-03-15 18:49:13 - progress_bar.py[line:272] - INFO: epoch 026:    730 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=355.5, nsentences=8, sample_size=355.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1120.4, ups=3.15, wpb=355.5, bsz=8, num_updates=50510, lr=5.00917e-05, gnorm=2.225, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=17371
2023-03-15 18:49:16 - progress_bar.py[line:272] - INFO: epoch 026:    740 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=330.9, nsentences=8, sample_size=330.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1070, ups=3.23, wpb=330.9, bsz=8, num_updates=50520, lr=5.00817e-05, gnorm=2.069, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=17374
2023-03-15 18:49:19 - progress_bar.py[line:272] - INFO: epoch 026:    750 / 2004 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=367.4, nsentences=8, sample_size=367.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1168.5, ups=3.18, wpb=367.4, bsz=8, num_updates=50530, lr=5.00716e-05, gnorm=2.328, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=17377
2023-03-15 18:49:23 - progress_bar.py[line:272] - INFO: epoch 026:    760 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=305.9, nsentences=8, sample_size=305.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=982.2, ups=3.21, wpb=305.9, bsz=8, num_updates=50540, lr=5.00615e-05, gnorm=1.969, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=17380
2023-03-15 18:49:26 - progress_bar.py[line:272] - INFO: epoch 026:    770 / 2004 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=412.1, nsentences=8, sample_size=412.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1268, ups=3.08, wpb=412.1, bsz=8, num_updates=50550, lr=5.00514e-05, gnorm=2.179, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=17383
2023-03-15 18:49:29 - progress_bar.py[line:272] - INFO: epoch 026:    780 / 2004 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=326.4, nsentences=8, sample_size=326.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1037.9, ups=3.18, wpb=326.4, bsz=8, num_updates=50560, lr=5.00413e-05, gnorm=2.273, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=17387
2023-03-15 18:49:32 - progress_bar.py[line:272] - INFO: epoch 026:    790 / 2004 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=352, nsentences=8, sample_size=352, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1125, ups=3.2, wpb=352, bsz=8, num_updates=50570, lr=5.00313e-05, gnorm=1.865, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=17390
2023-03-15 18:49:35 - progress_bar.py[line:272] - INFO: epoch 026:    800 / 2004 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=324.6, nsentences=8, sample_size=324.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1045.2, ups=3.22, wpb=324.6, bsz=8, num_updates=50580, lr=5.00212e-05, gnorm=2.091, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=17393
2023-03-15 18:49:38 - progress_bar.py[line:272] - INFO: epoch 026:    810 / 2004 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=352.2, nsentences=8, sample_size=352.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1106.9, ups=3.14, wpb=352.2, bsz=8, num_updates=50590, lr=5.00111e-05, gnorm=2.191, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=17396
2023-03-15 18:49:41 - progress_bar.py[line:272] - INFO: epoch 026:    820 / 2004 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=315.2, nsentences=8, sample_size=315.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1007.4, ups=3.2, wpb=315.2, bsz=8, num_updates=50600, lr=5.0001e-05, gnorm=2.067, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=17399
2023-03-15 18:49:45 - progress_bar.py[line:272] - INFO: epoch 026:    830 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=364.8, nsentences=8, sample_size=364.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1140.1, ups=3.13, wpb=364.8, bsz=8, num_updates=50610, lr=4.99909e-05, gnorm=2.176, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=17402
2023-03-15 18:49:48 - progress_bar.py[line:272] - INFO: epoch 026:    840 / 2004 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=347.7, nsentences=8, sample_size=347.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1094.3, ups=3.15, wpb=347.7, bsz=8, num_updates=50620, lr=4.99808e-05, gnorm=2.318, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=17405
2023-03-15 18:49:51 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 18:49:51 - progress_bar.py[line:272] - INFO: epoch 026:    851 / 2004 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=353.3, nsentences=8, sample_size=353.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1023.4, ups=2.9, wpb=353.3, bsz=8, num_updates=50630, lr=4.99708e-05, gnorm=1.74, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=17409
2023-03-15 18:49:54 - progress_bar.py[line:272] - INFO: epoch 026:    861 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=345, nsentences=8, sample_size=345, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1106.5, ups=3.21, wpb=345, bsz=8, num_updates=50640, lr=4.99607e-05, gnorm=2.047, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=17412
2023-03-15 18:49:58 - progress_bar.py[line:272] - INFO: epoch 026:    871 / 2004 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=373.7, nsentences=8, sample_size=373.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1188.1, ups=3.18, wpb=373.7, bsz=8, num_updates=50650, lr=4.99506e-05, gnorm=2.246, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=17415
2023-03-15 18:50:01 - progress_bar.py[line:272] - INFO: epoch 026:    881 / 2004 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=313.5, nsentences=8, sample_size=313.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1010.7, ups=3.22, wpb=313.5, bsz=8, num_updates=50660, lr=4.99405e-05, gnorm=2.25, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=17418
2023-03-15 18:50:04 - progress_bar.py[line:272] - INFO: epoch 026:    891 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=320.9, nsentences=8, sample_size=320.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1005.9, ups=3.13, wpb=320.9, bsz=8, num_updates=50670, lr=4.99304e-05, gnorm=2.165, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=17421
2023-03-15 18:50:07 - progress_bar.py[line:272] - INFO: epoch 026:    901 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=364.7, nsentences=8, sample_size=364.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1124.7, ups=3.08, wpb=364.7, bsz=8, num_updates=50680, lr=4.99204e-05, gnorm=2.151, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=17425
2023-03-15 18:50:10 - progress_bar.py[line:272] - INFO: epoch 026:    911 / 2004 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=354, nsentences=8, sample_size=354, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1134.6, ups=3.21, wpb=354, bsz=8, num_updates=50690, lr=4.99103e-05, gnorm=1.958, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=17428
2023-03-15 18:50:13 - progress_bar.py[line:272] - INFO: epoch 026:    921 / 2004 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=345.4, nsentences=8, sample_size=345.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1104.4, ups=3.2, wpb=345.4, bsz=8, num_updates=50700, lr=4.99002e-05, gnorm=2.219, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=17431
2023-03-15 18:50:16 - progress_bar.py[line:272] - INFO: epoch 026:    931 / 2004 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=333, nsentences=8, sample_size=333, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1068.9, ups=3.21, wpb=333, bsz=8, num_updates=50710, lr=4.98901e-05, gnorm=2.036, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=17434
2023-03-15 18:50:20 - progress_bar.py[line:272] - INFO: epoch 026:    941 / 2004 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=368.6, nsentences=8, sample_size=368.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1161.9, ups=3.15, wpb=368.6, bsz=8, num_updates=50720, lr=4.988e-05, gnorm=2.073, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=17437
2023-03-15 18:50:23 - progress_bar.py[line:272] - INFO: epoch 026:    951 / 2004 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=351.3, nsentences=8, sample_size=351.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1106.3, ups=3.15, wpb=351.3, bsz=8, num_updates=50730, lr=4.987e-05, gnorm=2.17, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=17440
2023-03-15 18:50:26 - progress_bar.py[line:272] - INFO: epoch 026:    961 / 2004 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=382.9, nsentences=8, sample_size=382.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1229, ups=3.21, wpb=382.9, bsz=8, num_updates=50740, lr=4.98599e-05, gnorm=1.932, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=17444
2023-03-15 18:50:29 - progress_bar.py[line:272] - INFO: epoch 026:    971 / 2004 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=325.6, nsentences=8, sample_size=325.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1026.5, ups=3.15, wpb=325.6, bsz=8, num_updates=50750, lr=4.98498e-05, gnorm=1.953, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=17447
2023-03-15 18:50:32 - progress_bar.py[line:272] - INFO: epoch 026:    981 / 2004 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=317.9, nsentences=8, sample_size=317.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1024.9, ups=3.22, wpb=317.9, bsz=8, num_updates=50760, lr=4.98397e-05, gnorm=1.982, clip=0, loss_scale=4096, train_wall=3, gb_free=15.5, wall=17450
2023-03-15 18:50:32 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 18:50:36 - progress_bar.py[line:272] - INFO: epoch 026:    992 / 2004 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=380.5, nsentences=8, sample_size=380.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1102.3, ups=2.9, wpb=380.5, bsz=8, num_updates=50770, lr=4.98296e-05, gnorm=2.097, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=17453
2023-03-15 18:50:39 - progress_bar.py[line:272] - INFO: epoch 026:   1002 / 2004 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=334.7, nsentences=8, sample_size=334.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1059.5, ups=3.17, wpb=334.7, bsz=8, num_updates=50780, lr=4.98196e-05, gnorm=2.221, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=17456
2023-03-15 18:50:42 - progress_bar.py[line:272] - INFO: epoch 026:   1012 / 2004 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=329.9, nsentences=8, sample_size=329.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1055.4, ups=3.2, wpb=329.9, bsz=8, num_updates=50790, lr=4.98095e-05, gnorm=2.369, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=17460
2023-03-15 18:50:45 - progress_bar.py[line:272] - INFO: epoch 026:   1022 / 2004 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=319.8, nsentences=8, sample_size=319.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1045.3, ups=3.27, wpb=319.8, bsz=8, num_updates=50800, lr=4.97994e-05, gnorm=2.128, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=17463
2023-03-15 18:50:48 - progress_bar.py[line:272] - INFO: epoch 026:   1032 / 2004 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=331, nsentences=8, sample_size=331, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1056.1, ups=3.19, wpb=331, bsz=8, num_updates=50810, lr=4.97893e-05, gnorm=1.891, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=17466
2023-03-15 18:50:51 - progress_bar.py[line:272] - INFO: epoch 026:   1042 / 2004 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=338.7, nsentences=8, sample_size=338.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1070.1, ups=3.16, wpb=338.7, bsz=8, num_updates=50820, lr=4.97792e-05, gnorm=1.964, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=17469
2023-03-15 18:50:54 - progress_bar.py[line:272] - INFO: epoch 026:   1052 / 2004 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=368, nsentences=8, sample_size=368, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1152, ups=3.13, wpb=368, bsz=8, num_updates=50830, lr=4.97691e-05, gnorm=2.101, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=17472
2023-03-15 18:50:58 - progress_bar.py[line:272] - INFO: epoch 026:   1062 / 2004 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=338.8, nsentences=8, sample_size=338.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1096.1, ups=3.24, wpb=338.8, bsz=8, num_updates=50840, lr=4.97591e-05, gnorm=2.288, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=17475
2023-03-15 18:51:01 - progress_bar.py[line:272] - INFO: epoch 026:   1072 / 2004 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=355.7, nsentences=8, sample_size=355.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1102.4, ups=3.1, wpb=355.7, bsz=8, num_updates=50850, lr=4.9749e-05, gnorm=2.111, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=17478
2023-03-15 18:51:04 - progress_bar.py[line:272] - INFO: epoch 026:   1082 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=368.8, nsentences=8, sample_size=368.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1147.3, ups=3.11, wpb=368.8, bsz=8, num_updates=50860, lr=4.97389e-05, gnorm=2.202, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=17482
2023-03-15 18:51:07 - progress_bar.py[line:272] - INFO: epoch 026:   1092 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=329.3, nsentences=8, sample_size=329.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1056.7, ups=3.21, wpb=329.3, bsz=8, num_updates=50870, lr=4.97288e-05, gnorm=2.241, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=17485
2023-03-15 18:51:10 - progress_bar.py[line:272] - INFO: epoch 026:   1102 / 2004 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=362, nsentences=8, sample_size=362, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1132.9, ups=3.13, wpb=362, bsz=8, num_updates=50880, lr=4.97187e-05, gnorm=2.281, clip=0, loss_scale=2048, train_wall=3, gb_free=13.9, wall=17488
2023-03-15 18:51:14 - progress_bar.py[line:272] - INFO: epoch 026:   1112 / 2004 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=360.1, nsentences=8, sample_size=360.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1131.9, ups=3.14, wpb=360.1, bsz=8, num_updates=50890, lr=4.97087e-05, gnorm=2.154, clip=0, loss_scale=4096, train_wall=3, gb_free=15.1, wall=17491
2023-03-15 18:51:17 - progress_bar.py[line:272] - INFO: epoch 026:   1122 / 2004 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=307.3, nsentences=8, sample_size=307.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1003.3, ups=3.26, wpb=307.3, bsz=8, num_updates=50900, lr=4.96986e-05, gnorm=2.081, clip=0, loss_scale=4096, train_wall=3, gb_free=15.7, wall=17494
2023-03-15 18:51:17 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 18:51:20 - progress_bar.py[line:272] - INFO: epoch 026:   1133 / 2004 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=371.5, nsentences=8, sample_size=371.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1072.9, ups=2.89, wpb=371.5, bsz=8, num_updates=50910, lr=4.96885e-05, gnorm=2.01, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=17498
2023-03-15 18:51:23 - progress_bar.py[line:272] - INFO: epoch 026:   1143 / 2004 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=363.5, nsentences=8, sample_size=363.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1175.7, ups=3.23, wpb=363.5, bsz=8, num_updates=50920, lr=4.96784e-05, gnorm=2.086, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=17501
2023-03-15 18:51:26 - progress_bar.py[line:272] - INFO: epoch 026:   1153 / 2004 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=380.2, nsentences=8, sample_size=380.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1212.2, ups=3.19, wpb=380.2, bsz=8, num_updates=50930, lr=4.96683e-05, gnorm=2.426, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=17504
2023-03-15 18:51:30 - progress_bar.py[line:272] - INFO: epoch 026:   1163 / 2004 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=369.2, nsentences=8, sample_size=369.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1138.7, ups=3.08, wpb=369.2, bsz=8, num_updates=50940, lr=4.96583e-05, gnorm=2.217, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=17507
2023-03-15 18:51:33 - progress_bar.py[line:272] - INFO: epoch 026:   1173 / 2004 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=355.6, nsentences=8, sample_size=355.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1119, ups=3.15, wpb=355.6, bsz=8, num_updates=50950, lr=4.96482e-05, gnorm=2.224, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=17510
2023-03-15 18:51:36 - progress_bar.py[line:272] - INFO: epoch 026:   1183 / 2004 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=333.7, nsentences=8, sample_size=333.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1051.9, ups=3.15, wpb=333.7, bsz=8, num_updates=50960, lr=4.96381e-05, gnorm=2.071, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=17513
2023-03-15 18:51:39 - progress_bar.py[line:272] - INFO: epoch 026:   1193 / 2004 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=362.1, nsentences=8, sample_size=362.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1144.1, ups=3.16, wpb=362.1, bsz=8, num_updates=50970, lr=4.9628e-05, gnorm=2.232, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=17517
2023-03-15 18:51:42 - progress_bar.py[line:272] - INFO: epoch 026:   1203 / 2004 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=324.4, nsentences=8, sample_size=324.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1047.8, ups=3.23, wpb=324.4, bsz=8, num_updates=50980, lr=4.96179e-05, gnorm=1.939, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=17520
2023-03-15 18:51:45 - progress_bar.py[line:272] - INFO: epoch 026:   1213 / 2004 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=286.3, nsentences=8, sample_size=286.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=935.9, ups=3.27, wpb=286.3, bsz=8, num_updates=50990, lr=4.96079e-05, gnorm=2.037, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=17523
2023-03-15 18:51:48 - progress_bar.py[line:272] - INFO: epoch 026:   1223 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=341.2, nsentences=8, sample_size=341.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1081.2, ups=3.17, wpb=341.2, bsz=8, num_updates=51000, lr=4.95978e-05, gnorm=2.11, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=17526
2023-03-15 18:51:51 - progress_bar.py[line:272] - INFO: epoch 026:   1233 / 2004 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=304.3, nsentences=8, sample_size=304.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=985.6, ups=3.24, wpb=304.3, bsz=8, num_updates=51010, lr=4.95877e-05, gnorm=2.067, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=17529
2023-03-15 18:51:55 - progress_bar.py[line:272] - INFO: epoch 026:   1243 / 2004 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=392.9, nsentences=8, sample_size=392.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1216.1, ups=3.1, wpb=392.9, bsz=8, num_updates=51020, lr=4.95776e-05, gnorm=2.152, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=17532
2023-03-15 18:51:58 - progress_bar.py[line:272] - INFO: epoch 026:   1253 / 2004 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=347.9, nsentences=8, sample_size=347.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1097.4, ups=3.15, wpb=347.9, bsz=8, num_updates=51030, lr=4.95675e-05, gnorm=2.091, clip=0, loss_scale=4096, train_wall=3, gb_free=14.9, wall=17535
2023-03-15 18:51:58 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 18:52:01 - progress_bar.py[line:272] - INFO: epoch 026:   1264 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=339.2, nsentences=8, sample_size=339.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=995.4, ups=2.93, wpb=339.2, bsz=8, num_updates=51040, lr=4.95575e-05, gnorm=2.031, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=17539
2023-03-15 18:52:04 - progress_bar.py[line:272] - INFO: epoch 026:   1274 / 2004 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=353.2, nsentences=8, sample_size=353.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1104.1, ups=3.13, wpb=353.2, bsz=8, num_updates=51050, lr=4.95474e-05, gnorm=1.995, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=17542
2023-03-15 18:52:08 - progress_bar.py[line:272] - INFO: epoch 026:   1284 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=329.3, nsentences=8, sample_size=329.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1055.9, ups=3.21, wpb=329.3, bsz=8, num_updates=51060, lr=4.95373e-05, gnorm=2.011, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=17545
2023-03-15 18:52:11 - progress_bar.py[line:272] - INFO: epoch 026:   1294 / 2004 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=308.4, nsentences=8, sample_size=308.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=992.8, ups=3.22, wpb=308.4, bsz=8, num_updates=51070, lr=4.95272e-05, gnorm=2.105, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=17548
2023-03-15 18:52:14 - progress_bar.py[line:272] - INFO: epoch 026:   1304 / 2004 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=325.4, nsentences=8, sample_size=325.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1024.3, ups=3.15, wpb=325.4, bsz=8, num_updates=51080, lr=4.95171e-05, gnorm=1.971, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=17551
2023-03-15 18:52:17 - progress_bar.py[line:272] - INFO: epoch 026:   1314 / 2004 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=330, nsentences=8, sample_size=330, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1049.5, ups=3.18, wpb=330, bsz=8, num_updates=51090, lr=4.9507e-05, gnorm=2.157, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=17555
2023-03-15 18:52:20 - progress_bar.py[line:272] - INFO: epoch 026:   1324 / 2004 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=310.7, nsentences=8, sample_size=310.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=997.6, ups=3.21, wpb=310.7, bsz=8, num_updates=51100, lr=4.9497e-05, gnorm=2.221, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=17558
2023-03-15 18:52:23 - progress_bar.py[line:272] - INFO: epoch 026:   1334 / 2004 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=346.2, nsentences=8, sample_size=346.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1092.2, ups=3.15, wpb=346.2, bsz=8, num_updates=51110, lr=4.94869e-05, gnorm=2.108, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=17561
2023-03-15 18:52:26 - progress_bar.py[line:272] - INFO: epoch 026:   1344 / 2004 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=305.3, nsentences=8, sample_size=305.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=992.2, ups=3.25, wpb=305.3, bsz=8, num_updates=51120, lr=4.94768e-05, gnorm=2.173, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=17564
2023-03-15 18:52:29 - progress_bar.py[line:272] - INFO: epoch 026:   1354 / 2004 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=322.6, nsentences=8, sample_size=322.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1026.2, ups=3.18, wpb=322.6, bsz=8, num_updates=51130, lr=4.94667e-05, gnorm=2.084, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=17567
2023-03-15 18:52:33 - progress_bar.py[line:272] - INFO: epoch 026:   1364 / 2004 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=312.3, nsentences=8, sample_size=312.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1002.5, ups=3.21, wpb=312.3, bsz=8, num_updates=51140, lr=4.94566e-05, gnorm=2.378, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=17570
2023-03-15 18:52:36 - progress_bar.py[line:272] - INFO: epoch 026:   1374 / 2004 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=321.2, nsentences=8, sample_size=321.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=994.5, ups=3.1, wpb=321.2, bsz=8, num_updates=51150, lr=4.94466e-05, gnorm=2.254, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=17573
2023-03-15 18:52:39 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 18:52:39 - progress_bar.py[line:272] - INFO: epoch 026:   1385 / 2004 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=386.6, nsentences=8, sample_size=386.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1069.6, ups=2.77, wpb=386.6, bsz=8, num_updates=51160, lr=4.94365e-05, gnorm=2.228, clip=0, loss_scale=2048, train_wall=4, gb_free=15.2, wall=17577
2023-03-15 18:52:43 - progress_bar.py[line:272] - INFO: epoch 026:   1395 / 2004 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=358.4, nsentences=8, sample_size=358.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1164.1, ups=3.25, wpb=358.4, bsz=8, num_updates=51170, lr=4.94264e-05, gnorm=2.235, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=17580
2023-03-15 18:52:46 - progress_bar.py[line:272] - INFO: epoch 026:   1405 / 2004 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=330, nsentences=8, sample_size=330, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1066.9, ups=3.23, wpb=330, bsz=8, num_updates=51180, lr=4.94163e-05, gnorm=2.272, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=17583
2023-03-15 18:52:49 - progress_bar.py[line:272] - INFO: epoch 026:   1415 / 2004 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=402.8, nsentences=8, sample_size=402.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1262.9, ups=3.14, wpb=402.8, bsz=8, num_updates=51190, lr=4.94062e-05, gnorm=2.168, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=17586
2023-03-15 18:52:52 - progress_bar.py[line:272] - INFO: epoch 026:   1425 / 2004 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=286.3, nsentences=8, sample_size=286.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=925.6, ups=3.23, wpb=286.3, bsz=8, num_updates=51200, lr=4.93962e-05, gnorm=2.051, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=17590
2023-03-15 18:52:55 - progress_bar.py[line:272] - INFO: epoch 026:   1435 / 2004 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=354.5, nsentences=8, sample_size=354.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1117.1, ups=3.15, wpb=354.5, bsz=8, num_updates=51210, lr=4.93861e-05, gnorm=2.601, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=17593
2023-03-15 18:52:58 - progress_bar.py[line:272] - INFO: epoch 026:   1445 / 2004 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=330.5, nsentences=8, sample_size=330.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1046.3, ups=3.17, wpb=330.5, bsz=8, num_updates=51220, lr=4.9376e-05, gnorm=2.324, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=17596
2023-03-15 18:53:01 - progress_bar.py[line:272] - INFO: epoch 026:   1455 / 2004 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=369.9, nsentences=8, sample_size=369.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1179, ups=3.19, wpb=369.9, bsz=8, num_updates=51230, lr=4.93659e-05, gnorm=2.292, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=17599
2023-03-15 18:53:05 - progress_bar.py[line:272] - INFO: epoch 026:   1465 / 2004 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=395.3, nsentences=8, sample_size=395.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1232, ups=3.12, wpb=395.3, bsz=8, num_updates=51240, lr=4.93558e-05, gnorm=2.109, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=17602
2023-03-15 18:53:08 - progress_bar.py[line:272] - INFO: epoch 026:   1475 / 2004 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=403.8, nsentences=8, sample_size=403.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1150.2, ups=2.85, wpb=403.8, bsz=8, num_updates=51250, lr=4.93458e-05, gnorm=2.185, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=17606
2023-03-15 18:53:12 - progress_bar.py[line:272] - INFO: epoch 026:   1485 / 2004 loss=0.134, loss_v1=0, loss_v2=0, nll_loss=0.134, ntokens=357.2, nsentences=8, sample_size=357.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1015.6, ups=2.84, wpb=357.2, bsz=8, num_updates=51260, lr=4.93357e-05, gnorm=1.916, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=17609
2023-03-15 18:53:15 - progress_bar.py[line:272] - INFO: epoch 026:   1495 / 2004 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=321, nsentences=8, sample_size=321, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=965.9, ups=3.01, wpb=321, bsz=8, num_updates=51270, lr=4.93256e-05, gnorm=2.013, clip=0, loss_scale=2048, train_wall=3, gb_free=13.9, wall=17613
2023-03-15 18:53:18 - progress_bar.py[line:272] - INFO: epoch 026:   1505 / 2004 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=325.8, nsentences=8, sample_size=325.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=947.5, ups=2.91, wpb=325.8, bsz=8, num_updates=51280, lr=4.93155e-05, gnorm=1.949, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=17616
2023-03-15 18:53:22 - progress_bar.py[line:272] - INFO: epoch 026:   1515 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=322.9, nsentences=8, sample_size=322.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=960.3, ups=2.97, wpb=322.9, bsz=8, num_updates=51290, lr=4.93054e-05, gnorm=2.093, clip=0, loss_scale=4096, train_wall=3, gb_free=14.9, wall=17619
2023-03-15 18:53:23 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 18:53:25 - progress_bar.py[line:272] - INFO: epoch 026:   1526 / 2004 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=333.9, nsentences=8, sample_size=333.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=898.4, ups=2.69, wpb=333.9, bsz=8, num_updates=51300, lr=4.92953e-05, gnorm=2.343, clip=0, loss_scale=2048, train_wall=4, gb_free=15, wall=17623
2023-03-15 18:53:29 - progress_bar.py[line:272] - INFO: epoch 026:   1536 / 2004 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=351.6, nsentences=8, sample_size=351.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1034.4, ups=2.94, wpb=351.6, bsz=8, num_updates=51310, lr=4.92853e-05, gnorm=2.401, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=17626
2023-03-15 18:53:32 - progress_bar.py[line:272] - INFO: epoch 026:   1546 / 2004 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=325.6, nsentences=8, sample_size=325.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=937.4, ups=2.88, wpb=325.6, bsz=8, num_updates=51320, lr=4.92752e-05, gnorm=2.164, clip=0, loss_scale=2048, train_wall=3, gb_free=13.8, wall=17630
2023-03-15 18:53:36 - progress_bar.py[line:272] - INFO: epoch 026:   1556 / 2004 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=338.7, nsentences=8, sample_size=338.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=964.2, ups=2.85, wpb=338.7, bsz=8, num_updates=51330, lr=4.92651e-05, gnorm=1.845, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=17633
2023-03-15 18:53:39 - progress_bar.py[line:272] - INFO: epoch 026:   1566 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=345.3, nsentences=8, sample_size=345.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=973, ups=2.82, wpb=345.3, bsz=8, num_updates=51340, lr=4.9255e-05, gnorm=2.235, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=17637
2023-03-15 18:53:43 - progress_bar.py[line:272] - INFO: epoch 026:   1576 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=346.8, nsentences=8, sample_size=346.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1028, ups=2.96, wpb=346.8, bsz=8, num_updates=51350, lr=4.92449e-05, gnorm=1.893, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=17640
2023-03-15 18:53:46 - progress_bar.py[line:272] - INFO: epoch 026:   1586 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=326.3, nsentences=8, sample_size=326.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=944.1, ups=2.89, wpb=326.3, bsz=8, num_updates=51360, lr=4.92349e-05, gnorm=2.076, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=17644
2023-03-15 18:53:50 - progress_bar.py[line:272] - INFO: epoch 026:   1596 / 2004 loss=0.137, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=353.9, nsentences=8, sample_size=353.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1022.8, ups=2.89, wpb=353.9, bsz=8, num_updates=51370, lr=4.92248e-05, gnorm=1.857, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=17647
2023-03-15 18:53:53 - progress_bar.py[line:272] - INFO: epoch 026:   1606 / 2004 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=331.2, nsentences=8, sample_size=331.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1061.8, ups=3.21, wpb=331.2, bsz=8, num_updates=51380, lr=4.92147e-05, gnorm=2.061, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=17650
2023-03-15 18:53:56 - progress_bar.py[line:272] - INFO: epoch 026:   1616 / 2004 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=338.2, nsentences=8, sample_size=338.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1074.3, ups=3.18, wpb=338.2, bsz=8, num_updates=51390, lr=4.92046e-05, gnorm=2.348, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=17654
2023-03-15 18:53:59 - progress_bar.py[line:272] - INFO: epoch 026:   1626 / 2004 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=368.1, nsentences=8, sample_size=368.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1158.5, ups=3.15, wpb=368.1, bsz=8, num_updates=51400, lr=4.91945e-05, gnorm=1.929, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=17657
2023-03-15 18:54:02 - progress_bar.py[line:272] - INFO: epoch 026:   1636 / 2004 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=321.5, nsentences=8, sample_size=321.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1033, ups=3.21, wpb=321.5, bsz=8, num_updates=51410, lr=4.91845e-05, gnorm=2.616, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=17660
2023-03-15 18:54:05 - progress_bar.py[line:272] - INFO: epoch 026:   1646 / 2004 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=316.2, nsentences=8, sample_size=316.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1024.5, ups=3.24, wpb=316.2, bsz=8, num_updates=51420, lr=4.91744e-05, gnorm=1.989, clip=0, loss_scale=4096, train_wall=3, gb_free=15.6, wall=17663
2023-03-15 18:54:06 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 18:54:09 - progress_bar.py[line:272] - INFO: epoch 026:   1657 / 2004 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=356.4, nsentences=8, sample_size=356.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1019, ups=2.86, wpb=356.4, bsz=8, num_updates=51430, lr=4.91643e-05, gnorm=2.374, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=17666
2023-03-15 18:54:12 - progress_bar.py[line:272] - INFO: epoch 026:   1667 / 2004 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=342.8, nsentences=8, sample_size=342.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1057, ups=3.08, wpb=342.8, bsz=8, num_updates=51440, lr=4.91542e-05, gnorm=2.515, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=17670
2023-03-15 18:54:15 - progress_bar.py[line:272] - INFO: epoch 026:   1677 / 2004 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=327.6, nsentences=8, sample_size=327.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1029.3, ups=3.14, wpb=327.6, bsz=8, num_updates=51450, lr=4.91441e-05, gnorm=2.457, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=17673
2023-03-15 18:54:18 - progress_bar.py[line:272] - INFO: epoch 026:   1687 / 2004 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=332.1, nsentences=8, sample_size=332.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1034.7, ups=3.12, wpb=332.1, bsz=8, num_updates=51460, lr=4.91341e-05, gnorm=2.318, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=17676
2023-03-15 18:54:22 - progress_bar.py[line:272] - INFO: epoch 026:   1697 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=336.6, nsentences=8, sample_size=336.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1004.3, ups=2.98, wpb=336.6, bsz=8, num_updates=51470, lr=4.9124e-05, gnorm=2.208, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=17679
2023-03-15 18:54:25 - progress_bar.py[line:272] - INFO: epoch 026:   1707 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=346.7, nsentences=8, sample_size=346.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=996.9, ups=2.88, wpb=346.7, bsz=8, num_updates=51480, lr=4.91139e-05, gnorm=2.18, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=17683
2023-03-15 18:54:29 - progress_bar.py[line:272] - INFO: epoch 026:   1717 / 2004 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=372.9, nsentences=8, sample_size=372.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1088.7, ups=2.92, wpb=372.9, bsz=8, num_updates=51490, lr=4.91038e-05, gnorm=2.019, clip=0, loss_scale=2048, train_wall=3, gb_free=14, wall=17686
2023-03-15 18:54:32 - progress_bar.py[line:272] - INFO: epoch 026:   1727 / 2004 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=397.7, nsentences=8, sample_size=397.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1139.5, ups=2.87, wpb=397.7, bsz=8, num_updates=51500, lr=4.90937e-05, gnorm=2.119, clip=0, loss_scale=2048, train_wall=3, gb_free=13.9, wall=17690
2023-03-15 18:54:36 - progress_bar.py[line:272] - INFO: epoch 026:   1737 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=333.1, nsentences=8, sample_size=333.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=981, ups=2.94, wpb=333.1, bsz=8, num_updates=51510, lr=4.90837e-05, gnorm=2.13, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=17693
2023-03-15 18:54:39 - progress_bar.py[line:272] - INFO: epoch 026:   1747 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=347.4, nsentences=8, sample_size=347.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1001.1, ups=2.88, wpb=347.4, bsz=8, num_updates=51520, lr=4.90736e-05, gnorm=2.145, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=17697
2023-03-15 18:54:43 - progress_bar.py[line:272] - INFO: epoch 026:   1757 / 2004 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=325, nsentences=8, sample_size=325, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=934.4, ups=2.88, wpb=325, bsz=8, num_updates=51530, lr=4.90635e-05, gnorm=2.581, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=17700
2023-03-15 18:54:46 - progress_bar.py[line:272] - INFO: epoch 026:   1767 / 2004 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=320.2, nsentences=8, sample_size=320.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=937.1, ups=2.93, wpb=320.2, bsz=8, num_updates=51540, lr=4.90534e-05, gnorm=2.184, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=17704
2023-03-15 18:54:49 - progress_bar.py[line:272] - INFO: epoch 026:   1777 / 2004 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=347.8, nsentences=8, sample_size=347.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1010.9, ups=2.91, wpb=347.8, bsz=8, num_updates=51550, lr=4.90433e-05, gnorm=2.265, clip=0, loss_scale=4096, train_wall=3, gb_free=15, wall=17707
2023-03-15 18:54:53 - progress_bar.py[line:272] - INFO: epoch 026:   1787 / 2004 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=301.8, nsentences=8, sample_size=301.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=895.8, ups=2.97, wpb=301.8, bsz=8, num_updates=51560, lr=4.90332e-05, gnorm=2.139, clip=0, loss_scale=4096, train_wall=3, gb_free=15.6, wall=17710
2023-03-15 18:54:55 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 18:54:56 - progress_bar.py[line:272] - INFO: epoch 026:   1798 / 2004 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=349.9, nsentences=8, sample_size=349.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=953, ups=2.72, wpb=349.9, bsz=8, num_updates=51570, lr=4.90232e-05, gnorm=2.192, clip=0, loss_scale=2048, train_wall=4, gb_free=15.1, wall=17714
2023-03-15 18:55:00 - progress_bar.py[line:272] - INFO: epoch 026:   1808 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=349.1, nsentences=8, sample_size=349.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=996.4, ups=2.85, wpb=349.1, bsz=8, num_updates=51580, lr=4.90131e-05, gnorm=2.098, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=17718
2023-03-15 18:55:03 - progress_bar.py[line:272] - INFO: epoch 026:   1818 / 2004 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=352.5, nsentences=8, sample_size=352.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1003.8, ups=2.85, wpb=352.5, bsz=8, num_updates=51590, lr=4.9003e-05, gnorm=2.044, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=17721
2023-03-15 18:55:07 - progress_bar.py[line:272] - INFO: epoch 026:   1828 / 2004 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=346.7, nsentences=8, sample_size=346.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1021.3, ups=2.95, wpb=346.7, bsz=8, num_updates=51600, lr=4.89929e-05, gnorm=1.998, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=17724
2023-03-15 18:55:10 - progress_bar.py[line:272] - INFO: epoch 026:   1838 / 2004 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=339.3, nsentences=8, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=977, ups=2.88, wpb=339.3, bsz=8, num_updates=51610, lr=4.89828e-05, gnorm=2.204, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=17728
2023-03-15 18:55:14 - progress_bar.py[line:272] - INFO: epoch 026:   1848 / 2004 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=352.1, nsentences=8, sample_size=352.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1020.7, ups=2.9, wpb=352.1, bsz=8, num_updates=51620, lr=4.89728e-05, gnorm=2.149, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=17731
2023-03-15 18:55:17 - progress_bar.py[line:272] - INFO: epoch 026:   1858 / 2004 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=325.7, nsentences=8, sample_size=325.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=935.4, ups=2.87, wpb=325.7, bsz=8, num_updates=51630, lr=4.89627e-05, gnorm=2.209, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=17735
2023-03-15 18:55:21 - progress_bar.py[line:272] - INFO: epoch 026:   1868 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=333.9, nsentences=8, sample_size=333.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=984.6, ups=2.95, wpb=333.9, bsz=8, num_updates=51640, lr=4.89526e-05, gnorm=2.185, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=17738
2023-03-15 18:55:24 - progress_bar.py[line:272] - INFO: epoch 026:   1878 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=339.4, nsentences=8, sample_size=339.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=993.4, ups=2.93, wpb=339.4, bsz=8, num_updates=51650, lr=4.89425e-05, gnorm=2.301, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=17742
2023-03-15 18:55:27 - progress_bar.py[line:272] - INFO: epoch 026:   1888 / 2004 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=317.3, nsentences=8, sample_size=317.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=946.1, ups=2.98, wpb=317.3, bsz=8, num_updates=51660, lr=4.89324e-05, gnorm=2.077, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=17745
2023-03-15 18:55:31 - progress_bar.py[line:272] - INFO: epoch 026:   1898 / 2004 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=346, nsentences=8, sample_size=346, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1028.2, ups=2.97, wpb=346, bsz=8, num_updates=51670, lr=4.89224e-05, gnorm=1.962, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=17748
2023-03-15 18:55:34 - progress_bar.py[line:272] - INFO: epoch 026:   1908 / 2004 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=341.1, nsentences=8, sample_size=341.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1079.1, ups=3.16, wpb=341.1, bsz=8, num_updates=51680, lr=4.89123e-05, gnorm=2.052, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=17752
2023-03-15 18:55:37 - progress_bar.py[line:272] - INFO: epoch 026:   1918 / 2004 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=343.4, nsentences=8, sample_size=343.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1078.7, ups=3.14, wpb=343.4, bsz=8, num_updates=51690, lr=4.89022e-05, gnorm=2.161, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=17755
2023-03-15 18:55:39 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 18:55:41 - progress_bar.py[line:272] - INFO: epoch 026:   1929 / 2004 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=302.7, nsentences=8, sample_size=302.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=822.8, ups=2.72, wpb=302.7, bsz=8, num_updates=51700, lr=4.88921e-05, gnorm=2.115, clip=0, loss_scale=2048, train_wall=4, gb_free=15.2, wall=17758
2023-03-15 18:55:44 - progress_bar.py[line:272] - INFO: epoch 026:   1939 / 2004 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=349.2, nsentences=8, sample_size=349.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1002.4, ups=2.87, wpb=349.2, bsz=8, num_updates=51710, lr=4.8882e-05, gnorm=2.326, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=17762
2023-03-15 18:55:48 - progress_bar.py[line:272] - INFO: epoch 026:   1949 / 2004 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=345.4, nsentences=8, sample_size=345.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1010.6, ups=2.93, wpb=345.4, bsz=8, num_updates=51720, lr=4.8872e-05, gnorm=2.526, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=17765
2023-03-15 18:55:49 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 18:55:52 - progress_bar.py[line:272] - INFO: epoch 026:   1960 / 2004 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=360.6, nsentences=8, sample_size=360.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=956.5, ups=2.65, wpb=360.6, bsz=8, num_updates=51730, lr=4.88619e-05, gnorm=2.005, clip=0, loss_scale=1024, train_wall=4, gb_free=15.1, wall=17769
2023-03-15 18:55:55 - progress_bar.py[line:272] - INFO: epoch 026:   1970 / 2004 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=336.8, nsentences=8, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=995.1, ups=2.95, wpb=336.8, bsz=8, num_updates=51740, lr=4.88518e-05, gnorm=2.342, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=17772
2023-03-15 18:55:58 - progress_bar.py[line:272] - INFO: epoch 026:   1980 / 2004 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=343.1, nsentences=8, sample_size=343.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=977.2, ups=2.85, wpb=343.1, bsz=8, num_updates=51750, lr=4.88417e-05, gnorm=2.224, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=17776
2023-03-15 18:56:02 - progress_bar.py[line:272] - INFO: epoch 026:   1990 / 2004 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=355.1, nsentences=8, sample_size=355.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1009.5, ups=2.84, wpb=355.1, bsz=8, num_updates=51760, lr=4.88316e-05, gnorm=2.166, clip=0, loss_scale=1024, train_wall=3, gb_free=14.2, wall=17780
2023-03-15 18:56:05 - progress_bar.py[line:272] - INFO: epoch 026:   2000 / 2004 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=377.8, nsentences=8, sample_size=377.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1155.9, ups=3.06, wpb=377.8, bsz=8, num_updates=51770, lr=4.88215e-05, gnorm=2.151, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=17783
2023-03-15 18:56:06 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 26 @ 51774 updates
2023-03-15 18:56:06 - trainer.py[line:431] - INFO: Saving checkpoint to ./checkpoints/checkpoint26.pt
2023-03-15 18:56:12 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./checkpoints/checkpoint26.pt
2023-03-15 18:56:15 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./checkpoints/checkpoint26.pt (epoch 26 @ 51774 updates, score None) (writing took 8.122544540092349 seconds)
2023-03-15 18:56:15 - train.py[line:332] - INFO: end of epoch 26 (average epoch stats below)
2023-03-15 18:56:15 - progress_bar.py[line:282] - INFO: epoch 026 | loss 0.156 | loss_v1 0 | loss_v2 0 | nll_loss 0.156 | ntokens 345.412 | nsentences 8 | sample_size 345.412 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.11 | wps 1040 | ups 3.01 | wpb 345.4 | bsz 8 | num_updates 51774 | lr 4.88175e-05 | gnorm 2.167 | clip 0.2 | loss_scale 1024 | train_wall 641 | gb_free 14.9 | wall 17792
2023-03-15 18:56:15 - trainer.py[line:639] - INFO: loading train data for epoch 27
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 row count 8015 total row count 8015
slice_id 0 seek offset 0
2023-03-15 18:56:16 - trainer.py[line:703] - INFO: begin training epoch 27
2023-03-15 18:56:16 - train.py[line:305] - INFO: Start iterating over samples
2023-03-15 18:56:18 - progress_bar.py[line:272] - INFO: epoch 027:      6 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=382.1, nsentences=8, sample_size=382.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=298.4, ups=0.78, wpb=382.1, bsz=8, num_updates=51780, lr=4.88115e-05, gnorm=2.248, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=17796
2023-03-15 18:56:21 - progress_bar.py[line:272] - INFO: epoch 027:     16 / 2004 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=311.6, nsentences=8, sample_size=311.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=911.5, ups=2.93, wpb=311.6, bsz=8, num_updates=51790, lr=4.88014e-05, gnorm=2.224, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=17799
2023-03-15 18:56:25 - progress_bar.py[line:272] - INFO: epoch 027:     26 / 2004 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=366.9, nsentences=8, sample_size=366.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1050.1, ups=2.86, wpb=366.9, bsz=8, num_updates=51800, lr=4.87913e-05, gnorm=2.093, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=17803
2023-03-15 18:56:28 - progress_bar.py[line:272] - INFO: epoch 027:     36 / 2004 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=337.9, nsentences=8, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=990.4, ups=2.93, wpb=337.9, bsz=8, num_updates=51810, lr=4.87812e-05, gnorm=2.168, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=17806
2023-03-15 18:56:32 - progress_bar.py[line:272] - INFO: epoch 027:     46 / 2004 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=362.6, nsentences=8, sample_size=362.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1030.4, ups=2.84, wpb=362.6, bsz=8, num_updates=51820, lr=4.87711e-05, gnorm=2.302, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=17809
2023-03-15 18:56:35 - progress_bar.py[line:272] - INFO: epoch 027:     56 / 2004 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=343, nsentences=8, sample_size=343, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1015.3, ups=2.96, wpb=343, bsz=8, num_updates=51830, lr=4.87611e-05, gnorm=2.381, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=17813
2023-03-15 18:56:39 - progress_bar.py[line:272] - INFO: epoch 027:     66 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=337.6, nsentences=8, sample_size=337.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=964.8, ups=2.86, wpb=337.6, bsz=8, num_updates=51840, lr=4.8751e-05, gnorm=1.942, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=17816
2023-03-15 18:56:42 - progress_bar.py[line:272] - INFO: epoch 027:     76 / 2004 loss=0.187, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=347, nsentences=8, sample_size=347, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=996.7, ups=2.87, wpb=347, bsz=8, num_updates=51850, lr=4.87409e-05, gnorm=2.433, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=17820
2023-03-15 18:56:46 - progress_bar.py[line:272] - INFO: epoch 027:     86 / 2004 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=345.7, nsentences=8, sample_size=345.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=991, ups=2.87, wpb=345.7, bsz=8, num_updates=51860, lr=4.87308e-05, gnorm=2.199, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=17823
2023-03-15 18:56:49 - progress_bar.py[line:272] - INFO: epoch 027:     96 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=368, nsentences=8, sample_size=368, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1057.9, ups=2.87, wpb=368, bsz=8, num_updates=51870, lr=4.87207e-05, gnorm=2.071, clip=0, loss_scale=2048, train_wall=3, gb_free=14, wall=17827
2023-03-15 18:56:53 - progress_bar.py[line:272] - INFO: epoch 027:    106 / 2004 loss=0.137, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=367.2, nsentences=8, sample_size=367.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1066.1, ups=2.9, wpb=367.2, bsz=8, num_updates=51880, lr=4.87107e-05, gnorm=1.972, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=17830
2023-03-15 18:56:56 - progress_bar.py[line:272] - INFO: epoch 027:    116 / 2004 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=336, nsentences=8, sample_size=336, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=982, ups=2.92, wpb=336, bsz=8, num_updates=51890, lr=4.87006e-05, gnorm=2.328, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=17834
2023-03-15 18:56:59 - progress_bar.py[line:272] - INFO: epoch 027:    126 / 2004 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=332.7, nsentences=8, sample_size=332.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=979.8, ups=2.95, wpb=332.7, bsz=8, num_updates=51900, lr=4.86905e-05, gnorm=2.257, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=17837
2023-03-15 18:57:03 - progress_bar.py[line:272] - INFO: epoch 027:    136 / 2004 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=333.1, nsentences=8, sample_size=333.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=966.7, ups=2.9, wpb=333.1, bsz=8, num_updates=51910, lr=4.86804e-05, gnorm=2.222, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=17840
2023-03-15 18:57:06 - progress_bar.py[line:272] - INFO: epoch 027:    146 / 2004 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=333.7, nsentences=8, sample_size=333.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=961.4, ups=2.88, wpb=333.7, bsz=8, num_updates=51920, lr=4.86703e-05, gnorm=2.06, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=17844
2023-03-15 18:57:10 - progress_bar.py[line:272] - INFO: epoch 027:    156 / 2004 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=344.1, nsentences=8, sample_size=344.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=990.9, ups=2.88, wpb=344.1, bsz=8, num_updates=51930, lr=4.86603e-05, gnorm=1.957, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=17847
2023-03-15 18:57:13 - progress_bar.py[line:272] - INFO: epoch 027:    166 / 2004 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=351.8, nsentences=8, sample_size=351.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1003.3, ups=2.85, wpb=351.8, bsz=8, num_updates=51940, lr=4.86502e-05, gnorm=2.14, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=17851
2023-03-15 18:57:17 - progress_bar.py[line:272] - INFO: epoch 027:    176 / 2004 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=333.7, nsentences=8, sample_size=333.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=967.4, ups=2.9, wpb=333.7, bsz=8, num_updates=51950, lr=4.86401e-05, gnorm=1.853, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=17854
2023-03-15 18:57:20 - progress_bar.py[line:272] - INFO: epoch 027:    186 / 2004 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=332.7, nsentences=8, sample_size=332.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1072.6, ups=3.22, wpb=332.7, bsz=8, num_updates=51960, lr=4.863e-05, gnorm=2.243, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=17857
2023-03-15 18:57:23 - progress_bar.py[line:272] - INFO: epoch 027:    196 / 2004 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=321, nsentences=8, sample_size=321, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1084.9, ups=3.38, wpb=321, bsz=8, num_updates=51970, lr=4.86199e-05, gnorm=2.077, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=17860
2023-03-15 18:57:26 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 18:57:26 - progress_bar.py[line:272] - INFO: epoch 027:    207 / 2004 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=339.8, nsentences=8, sample_size=339.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=999.6, ups=2.94, wpb=339.8, bsz=8, num_updates=51980, lr=4.86099e-05, gnorm=2.096, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=17864
2023-03-15 18:57:29 - progress_bar.py[line:272] - INFO: epoch 027:    217 / 2004 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=321.6, nsentences=8, sample_size=321.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1048, ups=3.26, wpb=321.6, bsz=8, num_updates=51990, lr=4.85998e-05, gnorm=1.823, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=17867
2023-03-15 18:57:32 - progress_bar.py[line:272] - INFO: epoch 027:    227 / 2004 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=347.8, nsentences=8, sample_size=347.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1092.9, ups=3.14, wpb=347.8, bsz=8, num_updates=52000, lr=4.85897e-05, gnorm=2.293, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=17870
2023-03-15 18:57:36 - progress_bar.py[line:272] - INFO: epoch 027:    237 / 2004 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=375.8, nsentences=8, sample_size=375.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1178.9, ups=3.14, wpb=375.8, bsz=8, num_updates=52010, lr=4.85796e-05, gnorm=2.188, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=17873
2023-03-15 18:57:39 - progress_bar.py[line:272] - INFO: epoch 027:    247 / 2004 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=347.4, nsentences=8, sample_size=347.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1033.1, ups=2.97, wpb=347.4, bsz=8, num_updates=52020, lr=4.85695e-05, gnorm=2.342, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=17877
2023-03-15 18:57:42 - progress_bar.py[line:272] - INFO: epoch 027:    257 / 2004 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=336.8, nsentences=8, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=973.5, ups=2.89, wpb=336.8, bsz=8, num_updates=52030, lr=4.85594e-05, gnorm=2.11, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=17880
2023-03-15 18:57:46 - progress_bar.py[line:272] - INFO: epoch 027:    267 / 2004 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=352.4, nsentences=8, sample_size=352.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1004.9, ups=2.85, wpb=352.4, bsz=8, num_updates=52040, lr=4.85494e-05, gnorm=2.393, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=17884
2023-03-15 18:57:49 - progress_bar.py[line:272] - INFO: epoch 027:    277 / 2004 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=345.8, nsentences=8, sample_size=345.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1003.8, ups=2.9, wpb=345.8, bsz=8, num_updates=52050, lr=4.85393e-05, gnorm=2.131, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=17887
2023-03-15 18:57:53 - progress_bar.py[line:272] - INFO: epoch 027:    287 / 2004 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=357.4, nsentences=8, sample_size=357.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1019.8, ups=2.85, wpb=357.4, bsz=8, num_updates=52060, lr=4.85292e-05, gnorm=2.069, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=17891
2023-03-15 18:57:56 - progress_bar.py[line:272] - INFO: epoch 027:    297 / 2004 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=374.1, nsentences=8, sample_size=374.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1087.1, ups=2.91, wpb=374.1, bsz=8, num_updates=52070, lr=4.85191e-05, gnorm=2.051, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=17894
2023-03-15 18:58:00 - progress_bar.py[line:272] - INFO: epoch 027:    307 / 2004 loss=0.175, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=336, nsentences=8, sample_size=336, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=970.7, ups=2.89, wpb=336, bsz=8, num_updates=52080, lr=4.8509e-05, gnorm=2.292, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=17897
2023-03-15 18:58:03 - progress_bar.py[line:272] - INFO: epoch 027:    317 / 2004 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=348, nsentences=8, sample_size=348, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1006, ups=2.89, wpb=348, bsz=8, num_updates=52090, lr=4.8499e-05, gnorm=2.289, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=17901
2023-03-15 18:58:07 - progress_bar.py[line:272] - INFO: epoch 027:    327 / 2004 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=323.6, nsentences=8, sample_size=323.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=948.1, ups=2.93, wpb=323.6, bsz=8, num_updates=52100, lr=4.84889e-05, gnorm=2.178, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=17904
2023-03-15 18:58:10 - progress_bar.py[line:272] - INFO: epoch 027:    337 / 2004 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=342.5, nsentences=8, sample_size=342.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1012.3, ups=2.96, wpb=342.5, bsz=8, num_updates=52110, lr=4.84788e-05, gnorm=2.13, clip=0, loss_scale=4096, train_wall=3, gb_free=15.4, wall=17908
2023-03-15 18:58:10 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 18:58:14 - progress_bar.py[line:272] - INFO: epoch 027:    348 / 2004 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=367.8, nsentences=8, sample_size=367.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=957.1, ups=2.6, wpb=367.8, bsz=8, num_updates=52120, lr=4.84687e-05, gnorm=2.045, clip=0, loss_scale=2048, train_wall=4, gb_free=14.9, wall=17912
2023-03-15 18:58:17 - progress_bar.py[line:272] - INFO: epoch 027:    358 / 2004 loss=0.137, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=342, nsentences=8, sample_size=342, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=979.2, ups=2.86, wpb=342, bsz=8, num_updates=52130, lr=4.84586e-05, gnorm=1.995, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=17915
2023-03-15 18:58:21 - progress_bar.py[line:272] - INFO: epoch 027:    368 / 2004 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=360, nsentences=8, sample_size=360, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1037.2, ups=2.88, wpb=360, bsz=8, num_updates=52140, lr=4.84486e-05, gnorm=2.395, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=17919
2023-03-15 18:58:24 - progress_bar.py[line:272] - INFO: epoch 027:    378 / 2004 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=293.4, nsentences=8, sample_size=293.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=850.5, ups=2.9, wpb=293.4, bsz=8, num_updates=52150, lr=4.84385e-05, gnorm=2.349, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=17922
2023-03-15 18:58:28 - progress_bar.py[line:272] - INFO: epoch 027:    388 / 2004 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=352, nsentences=8, sample_size=352, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1009.8, ups=2.87, wpb=352, bsz=8, num_updates=52160, lr=4.84284e-05, gnorm=1.981, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=17925
2023-03-15 18:58:31 - progress_bar.py[line:272] - INFO: epoch 027:    398 / 2004 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=344.2, nsentences=8, sample_size=344.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=985.9, ups=2.86, wpb=344.2, bsz=8, num_updates=52170, lr=4.84183e-05, gnorm=2.309, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=17929
2023-03-15 18:58:35 - progress_bar.py[line:272] - INFO: epoch 027:    408 / 2004 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=370.6, nsentences=8, sample_size=370.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1073, ups=2.9, wpb=370.6, bsz=8, num_updates=52180, lr=4.84082e-05, gnorm=2.347, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=17932
2023-03-15 18:58:38 - progress_bar.py[line:272] - INFO: epoch 027:    418 / 2004 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=340.8, nsentences=8, sample_size=340.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=988, ups=2.9, wpb=340.8, bsz=8, num_updates=52190, lr=4.83982e-05, gnorm=2.02, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=17936
2023-03-15 18:58:42 - progress_bar.py[line:272] - INFO: epoch 027:    428 / 2004 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=336, nsentences=8, sample_size=336, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=958.2, ups=2.85, wpb=336, bsz=8, num_updates=52200, lr=4.83881e-05, gnorm=1.91, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=17939
2023-03-15 18:58:45 - progress_bar.py[line:272] - INFO: epoch 027:    438 / 2004 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=357, nsentences=8, sample_size=357, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1032.5, ups=2.89, wpb=357, bsz=8, num_updates=52210, lr=4.8378e-05, gnorm=2.145, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=17943
2023-03-15 18:58:49 - progress_bar.py[line:272] - INFO: epoch 027:    448 / 2004 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=377.2, nsentences=8, sample_size=377.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1090.6, ups=2.89, wpb=377.2, bsz=8, num_updates=52220, lr=4.83679e-05, gnorm=2.198, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=17946
2023-03-15 18:58:52 - progress_bar.py[line:272] - INFO: epoch 027:    458 / 2004 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=394, nsentences=8, sample_size=394, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1128.7, ups=2.86, wpb=394, bsz=8, num_updates=52230, lr=4.83578e-05, gnorm=2.097, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=17950
2023-03-15 18:58:56 - progress_bar.py[line:272] - INFO: epoch 027:    468 / 2004 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=358.4, nsentences=8, sample_size=358.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1036.6, ups=2.89, wpb=358.4, bsz=8, num_updates=52240, lr=4.83477e-05, gnorm=2.041, clip=0, loss_scale=4096, train_wall=3, gb_free=14.8, wall=17953
2023-03-15 18:58:56 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 18:58:59 - progress_bar.py[line:272] - INFO: epoch 027:    479 / 2004 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=345.5, nsentences=8, sample_size=345.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=905.6, ups=2.62, wpb=345.5, bsz=8, num_updates=52250, lr=4.83377e-05, gnorm=2.265, clip=0, loss_scale=2048, train_wall=4, gb_free=14.9, wall=17957
2023-03-15 18:59:03 - progress_bar.py[line:272] - INFO: epoch 027:    489 / 2004 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=373.4, nsentences=8, sample_size=373.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1089.7, ups=2.92, wpb=373.4, bsz=8, num_updates=52260, lr=4.83276e-05, gnorm=2.313, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=17960
2023-03-15 18:59:06 - progress_bar.py[line:272] - INFO: epoch 027:    499 / 2004 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=354.9, nsentences=8, sample_size=354.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1011.7, ups=2.85, wpb=354.9, bsz=8, num_updates=52270, lr=4.83175e-05, gnorm=2.23, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=17964
2023-03-15 18:59:10 - progress_bar.py[line:272] - INFO: epoch 027:    509 / 2004 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=358.8, nsentences=8, sample_size=358.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1012.9, ups=2.82, wpb=358.8, bsz=8, num_updates=52280, lr=4.83074e-05, gnorm=2.401, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=17968
2023-03-15 18:59:13 - progress_bar.py[line:272] - INFO: epoch 027:    519 / 2004 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=354, nsentences=8, sample_size=354, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1011.8, ups=2.86, wpb=354, bsz=8, num_updates=52290, lr=4.82973e-05, gnorm=2.398, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=17971
2023-03-15 18:59:17 - progress_bar.py[line:272] - INFO: epoch 027:    529 / 2004 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=398.8, nsentences=8, sample_size=398.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1143.3, ups=2.87, wpb=398.8, bsz=8, num_updates=52300, lr=4.82873e-05, gnorm=2.012, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=17975
2023-03-15 18:59:20 - progress_bar.py[line:272] - INFO: epoch 027:    539 / 2004 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=390.9, nsentences=8, sample_size=390.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1117.3, ups=2.86, wpb=390.9, bsz=8, num_updates=52310, lr=4.82772e-05, gnorm=2.194, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=17978
2023-03-15 18:59:24 - progress_bar.py[line:272] - INFO: epoch 027:    549 / 2004 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=355.2, nsentences=8, sample_size=355.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1013.9, ups=2.85, wpb=355.2, bsz=8, num_updates=52320, lr=4.82671e-05, gnorm=2.07, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=17982
2023-03-15 18:59:27 - progress_bar.py[line:272] - INFO: epoch 027:    559 / 2004 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=367.9, nsentences=8, sample_size=367.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1070.8, ups=2.91, wpb=367.9, bsz=8, num_updates=52330, lr=4.8257e-05, gnorm=2.014, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=17985
2023-03-15 18:59:31 - progress_bar.py[line:272] - INFO: epoch 027:    569 / 2004 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=378.1, nsentences=8, sample_size=378.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1075.7, ups=2.85, wpb=378.1, bsz=8, num_updates=52340, lr=4.82469e-05, gnorm=2.275, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=17988
2023-03-15 18:59:34 - progress_bar.py[line:272] - INFO: epoch 027:    579 / 2004 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=322.4, nsentences=8, sample_size=322.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=920.9, ups=2.86, wpb=322.4, bsz=8, num_updates=52350, lr=4.82369e-05, gnorm=2, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=17992
2023-03-15 18:59:38 - progress_bar.py[line:272] - INFO: epoch 027:    589 / 2004 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=378.2, nsentences=8, sample_size=378.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1084.7, ups=2.87, wpb=378.2, bsz=8, num_updates=52360, lr=4.82268e-05, gnorm=2.044, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=17995
2023-03-15 18:59:41 - progress_bar.py[line:272] - INFO: epoch 027:    599 / 2004 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=352.5, nsentences=8, sample_size=352.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1012.9, ups=2.87, wpb=352.5, bsz=8, num_updates=52370, lr=4.82167e-05, gnorm=2.251, clip=0, loss_scale=4096, train_wall=3, gb_free=14, wall=17999
2023-03-15 18:59:42 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 18:59:45 - progress_bar.py[line:272] - INFO: epoch 027:    610 / 2004 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=338, nsentences=8, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=884.4, ups=2.62, wpb=338, bsz=8, num_updates=52380, lr=4.82066e-05, gnorm=2.106, clip=0, loss_scale=2048, train_wall=4, gb_free=15.4, wall=18003
2023-03-15 18:59:49 - progress_bar.py[line:272] - INFO: epoch 027:    620 / 2004 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=370.2, nsentences=8, sample_size=370.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1048.9, ups=2.83, wpb=370.2, bsz=8, num_updates=52390, lr=4.81965e-05, gnorm=1.965, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=18006
2023-03-15 18:59:53 - progress_bar.py[line:272] - INFO: epoch 027:    630 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=347.8, nsentences=8, sample_size=347.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=778.8, ups=2.24, wpb=347.8, bsz=8, num_updates=52400, lr=4.81865e-05, gnorm=2.052, clip=0, loss_scale=2048, train_wall=4, gb_free=15.5, wall=18011
2023-03-15 18:59:57 - progress_bar.py[line:272] - INFO: epoch 027:    640 / 2004 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=347.1, nsentences=8, sample_size=347.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1020, ups=2.94, wpb=347.1, bsz=8, num_updates=52410, lr=4.81764e-05, gnorm=2.276, clip=0, loss_scale=2048, train_wall=3, gb_free=13.5, wall=18014
2023-03-15 19:00:00 - progress_bar.py[line:272] - INFO: epoch 027:    650 / 2004 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=321.3, nsentences=8, sample_size=321.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=948.5, ups=2.95, wpb=321.3, bsz=8, num_updates=52420, lr=4.81663e-05, gnorm=2.139, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=18018
2023-03-15 19:00:03 - progress_bar.py[line:272] - INFO: epoch 027:    660 / 2004 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=341.3, nsentences=8, sample_size=341.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=978, ups=2.87, wpb=341.3, bsz=8, num_updates=52430, lr=4.81562e-05, gnorm=2.013, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=18021
2023-03-15 19:00:07 - progress_bar.py[line:272] - INFO: epoch 027:    670 / 2004 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=323.1, nsentences=8, sample_size=323.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=938.3, ups=2.9, wpb=323.1, bsz=8, num_updates=52440, lr=4.81461e-05, gnorm=2.017, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=18024
2023-03-15 19:00:10 - progress_bar.py[line:272] - INFO: epoch 027:    680 / 2004 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=332.9, nsentences=8, sample_size=332.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=962, ups=2.89, wpb=332.9, bsz=8, num_updates=52450, lr=4.81361e-05, gnorm=2.155, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=18028
2023-03-15 19:00:14 - progress_bar.py[line:272] - INFO: epoch 027:    690 / 2004 loss=0.137, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=355.4, nsentences=8, sample_size=355.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1033, ups=2.91, wpb=355.4, bsz=8, num_updates=52460, lr=4.8126e-05, gnorm=1.887, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=18031
2023-03-15 19:00:17 - progress_bar.py[line:272] - INFO: epoch 027:    700 / 2004 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=341, nsentences=8, sample_size=341, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=961, ups=2.82, wpb=341, bsz=8, num_updates=52470, lr=4.81159e-05, gnorm=2.035, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=18035
2023-03-15 19:00:21 - progress_bar.py[line:272] - INFO: epoch 027:    710 / 2004 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=334.2, nsentences=8, sample_size=334.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=977.3, ups=2.92, wpb=334.2, bsz=8, num_updates=52480, lr=4.81058e-05, gnorm=2.292, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=18038
2023-03-15 19:00:24 - progress_bar.py[line:272] - INFO: epoch 027:    720 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=351.7, nsentences=8, sample_size=351.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1030, ups=2.93, wpb=351.7, bsz=8, num_updates=52490, lr=4.80957e-05, gnorm=2.314, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=18042
2023-03-15 19:00:28 - progress_bar.py[line:272] - INFO: epoch 027:    730 / 2004 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=355.5, nsentences=8, sample_size=355.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1025.3, ups=2.88, wpb=355.5, bsz=8, num_updates=52500, lr=4.80856e-05, gnorm=1.769, clip=0, loss_scale=4096, train_wall=3, gb_free=14.9, wall=18045
2023-03-15 19:00:30 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 19:00:31 - progress_bar.py[line:272] - INFO: epoch 027:    741 / 2004 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=310.6, nsentences=7.8, sample_size=310.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=832.2, ups=2.68, wpb=310.6, bsz=7.8, num_updates=52510, lr=4.80756e-05, gnorm=2.216, clip=0, loss_scale=2048, train_wall=4, gb_free=16.4, wall=18049
2023-03-15 19:00:35 - progress_bar.py[line:272] - INFO: epoch 027:    751 / 2004 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=361.5, nsentences=8, sample_size=361.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1042.5, ups=2.88, wpb=361.5, bsz=8, num_updates=52520, lr=4.80655e-05, gnorm=2.115, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=18052
2023-03-15 19:00:38 - progress_bar.py[line:272] - INFO: epoch 027:    761 / 2004 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=324.2, nsentences=8, sample_size=324.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=943.9, ups=2.91, wpb=324.2, bsz=8, num_updates=52530, lr=4.80554e-05, gnorm=1.85, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=18056
2023-03-15 19:00:42 - progress_bar.py[line:272] - INFO: epoch 027:    771 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=396, nsentences=8, sample_size=396, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1138.4, ups=2.87, wpb=396, bsz=8, num_updates=52540, lr=4.80453e-05, gnorm=2.324, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=18059
2023-03-15 19:00:45 - progress_bar.py[line:272] - INFO: epoch 027:    781 / 2004 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=338.7, nsentences=8, sample_size=338.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=979.1, ups=2.89, wpb=338.7, bsz=8, num_updates=52550, lr=4.80352e-05, gnorm=1.968, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=18063
2023-03-15 19:00:49 - progress_bar.py[line:272] - INFO: epoch 027:    791 / 2004 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=342.2, nsentences=8, sample_size=342.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=992.4, ups=2.9, wpb=342.2, bsz=8, num_updates=52560, lr=4.80252e-05, gnorm=2.144, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=18066
2023-03-15 19:00:52 - progress_bar.py[line:272] - INFO: epoch 027:    801 / 2004 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=329, nsentences=8, sample_size=329, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=965.9, ups=2.94, wpb=329, bsz=8, num_updates=52570, lr=4.80151e-05, gnorm=2.064, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=18070
2023-03-15 19:00:56 - progress_bar.py[line:272] - INFO: epoch 027:    811 / 2004 loss=0.137, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=352.5, nsentences=8, sample_size=352.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=993.7, ups=2.82, wpb=352.5, bsz=8, num_updates=52580, lr=4.8005e-05, gnorm=2.065, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=18073
2023-03-15 19:00:59 - progress_bar.py[line:272] - INFO: epoch 027:    821 / 2004 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=321, nsentences=8, sample_size=321, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=943, ups=2.94, wpb=321, bsz=8, num_updates=52590, lr=4.79949e-05, gnorm=2.248, clip=0, loss_scale=2048, train_wall=3, gb_free=13.6, wall=18077
2023-03-15 19:01:02 - progress_bar.py[line:272] - INFO: epoch 027:    831 / 2004 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=355.1, nsentences=8, sample_size=355.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1089.3, ups=3.07, wpb=355.1, bsz=8, num_updates=52600, lr=4.79848e-05, gnorm=2.155, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=18080
2023-03-15 19:01:06 - progress_bar.py[line:272] - INFO: epoch 027:    841 / 2004 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=353.7, nsentences=8, sample_size=353.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1095.2, ups=3.1, wpb=353.7, bsz=8, num_updates=52610, lr=4.79748e-05, gnorm=2.227, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=18083
2023-03-15 19:01:09 - progress_bar.py[line:272] - INFO: epoch 027:    851 / 2004 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=358, nsentences=8, sample_size=358, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1051.5, ups=2.94, wpb=358, bsz=8, num_updates=52620, lr=4.79647e-05, gnorm=2.226, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=18087
2023-03-15 19:01:12 - progress_bar.py[line:272] - INFO: epoch 027:    861 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=345.4, nsentences=8, sample_size=345.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1001.1, ups=2.9, wpb=345.4, bsz=8, num_updates=52630, lr=4.79546e-05, gnorm=2.055, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=18090
2023-03-15 19:01:14 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 19:01:16 - progress_bar.py[line:272] - INFO: epoch 027:    872 / 2004 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=366.5, nsentences=8, sample_size=366.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=956.8, ups=2.61, wpb=366.5, bsz=8, num_updates=52640, lr=4.79445e-05, gnorm=2.021, clip=0, loss_scale=2048, train_wall=4, gb_free=15.1, wall=18094
2023-03-15 19:01:20 - progress_bar.py[line:272] - INFO: epoch 027:    882 / 2004 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=321.6, nsentences=8, sample_size=321.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=930.6, ups=2.89, wpb=321.6, bsz=8, num_updates=52650, lr=4.79344e-05, gnorm=2.215, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=18097
2023-03-15 19:01:23 - progress_bar.py[line:272] - INFO: epoch 027:    892 / 2004 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=308.5, nsentences=8, sample_size=308.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=897, ups=2.91, wpb=308.5, bsz=8, num_updates=52660, lr=4.79244e-05, gnorm=2.076, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=18101
2023-03-15 19:01:27 - progress_bar.py[line:272] - INFO: epoch 027:    902 / 2004 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=364.3, nsentences=8, sample_size=364.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1039.1, ups=2.85, wpb=364.3, bsz=8, num_updates=52670, lr=4.79143e-05, gnorm=2.471, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=18104
2023-03-15 19:01:30 - progress_bar.py[line:272] - INFO: epoch 027:    912 / 2004 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=373.3, nsentences=8, sample_size=373.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1138.3, ups=3.05, wpb=373.3, bsz=8, num_updates=52680, lr=4.79042e-05, gnorm=2.264, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=18107
2023-03-15 19:01:33 - progress_bar.py[line:272] - INFO: epoch 027:    922 / 2004 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=330.8, nsentences=8, sample_size=330.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1036.8, ups=3.13, wpb=330.8, bsz=8, num_updates=52690, lr=4.78941e-05, gnorm=2.091, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=18111
2023-03-15 19:01:36 - progress_bar.py[line:272] - INFO: epoch 027:    932 / 2004 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=335.4, nsentences=8, sample_size=335.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1051.7, ups=3.14, wpb=335.4, bsz=8, num_updates=52700, lr=4.7884e-05, gnorm=2.218, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=18114
2023-03-15 19:01:39 - progress_bar.py[line:272] - INFO: epoch 027:    942 / 2004 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=376.6, nsentences=8, sample_size=376.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1201, ups=3.19, wpb=376.6, bsz=8, num_updates=52710, lr=4.78739e-05, gnorm=2.415, clip=0, loss_scale=2048, train_wall=3, gb_free=13.9, wall=18117
2023-03-15 19:01:43 - progress_bar.py[line:272] - INFO: epoch 027:    952 / 2004 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=343.4, nsentences=8, sample_size=343.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1105.9, ups=3.22, wpb=343.4, bsz=8, num_updates=52720, lr=4.78639e-05, gnorm=2.342, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=18120
2023-03-15 19:01:46 - progress_bar.py[line:272] - INFO: epoch 027:    962 / 2004 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=381.7, nsentences=8, sample_size=381.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1198.2, ups=3.14, wpb=381.7, bsz=8, num_updates=52730, lr=4.78538e-05, gnorm=2.055, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=18123
2023-03-15 19:01:49 - progress_bar.py[line:272] - INFO: epoch 027:    972 / 2004 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=332.1, nsentences=8, sample_size=332.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1041.5, ups=3.14, wpb=332.1, bsz=8, num_updates=52740, lr=4.78437e-05, gnorm=2.528, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=18126
2023-03-15 19:01:52 - progress_bar.py[line:272] - INFO: epoch 027:    982 / 2004 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=315.8, nsentences=8, sample_size=315.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1017.7, ups=3.22, wpb=315.8, bsz=8, num_updates=52750, lr=4.78336e-05, gnorm=2.143, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=18130
2023-03-15 19:01:55 - progress_bar.py[line:272] - INFO: epoch 027:    992 / 2004 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=382.3, nsentences=8, sample_size=382.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1140.1, ups=2.98, wpb=382.3, bsz=8, num_updates=52760, lr=4.78235e-05, gnorm=2.252, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=18133
2023-03-15 19:01:56 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 19:01:59 - progress_bar.py[line:272] - INFO: epoch 027:   1003 / 2004 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=334.6, nsentences=8, sample_size=334.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=879.7, ups=2.63, wpb=334.6, bsz=8, num_updates=52770, lr=4.78135e-05, gnorm=1.895, clip=0, loss_scale=2048, train_wall=4, gb_free=14.4, wall=18137
2023-03-15 19:02:02 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 19:02:03 - progress_bar.py[line:272] - INFO: epoch 027:   1014 / 2004 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=320.3, nsentences=8, sample_size=320.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=865.8, ups=2.7, wpb=320.3, bsz=8, num_updates=52780, lr=4.78034e-05, gnorm=2.277, clip=0, loss_scale=1024, train_wall=4, gb_free=15.2, wall=18140
2023-03-15 19:02:06 - progress_bar.py[line:272] - INFO: epoch 027:   1024 / 2004 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=327.4, nsentences=8, sample_size=327.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1053.6, ups=3.22, wpb=327.4, bsz=8, num_updates=52790, lr=4.77933e-05, gnorm=2.201, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=18144
2023-03-15 19:02:09 - progress_bar.py[line:272] - INFO: epoch 027:   1034 / 2004 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=305.6, nsentences=8, sample_size=305.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=968.2, ups=3.17, wpb=305.6, bsz=8, num_updates=52800, lr=4.77832e-05, gnorm=2.103, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=18147
2023-03-15 19:02:12 - progress_bar.py[line:272] - INFO: epoch 027:   1044 / 2004 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=362.4, nsentences=8, sample_size=362.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1073.1, ups=2.96, wpb=362.4, bsz=8, num_updates=52810, lr=4.77731e-05, gnorm=2.329, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=18150
2023-03-15 19:02:16 - progress_bar.py[line:272] - INFO: epoch 027:   1054 / 2004 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=381.1, nsentences=8, sample_size=381.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1082.4, ups=2.84, wpb=381.1, bsz=8, num_updates=52820, lr=4.77631e-05, gnorm=2.179, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=18154
2023-03-15 19:02:19 - progress_bar.py[line:272] - INFO: epoch 027:   1064 / 2004 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=330.9, nsentences=8, sample_size=330.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=955.3, ups=2.89, wpb=330.9, bsz=8, num_updates=52830, lr=4.7753e-05, gnorm=2.318, clip=0, loss_scale=1024, train_wall=3, gb_free=13.9, wall=18157
2023-03-15 19:02:23 - progress_bar.py[line:272] - INFO: epoch 027:   1074 / 2004 loss=0.171, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=344.7, nsentences=8, sample_size=344.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=982.3, ups=2.85, wpb=344.7, bsz=8, num_updates=52840, lr=4.77429e-05, gnorm=2.542, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=18161
2023-03-15 19:02:26 - progress_bar.py[line:272] - INFO: epoch 027:   1084 / 2004 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=383.1, nsentences=8, sample_size=383.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1087, ups=2.84, wpb=383.1, bsz=8, num_updates=52850, lr=4.77328e-05, gnorm=2.133, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=18164
2023-03-15 19:02:30 - progress_bar.py[line:272] - INFO: epoch 027:   1094 / 2004 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=325.4, nsentences=8, sample_size=325.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=942.6, ups=2.9, wpb=325.4, bsz=8, num_updates=52860, lr=4.77227e-05, gnorm=2.044, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=18168
2023-03-15 19:02:33 - progress_bar.py[line:272] - INFO: epoch 027:   1104 / 2004 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=370.4, nsentences=8, sample_size=370.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1061.1, ups=2.86, wpb=370.4, bsz=8, num_updates=52870, lr=4.77127e-05, gnorm=2.211, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=18171
2023-03-15 19:02:37 - progress_bar.py[line:272] - INFO: epoch 027:   1114 / 2004 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=346.4, nsentences=8, sample_size=346.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=991.3, ups=2.86, wpb=346.4, bsz=8, num_updates=52880, lr=4.77026e-05, gnorm=2.045, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=18175
2023-03-15 19:02:40 - progress_bar.py[line:272] - INFO: epoch 027:   1124 / 2004 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=309.8, nsentences=8, sample_size=309.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=903.6, ups=2.92, wpb=309.8, bsz=8, num_updates=52890, lr=4.76925e-05, gnorm=1.871, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=18178
2023-03-15 19:02:44 - progress_bar.py[line:272] - INFO: epoch 027:   1134 / 2004 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=394.8, nsentences=8, sample_size=394.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1111.2, ups=2.81, wpb=394.8, bsz=8, num_updates=52900, lr=4.76824e-05, gnorm=2.268, clip=0, loss_scale=1024, train_wall=3, gb_free=13.6, wall=18182
2023-03-15 19:02:47 - progress_bar.py[line:272] - INFO: epoch 027:   1144 / 2004 loss=0.171, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=338.3, nsentences=8, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=983.4, ups=2.91, wpb=338.3, bsz=8, num_updates=52910, lr=4.76723e-05, gnorm=2.416, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=18185
2023-03-15 19:02:51 - progress_bar.py[line:272] - INFO: epoch 027:   1154 / 2004 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=391.1, nsentences=8, sample_size=391.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1103.3, ups=2.82, wpb=391.1, bsz=8, num_updates=52920, lr=4.76623e-05, gnorm=2.372, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=18189
2023-03-15 19:02:54 - progress_bar.py[line:272] - INFO: epoch 027:   1164 / 2004 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=364.6, nsentences=8, sample_size=364.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1047, ups=2.87, wpb=364.6, bsz=8, num_updates=52930, lr=4.76522e-05, gnorm=2.253, clip=0, loss_scale=2048, train_wall=3, gb_free=13.9, wall=18192
2023-03-15 19:02:58 - progress_bar.py[line:272] - INFO: epoch 027:   1174 / 2004 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=356.9, nsentences=8, sample_size=356.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1028.4, ups=2.88, wpb=356.9, bsz=8, num_updates=52940, lr=4.76421e-05, gnorm=1.946, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=18195
2023-03-15 19:03:01 - progress_bar.py[line:272] - INFO: epoch 027:   1184 / 2004 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=328.1, nsentences=8, sample_size=328.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=956.8, ups=2.92, wpb=328.1, bsz=8, num_updates=52950, lr=4.7632e-05, gnorm=2.204, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=18199
2023-03-15 19:03:05 - progress_bar.py[line:272] - INFO: epoch 027:   1194 / 2004 loss=0.136, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=360.4, nsentences=8, sample_size=360.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1090.5, ups=3.03, wpb=360.4, bsz=8, num_updates=52960, lr=4.76219e-05, gnorm=1.736, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=18202
2023-03-15 19:03:08 - progress_bar.py[line:272] - INFO: epoch 027:   1204 / 2004 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=313.8, nsentences=8, sample_size=313.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1001.2, ups=3.19, wpb=313.8, bsz=8, num_updates=52970, lr=4.76118e-05, gnorm=2.1, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=18205
2023-03-15 19:03:11 - progress_bar.py[line:272] - INFO: epoch 027:   1214 / 2004 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=308.1, nsentences=8, sample_size=308.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=961.5, ups=3.12, wpb=308.1, bsz=8, num_updates=52980, lr=4.76018e-05, gnorm=2.203, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=18209
2023-03-15 19:03:14 - progress_bar.py[line:272] - INFO: epoch 027:   1224 / 2004 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=323.6, nsentences=8, sample_size=323.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1015.6, ups=3.14, wpb=323.6, bsz=8, num_updates=52990, lr=4.75917e-05, gnorm=2.022, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=18212
2023-03-15 19:03:17 - progress_bar.py[line:272] - INFO: epoch 027:   1234 / 2004 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=326, nsentences=8, sample_size=326, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1024.8, ups=3.14, wpb=326, bsz=8, num_updates=53000, lr=4.75816e-05, gnorm=1.982, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=18215
2023-03-15 19:03:21 - progress_bar.py[line:272] - INFO: epoch 027:   1244 / 2004 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=385.1, nsentences=8, sample_size=385.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1190.9, ups=3.09, wpb=385.1, bsz=8, num_updates=53010, lr=4.75715e-05, gnorm=2.106, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=18218
2023-03-15 19:03:24 - progress_bar.py[line:272] - INFO: epoch 027:   1254 / 2004 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=339.2, nsentences=8, sample_size=339.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1058.4, ups=3.12, wpb=339.2, bsz=8, num_updates=53020, lr=4.75614e-05, gnorm=2.323, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=18221
2023-03-15 19:03:27 - progress_bar.py[line:272] - INFO: epoch 027:   1264 / 2004 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=337.7, nsentences=8, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1064.7, ups=3.15, wpb=337.7, bsz=8, num_updates=53030, lr=4.75514e-05, gnorm=1.829, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=18225
2023-03-15 19:03:29 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 19:03:30 - progress_bar.py[line:272] - INFO: epoch 027:   1275 / 2004 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=339.6, nsentences=8, sample_size=339.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=961.7, ups=2.83, wpb=339.6, bsz=8, num_updates=53040, lr=4.75413e-05, gnorm=2.399, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=18228
2023-03-15 19:03:34 - progress_bar.py[line:272] - INFO: epoch 027:   1285 / 2004 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=321.5, nsentences=8, sample_size=321.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=916.9, ups=2.85, wpb=321.5, bsz=8, num_updates=53050, lr=4.75312e-05, gnorm=1.891, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=18232
2023-03-15 19:03:37 - progress_bar.py[line:272] - INFO: epoch 027:   1295 / 2004 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=318.4, nsentences=8, sample_size=318.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=927.3, ups=2.91, wpb=318.4, bsz=8, num_updates=53060, lr=4.75211e-05, gnorm=1.976, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=18235
2023-03-15 19:03:41 - progress_bar.py[line:272] - INFO: epoch 027:   1305 / 2004 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=311.2, nsentences=8, sample_size=311.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=911.2, ups=2.93, wpb=311.2, bsz=8, num_updates=53070, lr=4.7511e-05, gnorm=1.883, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=18238
2023-03-15 19:03:44 - progress_bar.py[line:272] - INFO: epoch 027:   1315 / 2004 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=332.7, nsentences=8, sample_size=332.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=968.5, ups=2.91, wpb=332.7, bsz=8, num_updates=53080, lr=4.7501e-05, gnorm=2.106, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=18242
2023-03-15 19:03:48 - progress_bar.py[line:272] - INFO: epoch 027:   1325 / 2004 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=313.7, nsentences=8, sample_size=313.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=922.7, ups=2.94, wpb=313.7, bsz=8, num_updates=53090, lr=4.74909e-05, gnorm=1.947, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=18245
2023-03-15 19:03:51 - progress_bar.py[line:272] - INFO: epoch 027:   1335 / 2004 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=350.2, nsentences=8, sample_size=350.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1063.9, ups=3.04, wpb=350.2, bsz=8, num_updates=53100, lr=4.74808e-05, gnorm=2.344, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=18249
2023-03-15 19:03:54 - progress_bar.py[line:272] - INFO: epoch 027:   1345 / 2004 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=299.1, nsentences=8, sample_size=299.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=955.3, ups=3.19, wpb=299.1, bsz=8, num_updates=53110, lr=4.74707e-05, gnorm=2.078, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=18252
2023-03-15 19:03:57 - progress_bar.py[line:272] - INFO: epoch 027:   1355 / 2004 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=322.6, nsentences=8, sample_size=322.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=977.6, ups=3.03, wpb=322.6, bsz=8, num_updates=53120, lr=4.74606e-05, gnorm=2.054, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=18255
2023-03-15 19:04:01 - progress_bar.py[line:272] - INFO: epoch 027:   1365 / 2004 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=315.7, nsentences=8, sample_size=315.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=924, ups=2.93, wpb=315.7, bsz=8, num_updates=53130, lr=4.74506e-05, gnorm=2.067, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=18258
2023-03-15 19:04:04 - progress_bar.py[line:272] - INFO: epoch 027:   1375 / 2004 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=319, nsentences=8, sample_size=319, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=933.5, ups=2.93, wpb=319, bsz=8, num_updates=53140, lr=4.74405e-05, gnorm=2.037, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=18262
2023-03-15 19:04:08 - progress_bar.py[line:272] - INFO: epoch 027:   1385 / 2004 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=399.1, nsentences=8, sample_size=399.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1164, ups=2.92, wpb=399.1, bsz=8, num_updates=53150, lr=4.74304e-05, gnorm=2.234, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=18265
2023-03-15 19:04:11 - progress_bar.py[line:272] - INFO: epoch 027:   1395 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=348.3, nsentences=8, sample_size=348.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1108.3, ups=3.18, wpb=348.3, bsz=8, num_updates=53160, lr=4.74203e-05, gnorm=2.146, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=18268
2023-03-15 19:04:14 - progress_bar.py[line:272] - INFO: epoch 027:   1405 / 2004 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=342.2, nsentences=8, sample_size=342.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1051.2, ups=3.07, wpb=342.2, bsz=8, num_updates=53170, lr=4.74102e-05, gnorm=2.192, clip=0, loss_scale=4096, train_wall=3, gb_free=15, wall=18272
2023-03-15 19:04:14 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 19:04:18 - progress_bar.py[line:272] - INFO: epoch 027:   1416 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=394.7, nsentences=8, sample_size=394.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1050.9, ups=2.66, wpb=394.7, bsz=8, num_updates=53180, lr=4.74001e-05, gnorm=2.089, clip=0, loss_scale=2048, train_wall=4, gb_free=14.6, wall=18275
2023-03-15 19:04:21 - progress_bar.py[line:272] - INFO: epoch 027:   1426 / 2004 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=282.6, nsentences=8, sample_size=282.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=837.6, ups=2.96, wpb=282.6, bsz=8, num_updates=53190, lr=4.73901e-05, gnorm=2.05, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=18279
2023-03-15 19:04:25 - progress_bar.py[line:272] - INFO: epoch 027:   1436 / 2004 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=356.9, nsentences=8, sample_size=356.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1020.4, ups=2.86, wpb=356.9, bsz=8, num_updates=53200, lr=4.738e-05, gnorm=2.151, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=18282
2023-03-15 19:04:28 - progress_bar.py[line:272] - INFO: epoch 027:   1446 / 2004 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=340.3, nsentences=8, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=991.9, ups=2.91, wpb=340.3, bsz=8, num_updates=53210, lr=4.73699e-05, gnorm=2.125, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=18286
2023-03-15 19:04:32 - progress_bar.py[line:272] - INFO: epoch 027:   1456 / 2004 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=369.2, nsentences=8, sample_size=369.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1071.5, ups=2.9, wpb=369.2, bsz=8, num_updates=53220, lr=4.73598e-05, gnorm=1.95, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=18289
2023-03-15 19:04:35 - progress_bar.py[line:272] - INFO: epoch 027:   1466 / 2004 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=393.9, nsentences=8, sample_size=393.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1107.1, ups=2.81, wpb=393.9, bsz=8, num_updates=53230, lr=4.73497e-05, gnorm=1.968, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=18293
2023-03-15 19:04:39 - progress_bar.py[line:272] - INFO: epoch 027:   1476 / 2004 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=399.2, nsentences=8, sample_size=399.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1128.4, ups=2.83, wpb=399.2, bsz=8, num_updates=53240, lr=4.73397e-05, gnorm=2.12, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=18296
2023-03-15 19:04:42 - progress_bar.py[line:272] - INFO: epoch 027:   1486 / 2004 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=351.9, nsentences=8, sample_size=351.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1017.8, ups=2.89, wpb=351.9, bsz=8, num_updates=53250, lr=4.73296e-05, gnorm=2.221, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=18300
2023-03-15 19:04:46 - progress_bar.py[line:272] - INFO: epoch 027:   1496 / 2004 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=334, nsentences=8, sample_size=334, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=969.9, ups=2.9, wpb=334, bsz=8, num_updates=53260, lr=4.73195e-05, gnorm=1.907, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=18303
2023-03-15 19:04:49 - progress_bar.py[line:272] - INFO: epoch 027:   1506 / 2004 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=318.9, nsentences=8, sample_size=318.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=926.9, ups=2.91, wpb=318.9, bsz=8, num_updates=53270, lr=4.73094e-05, gnorm=1.807, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=18307
2023-03-15 19:04:52 - progress_bar.py[line:272] - INFO: epoch 027:   1516 / 2004 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=327.6, nsentences=8, sample_size=327.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=937.5, ups=2.86, wpb=327.6, bsz=8, num_updates=53280, lr=4.72993e-05, gnorm=1.988, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=18310
2023-03-15 19:04:56 - progress_bar.py[line:272] - INFO: epoch 027:   1526 / 2004 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=330.1, nsentences=8, sample_size=330.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=927.8, ups=2.81, wpb=330.1, bsz=8, num_updates=53290, lr=4.72893e-05, gnorm=2.044, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=18314
2023-03-15 19:05:00 - progress_bar.py[line:272] - INFO: epoch 027:   1536 / 2004 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=354.8, nsentences=8, sample_size=354.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1013.1, ups=2.86, wpb=354.8, bsz=8, num_updates=53300, lr=4.72792e-05, gnorm=2.137, clip=0, loss_scale=4096, train_wall=3, gb_free=14.9, wall=18317
2023-03-15 19:05:03 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 19:05:03 - progress_bar.py[line:272] - INFO: epoch 027:   1547 / 2004 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=302.2, nsentences=8, sample_size=302.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=802, ups=2.65, wpb=302.2, bsz=8, num_updates=53310, lr=4.72691e-05, gnorm=1.878, clip=0, loss_scale=2048, train_wall=4, gb_free=14.1, wall=18321
2023-03-15 19:05:07 - progress_bar.py[line:272] - INFO: epoch 027:   1557 / 2004 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=349.2, nsentences=8, sample_size=349.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=995.1, ups=2.85, wpb=349.2, bsz=8, num_updates=53320, lr=4.7259e-05, gnorm=2.124, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=18324
2023-03-15 19:05:10 - progress_bar.py[line:272] - INFO: epoch 027:   1567 / 2004 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=334.5, nsentences=8, sample_size=334.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=974.7, ups=2.91, wpb=334.5, bsz=8, num_updates=53330, lr=4.72489e-05, gnorm=2.262, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=18328
2023-03-15 19:05:14 - progress_bar.py[line:272] - INFO: epoch 027:   1577 / 2004 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=357.8, nsentences=8, sample_size=357.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1041.9, ups=2.91, wpb=357.8, bsz=8, num_updates=53340, lr=4.72389e-05, gnorm=2.181, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=18331
2023-03-15 19:05:17 - progress_bar.py[line:272] - INFO: epoch 027:   1587 / 2004 loss=0.136, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=308.2, nsentences=8, sample_size=308.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=890.1, ups=2.89, wpb=308.2, bsz=8, num_updates=53350, lr=4.72288e-05, gnorm=1.755, clip=0, loss_scale=2048, train_wall=3, gb_free=15.9, wall=18335
2023-03-15 19:05:21 - progress_bar.py[line:272] - INFO: epoch 027:   1597 / 2004 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=358.6, nsentences=8, sample_size=358.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1029.1, ups=2.87, wpb=358.6, bsz=8, num_updates=53360, lr=4.72187e-05, gnorm=1.979, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=18338
2023-03-15 19:05:24 - progress_bar.py[line:272] - INFO: epoch 027:   1607 / 2004 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=341.3, nsentences=8, sample_size=341.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=978.7, ups=2.87, wpb=341.3, bsz=8, num_updates=53370, lr=4.72086e-05, gnorm=1.972, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=18342
2023-03-15 19:05:28 - progress_bar.py[line:272] - INFO: epoch 027:   1617 / 2004 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=336.2, nsentences=8, sample_size=336.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=977.8, ups=2.91, wpb=336.2, bsz=8, num_updates=53380, lr=4.71985e-05, gnorm=2.201, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=18345
2023-03-15 19:05:31 - progress_bar.py[line:272] - INFO: epoch 027:   1627 / 2004 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=375.1, nsentences=8, sample_size=375.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1085.2, ups=2.89, wpb=375.1, bsz=8, num_updates=53390, lr=4.71885e-05, gnorm=2.311, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=18349
2023-03-15 19:05:34 - progress_bar.py[line:272] - INFO: epoch 027:   1637 / 2004 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=328.2, nsentences=8, sample_size=328.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=972.1, ups=2.96, wpb=328.2, bsz=8, num_updates=53400, lr=4.71784e-05, gnorm=2.338, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=18352
2023-03-15 19:05:38 - progress_bar.py[line:272] - INFO: epoch 027:   1647 / 2004 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=307.9, nsentences=8, sample_size=307.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=883.3, ups=2.87, wpb=307.9, bsz=8, num_updates=53410, lr=4.71683e-05, gnorm=1.814, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=18355
2023-03-15 19:05:41 - progress_bar.py[line:272] - INFO: epoch 027:   1657 / 2004 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=356.2, nsentences=8, sample_size=356.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1029.2, ups=2.89, wpb=356.2, bsz=8, num_updates=53420, lr=4.71582e-05, gnorm=2.092, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=18359
2023-03-15 19:05:45 - progress_bar.py[line:272] - INFO: epoch 027:   1667 / 2004 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=339.4, nsentences=8, sample_size=339.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=988.2, ups=2.91, wpb=339.4, bsz=8, num_updates=53430, lr=4.71481e-05, gnorm=2.04, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=18362
2023-03-15 19:05:48 - progress_bar.py[line:272] - INFO: epoch 027:   1677 / 2004 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=325.5, nsentences=8, sample_size=325.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=955.2, ups=2.93, wpb=325.5, bsz=8, num_updates=53440, lr=4.7138e-05, gnorm=2.313, clip=0, loss_scale=4096, train_wall=3, gb_free=14.9, wall=18366
2023-03-15 19:05:51 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 19:05:52 - progress_bar.py[line:272] - INFO: epoch 027:   1688 / 2004 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=333.2, nsentences=8, sample_size=333.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=882.1, ups=2.65, wpb=333.2, bsz=8, num_updates=53450, lr=4.7128e-05, gnorm=1.71, clip=0, loss_scale=2048, train_wall=4, gb_free=14.5, wall=18370
2023-03-15 19:05:55 - progress_bar.py[line:272] - INFO: epoch 027:   1698 / 2004 loss=0.132, loss_v1=0, loss_v2=0, nll_loss=0.132, ntokens=336.2, nsentences=8, sample_size=336.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=973.8, ups=2.9, wpb=336.2, bsz=8, num_updates=53460, lr=4.71179e-05, gnorm=1.735, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=18373
2023-03-15 19:05:59 - progress_bar.py[line:272] - INFO: epoch 027:   1708 / 2004 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=343.8, nsentences=8, sample_size=343.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=988.6, ups=2.88, wpb=343.8, bsz=8, num_updates=53470, lr=4.71078e-05, gnorm=2.022, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=18376
2023-03-15 19:06:02 - progress_bar.py[line:272] - INFO: epoch 027:   1718 / 2004 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=379.9, nsentences=8, sample_size=379.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1092.1, ups=2.87, wpb=379.9, bsz=8, num_updates=53480, lr=4.70977e-05, gnorm=2.062, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=18380
2023-03-15 19:06:06 - progress_bar.py[line:272] - INFO: epoch 027:   1728 / 2004 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=390.8, nsentences=8, sample_size=390.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1111.9, ups=2.85, wpb=390.8, bsz=8, num_updates=53490, lr=4.70876e-05, gnorm=2.198, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=18383
2023-03-15 19:06:09 - progress_bar.py[line:272] - INFO: epoch 027:   1738 / 2004 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=326.8, nsentences=8, sample_size=326.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=945.7, ups=2.89, wpb=326.8, bsz=8, num_updates=53500, lr=4.70776e-05, gnorm=1.851, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=18387
2023-03-15 19:06:13 - progress_bar.py[line:272] - INFO: epoch 027:   1748 / 2004 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=348.9, nsentences=8, sample_size=348.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1018.1, ups=2.92, wpb=348.9, bsz=8, num_updates=53510, lr=4.70675e-05, gnorm=2.013, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=18390
2023-03-15 19:06:16 - progress_bar.py[line:272] - INFO: epoch 027:   1758 / 2004 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=328, nsentences=8, sample_size=328, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=960.8, ups=2.93, wpb=328, bsz=8, num_updates=53520, lr=4.70574e-05, gnorm=1.974, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=18394
2023-03-15 19:06:20 - progress_bar.py[line:272] - INFO: epoch 027:   1768 / 2004 loss=0.135, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=323.1, nsentences=8, sample_size=323.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=933.9, ups=2.89, wpb=323.1, bsz=8, num_updates=53530, lr=4.70473e-05, gnorm=2.009, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=18397
2023-03-15 19:06:23 - progress_bar.py[line:272] - INFO: epoch 027:   1778 / 2004 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=347.6, nsentences=8, sample_size=347.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1006.9, ups=2.9, wpb=347.6, bsz=8, num_updates=53540, lr=4.70372e-05, gnorm=1.956, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=18401
2023-03-15 19:06:27 - progress_bar.py[line:272] - INFO: epoch 027:   1788 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=297.6, nsentences=8, sample_size=297.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=861.2, ups=2.89, wpb=297.6, bsz=8, num_updates=53550, lr=4.70272e-05, gnorm=2.173, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=18404
2023-03-15 19:06:30 - progress_bar.py[line:272] - INFO: epoch 027:   1798 / 2004 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=346.2, nsentences=8, sample_size=346.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1019.9, ups=2.95, wpb=346.2, bsz=8, num_updates=53560, lr=4.70171e-05, gnorm=2.173, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=18408
2023-03-15 19:06:33 - progress_bar.py[line:272] - INFO: epoch 027:   1808 / 2004 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=353.9, nsentences=8, sample_size=353.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1013.4, ups=2.86, wpb=353.9, bsz=8, num_updates=53570, lr=4.7007e-05, gnorm=1.961, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=18411
2023-03-15 19:06:37 - progress_bar.py[line:272] - INFO: epoch 027:   1818 / 2004 loss=0.135, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=349.7, nsentences=8, sample_size=349.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1004.4, ups=2.87, wpb=349.7, bsz=8, num_updates=53580, lr=4.69969e-05, gnorm=1.871, clip=0, loss_scale=4096, train_wall=3, gb_free=14.6, wall=18415
2023-03-15 19:06:40 - progress_bar.py[line:272] - INFO: epoch 027:   1828 / 2004 loss=0.135, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=349.5, nsentences=8, sample_size=349.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1000.5, ups=2.86, wpb=349.5, bsz=8, num_updates=53590, lr=4.69868e-05, gnorm=1.739, clip=0, loss_scale=4096, train_wall=3, gb_free=14.7, wall=18418
2023-03-15 19:06:42 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 19:06:44 - progress_bar.py[line:272] - INFO: epoch 027:   1839 / 2004 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=336.3, nsentences=8, sample_size=336.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=900.5, ups=2.68, wpb=336.3, bsz=8, num_updates=53600, lr=4.69768e-05, gnorm=2.009, clip=0, loss_scale=2048, train_wall=4, gb_free=14.7, wall=18422
2023-03-15 19:06:48 - progress_bar.py[line:272] - INFO: epoch 027:   1849 / 2004 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=351.7, nsentences=8, sample_size=351.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1028.4, ups=2.92, wpb=351.7, bsz=8, num_updates=53610, lr=4.69667e-05, gnorm=1.903, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=18425
2023-03-15 19:06:51 - progress_bar.py[line:272] - INFO: epoch 027:   1859 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=330.7, nsentences=8, sample_size=330.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=941.5, ups=2.85, wpb=330.7, bsz=8, num_updates=53620, lr=4.69566e-05, gnorm=1.962, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=18429
2023-03-15 19:06:55 - progress_bar.py[line:272] - INFO: epoch 027:   1869 / 2004 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=335.2, nsentences=8, sample_size=335.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=958.6, ups=2.86, wpb=335.2, bsz=8, num_updates=53630, lr=4.69465e-05, gnorm=2.168, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=18432
2023-03-15 19:06:58 - progress_bar.py[line:272] - INFO: epoch 027:   1879 / 2004 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=333.8, nsentences=8, sample_size=333.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=949.1, ups=2.84, wpb=333.8, bsz=8, num_updates=53640, lr=4.69364e-05, gnorm=2.101, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=18436
2023-03-15 19:07:02 - progress_bar.py[line:272] - INFO: epoch 027:   1889 / 2004 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=317, nsentences=8, sample_size=317, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=929, ups=2.93, wpb=317, bsz=8, num_updates=53650, lr=4.69263e-05, gnorm=2.261, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=18439
2023-03-15 19:07:05 - progress_bar.py[line:272] - INFO: epoch 027:   1899 / 2004 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=351, nsentences=8, sample_size=351, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1004.6, ups=2.86, wpb=351, bsz=8, num_updates=53660, lr=4.69163e-05, gnorm=2.046, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=18443
2023-03-15 19:07:08 - progress_bar.py[line:272] - INFO: epoch 027:   1909 / 2004 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=337.3, nsentences=8, sample_size=337.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=980.6, ups=2.91, wpb=337.3, bsz=8, num_updates=53670, lr=4.69062e-05, gnorm=1.923, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=18446
2023-03-15 19:07:12 - progress_bar.py[line:272] - INFO: epoch 027:   1919 / 2004 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=338.8, nsentences=8, sample_size=338.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=992.6, ups=2.93, wpb=338.8, bsz=8, num_updates=53680, lr=4.68961e-05, gnorm=2.118, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=18449
2023-03-15 19:07:15 - progress_bar.py[line:272] - INFO: epoch 027:   1929 / 2004 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=311.2, nsentences=8, sample_size=311.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=913.2, ups=2.93, wpb=311.2, bsz=8, num_updates=53690, lr=4.6886e-05, gnorm=2.075, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=18453
2023-03-15 19:07:19 - progress_bar.py[line:272] - INFO: epoch 027:   1939 / 2004 loss=0.13, loss_v1=0, loss_v2=0, nll_loss=0.13, ntokens=354.8, nsentences=8, sample_size=354.8, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1016.5, ups=2.86, wpb=354.8, bsz=8, num_updates=53700, lr=4.68759e-05, gnorm=1.764, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=18456
2023-03-15 19:07:22 - progress_bar.py[line:272] - INFO: epoch 027:   1949 / 2004 loss=0.131, loss_v1=0, loss_v2=0, nll_loss=0.131, ntokens=346.4, nsentences=8, sample_size=346.4, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=989.2, ups=2.86, wpb=346.4, bsz=8, num_updates=53710, lr=4.68659e-05, gnorm=1.944, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=18460
2023-03-15 19:07:26 - progress_bar.py[line:272] - INFO: epoch 027:   1959 / 2004 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=355.1, nsentences=8, sample_size=355.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1014, ups=2.86, wpb=355.1, bsz=8, num_updates=53720, lr=4.68558e-05, gnorm=2.06, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=18463
2023-03-15 19:07:28 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 19:07:30 - progress_bar.py[line:272] - INFO: epoch 027:   1970 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=327.6, nsentences=8, sample_size=327.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=866, ups=2.64, wpb=327.6, bsz=8, num_updates=53730, lr=4.68457e-05, gnorm=2.384, clip=0, loss_scale=2048, train_wall=4, gb_free=15, wall=18467
2023-03-15 19:07:33 - progress_bar.py[line:272] - INFO: epoch 027:   1980 / 2004 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=343.1, nsentences=8, sample_size=343.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=998.4, ups=2.91, wpb=343.1, bsz=8, num_updates=53740, lr=4.68356e-05, gnorm=2.326, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=18471
2023-03-15 19:07:36 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 19:07:37 - progress_bar.py[line:272] - INFO: epoch 027:   1991 / 2004 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=345.9, nsentences=8, sample_size=345.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=904.8, ups=2.62, wpb=345.9, bsz=8, num_updates=53750, lr=4.68255e-05, gnorm=2.223, clip=0, loss_scale=1024, train_wall=4, gb_free=14.5, wall=18474
2023-03-15 19:07:40 - progress_bar.py[line:272] - INFO: epoch 027:   2001 / 2004 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=370.4, nsentences=8, sample_size=370.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1117.4, ups=3.02, wpb=370.4, bsz=8, num_updates=53760, lr=4.68155e-05, gnorm=2.215, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=18478
2023-03-15 19:07:41 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 27 @ 53763 updates
2023-03-15 19:07:41 - trainer.py[line:431] - INFO: Saving checkpoint to ./checkpoints/checkpoint27.pt
2023-03-15 19:07:47 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./checkpoints/checkpoint27.pt
2023-03-15 19:07:49 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./checkpoints/checkpoint27.pt (epoch 27 @ 53763 updates, score None) (writing took 7.4227735958993435 seconds)
2023-03-15 19:07:49 - train.py[line:332] - INFO: end of epoch 27 (average epoch stats below)
2023-03-15 19:07:49 - progress_bar.py[line:282] - INFO: epoch 027 | loss 0.15 | loss_v1 0 | loss_v2 0 | nll_loss 0.15 | ntokens 345.263 | nsentences 7.999 | sample_size 345.263 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.11 | wps 989.6 | ups 2.87 | wpb 345.3 | bsz 8 | num_updates 53763 | lr 4.68124e-05 | gnorm 2.118 | clip 0 | loss_scale 1024 | train_wall 673 | gb_free 13.9 | wall 18486
2023-03-15 19:07:49 - trainer.py[line:639] - INFO: loading train data for epoch 28
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 row count 8015 total row count 8015
slice_id 0 seek offset 0
2023-03-15 19:07:50 - trainer.py[line:703] - INFO: begin training epoch 28
2023-03-15 19:07:50 - train.py[line:305] - INFO: Start iterating over samples
2023-03-15 19:07:51 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-03-15 19:07:52 - progress_bar.py[line:272] - INFO: epoch 028:      8 / 2004 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=375.9, nsentences=8, sample_size=375.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=308.5, ups=0.82, wpb=375.9, bsz=8, num_updates=53770, lr=4.68054e-05, gnorm=2.362, clip=0, loss_scale=512, train_wall=3, gb_free=14.9, wall=18490
2023-03-15 19:07:55 - progress_bar.py[line:272] - INFO: epoch 028:     18 / 2004 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=330.2, nsentences=8, sample_size=330.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1058.4, ups=3.21, wpb=330.2, bsz=8, num_updates=53780, lr=4.67953e-05, gnorm=1.951, clip=0, loss_scale=512, train_wall=3, gb_free=13.9, wall=18493
2023-03-15 19:07:57 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-03-15 19:07:59 - progress_bar.py[line:272] - INFO: epoch 028:     29 / 2004 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=336.9, nsentences=8, sample_size=336.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=913.1, ups=2.71, wpb=336.9, bsz=8, num_updates=53790, lr=4.67852e-05, gnorm=2.434, clip=0, loss_scale=256, train_wall=4, gb_free=14.8, wall=18497
2023-03-15 19:08:02 - progress_bar.py[line:272] - INFO: epoch 028:     39 / 2004 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=353.7, nsentences=8, sample_size=353.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1044.4, ups=2.95, wpb=353.7, bsz=8, num_updates=53800, lr=4.67751e-05, gnorm=2.143, clip=0, loss_scale=256, train_wall=3, gb_free=14.9, wall=18500
2023-03-15 19:08:06 - progress_bar.py[line:272] - INFO: epoch 028:     49 / 2004 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=338.5, nsentences=8, sample_size=338.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1066.2, ups=3.15, wpb=338.5, bsz=8, num_updates=53810, lr=4.67651e-05, gnorm=2.065, clip=0, loss_scale=256, train_wall=3, gb_free=14.9, wall=18503
2023-03-15 19:08:09 - progress_bar.py[line:272] - INFO: epoch 028:     59 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=357.9, nsentences=8, sample_size=357.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1130.8, ups=3.16, wpb=357.9, bsz=8, num_updates=53820, lr=4.6755e-05, gnorm=2.217, clip=0, loss_scale=256, train_wall=3, gb_free=15.5, wall=18506
2023-03-15 19:08:12 - progress_bar.py[line:272] - INFO: epoch 028:     69 / 2004 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=341, nsentences=8, sample_size=341, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1004.1, ups=2.94, wpb=341, bsz=8, num_updates=53830, lr=4.67449e-05, gnorm=2.263, clip=0, loss_scale=256, train_wall=3, gb_free=15.1, wall=18510
2023-03-15 19:08:16 - progress_bar.py[line:272] - INFO: epoch 028:     79 / 2004 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=322.9, nsentences=8, sample_size=322.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=941.9, ups=2.92, wpb=322.9, bsz=8, num_updates=53840, lr=4.67348e-05, gnorm=1.895, clip=0, loss_scale=256, train_wall=3, gb_free=15.2, wall=18513
2023-03-15 19:08:19 - progress_bar.py[line:272] - INFO: epoch 028:     89 / 2004 loss=0.134, loss_v1=0, loss_v2=0, nll_loss=0.134, ntokens=364.2, nsentences=8, sample_size=364.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1062.6, ups=2.92, wpb=364.2, bsz=8, num_updates=53850, lr=4.67247e-05, gnorm=1.996, clip=0, loss_scale=256, train_wall=3, gb_free=14.8, wall=18517
2023-03-15 19:08:23 - progress_bar.py[line:272] - INFO: epoch 028:     99 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=380.8, nsentences=8, sample_size=380.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1080, ups=2.84, wpb=380.8, bsz=8, num_updates=53860, lr=4.67147e-05, gnorm=2.371, clip=0, loss_scale=256, train_wall=3, gb_free=14.9, wall=18520
2023-03-15 19:08:26 - progress_bar.py[line:272] - INFO: epoch 028:    109 / 2004 loss=0.136, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=341.4, nsentences=8, sample_size=341.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=994.5, ups=2.91, wpb=341.4, bsz=8, num_updates=53870, lr=4.67046e-05, gnorm=1.897, clip=0, loss_scale=256, train_wall=3, gb_free=14.7, wall=18524
2023-03-15 19:08:30 - progress_bar.py[line:272] - INFO: epoch 028:    119 / 2004 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=347.4, nsentences=8, sample_size=347.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=987, ups=2.84, wpb=347.4, bsz=8, num_updates=53880, lr=4.66945e-05, gnorm=2.192, clip=0, loss_scale=256, train_wall=3, gb_free=12.7, wall=18527
2023-03-15 19:08:33 - progress_bar.py[line:272] - INFO: epoch 028:    129 / 2004 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=333.8, nsentences=8, sample_size=333.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=955, ups=2.86, wpb=333.8, bsz=8, num_updates=53890, lr=4.66844e-05, gnorm=1.935, clip=0, loss_scale=256, train_wall=3, gb_free=14.7, wall=18531
2023-03-15 19:08:37 - progress_bar.py[line:272] - INFO: epoch 028:    139 / 2004 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=329.9, nsentences=8, sample_size=329.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=937.6, ups=2.84, wpb=329.9, bsz=8, num_updates=53900, lr=4.66743e-05, gnorm=1.968, clip=0, loss_scale=256, train_wall=3, gb_free=15.2, wall=18534
2023-03-15 19:08:40 - progress_bar.py[line:272] - INFO: epoch 028:    149 / 2004 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=322.7, nsentences=8, sample_size=322.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=926.2, ups=2.87, wpb=322.7, bsz=8, num_updates=53910, lr=4.66642e-05, gnorm=2.033, clip=0, loss_scale=256, train_wall=3, gb_free=14.7, wall=18538
2023-03-15 19:08:44 - progress_bar.py[line:272] - INFO: epoch 028:    159 / 2004 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=377.6, nsentences=8, sample_size=377.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1071.7, ups=2.84, wpb=377.6, bsz=8, num_updates=53920, lr=4.66542e-05, gnorm=2.012, clip=0, loss_scale=512, train_wall=3, gb_free=14.1, wall=18541
2023-03-15 19:08:47 - progress_bar.py[line:272] - INFO: epoch 028:    169 / 2004 loss=0.133, loss_v1=0, loss_v2=0, nll_loss=0.133, ntokens=326.8, nsentences=8, sample_size=326.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=954.1, ups=2.92, wpb=326.8, bsz=8, num_updates=53930, lr=4.66441e-05, gnorm=1.738, clip=0, loss_scale=512, train_wall=3, gb_free=14.5, wall=18545
2023-03-15 19:08:50 - progress_bar.py[line:272] - INFO: epoch 028:    179 / 2004 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=323.9, nsentences=8, sample_size=323.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=931.8, ups=2.88, wpb=323.9, bsz=8, num_updates=53940, lr=4.6634e-05, gnorm=2.14, clip=0, loss_scale=512, train_wall=3, gb_free=15.2, wall=18548
2023-03-15 19:08:54 - progress_bar.py[line:272] - INFO: epoch 028:    189 / 2004 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=338.3, nsentences=8, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=952.9, ups=2.82, wpb=338.3, bsz=8, num_updates=53950, lr=4.66239e-05, gnorm=2.107, clip=0, loss_scale=512, train_wall=3, gb_free=13.9, wall=18552
2023-03-15 19:08:58 - progress_bar.py[line:272] - INFO: epoch 028:    199 / 2004 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=328.9, nsentences=8, sample_size=328.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=947.5, ups=2.88, wpb=328.9, bsz=8, num_updates=53960, lr=4.66138e-05, gnorm=1.939, clip=0, loss_scale=512, train_wall=3, gb_free=14.6, wall=18555
2023-03-15 19:09:01 - progress_bar.py[line:272] - INFO: epoch 028:    209 / 2004 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=344, nsentences=8, sample_size=344, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=987.3, ups=2.87, wpb=344, bsz=8, num_updates=53970, lr=4.66038e-05, gnorm=2.044, clip=0, loss_scale=512, train_wall=3, gb_free=14.7, wall=18559
2023-03-15 19:09:04 - progress_bar.py[line:272] - INFO: epoch 028:    219 / 2004 loss=0.133, loss_v1=0, loss_v2=0, nll_loss=0.133, ntokens=327.8, nsentences=8, sample_size=327.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=947.7, ups=2.89, wpb=327.8, bsz=8, num_updates=53980, lr=4.65937e-05, gnorm=1.566, clip=0, loss_scale=512, train_wall=3, gb_free=14.1, wall=18562
2023-03-15 19:09:08 - progress_bar.py[line:272] - INFO: epoch 028:    229 / 2004 loss=0.13, loss_v1=0, loss_v2=0, nll_loss=0.13, ntokens=337.7, nsentences=8, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=968.9, ups=2.87, wpb=337.7, bsz=8, num_updates=53990, lr=4.65836e-05, gnorm=1.86, clip=0, loss_scale=512, train_wall=3, gb_free=14.5, wall=18566
2023-03-15 19:09:11 - progress_bar.py[line:272] - INFO: epoch 028:    239 / 2004 loss=0.137, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=384.6, nsentences=8, sample_size=384.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1093.7, ups=2.84, wpb=384.6, bsz=8, num_updates=54000, lr=4.65735e-05, gnorm=1.92, clip=0, loss_scale=512, train_wall=3, gb_free=13.8, wall=18569
2023-03-15 19:09:11 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 28 @ 54000 updates
2023-03-15 19:09:11 - trainer.py[line:431] - INFO: Saving checkpoint to ./checkpoints/checkpoint_28_54000.pt
2023-03-15 19:09:18 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./checkpoints/checkpoint_28_54000.pt
2023-03-15 19:09:22 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./checkpoints/checkpoint_28_54000.pt (epoch 28 @ 54000 updates, score None) (writing took 10.055396372452378 seconds)
2023-03-15 19:09:25 - progress_bar.py[line:272] - INFO: epoch 028:    249 / 2004 loss=0.131, loss_v1=0, loss_v2=0, nll_loss=0.131, ntokens=346.2, nsentences=8, sample_size=346.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=260.4, ups=0.75, wpb=346.2, bsz=8, num_updates=54010, lr=4.65634e-05, gnorm=1.72, clip=0, loss_scale=512, train_wall=3, gb_free=14.1, wall=18582
2023-03-15 19:09:28 - progress_bar.py[line:272] - INFO: epoch 028:    259 / 2004 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=339.1, nsentences=8, sample_size=339.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=986.4, ups=2.91, wpb=339.1, bsz=8, num_updates=54020, lr=4.65534e-05, gnorm=2.364, clip=0, loss_scale=512, train_wall=3, gb_free=14.2, wall=18586
2023-03-15 19:09:32 - progress_bar.py[line:272] - INFO: epoch 028:    269 / 2004 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=344.2, nsentences=8, sample_size=344.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=985.6, ups=2.86, wpb=344.2, bsz=8, num_updates=54030, lr=4.65433e-05, gnorm=2.057, clip=0, loss_scale=512, train_wall=3, gb_free=14.3, wall=18589
2023-03-15 19:09:35 - progress_bar.py[line:272] - INFO: epoch 028:    279 / 2004 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=341.6, nsentences=8, sample_size=341.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=976.7, ups=2.86, wpb=341.6, bsz=8, num_updates=54040, lr=4.65332e-05, gnorm=1.99, clip=0, loss_scale=512, train_wall=3, gb_free=14.5, wall=18593
2023-03-15 19:09:39 - progress_bar.py[line:272] - INFO: epoch 028:    289 / 2004 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=345.9, nsentences=8, sample_size=345.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=972.2, ups=2.81, wpb=345.9, bsz=8, num_updates=54050, lr=4.65231e-05, gnorm=2.177, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=18596
2023-03-15 19:09:42 - progress_bar.py[line:272] - INFO: epoch 028:    299 / 2004 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=380.7, nsentences=8, sample_size=380.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1067, ups=2.8, wpb=380.7, bsz=8, num_updates=54060, lr=4.6513e-05, gnorm=1.919, clip=0, loss_scale=1024, train_wall=4, gb_free=15.4, wall=18600
2023-03-15 19:09:46 - progress_bar.py[line:272] - INFO: epoch 028:    309 / 2004 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=344.3, nsentences=8, sample_size=344.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=980.6, ups=2.85, wpb=344.3, bsz=8, num_updates=54070, lr=4.6503e-05, gnorm=1.861, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=18603
2023-03-15 19:09:49 - progress_bar.py[line:272] - INFO: epoch 028:    319 / 2004 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=344.9, nsentences=8, sample_size=344.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=983.8, ups=2.85, wpb=344.9, bsz=8, num_updates=54080, lr=4.64929e-05, gnorm=2.049, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=18607
2023-03-15 19:09:53 - progress_bar.py[line:272] - INFO: epoch 028:    329 / 2004 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=331.9, nsentences=8, sample_size=331.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=968.6, ups=2.92, wpb=331.9, bsz=8, num_updates=54090, lr=4.64828e-05, gnorm=1.867, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=18610
2023-03-15 19:09:56 - progress_bar.py[line:272] - INFO: epoch 028:    339 / 2004 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=355.8, nsentences=8, sample_size=355.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1026.1, ups=2.88, wpb=355.8, bsz=8, num_updates=54100, lr=4.64727e-05, gnorm=1.995, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=18614
2023-03-15 19:10:00 - progress_bar.py[line:272] - INFO: epoch 028:    349 / 2004 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=363, nsentences=8, sample_size=363, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1016.8, ups=2.8, wpb=363, bsz=8, num_updates=54110, lr=4.64626e-05, gnorm=2.212, clip=0, loss_scale=1024, train_wall=4, gb_free=14.6, wall=18617
2023-03-15 19:10:03 - progress_bar.py[line:272] - INFO: epoch 028:    359 / 2004 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=330.9, nsentences=8, sample_size=330.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=964.1, ups=2.91, wpb=330.9, bsz=8, num_updates=54120, lr=4.64525e-05, gnorm=1.903, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=18621
2023-03-15 19:10:07 - progress_bar.py[line:272] - INFO: epoch 028:    369 / 2004 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=354.7, nsentences=8, sample_size=354.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1005.1, ups=2.83, wpb=354.7, bsz=8, num_updates=54130, lr=4.64425e-05, gnorm=2.402, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=18624
2023-03-15 19:10:10 - progress_bar.py[line:272] - INFO: epoch 028:    379 / 2004 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=303.7, nsentences=8, sample_size=303.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=868.8, ups=2.86, wpb=303.7, bsz=8, num_updates=54140, lr=4.64324e-05, gnorm=2.394, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=18628
2023-03-15 19:10:14 - progress_bar.py[line:272] - INFO: epoch 028:    389 / 2004 loss=0.136, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=356.9, nsentences=8, sample_size=356.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1034.7, ups=2.9, wpb=356.9, bsz=8, num_updates=54150, lr=4.64223e-05, gnorm=1.803, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=18631
2023-03-15 19:10:17 - progress_bar.py[line:272] - INFO: epoch 028:    399 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=352.8, nsentences=8, sample_size=352.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1037.6, ups=2.94, wpb=352.8, bsz=8, num_updates=54160, lr=4.64122e-05, gnorm=1.994, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=18635
2023-03-15 19:10:21 - progress_bar.py[line:272] - INFO: epoch 028:    409 / 2004 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=351.5, nsentences=8, sample_size=351.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1019.1, ups=2.9, wpb=351.5, bsz=8, num_updates=54170, lr=4.64021e-05, gnorm=1.91, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=18638
2023-03-15 19:10:24 - progress_bar.py[line:272] - INFO: epoch 028:    419 / 2004 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=361.7, nsentences=8, sample_size=361.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1012.6, ups=2.8, wpb=361.7, bsz=8, num_updates=54180, lr=4.63921e-05, gnorm=2.067, clip=0, loss_scale=2048, train_wall=4, gb_free=14.2, wall=18642
2023-03-15 19:10:24 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 19:10:28 - progress_bar.py[line:272] - INFO: epoch 028:    430 / 2004 loss=0.13, loss_v1=0, loss_v2=0, nll_loss=0.13, ntokens=335.9, nsentences=8, sample_size=335.9, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=859.5, ups=2.56, wpb=335.9, bsz=8, num_updates=54190, lr=4.6382e-05, gnorm=1.998, clip=0, loss_scale=1024, train_wall=4, gb_free=13.7, wall=18646
2023-03-15 19:10:30 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-03-15 19:10:32 - progress_bar.py[line:272] - INFO: epoch 028:    441 / 2004 loss=0.137, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=376.1, nsentences=8, sample_size=376.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=977.1, ups=2.6, wpb=376.1, bsz=8, num_updates=54200, lr=4.63719e-05, gnorm=1.948, clip=0, loss_scale=512, train_wall=4, gb_free=14.1, wall=18650
2023-03-15 19:10:35 - progress_bar.py[line:272] - INFO: epoch 028:    451 / 2004 loss=0.134, loss_v1=0, loss_v2=0, nll_loss=0.134, ntokens=369.6, nsentences=8, sample_size=369.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1043.7, ups=2.82, wpb=369.6, bsz=8, num_updates=54210, lr=4.63618e-05, gnorm=1.944, clip=0, loss_scale=512, train_wall=3, gb_free=14.3, wall=18653
2023-03-15 19:10:39 - progress_bar.py[line:272] - INFO: epoch 028:    461 / 2004 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=379.4, nsentences=8, sample_size=379.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1082.5, ups=2.85, wpb=379.4, bsz=8, num_updates=54220, lr=4.63517e-05, gnorm=2.461, clip=0, loss_scale=512, train_wall=3, gb_free=14.6, wall=18657
2023-03-15 19:10:42 - progress_bar.py[line:272] - INFO: epoch 028:    471 / 2004 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=356.9, nsentences=8, sample_size=356.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1018.2, ups=2.85, wpb=356.9, bsz=8, num_updates=54230, lr=4.63417e-05, gnorm=2.202, clip=0, loss_scale=512, train_wall=3, gb_free=15.1, wall=18660
2023-03-15 19:10:46 - progress_bar.py[line:272] - INFO: epoch 028:    481 / 2004 loss=0.136, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=358.2, nsentences=8, sample_size=358.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1037.6, ups=2.9, wpb=358.2, bsz=8, num_updates=54240, lr=4.63316e-05, gnorm=1.91, clip=0, loss_scale=512, train_wall=3, gb_free=14.8, wall=18664
2023-03-15 19:10:49 - progress_bar.py[line:272] - INFO: epoch 028:    491 / 2004 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=372.5, nsentences=8, sample_size=372.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1053.7, ups=2.83, wpb=372.5, bsz=8, num_updates=54250, lr=4.63215e-05, gnorm=2.125, clip=0, loss_scale=512, train_wall=3, gb_free=14.3, wall=18667
2023-03-15 19:10:53 - progress_bar.py[line:272] - INFO: epoch 028:    501 / 2004 loss=0.136, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=364.5, nsentences=8, sample_size=364.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1054.3, ups=2.89, wpb=364.5, bsz=8, num_updates=54260, lr=4.63114e-05, gnorm=1.94, clip=0, loss_scale=512, train_wall=3, gb_free=14.8, wall=18671
2023-03-15 19:10:56 - progress_bar.py[line:272] - INFO: epoch 028:    511 / 2004 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=351.3, nsentences=8, sample_size=351.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1005.2, ups=2.86, wpb=351.3, bsz=8, num_updates=54270, lr=4.63013e-05, gnorm=2.247, clip=0, loss_scale=512, train_wall=3, gb_free=14.7, wall=18674
2023-03-15 19:11:00 - progress_bar.py[line:272] - INFO: epoch 028:    521 / 2004 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=364.3, nsentences=8, sample_size=364.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1030.8, ups=2.83, wpb=364.3, bsz=8, num_updates=54280, lr=4.62913e-05, gnorm=2.099, clip=0, loss_scale=512, train_wall=3, gb_free=14.3, wall=18678
2023-03-15 19:11:04 - progress_bar.py[line:272] - INFO: epoch 028:    531 / 2004 loss=0.135, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=394, nsentences=8, sample_size=394, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1098.6, ups=2.79, wpb=394, bsz=8, num_updates=54290, lr=4.62812e-05, gnorm=1.87, clip=0, loss_scale=512, train_wall=4, gb_free=14.7, wall=18681
2023-03-15 19:11:07 - progress_bar.py[line:272] - INFO: epoch 028:    541 / 2004 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=375.7, nsentences=8, sample_size=375.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1061.2, ups=2.82, wpb=375.7, bsz=8, num_updates=54300, lr=4.62711e-05, gnorm=2.071, clip=0, loss_scale=512, train_wall=3, gb_free=15.4, wall=18685
2023-03-15 19:11:10 - progress_bar.py[line:272] - INFO: epoch 028:    551 / 2004 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=364.4, nsentences=8, sample_size=364.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1056.7, ups=2.9, wpb=364.4, bsz=8, num_updates=54310, lr=4.6261e-05, gnorm=2.164, clip=0, loss_scale=512, train_wall=3, gb_free=15.2, wall=18688
2023-03-15 19:11:14 - progress_bar.py[line:272] - INFO: epoch 028:    561 / 2004 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=367.8, nsentences=8, sample_size=367.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1058.2, ups=2.88, wpb=367.8, bsz=8, num_updates=54320, lr=4.62509e-05, gnorm=2.237, clip=0, loss_scale=512, train_wall=3, gb_free=14.5, wall=18692
2023-03-15 19:11:18 - progress_bar.py[line:272] - INFO: epoch 028:    571 / 2004 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=372.4, nsentences=8, sample_size=372.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1051.3, ups=2.82, wpb=372.4, bsz=8, num_updates=54330, lr=4.62409e-05, gnorm=2.083, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=18695
2023-03-15 19:11:21 - progress_bar.py[line:272] - INFO: epoch 028:    581 / 2004 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=348, nsentences=8, sample_size=348, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=979.3, ups=2.81, wpb=348, bsz=8, num_updates=54340, lr=4.62308e-05, gnorm=2.238, clip=0, loss_scale=1024, train_wall=3, gb_free=13, wall=18699
2023-03-15 19:11:25 - progress_bar.py[line:272] - INFO: epoch 028:    591 / 2004 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=348.9, nsentences=8, sample_size=348.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=991.7, ups=2.84, wpb=348.9, bsz=8, num_updates=54350, lr=4.62207e-05, gnorm=2.228, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=18702
2023-03-15 19:11:28 - progress_bar.py[line:272] - INFO: epoch 028:    601 / 2004 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=353.9, nsentences=8, sample_size=353.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1002.9, ups=2.83, wpb=353.9, bsz=8, num_updates=54360, lr=4.62106e-05, gnorm=2.045, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=18706
2023-03-15 19:11:32 - progress_bar.py[line:272] - INFO: epoch 028:    611 / 2004 loss=0.13, loss_v1=0, loss_v2=0, nll_loss=0.13, ntokens=342.4, nsentences=8, sample_size=342.4, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=991, ups=2.89, wpb=342.4, bsz=8, num_updates=54370, lr=4.62005e-05, gnorm=1.765, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=18709
2023-03-15 19:11:35 - progress_bar.py[line:272] - INFO: epoch 028:    621 / 2004 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=368.3, nsentences=8, sample_size=368.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1053.2, ups=2.86, wpb=368.3, bsz=8, num_updates=54380, lr=4.61904e-05, gnorm=1.937, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=18713
2023-03-15 19:11:39 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-03-15 19:11:39 - progress_bar.py[line:272] - INFO: epoch 028:    632 / 2004 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=339.8, nsentences=8, sample_size=339.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=903.7, ups=2.66, wpb=339.8, bsz=8, num_updates=54390, lr=4.61804e-05, gnorm=2.16, clip=0, loss_scale=512, train_wall=4, gb_free=14.6, wall=18716
2023-03-15 19:11:42 - progress_bar.py[line:272] - INFO: epoch 028:    642 / 2004 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=340.3, nsentences=8, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=960.8, ups=2.82, wpb=340.3, bsz=8, num_updates=54400, lr=4.61703e-05, gnorm=2.309, clip=0, loss_scale=512, train_wall=3, gb_free=15.5, wall=18720
2023-03-15 19:11:46 - progress_bar.py[line:272] - INFO: epoch 028:    652 / 2004 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=330.2, nsentences=8, sample_size=330.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=944, ups=2.86, wpb=330.2, bsz=8, num_updates=54410, lr=4.61602e-05, gnorm=2.144, clip=0, loss_scale=512, train_wall=3, gb_free=14.8, wall=18723
2023-03-15 19:11:49 - progress_bar.py[line:272] - INFO: epoch 028:    662 / 2004 loss=0.131, loss_v1=0, loss_v2=0, nll_loss=0.131, ntokens=322.9, nsentences=8, sample_size=322.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=918.2, ups=2.84, wpb=322.9, bsz=8, num_updates=54420, lr=4.61501e-05, gnorm=1.83, clip=0, loss_scale=512, train_wall=3, gb_free=15.6, wall=18727
2023-03-15 19:11:53 - progress_bar.py[line:272] - INFO: epoch 028:    672 / 2004 loss=0.13, loss_v1=0, loss_v2=0, nll_loss=0.13, ntokens=335.3, nsentences=8, sample_size=335.3, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=943.7, ups=2.81, wpb=335.3, bsz=8, num_updates=54430, lr=4.614e-05, gnorm=1.722, clip=0, loss_scale=512, train_wall=3, gb_free=14.4, wall=18731
2023-03-15 19:11:56 - progress_bar.py[line:272] - INFO: epoch 028:    682 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=346.4, nsentences=8, sample_size=346.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=985.4, ups=2.84, wpb=346.4, bsz=8, num_updates=54440, lr=4.613e-05, gnorm=2.255, clip=0, loss_scale=512, train_wall=3, gb_free=15.2, wall=18734
2023-03-15 19:12:00 - progress_bar.py[line:272] - INFO: epoch 028:    692 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=353.3, nsentences=8, sample_size=353.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1002.9, ups=2.84, wpb=353.3, bsz=8, num_updates=54450, lr=4.61199e-05, gnorm=2.094, clip=0, loss_scale=512, train_wall=3, gb_free=14.8, wall=18738
2023-03-15 19:12:03 - progress_bar.py[line:272] - INFO: epoch 028:    702 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=335, nsentences=8, sample_size=335, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=962.9, ups=2.87, wpb=335, bsz=8, num_updates=54460, lr=4.61098e-05, gnorm=2.053, clip=0, loss_scale=512, train_wall=3, gb_free=14.7, wall=18741
2023-03-15 19:12:07 - progress_bar.py[line:272] - INFO: epoch 028:    712 / 2004 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=318.9, nsentences=8, sample_size=318.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=925.5, ups=2.9, wpb=318.9, bsz=8, num_updates=54470, lr=4.60997e-05, gnorm=2.028, clip=0, loss_scale=512, train_wall=3, gb_free=15.7, wall=18745
2023-03-15 19:12:10 - progress_bar.py[line:272] - INFO: epoch 028:    722 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=368.8, nsentences=8, sample_size=368.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1043, ups=2.83, wpb=368.8, bsz=8, num_updates=54480, lr=4.60896e-05, gnorm=2.027, clip=0, loss_scale=512, train_wall=3, gb_free=14.5, wall=18748
2023-03-15 19:12:14 - progress_bar.py[line:272] - INFO: epoch 028:    732 / 2004 loss=0.132, loss_v1=0, loss_v2=0, nll_loss=0.132, ntokens=350, nsentences=8, sample_size=350, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=998.8, ups=2.85, wpb=350, bsz=8, num_updates=54490, lr=4.60796e-05, gnorm=1.836, clip=0, loss_scale=512, train_wall=3, gb_free=15.2, wall=18752
2023-03-15 19:12:17 - progress_bar.py[line:272] - INFO: epoch 028:    742 / 2004 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=345.2, nsentences=8, sample_size=345.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=996.9, ups=2.89, wpb=345.2, bsz=8, num_updates=54500, lr=4.60695e-05, gnorm=2.126, clip=0, loss_scale=512, train_wall=3, gb_free=14.6, wall=18755
2023-03-15 19:12:21 - progress_bar.py[line:272] - INFO: epoch 028:    752 / 2004 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=346.3, nsentences=8, sample_size=346.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=980.4, ups=2.83, wpb=346.3, bsz=8, num_updates=54510, lr=4.60594e-05, gnorm=2.339, clip=0, loss_scale=512, train_wall=3, gb_free=14.8, wall=18759
2023-03-15 19:12:24 - progress_bar.py[line:272] - INFO: epoch 028:    762 / 2004 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=343, nsentences=8, sample_size=343, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=965.4, ups=2.81, wpb=343, bsz=8, num_updates=54520, lr=4.60493e-05, gnorm=2.032, clip=0, loss_scale=1024, train_wall=3, gb_free=13.2, wall=18762
2023-03-15 19:12:28 - progress_bar.py[line:272] - INFO: epoch 028:    772 / 2004 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=380.4, nsentences=8, sample_size=380.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1091.8, ups=2.87, wpb=380.4, bsz=8, num_updates=54530, lr=4.60392e-05, gnorm=2.207, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=18766
2023-03-15 19:12:31 - progress_bar.py[line:272] - INFO: epoch 028:    782 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=337.1, nsentences=8, sample_size=337.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=967, ups=2.87, wpb=337.1, bsz=8, num_updates=54540, lr=4.60292e-05, gnorm=2.398, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=18769
2023-03-15 19:12:35 - progress_bar.py[line:272] - INFO: epoch 028:    792 / 2004 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=340.4, nsentences=8, sample_size=340.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=959.7, ups=2.82, wpb=340.4, bsz=8, num_updates=54550, lr=4.60191e-05, gnorm=2.214, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=18773
2023-03-15 19:12:39 - progress_bar.py[line:272] - INFO: epoch 028:    802 / 2004 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=328.8, nsentences=8, sample_size=328.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=936.5, ups=2.85, wpb=328.8, bsz=8, num_updates=54560, lr=4.6009e-05, gnorm=2.364, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=18776
2023-03-15 19:12:42 - progress_bar.py[line:272] - INFO: epoch 028:    812 / 2004 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=342.8, nsentences=8, sample_size=342.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=971.6, ups=2.83, wpb=342.8, bsz=8, num_updates=54570, lr=4.59989e-05, gnorm=2.218, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=18780
2023-03-15 19:12:46 - progress_bar.py[line:272] - INFO: epoch 028:    822 / 2004 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=340.2, nsentences=8, sample_size=340.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=971.6, ups=2.86, wpb=340.2, bsz=8, num_updates=54580, lr=4.59888e-05, gnorm=1.922, clip=0, loss_scale=1024, train_wall=3, gb_free=14.1, wall=18783
2023-03-15 19:12:49 - progress_bar.py[line:272] - INFO: epoch 028:    832 / 2004 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=348.5, nsentences=8, sample_size=348.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1014, ups=2.91, wpb=348.5, bsz=8, num_updates=54590, lr=4.59787e-05, gnorm=2.194, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=18787
2023-03-15 19:12:52 - progress_bar.py[line:272] - INFO: epoch 028:    842 / 2004 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=359, nsentences=8, sample_size=359, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1037.7, ups=2.89, wpb=359, bsz=8, num_updates=54600, lr=4.59687e-05, gnorm=2.262, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=18790
2023-03-15 19:12:56 - progress_bar.py[line:272] - INFO: epoch 028:    852 / 2004 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=358.4, nsentences=8, sample_size=358.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1019, ups=2.84, wpb=358.4, bsz=8, num_updates=54610, lr=4.59586e-05, gnorm=2.059, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=18794
2023-03-15 19:12:59 - progress_bar.py[line:272] - INFO: epoch 028:    862 / 2004 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=336.6, nsentences=8, sample_size=336.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=965.7, ups=2.87, wpb=336.6, bsz=8, num_updates=54620, lr=4.59485e-05, gnorm=2.004, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=18797
2023-03-15 19:13:03 - progress_bar.py[line:272] - INFO: epoch 028:    872 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=374.6, nsentences=8, sample_size=374.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1081.7, ups=2.89, wpb=374.6, bsz=8, num_updates=54630, lr=4.59384e-05, gnorm=2.138, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=18801
2023-03-15 19:13:06 - progress_bar.py[line:272] - INFO: epoch 028:    882 / 2004 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=320.4, nsentences=8, sample_size=320.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=925.5, ups=2.89, wpb=320.4, bsz=8, num_updates=54640, lr=4.59283e-05, gnorm=2.542, clip=0, loss_scale=1024, train_wall=3, gb_free=13.7, wall=18804
2023-03-15 19:13:10 - progress_bar.py[line:272] - INFO: epoch 028:    892 / 2004 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=310, nsentences=8, sample_size=310, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=888.1, ups=2.86, wpb=310, bsz=8, num_updates=54650, lr=4.59183e-05, gnorm=1.945, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=18807
2023-03-15 19:13:13 - progress_bar.py[line:272] - INFO: epoch 028:    902 / 2004 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=355.2, nsentences=7.8, sample_size=355.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1026.8, ups=2.89, wpb=355.2, bsz=7.8, num_updates=54660, lr=4.59082e-05, gnorm=2.154, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=18811
2023-03-15 19:13:17 - progress_bar.py[line:272] - INFO: epoch 028:    912 / 2004 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=373.3, nsentences=8, sample_size=373.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1069.3, ups=2.86, wpb=373.3, bsz=8, num_updates=54670, lr=4.58981e-05, gnorm=2.387, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=18814
2023-03-15 19:13:20 - progress_bar.py[line:272] - INFO: epoch 028:    922 / 2004 loss=0.13, loss_v1=0, loss_v2=0, nll_loss=0.13, ntokens=330.8, nsentences=8, sample_size=330.8, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=960.8, ups=2.9, wpb=330.8, bsz=8, num_updates=54680, lr=4.5888e-05, gnorm=1.813, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=18818
2023-03-15 19:13:24 - progress_bar.py[line:272] - INFO: epoch 028:    932 / 2004 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=335.4, nsentences=8, sample_size=335.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=957.2, ups=2.85, wpb=335.4, bsz=8, num_updates=54690, lr=4.58779e-05, gnorm=2.332, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=18821
2023-03-15 19:13:26 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 19:13:28 - progress_bar.py[line:272] - INFO: epoch 028:    943 / 2004 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=379.6, nsentences=8, sample_size=379.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=989.1, ups=2.61, wpb=379.6, bsz=8, num_updates=54700, lr=4.58679e-05, gnorm=2.07, clip=0, loss_scale=1024, train_wall=4, gb_free=14.7, wall=18825
2023-03-15 19:13:31 - progress_bar.py[line:272] - INFO: epoch 028:    953 / 2004 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=326.6, nsentences=8, sample_size=326.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=927.6, ups=2.84, wpb=326.6, bsz=8, num_updates=54710, lr=4.58578e-05, gnorm=2.022, clip=0, loss_scale=1024, train_wall=3, gb_free=15.8, wall=18829
2023-03-15 19:13:35 - progress_bar.py[line:272] - INFO: epoch 028:    963 / 2004 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=399.1, nsentences=8, sample_size=399.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1126.9, ups=2.82, wpb=399.1, bsz=8, num_updates=54720, lr=4.58477e-05, gnorm=2.084, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=18832
2023-03-15 19:13:38 - progress_bar.py[line:272] - INFO: epoch 028:    973 / 2004 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=323, nsentences=8, sample_size=323, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=934.1, ups=2.89, wpb=323, bsz=8, num_updates=54730, lr=4.58376e-05, gnorm=2.217, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=18836
2023-03-15 19:13:42 - progress_bar.py[line:272] - INFO: epoch 028:    983 / 2004 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=321.3, nsentences=8, sample_size=321.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=919.2, ups=2.86, wpb=321.3, bsz=8, num_updates=54740, lr=4.58275e-05, gnorm=2.068, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=18839
2023-03-15 19:13:45 - progress_bar.py[line:272] - INFO: epoch 028:    993 / 2004 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=381.2, nsentences=8, sample_size=381.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1076.2, ups=2.82, wpb=381.2, bsz=8, num_updates=54750, lr=4.58175e-05, gnorm=1.931, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=18843
2023-03-15 19:13:47 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-03-15 19:13:49 - progress_bar.py[line:272] - INFO: epoch 028:   1004 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=318.7, nsentences=8, sample_size=318.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=849.2, ups=2.66, wpb=318.7, bsz=8, num_updates=54760, lr=4.58074e-05, gnorm=2.131, clip=0, loss_scale=512, train_wall=4, gb_free=15.4, wall=18847
2023-03-15 19:13:52 - progress_bar.py[line:272] - INFO: epoch 028:   1014 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=337.4, nsentences=8, sample_size=337.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=972.7, ups=2.88, wpb=337.4, bsz=8, num_updates=54770, lr=4.57973e-05, gnorm=2.053, clip=0, loss_scale=512, train_wall=3, gb_free=15.1, wall=18850
2023-03-15 19:13:56 - progress_bar.py[line:272] - INFO: epoch 028:   1024 / 2004 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=327.4, nsentences=8, sample_size=327.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=943.5, ups=2.88, wpb=327.4, bsz=8, num_updates=54780, lr=4.57872e-05, gnorm=1.956, clip=0, loss_scale=512, train_wall=3, gb_free=15.3, wall=18853
2023-03-15 19:13:59 - progress_bar.py[line:272] - INFO: epoch 028:   1034 / 2004 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=305.6, nsentences=8, sample_size=305.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=874.9, ups=2.86, wpb=305.6, bsz=8, num_updates=54790, lr=4.57771e-05, gnorm=2.135, clip=0, loss_scale=512, train_wall=3, gb_free=15.6, wall=18857
2023-03-15 19:14:03 - progress_bar.py[line:272] - INFO: epoch 028:   1044 / 2004 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=362.4, nsentences=8, sample_size=362.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1009.5, ups=2.79, wpb=362.4, bsz=8, num_updates=54800, lr=4.57671e-05, gnorm=2.083, clip=0, loss_scale=512, train_wall=4, gb_free=14.9, wall=18861
2023-03-15 19:14:06 - progress_bar.py[line:272] - INFO: epoch 028:   1054 / 2004 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=381.1, nsentences=8, sample_size=381.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1076, ups=2.82, wpb=381.1, bsz=8, num_updates=54810, lr=4.5757e-05, gnorm=2.533, clip=0, loss_scale=512, train_wall=3, gb_free=14.4, wall=18864
2023-03-15 19:14:10 - progress_bar.py[line:272] - INFO: epoch 028:   1064 / 2004 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=330.9, nsentences=8, sample_size=330.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=950.3, ups=2.87, wpb=330.9, bsz=8, num_updates=54820, lr=4.57469e-05, gnorm=1.834, clip=0, loss_scale=512, train_wall=3, gb_free=14.4, wall=18868
2023-03-15 19:14:13 - progress_bar.py[line:272] - INFO: epoch 028:   1074 / 2004 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=344.7, nsentences=8, sample_size=344.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=993.2, ups=2.88, wpb=344.7, bsz=8, num_updates=54830, lr=4.57368e-05, gnorm=2.001, clip=0, loss_scale=512, train_wall=3, gb_free=15.2, wall=18871
2023-03-15 19:14:17 - progress_bar.py[line:272] - INFO: epoch 028:   1084 / 2004 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=383.1, nsentences=8, sample_size=383.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1091.7, ups=2.85, wpb=383.1, bsz=8, num_updates=54840, lr=4.57267e-05, gnorm=2.094, clip=0, loss_scale=512, train_wall=3, gb_free=14.1, wall=18875
2023-03-15 19:14:20 - progress_bar.py[line:272] - INFO: epoch 028:   1094 / 2004 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=325.4, nsentences=8, sample_size=325.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=934.3, ups=2.87, wpb=325.4, bsz=8, num_updates=54850, lr=4.57166e-05, gnorm=2.031, clip=0, loss_scale=512, train_wall=3, gb_free=14.7, wall=18878
2023-03-15 19:14:24 - progress_bar.py[line:272] - INFO: epoch 028:   1104 / 2004 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=370.4, nsentences=8, sample_size=370.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1041.7, ups=2.81, wpb=370.4, bsz=8, num_updates=54860, lr=4.57066e-05, gnorm=2.067, clip=0, loss_scale=512, train_wall=3, gb_free=15.1, wall=18882
2023-03-15 19:14:28 - progress_bar.py[line:272] - INFO: epoch 028:   1114 / 2004 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=346.4, nsentences=8, sample_size=346.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=981.2, ups=2.83, wpb=346.4, bsz=8, num_updates=54870, lr=4.56965e-05, gnorm=2.016, clip=0, loss_scale=512, train_wall=3, gb_free=15.2, wall=18885
2023-03-15 19:14:31 - progress_bar.py[line:272] - INFO: epoch 028:   1124 / 2004 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=309.8, nsentences=8, sample_size=309.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=903.8, ups=2.92, wpb=309.8, bsz=8, num_updates=54880, lr=4.56864e-05, gnorm=1.929, clip=0, loss_scale=512, train_wall=3, gb_free=15, wall=18889
2023-03-15 19:14:34 - progress_bar.py[line:272] - INFO: epoch 028:   1134 / 2004 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=394.8, nsentences=8, sample_size=394.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1137.7, ups=2.88, wpb=394.8, bsz=8, num_updates=54890, lr=4.56763e-05, gnorm=1.805, clip=0, loss_scale=1024, train_wall=3, gb_free=13.9, wall=18892
2023-03-15 19:14:38 - progress_bar.py[line:272] - INFO: epoch 028:   1144 / 2004 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=338.3, nsentences=8, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=971.5, ups=2.87, wpb=338.3, bsz=8, num_updates=54900, lr=4.56662e-05, gnorm=2.24, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=18896
2023-03-15 19:14:41 - progress_bar.py[line:272] - INFO: epoch 028:   1154 / 2004 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=391.1, nsentences=8, sample_size=391.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1113, ups=2.85, wpb=391.1, bsz=8, num_updates=54910, lr=4.56562e-05, gnorm=2.201, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=18899
2023-03-15 19:14:45 - progress_bar.py[line:272] - INFO: epoch 028:   1164 / 2004 loss=0.127, loss_v1=0, loss_v2=0, nll_loss=0.127, ntokens=364.6, nsentences=8, sample_size=364.6, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1022.4, ups=2.8, wpb=364.6, bsz=8, num_updates=54920, lr=4.56461e-05, gnorm=1.723, clip=0, loss_scale=1024, train_wall=4, gb_free=13.9, wall=18903
2023-03-15 19:14:48 - progress_bar.py[line:272] - INFO: epoch 028:   1174 / 2004 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=356.9, nsentences=8, sample_size=356.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1018.2, ups=2.85, wpb=356.9, bsz=8, num_updates=54930, lr=4.5636e-05, gnorm=2.185, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=18906
2023-03-15 19:14:52 - progress_bar.py[line:272] - INFO: epoch 028:   1184 / 2004 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=328.1, nsentences=8, sample_size=328.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=967.3, ups=2.95, wpb=328.1, bsz=8, num_updates=54940, lr=4.56259e-05, gnorm=2.219, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=18910
2023-03-15 19:14:55 - progress_bar.py[line:272] - INFO: epoch 028:   1194 / 2004 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=360.4, nsentences=8, sample_size=360.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1060.8, ups=2.94, wpb=360.4, bsz=8, num_updates=54950, lr=4.56158e-05, gnorm=2.052, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=18913
2023-03-15 19:14:58 - progress_bar.py[line:272] - INFO: epoch 028:   1204 / 2004 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=313.8, nsentences=8, sample_size=313.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=990.8, ups=3.16, wpb=313.8, bsz=8, num_updates=54960, lr=4.56058e-05, gnorm=2.074, clip=0, loss_scale=1024, train_wall=3, gb_free=15.7, wall=18916
2023-03-15 19:15:02 - progress_bar.py[line:272] - INFO: epoch 028:   1214 / 2004 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=308.1, nsentences=8, sample_size=308.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=985.4, ups=3.2, wpb=308.1, bsz=8, num_updates=54970, lr=4.55957e-05, gnorm=1.85, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=18919
2023-03-15 19:15:05 - progress_bar.py[line:272] - INFO: epoch 028:   1224 / 2004 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=323.6, nsentences=8, sample_size=323.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1025.9, ups=3.17, wpb=323.6, bsz=8, num_updates=54980, lr=4.55856e-05, gnorm=1.943, clip=0, loss_scale=1024, train_wall=3, gb_free=15.7, wall=18922
2023-03-15 19:15:08 - progress_bar.py[line:272] - INFO: epoch 028:   1234 / 2004 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=326, nsentences=8, sample_size=326, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1006.5, ups=3.09, wpb=326, bsz=8, num_updates=54990, lr=4.55755e-05, gnorm=1.876, clip=0, loss_scale=1024, train_wall=3, gb_free=14.1, wall=18926
2023-03-15 19:15:11 - progress_bar.py[line:272] - INFO: epoch 028:   1244 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=385.1, nsentences=8, sample_size=385.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1110.9, ups=2.88, wpb=385.1, bsz=8, num_updates=55000, lr=4.55654e-05, gnorm=2.054, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=18929
2023-03-15 19:15:15 - progress_bar.py[line:272] - INFO: epoch 028:   1254 / 2004 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=339.2, nsentences=8, sample_size=339.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=972, ups=2.87, wpb=339.2, bsz=8, num_updates=55010, lr=4.55554e-05, gnorm=2.374, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=18933
2023-03-15 19:15:18 - progress_bar.py[line:272] - INFO: epoch 028:   1264 / 2004 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=337.7, nsentences=8, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=966.3, ups=2.86, wpb=337.7, bsz=8, num_updates=55020, lr=4.55453e-05, gnorm=1.986, clip=0, loss_scale=2048, train_wall=3, gb_free=14, wall=18936
2023-03-15 19:15:22 - progress_bar.py[line:272] - INFO: epoch 028:   1274 / 2004 loss=0.136, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=346.2, nsentences=8, sample_size=346.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=995.2, ups=2.87, wpb=346.2, bsz=8, num_updates=55030, lr=4.55352e-05, gnorm=1.805, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=18940
2023-03-15 19:15:25 - progress_bar.py[line:272] - INFO: epoch 028:   1284 / 2004 loss=0.135, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=334.4, nsentences=8, sample_size=334.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=948.5, ups=2.84, wpb=334.4, bsz=8, num_updates=55040, lr=4.55251e-05, gnorm=1.818, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=18943
2023-03-15 19:15:29 - progress_bar.py[line:272] - INFO: epoch 028:   1294 / 2004 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=310.1, nsentences=8, sample_size=310.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=901.3, ups=2.91, wpb=310.1, bsz=8, num_updates=55050, lr=4.5515e-05, gnorm=2.22, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=18946
2023-03-15 19:15:32 - progress_bar.py[line:272] - INFO: epoch 028:   1304 / 2004 loss=0.131, loss_v1=0, loss_v2=0, nll_loss=0.131, ntokens=327.6, nsentences=8, sample_size=327.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=966, ups=2.95, wpb=327.6, bsz=8, num_updates=55060, lr=4.55049e-05, gnorm=1.754, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=18950
2023-03-15 19:15:36 - progress_bar.py[line:272] - INFO: epoch 028:   1314 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=326.5, nsentences=8, sample_size=326.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=941.3, ups=2.88, wpb=326.5, bsz=8, num_updates=55070, lr=4.54949e-05, gnorm=2.037, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=18953
2023-03-15 19:15:39 - progress_bar.py[line:272] - INFO: epoch 028:   1324 / 2004 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=316.7, nsentences=8, sample_size=316.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=902.8, ups=2.85, wpb=316.7, bsz=8, num_updates=55080, lr=4.54848e-05, gnorm=1.857, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=18957
2023-03-15 19:15:43 - progress_bar.py[line:272] - INFO: epoch 028:   1334 / 2004 loss=0.134, loss_v1=0, loss_v2=0, nll_loss=0.134, ntokens=343.7, nsentences=8, sample_size=343.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=983, ups=2.86, wpb=343.7, bsz=8, num_updates=55090, lr=4.54747e-05, gnorm=2.072, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=18960
2023-03-15 19:15:46 - progress_bar.py[line:272] - INFO: epoch 028:   1344 / 2004 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=302.8, nsentences=8, sample_size=302.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=870.2, ups=2.87, wpb=302.8, bsz=8, num_updates=55100, lr=4.54646e-05, gnorm=2.17, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=18964
2023-03-15 19:15:51 - progress_bar.py[line:272] - INFO: epoch 028:   1354 / 2004 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=324.6, nsentences=8, sample_size=324.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=735.3, ups=2.27, wpb=324.6, bsz=8, num_updates=55110, lr=4.54545e-05, gnorm=2.039, clip=0, loss_scale=2048, train_wall=4, gb_free=15.1, wall=18968
2023-03-15 19:15:54 - progress_bar.py[line:272] - INFO: epoch 028:   1364 / 2004 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=315.6, nsentences=8, sample_size=315.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=900.1, ups=2.85, wpb=315.6, bsz=8, num_updates=55120, lr=4.54445e-05, gnorm=2.138, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=18972
2023-03-15 19:15:58 - progress_bar.py[line:272] - INFO: epoch 028:   1374 / 2004 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=314.7, nsentences=8, sample_size=314.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=899.9, ups=2.86, wpb=314.7, bsz=8, num_updates=55130, lr=4.54344e-05, gnorm=2.308, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=18975
2023-03-15 19:16:01 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 19:16:02 - progress_bar.py[line:272] - INFO: epoch 028:   1385 / 2004 loss=0.137, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=391.9, nsentences=8, sample_size=391.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1011.4, ups=2.58, wpb=391.9, bsz=8, num_updates=55140, lr=4.54243e-05, gnorm=2.052, clip=0, loss_scale=2048, train_wall=4, gb_free=15, wall=18979
2023-03-15 19:16:05 - progress_bar.py[line:272] - INFO: epoch 028:   1395 / 2004 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=348.3, nsentences=8, sample_size=348.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=998.1, ups=2.87, wpb=348.3, bsz=8, num_updates=55150, lr=4.54142e-05, gnorm=1.926, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=18983
2023-03-15 19:16:09 - progress_bar.py[line:272] - INFO: epoch 028:   1405 / 2004 loss=0.132, loss_v1=0, loss_v2=0, nll_loss=0.132, ntokens=342.2, nsentences=8, sample_size=342.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=978.3, ups=2.86, wpb=342.2, bsz=8, num_updates=55160, lr=4.54041e-05, gnorm=1.905, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=18986
2023-03-15 19:16:12 - progress_bar.py[line:272] - INFO: epoch 028:   1415 / 2004 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=395.9, nsentences=8, sample_size=395.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1131.2, ups=2.86, wpb=395.9, bsz=8, num_updates=55170, lr=4.53941e-05, gnorm=2.753, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=18990
2023-03-15 19:16:15 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 19:16:16 - progress_bar.py[line:272] - INFO: epoch 028:   1426 / 2004 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=285.9, nsentences=8, sample_size=285.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=749.2, ups=2.62, wpb=285.9, bsz=8, num_updates=55180, lr=4.5384e-05, gnorm=1.901, clip=0, loss_scale=1024, train_wall=4, gb_free=14.8, wall=18993
2023-03-15 19:16:19 - progress_bar.py[line:272] - INFO: epoch 028:   1436 / 2004 loss=0.133, loss_v1=0, loss_v2=0, nll_loss=0.133, ntokens=356.9, nsentences=8, sample_size=356.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=996.5, ups=2.79, wpb=356.9, bsz=8, num_updates=55190, lr=4.53739e-05, gnorm=1.961, clip=0, loss_scale=1024, train_wall=4, gb_free=15.5, wall=18997
2023-03-15 19:16:23 - progress_bar.py[line:272] - INFO: epoch 028:   1446 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=340.3, nsentences=8, sample_size=340.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=993.9, ups=2.92, wpb=340.3, bsz=8, num_updates=55200, lr=4.53638e-05, gnorm=2.238, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=19000
2023-03-15 19:16:26 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-03-15 19:16:27 - progress_bar.py[line:272] - INFO: epoch 028:   1457 / 2004 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=362.9, nsentences=8, sample_size=362.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=941.3, ups=2.59, wpb=362.9, bsz=8, num_updates=55210, lr=4.53537e-05, gnorm=2.253, clip=0, loss_scale=512, train_wall=4, gb_free=15.4, wall=19004
2023-03-15 19:16:30 - progress_bar.py[line:272] - INFO: epoch 028:   1467 / 2004 loss=0.131, loss_v1=0, loss_v2=0, nll_loss=0.131, ntokens=409.2, nsentences=8, sample_size=409.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1152.2, ups=2.82, wpb=409.2, bsz=8, num_updates=55220, lr=4.53437e-05, gnorm=2.105, clip=0, loss_scale=512, train_wall=3, gb_free=14.7, wall=19008
2023-03-15 19:16:34 - progress_bar.py[line:272] - INFO: epoch 028:   1477 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=400.9, nsentences=8, sample_size=400.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1141.1, ups=2.85, wpb=400.9, bsz=8, num_updates=55230, lr=4.53336e-05, gnorm=2.313, clip=0, loss_scale=512, train_wall=3, gb_free=14.8, wall=19011
2023-03-15 19:16:37 - progress_bar.py[line:272] - INFO: epoch 028:   1487 / 2004 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=332, nsentences=8, sample_size=332, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=953.5, ups=2.87, wpb=332, bsz=8, num_updates=55240, lr=4.53235e-05, gnorm=2.068, clip=0, loss_scale=512, train_wall=3, gb_free=15.6, wall=19015
2023-03-15 19:16:41 - progress_bar.py[line:272] - INFO: epoch 028:   1497 / 2004 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=342.2, nsentences=8, sample_size=342.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=978.4, ups=2.86, wpb=342.2, bsz=8, num_updates=55250, lr=4.53134e-05, gnorm=2.241, clip=0, loss_scale=512, train_wall=3, gb_free=14.5, wall=19018
2023-03-15 19:16:44 - progress_bar.py[line:272] - INFO: epoch 028:   1507 / 2004 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=323.1, nsentences=8, sample_size=323.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=939.8, ups=2.91, wpb=323.1, bsz=8, num_updates=55260, lr=4.53033e-05, gnorm=1.952, clip=0, loss_scale=512, train_wall=3, gb_free=14.6, wall=19022
2023-03-15 19:16:48 - progress_bar.py[line:272] - INFO: epoch 028:   1517 / 2004 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=330.4, nsentences=8, sample_size=330.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=949.5, ups=2.87, wpb=330.4, bsz=8, num_updates=55270, lr=4.52933e-05, gnorm=2.437, clip=0, loss_scale=512, train_wall=3, gb_free=15, wall=19025
2023-03-15 19:16:51 - progress_bar.py[line:272] - INFO: epoch 028:   1527 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=321, nsentences=8, sample_size=321, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=921.5, ups=2.87, wpb=321, bsz=8, num_updates=55280, lr=4.52832e-05, gnorm=2.142, clip=0, loss_scale=512, train_wall=3, gb_free=15.4, wall=19029
2023-03-15 19:16:55 - progress_bar.py[line:272] - INFO: epoch 028:   1537 / 2004 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=353.2, nsentences=8, sample_size=353.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1036.6, ups=2.93, wpb=353.2, bsz=8, num_updates=55290, lr=4.52731e-05, gnorm=1.883, clip=0, loss_scale=512, train_wall=3, gb_free=15, wall=19032
2023-03-15 19:16:58 - progress_bar.py[line:272] - INFO: epoch 028:   1547 / 2004 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=318.7, nsentences=8, sample_size=318.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=896.8, ups=2.81, wpb=318.7, bsz=8, num_updates=55300, lr=4.5263e-05, gnorm=1.955, clip=0, loss_scale=512, train_wall=3, gb_free=15.3, wall=19036
2023-03-15 19:17:02 - progress_bar.py[line:272] - INFO: epoch 028:   1557 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=349.2, nsentences=8, sample_size=349.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1000.7, ups=2.87, wpb=349.2, bsz=8, num_updates=55310, lr=4.52529e-05, gnorm=2.192, clip=0, loss_scale=512, train_wall=3, gb_free=15.1, wall=19039
2023-03-15 19:17:05 - progress_bar.py[line:272] - INFO: epoch 028:   1567 / 2004 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=334.5, nsentences=8, sample_size=334.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=977.3, ups=2.92, wpb=334.5, bsz=8, num_updates=55320, lr=4.52428e-05, gnorm=2.147, clip=0, loss_scale=512, train_wall=3, gb_free=15.5, wall=19043
2023-03-15 19:17:08 - progress_bar.py[line:272] - INFO: epoch 028:   1577 / 2004 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=357.8, nsentences=8, sample_size=357.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1026.1, ups=2.87, wpb=357.8, bsz=8, num_updates=55330, lr=4.52328e-05, gnorm=2.112, clip=0, loss_scale=512, train_wall=3, gb_free=15, wall=19046
2023-03-15 19:17:12 - progress_bar.py[line:272] - INFO: epoch 028:   1587 / 2004 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=308.2, nsentences=8, sample_size=308.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=886.9, ups=2.88, wpb=308.2, bsz=8, num_updates=55340, lr=4.52227e-05, gnorm=2.041, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=19050
2023-03-15 19:17:16 - progress_bar.py[line:272] - INFO: epoch 028:   1597 / 2004 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=358.6, nsentences=8, sample_size=358.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1014.6, ups=2.83, wpb=358.6, bsz=8, num_updates=55350, lr=4.52126e-05, gnorm=2.185, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=19053
2023-03-15 19:17:19 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-03-15 19:17:19 - progress_bar.py[line:272] - INFO: epoch 028:   1608 / 2004 loss=0.129, loss_v1=0, loss_v2=0, nll_loss=0.129, ntokens=338.1, nsentences=8, sample_size=338.1, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=892.1, ups=2.64, wpb=338.1, bsz=8, num_updates=55360, lr=4.52025e-05, gnorm=1.722, clip=0, loss_scale=512, train_wall=4, gb_free=15.4, wall=19057
2023-03-15 19:17:23 - progress_bar.py[line:272] - INFO: epoch 028:   1618 / 2004 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=345.6, nsentences=8, sample_size=345.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1000.8, ups=2.9, wpb=345.6, bsz=8, num_updates=55370, lr=4.51924e-05, gnorm=2.294, clip=0, loss_scale=512, train_wall=3, gb_free=14.5, wall=19060
2023-03-15 19:17:26 - progress_bar.py[line:272] - INFO: epoch 028:   1628 / 2004 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=369.5, nsentences=8, sample_size=369.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1057.8, ups=2.86, wpb=369.5, bsz=8, num_updates=55380, lr=4.51824e-05, gnorm=2.016, clip=0, loss_scale=512, train_wall=3, gb_free=14.9, wall=19064
2023-03-15 19:17:30 - progress_bar.py[line:272] - INFO: epoch 028:   1638 / 2004 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=319, nsentences=8, sample_size=319, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=911.5, ups=2.86, wpb=319, bsz=8, num_updates=55390, lr=4.51723e-05, gnorm=2.249, clip=0, loss_scale=512, train_wall=3, gb_free=15.7, wall=19067
2023-03-15 19:17:33 - progress_bar.py[line:272] - INFO: epoch 028:   1648 / 2004 loss=0.134, loss_v1=0, loss_v2=0, nll_loss=0.134, ntokens=315.7, nsentences=8, sample_size=315.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=897.5, ups=2.84, wpb=315.7, bsz=8, num_updates=55400, lr=4.51622e-05, gnorm=1.838, clip=0, loss_scale=512, train_wall=3, gb_free=14.2, wall=19071
2023-03-15 19:17:37 - progress_bar.py[line:272] - INFO: epoch 028:   1658 / 2004 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=343.7, nsentences=8, sample_size=343.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=976.2, ups=2.84, wpb=343.7, bsz=8, num_updates=55410, lr=4.51521e-05, gnorm=2.183, clip=0, loss_scale=512, train_wall=3, gb_free=15.8, wall=19074
2023-03-15 19:17:40 - progress_bar.py[line:272] - INFO: epoch 028:   1668 / 2004 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=355, nsentences=8, sample_size=355, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=987.9, ups=2.78, wpb=355, bsz=8, num_updates=55420, lr=4.5142e-05, gnorm=2.013, clip=0, loss_scale=512, train_wall=4, gb_free=14.9, wall=19078
2023-03-15 19:17:44 - progress_bar.py[line:272] - INFO: epoch 028:   1678 / 2004 loss=0.135, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=321.1, nsentences=8, sample_size=321.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=931.3, ups=2.9, wpb=321.1, bsz=8, num_updates=55430, lr=4.5132e-05, gnorm=1.979, clip=0, loss_scale=512, train_wall=3, gb_free=15.4, wall=19081
2023-03-15 19:17:47 - progress_bar.py[line:272] - INFO: epoch 028:   1688 / 2004 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=341.6, nsentences=8, sample_size=341.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=989.1, ups=2.9, wpb=341.6, bsz=8, num_updates=55440, lr=4.51219e-05, gnorm=2.08, clip=0, loss_scale=512, train_wall=3, gb_free=14.9, wall=19085
2023-03-15 19:17:51 - progress_bar.py[line:272] - INFO: epoch 028:   1698 / 2004 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=336.2, nsentences=8, sample_size=336.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=968.6, ups=2.88, wpb=336.2, bsz=8, num_updates=55450, lr=4.51118e-05, gnorm=2.047, clip=0, loss_scale=512, train_wall=3, gb_free=14.9, wall=19088
2023-03-15 19:17:54 - progress_bar.py[line:272] - INFO: epoch 028:   1708 / 2004 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=343.8, nsentences=8, sample_size=343.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=997.8, ups=2.9, wpb=343.8, bsz=8, num_updates=55460, lr=4.51017e-05, gnorm=2.095, clip=0, loss_scale=512, train_wall=3, gb_free=15.5, wall=19092
2023-03-15 19:17:58 - progress_bar.py[line:272] - INFO: epoch 028:   1718 / 2004 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=379.9, nsentences=8, sample_size=379.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1064.1, ups=2.8, wpb=379.9, bsz=8, num_updates=55470, lr=4.50916e-05, gnorm=2.222, clip=0, loss_scale=512, train_wall=4, gb_free=14.4, wall=19095
2023-03-15 19:18:01 - progress_bar.py[line:272] - INFO: epoch 028:   1728 / 2004 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=390.8, nsentences=8, sample_size=390.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1110.2, ups=2.84, wpb=390.8, bsz=8, num_updates=55480, lr=4.50816e-05, gnorm=2.064, clip=0, loss_scale=512, train_wall=3, gb_free=14.7, wall=19099
2023-03-15 19:18:05 - progress_bar.py[line:272] - INFO: epoch 028:   1738 / 2004 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=326.8, nsentences=8, sample_size=326.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=948.6, ups=2.9, wpb=326.8, bsz=8, num_updates=55490, lr=4.50715e-05, gnorm=2.405, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=19102
2023-03-15 19:18:08 - progress_bar.py[line:272] - INFO: epoch 028:   1748 / 2004 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=348.9, nsentences=8, sample_size=348.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=992, ups=2.84, wpb=348.9, bsz=8, num_updates=55500, lr=4.50614e-05, gnorm=1.774, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=19106
2023-03-15 19:18:12 - progress_bar.py[line:272] - INFO: epoch 028:   1758 / 2004 loss=0.131, loss_v1=0, loss_v2=0, nll_loss=0.131, ntokens=328, nsentences=8, sample_size=328, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=942.7, ups=2.87, wpb=328, bsz=8, num_updates=55510, lr=4.50513e-05, gnorm=1.89, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=19109
2023-03-15 19:18:15 - progress_bar.py[line:272] - INFO: epoch 028:   1768 / 2004 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=323.1, nsentences=8, sample_size=323.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=937.5, ups=2.9, wpb=323.1, bsz=8, num_updates=55520, lr=4.50412e-05, gnorm=2.235, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=19113
2023-03-15 19:18:19 - progress_bar.py[line:272] - INFO: epoch 028:   1778 / 2004 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=347.6, nsentences=8, sample_size=347.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1002, ups=2.88, wpb=347.6, bsz=8, num_updates=55530, lr=4.50311e-05, gnorm=2.011, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=19116
2023-03-15 19:18:22 - progress_bar.py[line:272] - INFO: epoch 028:   1788 / 2004 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=297.6, nsentences=8, sample_size=297.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=875.6, ups=2.94, wpb=297.6, bsz=8, num_updates=55540, lr=4.50211e-05, gnorm=1.917, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=19120
2023-03-15 19:18:24 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-03-15 19:18:26 - progress_bar.py[line:272] - INFO: epoch 028:   1799 / 2004 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=358, nsentences=8, sample_size=358, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=935.1, ups=2.61, wpb=358, bsz=8, num_updates=55550, lr=4.5011e-05, gnorm=1.952, clip=0, loss_scale=512, train_wall=4, gb_free=14.7, wall=19123
2023-03-15 19:18:29 - progress_bar.py[line:272] - INFO: epoch 028:   1809 / 2004 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=347.7, nsentences=8, sample_size=347.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1021.9, ups=2.94, wpb=347.7, bsz=8, num_updates=55560, lr=4.50009e-05, gnorm=2.099, clip=0, loss_scale=512, train_wall=3, gb_free=14.8, wall=19127
2023-03-15 19:18:33 - progress_bar.py[line:272] - INFO: epoch 028:   1819 / 2004 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=357.9, nsentences=8, sample_size=357.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1026.6, ups=2.87, wpb=357.9, bsz=8, num_updates=55570, lr=4.49908e-05, gnorm=2.111, clip=0, loss_scale=512, train_wall=3, gb_free=14.8, wall=19130
2023-03-15 19:18:36 - progress_bar.py[line:272] - INFO: epoch 028:   1829 / 2004 loss=0.137, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=339.4, nsentences=8, sample_size=339.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=928.8, ups=2.74, wpb=339.4, bsz=8, num_updates=55580, lr=4.49807e-05, gnorm=2.004, clip=0, loss_scale=512, train_wall=4, gb_free=15, wall=19134
2023-03-15 19:18:40 - progress_bar.py[line:272] - INFO: epoch 028:   1839 / 2004 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=341.2, nsentences=8, sample_size=341.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=992.8, ups=2.91, wpb=341.2, bsz=8, num_updates=55590, lr=4.49707e-05, gnorm=1.985, clip=0, loss_scale=512, train_wall=3, gb_free=14.4, wall=19137
2023-03-15 19:18:43 - progress_bar.py[line:272] - INFO: epoch 028:   1849 / 2004 loss=0.135, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=351.7, nsentences=8, sample_size=351.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=993.9, ups=2.83, wpb=351.7, bsz=8, num_updates=55600, lr=4.49606e-05, gnorm=2.034, clip=0, loss_scale=512, train_wall=3, gb_free=14.6, wall=19141
2023-03-15 19:18:47 - progress_bar.py[line:272] - INFO: epoch 028:   1859 / 2004 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=330.7, nsentences=8, sample_size=330.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=923.1, ups=2.79, wpb=330.7, bsz=8, num_updates=55610, lr=4.49505e-05, gnorm=2.209, clip=0, loss_scale=512, train_wall=4, gb_free=14.8, wall=19145
2023-03-15 19:18:50 - progress_bar.py[line:272] - INFO: epoch 028:   1869 / 2004 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=335.2, nsentences=8, sample_size=335.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=979.2, ups=2.92, wpb=335.2, bsz=8, num_updates=55620, lr=4.49404e-05, gnorm=2.033, clip=0, loss_scale=512, train_wall=3, gb_free=14.9, wall=19148
2023-03-15 19:18:54 - progress_bar.py[line:272] - INFO: epoch 028:   1879 / 2004 loss=0.131, loss_v1=0, loss_v2=0, nll_loss=0.131, ntokens=333.8, nsentences=8, sample_size=333.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=954.5, ups=2.86, wpb=333.8, bsz=8, num_updates=55630, lr=4.49303e-05, gnorm=1.724, clip=0, loss_scale=512, train_wall=3, gb_free=15.2, wall=19152
2023-03-15 19:18:57 - progress_bar.py[line:272] - INFO: epoch 028:   1889 / 2004 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=317, nsentences=8, sample_size=317, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=929.7, ups=2.93, wpb=317, bsz=8, num_updates=55640, lr=4.49203e-05, gnorm=2.091, clip=0, loss_scale=512, train_wall=3, gb_free=15.3, wall=19155
2023-03-15 19:19:01 - progress_bar.py[line:272] - INFO: epoch 028:   1899 / 2004 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=351, nsentences=8, sample_size=351, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1007.8, ups=2.87, wpb=351, bsz=8, num_updates=55650, lr=4.49102e-05, gnorm=2.044, clip=0, loss_scale=512, train_wall=3, gb_free=14.3, wall=19158
2023-03-15 19:19:04 - progress_bar.py[line:272] - INFO: epoch 028:   1909 / 2004 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=337.3, nsentences=8, sample_size=337.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=972.6, ups=2.88, wpb=337.3, bsz=8, num_updates=55660, lr=4.49001e-05, gnorm=2.219, clip=0, loss_scale=512, train_wall=3, gb_free=15.5, wall=19162
2023-03-15 19:19:08 - progress_bar.py[line:272] - INFO: epoch 028:   1919 / 2004 loss=0.132, loss_v1=0, loss_v2=0, nll_loss=0.132, ntokens=338.8, nsentences=8, sample_size=338.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=982.6, ups=2.9, wpb=338.8, bsz=8, num_updates=55670, lr=4.489e-05, gnorm=1.97, clip=0, loss_scale=512, train_wall=3, gb_free=14.9, wall=19165
2023-03-15 19:19:11 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-03-15 19:19:11 - progress_bar.py[line:272] - INFO: epoch 028:   1930 / 2004 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=316.9, nsentences=8, sample_size=316.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=838.5, ups=2.65, wpb=316.9, bsz=8, num_updates=55680, lr=4.48799e-05, gnorm=1.928, clip=0, loss_scale=512, train_wall=4, gb_free=14.6, wall=19169
2023-03-15 19:19:15 - progress_bar.py[line:272] - INFO: epoch 028:   1940 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=349.9, nsentences=8, sample_size=349.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1000.9, ups=2.86, wpb=349.9, bsz=8, num_updates=55690, lr=4.48699e-05, gnorm=2.102, clip=0, loss_scale=512, train_wall=3, gb_free=15.1, wall=19173
2023-03-15 19:19:18 - progress_bar.py[line:272] - INFO: epoch 028:   1950 / 2004 loss=0.137, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=337.9, nsentences=8, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=971.5, ups=2.88, wpb=337.9, bsz=8, num_updates=55700, lr=4.48598e-05, gnorm=1.93, clip=0, loss_scale=512, train_wall=3, gb_free=15.6, wall=19176
2023-03-15 19:19:22 - progress_bar.py[line:272] - INFO: epoch 028:   1960 / 2004 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=365.6, nsentences=8, sample_size=365.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1020, ups=2.79, wpb=365.6, bsz=8, num_updates=55710, lr=4.48497e-05, gnorm=2.018, clip=0, loss_scale=512, train_wall=4, gb_free=14.7, wall=19180
2023-03-15 19:19:25 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-03-15 19:19:26 - progress_bar.py[line:272] - INFO: epoch 028:   1971 / 2004 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=362.3, nsentences=8, sample_size=362.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=945, ups=2.61, wpb=362.3, bsz=8, num_updates=55720, lr=4.48396e-05, gnorm=2.157, clip=0, loss_scale=256, train_wall=4, gb_free=14.1, wall=19184
2023-03-15 19:19:29 - progress_bar.py[line:272] - INFO: epoch 028:   1981 / 2004 loss=0.129, loss_v1=0, loss_v2=0, nll_loss=0.129, ntokens=321.6, nsentences=8, sample_size=321.6, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=916.7, ups=2.85, wpb=321.6, bsz=8, num_updates=55730, lr=4.48295e-05, gnorm=1.932, clip=0, loss_scale=256, train_wall=3, gb_free=15.4, wall=19187
2023-03-15 19:19:33 - progress_bar.py[line:272] - INFO: epoch 028:   1991 / 2004 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=360.9, nsentences=8, sample_size=360.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1014.6, ups=2.81, wpb=360.9, bsz=8, num_updates=55740, lr=4.48195e-05, gnorm=2.172, clip=0, loss_scale=256, train_wall=3, gb_free=14.9, wall=19191
2023-03-15 19:19:36 - progress_bar.py[line:272] - INFO: epoch 028:   2001 / 2004 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=370.4, nsentences=8, sample_size=370.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1085.3, ups=2.93, wpb=370.4, bsz=8, num_updates=55750, lr=4.48094e-05, gnorm=2.325, clip=0, loss_scale=256, train_wall=3, gb_free=14.8, wall=19194
2023-03-15 19:19:37 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 28 @ 55753 updates
2023-03-15 19:19:37 - trainer.py[line:431] - INFO: Saving checkpoint to ./checkpoints/checkpoint28.pt
2023-03-15 19:19:44 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./checkpoints/checkpoint28.pt
2023-03-15 19:19:46 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./checkpoints/checkpoint28.pt (epoch 28 @ 55753 updates, score None) (writing took 9.124691447243094 seconds)
2023-03-15 19:19:47 - train.py[line:332] - INFO: end of epoch 28 (average epoch stats below)
2023-03-15 19:19:47 - progress_bar.py[line:282] - INFO: epoch 028 | loss 0.146 | loss_v1 0 | loss_v2 0 | nll_loss 0.146 | ntokens 345.696 | nsentences 7.999 | sample_size 345.696 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.11 | wps 958.2 | ups 2.77 | wpb 345.7 | bsz 8 | num_updates 55753 | lr 4.48063e-05 | gnorm 2.072 | clip 0 | loss_scale 256 | train_wall 685 | gb_free 14.9 | wall 19204
2023-03-15 19:19:47 - trainer.py[line:639] - INFO: loading train data for epoch 29
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 row count 8015 total row count 8015
slice_id 0 seek offset 0
2023-03-15 19:19:48 - trainer.py[line:703] - INFO: begin training epoch 29
2023-03-15 19:19:48 - train.py[line:305] - INFO: Start iterating over samples
2023-03-15 19:19:50 - progress_bar.py[line:272] - INFO: epoch 029:      7 / 2004 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=384.9, nsentences=8, sample_size=384.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=277.5, ups=0.72, wpb=384.9, bsz=8, num_updates=55760, lr=4.47993e-05, gnorm=2.361, clip=0, loss_scale=256, train_wall=3, gb_free=15.4, wall=19208
2023-03-15 19:19:54 - progress_bar.py[line:272] - INFO: epoch 029:     17 / 2004 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=320.8, nsentences=8, sample_size=320.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=938.1, ups=2.92, wpb=320.8, bsz=8, num_updates=55770, lr=4.47892e-05, gnorm=1.844, clip=0, loss_scale=256, train_wall=3, gb_free=14.6, wall=19211
2023-03-15 19:19:57 - progress_bar.py[line:272] - INFO: epoch 029:     27 / 2004 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=357.9, nsentences=8, sample_size=357.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1025.5, ups=2.87, wpb=357.9, bsz=8, num_updates=55780, lr=4.47791e-05, gnorm=2.118, clip=0, loss_scale=256, train_wall=3, gb_free=15, wall=19215
2023-03-15 19:20:01 - progress_bar.py[line:272] - INFO: epoch 029:     37 / 2004 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=347.8, nsentences=8, sample_size=347.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1028.6, ups=2.96, wpb=347.8, bsz=8, num_updates=55790, lr=4.4769e-05, gnorm=2.046, clip=0, loss_scale=256, train_wall=3, gb_free=14.9, wall=19218
2023-03-15 19:20:04 - progress_bar.py[line:272] - INFO: epoch 029:     47 / 2004 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=350.5, nsentences=8, sample_size=350.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1004.8, ups=2.87, wpb=350.5, bsz=8, num_updates=55800, lr=4.4759e-05, gnorm=2.033, clip=0, loss_scale=256, train_wall=3, gb_free=15.5, wall=19222
2023-03-15 19:20:07 - progress_bar.py[line:272] - INFO: epoch 029:     57 / 2004 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=360.4, nsentences=8, sample_size=360.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1060.9, ups=2.94, wpb=360.4, bsz=8, num_updates=55810, lr=4.47489e-05, gnorm=1.962, clip=0, loss_scale=256, train_wall=3, gb_free=14.6, wall=19225
2023-03-15 19:20:11 - progress_bar.py[line:272] - INFO: epoch 029:     67 / 2004 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=328.9, nsentences=8, sample_size=328.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=931.6, ups=2.83, wpb=328.9, bsz=8, num_updates=55820, lr=4.47388e-05, gnorm=2.375, clip=0, loss_scale=256, train_wall=3, gb_free=14.9, wall=19229
2023-03-15 19:20:14 - progress_bar.py[line:272] - INFO: epoch 029:     77 / 2004 loss=0.132, loss_v1=0, loss_v2=0, nll_loss=0.132, ntokens=336.2, nsentences=8, sample_size=336.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=974.4, ups=2.9, wpb=336.2, bsz=8, num_updates=55830, lr=4.47287e-05, gnorm=1.899, clip=0, loss_scale=256, train_wall=3, gb_free=15, wall=19232
2023-03-15 19:20:18 - progress_bar.py[line:272] - INFO: epoch 029:     87 / 2004 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=353.6, nsentences=8, sample_size=353.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1002.7, ups=2.84, wpb=353.6, bsz=8, num_updates=55840, lr=4.47186e-05, gnorm=2.193, clip=0, loss_scale=256, train_wall=3, gb_free=14.9, wall=19236
2023-03-15 19:20:21 - progress_bar.py[line:272] - INFO: epoch 029:     97 / 2004 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=371.5, nsentences=8, sample_size=371.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1067.7, ups=2.87, wpb=371.5, bsz=8, num_updates=55850, lr=4.47086e-05, gnorm=2.128, clip=0, loss_scale=512, train_wall=3, gb_free=14.7, wall=19239
2023-03-15 19:20:25 - progress_bar.py[line:272] - INFO: epoch 029:    107 / 2004 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=363.5, nsentences=8, sample_size=363.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1047, ups=2.88, wpb=363.5, bsz=8, num_updates=55860, lr=4.46985e-05, gnorm=2.104, clip=0, loss_scale=512, train_wall=3, gb_free=14.7, wall=19242
2023-03-15 19:20:28 - progress_bar.py[line:272] - INFO: epoch 029:    117 / 2004 loss=0.135, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=328.6, nsentences=8, sample_size=328.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=949.9, ups=2.89, wpb=328.6, bsz=8, num_updates=55870, lr=4.46884e-05, gnorm=1.85, clip=0, loss_scale=512, train_wall=3, gb_free=15.5, wall=19246
2023-03-15 19:20:32 - progress_bar.py[line:272] - INFO: epoch 029:    127 / 2004 loss=0.134, loss_v1=0, loss_v2=0, nll_loss=0.134, ntokens=344.5, nsentences=8, sample_size=344.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=980.7, ups=2.85, wpb=344.5, bsz=8, num_updates=55880, lr=4.46783e-05, gnorm=1.771, clip=0, loss_scale=512, train_wall=3, gb_free=14.9, wall=19249
2023-03-15 19:20:35 - progress_bar.py[line:272] - INFO: epoch 029:    137 / 2004 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=325.1, nsentences=8, sample_size=325.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=941.1, ups=2.89, wpb=325.1, bsz=8, num_updates=55890, lr=4.46682e-05, gnorm=2.104, clip=0, loss_scale=512, train_wall=3, gb_free=14.8, wall=19253
2023-03-15 19:20:39 - progress_bar.py[line:272] - INFO: epoch 029:    147 / 2004 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=336.8, nsentences=8, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=995.4, ups=2.96, wpb=336.8, bsz=8, num_updates=55900, lr=4.46582e-05, gnorm=1.883, clip=0, loss_scale=512, train_wall=3, gb_free=14.7, wall=19256
2023-03-15 19:20:42 - progress_bar.py[line:272] - INFO: epoch 029:    157 / 2004 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=342.5, nsentences=8, sample_size=342.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=998.7, ups=2.92, wpb=342.5, bsz=8, num_updates=55910, lr=4.46481e-05, gnorm=2.114, clip=0, loss_scale=512, train_wall=3, gb_free=15.2, wall=19260
2023-03-15 19:20:46 - progress_bar.py[line:272] - INFO: epoch 029:    167 / 2004 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=351.3, nsentences=8, sample_size=351.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1008, ups=2.87, wpb=351.3, bsz=8, num_updates=55920, lr=4.4638e-05, gnorm=2.234, clip=0, loss_scale=512, train_wall=3, gb_free=14.4, wall=19263
2023-03-15 19:20:49 - progress_bar.py[line:272] - INFO: epoch 029:    177 / 2004 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=336.2, nsentences=8, sample_size=336.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=968, ups=2.88, wpb=336.2, bsz=8, num_updates=55930, lr=4.46279e-05, gnorm=2.148, clip=0, loss_scale=512, train_wall=3, gb_free=15.1, wall=19267
2023-03-15 19:20:53 - progress_bar.py[line:272] - INFO: epoch 029:    187 / 2004 loss=0.137, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=330.2, nsentences=8, sample_size=330.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=962.2, ups=2.91, wpb=330.2, bsz=8, num_updates=55940, lr=4.46178e-05, gnorm=2.108, clip=0, loss_scale=512, train_wall=3, gb_free=15.2, wall=19270
2023-03-15 19:20:56 - progress_bar.py[line:272] - INFO: epoch 029:    197 / 2004 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=319.2, nsentences=8, sample_size=319.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=922.5, ups=2.89, wpb=319.2, bsz=8, num_updates=55950, lr=4.46078e-05, gnorm=2.114, clip=0, loss_scale=512, train_wall=3, gb_free=15.1, wall=19274
2023-03-15 19:20:59 - progress_bar.py[line:272] - INFO: epoch 029:    207 / 2004 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=346.4, nsentences=8, sample_size=346.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=999.7, ups=2.89, wpb=346.4, bsz=8, num_updates=55960, lr=4.45977e-05, gnorm=2.144, clip=0, loss_scale=512, train_wall=3, gb_free=14.6, wall=19277
2023-03-15 19:21:03 - progress_bar.py[line:272] - INFO: epoch 029:    217 / 2004 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=321.6, nsentences=8, sample_size=321.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=932.1, ups=2.9, wpb=321.6, bsz=8, num_updates=55970, lr=4.45876e-05, gnorm=2.017, clip=0, loss_scale=512, train_wall=3, gb_free=14.7, wall=19281
2023-03-15 19:21:06 - progress_bar.py[line:272] - INFO: epoch 029:    227 / 2004 loss=0.121, loss_v1=0, loss_v2=0, nll_loss=0.121, ntokens=347.8, nsentences=8, sample_size=347.8, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=998.2, ups=2.87, wpb=347.8, bsz=8, num_updates=55980, lr=4.45775e-05, gnorm=1.754, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=19284
2023-03-15 19:21:10 - progress_bar.py[line:272] - INFO: epoch 029:    237 / 2004 loss=0.131, loss_v1=0, loss_v2=0, nll_loss=0.131, ntokens=375.8, nsentences=8, sample_size=375.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1072.6, ups=2.85, wpb=375.8, bsz=8, num_updates=55990, lr=4.45674e-05, gnorm=1.843, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=19287
2023-03-15 19:21:13 - progress_bar.py[line:272] - INFO: epoch 029:    247 / 2004 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=347.4, nsentences=8, sample_size=347.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=989.7, ups=2.85, wpb=347.4, bsz=8, num_updates=56000, lr=4.45573e-05, gnorm=1.916, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=19291
2023-03-15 19:21:17 - progress_bar.py[line:272] - INFO: epoch 029:    257 / 2004 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=336.8, nsentences=8, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=947.9, ups=2.81, wpb=336.8, bsz=8, num_updates=56010, lr=4.45473e-05, gnorm=2.213, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=19295
2023-03-15 19:21:20 - progress_bar.py[line:272] - INFO: epoch 029:    267 / 2004 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=352.4, nsentences=8, sample_size=352.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1023, ups=2.9, wpb=352.4, bsz=8, num_updates=56020, lr=4.45372e-05, gnorm=2.019, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=19298
2023-03-15 19:21:24 - progress_bar.py[line:272] - INFO: epoch 029:    277 / 2004 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=345.8, nsentences=8, sample_size=345.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1012.3, ups=2.93, wpb=345.8, bsz=8, num_updates=56030, lr=4.45271e-05, gnorm=1.84, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=19301
2023-03-15 19:21:27 - progress_bar.py[line:272] - INFO: epoch 029:    287 / 2004 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=357.4, nsentences=8, sample_size=357.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1022.1, ups=2.86, wpb=357.4, bsz=8, num_updates=56040, lr=4.4517e-05, gnorm=2.122, clip=0, loss_scale=1024, train_wall=3, gb_free=15.7, wall=19305
2023-03-15 19:21:31 - progress_bar.py[line:272] - INFO: epoch 029:    297 / 2004 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=374.1, nsentences=8, sample_size=374.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1083.7, ups=2.9, wpb=374.1, bsz=8, num_updates=56050, lr=4.45069e-05, gnorm=2.025, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=19308
2023-03-15 19:21:34 - progress_bar.py[line:272] - INFO: epoch 029:    307 / 2004 loss=0.137, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=336, nsentences=8, sample_size=336, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=998.4, ups=2.97, wpb=336, bsz=8, num_updates=56060, lr=4.44969e-05, gnorm=1.871, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=19312
2023-03-15 19:21:38 - progress_bar.py[line:272] - INFO: epoch 029:    317 / 2004 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=348, nsentences=8, sample_size=348, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=996.2, ups=2.86, wpb=348, bsz=8, num_updates=56070, lr=4.44868e-05, gnorm=2.238, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=19315
2023-03-15 19:21:41 - progress_bar.py[line:272] - INFO: epoch 029:    327 / 2004 loss=0.129, loss_v1=0, loss_v2=0, nll_loss=0.129, ntokens=323.6, nsentences=8, sample_size=323.6, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=935.5, ups=2.89, wpb=323.6, bsz=8, num_updates=56080, lr=4.44767e-05, gnorm=1.675, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=19319
2023-03-15 19:21:45 - progress_bar.py[line:272] - INFO: epoch 029:    337 / 2004 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=342.5, nsentences=8, sample_size=342.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=979.8, ups=2.86, wpb=342.5, bsz=8, num_updates=56090, lr=4.44666e-05, gnorm=2.219, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=19322
2023-03-15 19:21:48 - progress_bar.py[line:272] - INFO: epoch 029:    347 / 2004 loss=0.124, loss_v1=0, loss_v2=0, nll_loss=0.124, ntokens=374.8, nsentences=8, sample_size=374.8, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1063, ups=2.84, wpb=374.8, bsz=8, num_updates=56100, lr=4.44565e-05, gnorm=1.849, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=19326
2023-03-15 19:21:52 - progress_bar.py[line:272] - INFO: epoch 029:    357 / 2004 loss=0.134, loss_v1=0, loss_v2=0, nll_loss=0.134, ntokens=353.3, nsentences=8, sample_size=353.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1030.7, ups=2.92, wpb=353.3, bsz=8, num_updates=56110, lr=4.44465e-05, gnorm=1.836, clip=0, loss_scale=2048, train_wall=3, gb_free=13.7, wall=19329
2023-03-15 19:21:55 - progress_bar.py[line:272] - INFO: epoch 029:    367 / 2004 loss=0.128, loss_v1=0, loss_v2=0, nll_loss=0.128, ntokens=351.7, nsentences=8, sample_size=351.7, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1006.7, ups=2.86, wpb=351.7, bsz=8, num_updates=56120, lr=4.44364e-05, gnorm=1.828, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=19333
2023-03-15 19:21:58 - progress_bar.py[line:272] - INFO: epoch 029:    377 / 2004 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=302.3, nsentences=8, sample_size=302.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=877.8, ups=2.9, wpb=302.3, bsz=8, num_updates=56130, lr=4.44263e-05, gnorm=1.907, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=19336
2023-03-15 19:22:02 - progress_bar.py[line:272] - INFO: epoch 029:    387 / 2004 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=336.1, nsentences=8, sample_size=336.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=961.8, ups=2.86, wpb=336.1, bsz=8, num_updates=56140, lr=4.44162e-05, gnorm=2.07, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=19340
2023-03-15 19:22:05 - progress_bar.py[line:272] - INFO: epoch 029:    397 / 2004 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=347, nsentences=8, sample_size=347, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1001.3, ups=2.89, wpb=347, bsz=8, num_updates=56150, lr=4.44061e-05, gnorm=2.127, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=19343
2023-03-15 19:22:09 - progress_bar.py[line:272] - INFO: epoch 029:    407 / 2004 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=382, nsentences=8, sample_size=382, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1116.2, ups=2.92, wpb=382, bsz=8, num_updates=56160, lr=4.43961e-05, gnorm=2.092, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=19346
2023-03-15 19:22:12 - progress_bar.py[line:272] - INFO: epoch 029:    417 / 2004 loss=0.133, loss_v1=0, loss_v2=0, nll_loss=0.133, ntokens=337.8, nsentences=8, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=979.6, ups=2.9, wpb=337.8, bsz=8, num_updates=56170, lr=4.4386e-05, gnorm=2.02, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=19350
2023-03-15 19:22:16 - progress_bar.py[line:272] - INFO: epoch 029:    427 / 2004 loss=0.124, loss_v1=0, loss_v2=0, nll_loss=0.124, ntokens=338.1, nsentences=8, sample_size=338.1, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=959.7, ups=2.84, wpb=338.1, bsz=8, num_updates=56180, lr=4.43759e-05, gnorm=1.893, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=19353
2023-03-15 19:22:19 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 19:22:20 - progress_bar.py[line:272] - INFO: epoch 029:    438 / 2004 loss=0.136, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=347.1, nsentences=8, sample_size=347.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=922, ups=2.66, wpb=347.1, bsz=8, num_updates=56190, lr=4.43658e-05, gnorm=1.981, clip=0, loss_scale=1024, train_wall=4, gb_free=15.1, wall=19357
2023-03-15 19:22:23 - progress_bar.py[line:272] - INFO: epoch 029:    448 / 2004 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=377.2, nsentences=8, sample_size=377.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1075.8, ups=2.85, wpb=377.2, bsz=8, num_updates=56200, lr=4.43557e-05, gnorm=2.143, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=19361
2023-03-15 19:22:27 - progress_bar.py[line:272] - INFO: epoch 029:    458 / 2004 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=394, nsentences=8, sample_size=394, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1127.3, ups=2.86, wpb=394, bsz=8, num_updates=56210, lr=4.43457e-05, gnorm=2.499, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=19364
2023-03-15 19:22:30 - progress_bar.py[line:272] - INFO: epoch 029:    468 / 2004 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=358.4, nsentences=8, sample_size=358.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1054.1, ups=2.94, wpb=358.4, bsz=8, num_updates=56220, lr=4.43356e-05, gnorm=1.994, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=19368
2023-03-15 19:22:33 - progress_bar.py[line:272] - INFO: epoch 029:    478 / 2004 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=338.3, nsentences=8, sample_size=338.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=985, ups=2.91, wpb=338.3, bsz=8, num_updates=56230, lr=4.43255e-05, gnorm=2.037, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=19371
2023-03-15 19:22:37 - progress_bar.py[line:272] - INFO: epoch 029:    488 / 2004 loss=0.136, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=375.5, nsentences=8, sample_size=375.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1098, ups=2.92, wpb=375.5, bsz=8, num_updates=56240, lr=4.43154e-05, gnorm=2.128, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=19374
2023-03-15 19:22:40 - progress_bar.py[line:272] - INFO: epoch 029:    498 / 2004 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=365.1, nsentences=8, sample_size=365.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1043.6, ups=2.86, wpb=365.1, bsz=8, num_updates=56250, lr=4.43053e-05, gnorm=1.97, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=19378
2023-03-15 19:22:44 - progress_bar.py[line:272] - INFO: epoch 029:    508 / 2004 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=352.5, nsentences=8, sample_size=352.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1035.5, ups=2.94, wpb=352.5, bsz=8, num_updates=56260, lr=4.42952e-05, gnorm=2.152, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=19381
2023-03-15 19:22:47 - progress_bar.py[line:272] - INFO: epoch 029:    518 / 2004 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=351.6, nsentences=8, sample_size=351.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1022.1, ups=2.91, wpb=351.6, bsz=8, num_updates=56270, lr=4.42852e-05, gnorm=2.159, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=19385
2023-03-15 19:22:51 - progress_bar.py[line:272] - INFO: epoch 029:    528 / 2004 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=402.8, nsentences=8, sample_size=402.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1132.7, ups=2.81, wpb=402.8, bsz=8, num_updates=56280, lr=4.42751e-05, gnorm=1.905, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=19388
2023-03-15 19:22:54 - progress_bar.py[line:272] - INFO: epoch 029:    538 / 2004 loss=0.135, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=385.5, nsentences=8, sample_size=385.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1105.5, ups=2.87, wpb=385.5, bsz=8, num_updates=56290, lr=4.4265e-05, gnorm=1.956, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=19392
2023-03-15 19:22:58 - progress_bar.py[line:272] - INFO: epoch 029:    548 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=350.6, nsentences=8, sample_size=350.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=995.6, ups=2.84, wpb=350.6, bsz=8, num_updates=56300, lr=4.42549e-05, gnorm=2.238, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=19395
2023-03-15 19:23:01 - progress_bar.py[line:272] - INFO: epoch 029:    558 / 2004 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=378.2, nsentences=8, sample_size=378.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1069.3, ups=2.83, wpb=378.2, bsz=8, num_updates=56310, lr=4.42448e-05, gnorm=1.977, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=19399
2023-03-15 19:23:05 - progress_bar.py[line:272] - INFO: epoch 029:    568 / 2004 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=377.4, nsentences=8, sample_size=377.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1092.2, ups=2.89, wpb=377.4, bsz=8, num_updates=56320, lr=4.42348e-05, gnorm=2.216, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=19402
2023-03-15 19:23:08 - progress_bar.py[line:272] - INFO: epoch 029:    578 / 2004 loss=0.136, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=329.9, nsentences=8, sample_size=329.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=946.7, ups=2.87, wpb=329.9, bsz=8, num_updates=56330, lr=4.42247e-05, gnorm=1.961, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=19406
2023-03-15 19:23:12 - progress_bar.py[line:272] - INFO: epoch 029:    588 / 2004 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=372.9, nsentences=8, sample_size=372.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1058.4, ups=2.84, wpb=372.9, bsz=8, num_updates=56340, lr=4.42146e-05, gnorm=1.82, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=19409
2023-03-15 19:23:15 - progress_bar.py[line:272] - INFO: epoch 029:    598 / 2004 loss=0.134, loss_v1=0, loss_v2=0, nll_loss=0.134, ntokens=334.5, nsentences=8, sample_size=334.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=982.6, ups=2.94, wpb=334.5, bsz=8, num_updates=56350, lr=4.42045e-05, gnorm=1.814, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=19413
2023-03-15 19:23:19 - progress_bar.py[line:272] - INFO: epoch 029:    608 / 2004 loss=0.134, loss_v1=0, loss_v2=0, nll_loss=0.134, ntokens=351.9, nsentences=8, sample_size=351.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=998.2, ups=2.84, wpb=351.9, bsz=8, num_updates=56360, lr=4.41944e-05, gnorm=1.924, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=19416
2023-03-15 19:23:19 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 19:23:23 - progress_bar.py[line:272] - INFO: epoch 029:    619 / 2004 loss=0.13, loss_v1=0, loss_v2=0, nll_loss=0.13, ntokens=367.6, nsentences=8, sample_size=367.6, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=955, ups=2.6, wpb=367.6, bsz=8, num_updates=56370, lr=4.41844e-05, gnorm=1.928, clip=0, loss_scale=1024, train_wall=4, gb_free=14.4, wall=19420
2023-03-15 19:23:26 - progress_bar.py[line:272] - INFO: epoch 029:    629 / 2004 loss=0.126, loss_v1=0, loss_v2=0, nll_loss=0.126, ntokens=356.6, nsentences=8, sample_size=356.6, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1030, ups=2.89, wpb=356.6, bsz=8, num_updates=56380, lr=4.41743e-05, gnorm=1.683, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=19424
2023-03-15 19:23:29 - progress_bar.py[line:272] - INFO: epoch 029:    639 / 2004 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=330.3, nsentences=8, sample_size=330.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=945.9, ups=2.86, wpb=330.3, bsz=8, num_updates=56390, lr=4.41642e-05, gnorm=2.105, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=19427
2023-03-15 19:23:33 - progress_bar.py[line:272] - INFO: epoch 029:    649 / 2004 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=335.9, nsentences=8, sample_size=335.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=964.6, ups=2.87, wpb=335.9, bsz=8, num_updates=56400, lr=4.41541e-05, gnorm=2.123, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=19431
2023-03-15 19:23:36 - progress_bar.py[line:272] - INFO: epoch 029:    659 / 2004 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=342, nsentences=8, sample_size=342, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=976.7, ups=2.86, wpb=342, bsz=8, num_updates=56410, lr=4.4144e-05, gnorm=2.347, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=19434
2023-03-15 19:23:40 - progress_bar.py[line:272] - INFO: epoch 029:    669 / 2004 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=304.6, nsentences=8, sample_size=304.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=886.3, ups=2.91, wpb=304.6, bsz=8, num_updates=56420, lr=4.4134e-05, gnorm=1.93, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=19438
2023-03-15 19:23:43 - progress_bar.py[line:272] - INFO: epoch 029:    679 / 2004 loss=0.124, loss_v1=0, loss_v2=0, nll_loss=0.124, ntokens=353.2, nsentences=8, sample_size=353.2, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1029.9, ups=2.92, wpb=353.2, bsz=8, num_updates=56430, lr=4.41239e-05, gnorm=1.713, clip=0, loss_scale=1024, train_wall=3, gb_free=14.2, wall=19441
2023-03-15 19:23:47 - progress_bar.py[line:272] - INFO: epoch 029:    689 / 2004 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=343.1, nsentences=8, sample_size=343.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=988.2, ups=2.88, wpb=343.1, bsz=8, num_updates=56440, lr=4.41138e-05, gnorm=2.286, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=19444
2023-03-15 19:23:50 - progress_bar.py[line:272] - INFO: epoch 029:    699 / 2004 loss=0.135, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=350.5, nsentences=8, sample_size=350.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1016.6, ups=2.9, wpb=350.5, bsz=8, num_updates=56450, lr=4.41037e-05, gnorm=1.87, clip=0, loss_scale=1024, train_wall=3, gb_free=15.7, wall=19448
2023-03-15 19:23:54 - progress_bar.py[line:272] - INFO: epoch 029:    709 / 2004 loss=0.137, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=331.9, nsentences=8, sample_size=331.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=981.1, ups=2.96, wpb=331.9, bsz=8, num_updates=56460, lr=4.40936e-05, gnorm=2.018, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=19451
2023-03-15 19:23:57 - progress_bar.py[line:272] - INFO: epoch 029:    719 / 2004 loss=0.131, loss_v1=0, loss_v2=0, nll_loss=0.131, ntokens=346.6, nsentences=8, sample_size=346.6, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1025.8, ups=2.96, wpb=346.6, bsz=8, num_updates=56470, lr=4.40836e-05, gnorm=1.942, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=19455
2023-03-15 19:24:01 - progress_bar.py[line:272] - INFO: epoch 029:    729 / 2004 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=358.8, nsentences=8, sample_size=358.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1020.4, ups=2.84, wpb=358.8, bsz=8, num_updates=56480, lr=4.40735e-05, gnorm=2.179, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=19458
2023-03-15 19:24:04 - progress_bar.py[line:272] - INFO: epoch 029:    739 / 2004 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=332.5, nsentences=8, sample_size=332.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=961.3, ups=2.89, wpb=332.5, bsz=8, num_updates=56490, lr=4.40634e-05, gnorm=2.048, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=19462
2023-03-15 19:24:07 - progress_bar.py[line:272] - INFO: epoch 029:    749 / 2004 loss=0.131, loss_v1=0, loss_v2=0, nll_loss=0.131, ntokens=366.9, nsentences=8, sample_size=366.9, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1060.9, ups=2.89, wpb=366.9, bsz=8, num_updates=56500, lr=4.40533e-05, gnorm=2.041, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=19465
2023-03-15 19:24:11 - progress_bar.py[line:272] - INFO: epoch 029:    759 / 2004 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=303.1, nsentences=8, sample_size=303.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=884.1, ups=2.92, wpb=303.1, bsz=8, num_updates=56510, lr=4.40432e-05, gnorm=1.876, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=19469
2023-03-15 19:24:14 - progress_bar.py[line:272] - INFO: epoch 029:    769 / 2004 loss=0.137, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=409.5, nsentences=8, sample_size=409.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1171.2, ups=2.86, wpb=409.5, bsz=8, num_updates=56520, lr=4.40331e-05, gnorm=2.22, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=19472
2023-03-15 19:24:18 - progress_bar.py[line:272] - INFO: epoch 029:    779 / 2004 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=342.3, nsentences=8, sample_size=342.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1000.6, ups=2.92, wpb=342.3, bsz=8, num_updates=56530, lr=4.40231e-05, gnorm=1.961, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=19475
2023-03-15 19:24:21 - progress_bar.py[line:272] - INFO: epoch 029:    789 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=336.9, nsentences=8, sample_size=336.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1075.6, ups=3.19, wpb=336.9, bsz=8, num_updates=56540, lr=4.4013e-05, gnorm=2.207, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=19479
2023-03-15 19:24:24 - progress_bar.py[line:272] - INFO: epoch 029:    799 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=332.5, nsentences=8, sample_size=332.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1037.9, ups=3.12, wpb=332.5, bsz=8, num_updates=56550, lr=4.40029e-05, gnorm=2.129, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=19482
2023-03-15 19:24:27 - progress_bar.py[line:272] - INFO: epoch 029:    809 / 2004 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=345.3, nsentences=8, sample_size=345.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1088.7, ups=3.15, wpb=345.3, bsz=8, num_updates=56560, lr=4.39928e-05, gnorm=2.026, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=19485
2023-03-15 19:24:31 - progress_bar.py[line:272] - INFO: epoch 029:    819 / 2004 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=325.4, nsentences=8, sample_size=325.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=997.7, ups=3.07, wpb=325.4, bsz=8, num_updates=56570, lr=4.39827e-05, gnorm=2.063, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=19488
2023-03-15 19:24:34 - progress_bar.py[line:272] - INFO: epoch 029:    829 / 2004 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=369.5, nsentences=8, sample_size=369.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1044.8, ups=2.83, wpb=369.5, bsz=8, num_updates=56580, lr=4.39727e-05, gnorm=1.986, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=19492
2023-03-15 19:24:38 - progress_bar.py[line:272] - INFO: epoch 029:    839 / 2004 loss=0.125, loss_v1=0, loss_v2=0, nll_loss=0.125, ntokens=335.5, nsentences=8, sample_size=335.5, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=984.5, ups=2.93, wpb=335.5, bsz=8, num_updates=56590, lr=4.39626e-05, gnorm=1.779, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=19495
2023-03-15 19:24:41 - progress_bar.py[line:272] - INFO: epoch 029:    849 / 2004 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=365.8, nsentences=8, sample_size=365.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1058.6, ups=2.89, wpb=365.8, bsz=8, num_updates=56600, lr=4.39525e-05, gnorm=2.069, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=19499
2023-03-15 19:24:44 - progress_bar.py[line:272] - INFO: epoch 029:    859 / 2004 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=346.7, nsentences=8, sample_size=346.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1002.2, ups=2.89, wpb=346.7, bsz=8, num_updates=56610, lr=4.39424e-05, gnorm=1.968, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=19502
2023-03-15 19:24:48 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 19:24:48 - progress_bar.py[line:272] - INFO: epoch 029:    870 / 2004 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=366.5, nsentences=8, sample_size=366.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=970.1, ups=2.65, wpb=366.5, bsz=8, num_updates=56620, lr=4.39323e-05, gnorm=2.008, clip=0, loss_scale=2048, train_wall=4, gb_free=15.1, wall=19506
2023-03-15 19:24:52 - progress_bar.py[line:272] - INFO: epoch 029:    880 / 2004 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=323.1, nsentences=8, sample_size=323.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=917.4, ups=2.84, wpb=323.1, bsz=8, num_updates=56630, lr=4.39223e-05, gnorm=2.024, clip=10, loss_scale=2048, train_wall=3, gb_free=13.8, wall=19509
2023-03-15 19:24:55 - progress_bar.py[line:272] - INFO: epoch 029:    890 / 2004 loss=0.133, loss_v1=0, loss_v2=0, nll_loss=0.133, ntokens=315, nsentences=8, sample_size=315, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=891.3, ups=2.83, wpb=315, bsz=8, num_updates=56640, lr=4.39122e-05, gnorm=2.064, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=19513
2023-03-15 19:24:58 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 19:24:59 - progress_bar.py[line:272] - INFO: epoch 029:    901 / 2004 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=353, nsentences=8, sample_size=353, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=935.5, ups=2.65, wpb=353, bsz=8, num_updates=56650, lr=4.39021e-05, gnorm=2.294, clip=0, loss_scale=1024, train_wall=4, gb_free=15, wall=19517
2023-03-15 19:25:03 - progress_bar.py[line:272] - INFO: epoch 029:    911 / 2004 loss=0.135, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=354, nsentences=8, sample_size=354, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1017.1, ups=2.87, wpb=354, bsz=8, num_updates=56660, lr=4.3892e-05, gnorm=1.966, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=19520
2023-03-15 19:25:06 - progress_bar.py[line:272] - INFO: epoch 029:    921 / 2004 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=345.4, nsentences=8, sample_size=345.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=987.5, ups=2.86, wpb=345.4, bsz=8, num_updates=56670, lr=4.38819e-05, gnorm=2.328, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=19524
2023-03-15 19:25:09 - progress_bar.py[line:272] - INFO: epoch 029:    931 / 2004 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=333, nsentences=8, sample_size=333, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=972, ups=2.92, wpb=333, bsz=8, num_updates=56680, lr=4.38719e-05, gnorm=1.939, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=19527
2023-03-15 19:25:13 - progress_bar.py[line:272] - INFO: epoch 029:    941 / 2004 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=368.6, nsentences=8, sample_size=368.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1047.1, ups=2.84, wpb=368.6, bsz=8, num_updates=56690, lr=4.38618e-05, gnorm=1.882, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=19531
2023-03-15 19:25:16 - progress_bar.py[line:272] - INFO: epoch 029:    951 / 2004 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=351.3, nsentences=8, sample_size=351.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1009.9, ups=2.87, wpb=351.3, bsz=8, num_updates=56700, lr=4.38517e-05, gnorm=2.224, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=19534
2023-03-15 19:25:20 - progress_bar.py[line:272] - INFO: epoch 029:    961 / 2004 loss=0.134, loss_v1=0, loss_v2=0, nll_loss=0.134, ntokens=382.9, nsentences=8, sample_size=382.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1100.3, ups=2.87, wpb=382.9, bsz=8, num_updates=56710, lr=4.38416e-05, gnorm=1.933, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=19538
2023-03-15 19:25:23 - progress_bar.py[line:272] - INFO: epoch 029:    971 / 2004 loss=0.132, loss_v1=0, loss_v2=0, nll_loss=0.132, ntokens=325.6, nsentences=8, sample_size=325.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=960.6, ups=2.95, wpb=325.6, bsz=8, num_updates=56720, lr=4.38315e-05, gnorm=1.753, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=19541
2023-03-15 19:25:27 - progress_bar.py[line:272] - INFO: epoch 029:    981 / 2004 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=317.9, nsentences=8, sample_size=317.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=942.6, ups=2.96, wpb=317.9, bsz=8, num_updates=56730, lr=4.38214e-05, gnorm=2.176, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=19544
2023-03-15 19:25:30 - progress_bar.py[line:272] - INFO: epoch 029:    991 / 2004 loss=0.135, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=384.7, nsentences=8, sample_size=384.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1088.3, ups=2.83, wpb=384.7, bsz=8, num_updates=56740, lr=4.38114e-05, gnorm=1.978, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=19548
2023-03-15 19:25:34 - progress_bar.py[line:272] - INFO: epoch 029:   1001 / 2004 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=332.3, nsentences=8, sample_size=332.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=962.4, ups=2.9, wpb=332.3, bsz=8, num_updates=56750, lr=4.38013e-05, gnorm=2.103, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=19551
2023-03-15 19:25:37 - progress_bar.py[line:272] - INFO: epoch 029:   1011 / 2004 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=316.4, nsentences=7.8, sample_size=316.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=924.9, ups=2.92, wpb=316.4, bsz=7.8, num_updates=56760, lr=4.37912e-05, gnorm=1.892, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=19555
2023-03-15 19:25:41 - progress_bar.py[line:272] - INFO: epoch 029:   1021 / 2004 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=344.8, nsentences=8, sample_size=344.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1012.7, ups=2.94, wpb=344.8, bsz=8, num_updates=56770, lr=4.37811e-05, gnorm=2.075, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=19558
2023-03-15 19:25:44 - progress_bar.py[line:272] - INFO: epoch 029:   1031 / 2004 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=310.2, nsentences=8, sample_size=310.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=916, ups=2.95, wpb=310.2, bsz=8, num_updates=56780, lr=4.3771e-05, gnorm=2.028, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=19562
2023-03-15 19:25:47 - progress_bar.py[line:272] - INFO: epoch 029:   1041 / 2004 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=338, nsentences=8, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1048.9, ups=3.1, wpb=338, bsz=8, num_updates=56790, lr=4.3761e-05, gnorm=2.072, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=19565
2023-03-15 19:25:50 - progress_bar.py[line:272] - INFO: epoch 029:   1051 / 2004 loss=0.129, loss_v1=0, loss_v2=0, nll_loss=0.129, ntokens=375, nsentences=8, sample_size=375, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1129.8, ups=3.01, wpb=375, bsz=8, num_updates=56800, lr=4.37509e-05, gnorm=2.099, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=19568
2023-03-15 19:25:54 - progress_bar.py[line:272] - INFO: epoch 029:   1061 / 2004 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=334.5, nsentences=8, sample_size=334.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=966.6, ups=2.89, wpb=334.5, bsz=8, num_updates=56810, lr=4.37408e-05, gnorm=2.151, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=19572
2023-03-15 19:25:57 - progress_bar.py[line:272] - INFO: epoch 029:   1071 / 2004 loss=0.135, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=362.4, nsentences=8, sample_size=362.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1044.5, ups=2.88, wpb=362.4, bsz=8, num_updates=56820, lr=4.37307e-05, gnorm=1.855, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=19575
2023-03-15 19:26:01 - progress_bar.py[line:272] - INFO: epoch 029:   1081 / 2004 loss=0.137, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=358.9, nsentences=8, sample_size=358.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1026.9, ups=2.86, wpb=358.9, bsz=8, num_updates=56830, lr=4.37206e-05, gnorm=2.29, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=19578
2023-03-15 19:26:04 - progress_bar.py[line:272] - INFO: epoch 029:   1091 / 2004 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=339.3, nsentences=8, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=981.2, ups=2.89, wpb=339.3, bsz=8, num_updates=56840, lr=4.37106e-05, gnorm=1.919, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=19582
2023-03-15 19:26:08 - progress_bar.py[line:272] - INFO: epoch 029:   1101 / 2004 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=349.6, nsentences=8, sample_size=349.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1025, ups=2.93, wpb=349.6, bsz=8, num_updates=56850, lr=4.37005e-05, gnorm=2.097, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=19585
2023-03-15 19:26:11 - progress_bar.py[line:272] - INFO: epoch 029:   1111 / 2004 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=373, nsentences=8, sample_size=373, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1094.5, ups=2.93, wpb=373, bsz=8, num_updates=56860, lr=4.36904e-05, gnorm=2.047, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=19589
2023-03-15 19:26:15 - progress_bar.py[line:272] - INFO: epoch 029:   1121 / 2004 loss=0.134, loss_v1=0, loss_v2=0, nll_loss=0.134, ntokens=314, nsentences=8, sample_size=314, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=903.8, ups=2.88, wpb=314, bsz=8, num_updates=56870, lr=4.36803e-05, gnorm=2.123, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=19592
2023-03-15 19:26:18 - progress_bar.py[line:272] - INFO: epoch 029:   1131 / 2004 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=370.8, nsentences=8, sample_size=370.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1056.3, ups=2.85, wpb=370.8, bsz=8, num_updates=56880, lr=4.36702e-05, gnorm=2.114, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=19596
2023-03-15 19:26:22 - progress_bar.py[line:272] - INFO: epoch 029:   1141 / 2004 loss=0.13, loss_v1=0, loss_v2=0, nll_loss=0.13, ntokens=362.1, nsentences=8, sample_size=362.1, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1061.1, ups=2.93, wpb=362.1, bsz=8, num_updates=56890, lr=4.36602e-05, gnorm=1.982, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=19599
2023-03-15 19:26:25 - progress_bar.py[line:272] - INFO: epoch 029:   1151 / 2004 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=365.2, nsentences=8, sample_size=365.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1050.2, ups=2.88, wpb=365.2, bsz=8, num_updates=56900, lr=4.36501e-05, gnorm=2.002, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=19603
2023-03-15 19:26:27 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 19:26:29 - progress_bar.py[line:272] - INFO: epoch 029:   1162 / 2004 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=376, nsentences=8, sample_size=376, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=977.1, ups=2.6, wpb=376, bsz=8, num_updates=56910, lr=4.364e-05, gnorm=2.211, clip=0, loss_scale=2048, train_wall=4, gb_free=15.2, wall=19606
2023-03-15 19:26:32 - progress_bar.py[line:272] - INFO: epoch 029:   1172 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=343.5, nsentences=8, sample_size=343.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=987.2, ups=2.87, wpb=343.5, bsz=8, num_updates=56920, lr=4.36299e-05, gnorm=2.016, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=19610
2023-03-15 19:26:36 - progress_bar.py[line:272] - INFO: epoch 029:   1182 / 2004 loss=0.136, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=352.3, nsentences=8, sample_size=352.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1008.2, ups=2.86, wpb=352.3, bsz=8, num_updates=56930, lr=4.36198e-05, gnorm=1.902, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=19613
2023-03-15 19:26:39 - progress_bar.py[line:272] - INFO: epoch 029:   1192 / 2004 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=345.2, nsentences=8, sample_size=345.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1017.7, ups=2.95, wpb=345.2, bsz=8, num_updates=56940, lr=4.36098e-05, gnorm=2.191, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=19617
2023-03-15 19:26:43 - progress_bar.py[line:272] - INFO: epoch 029:   1202 / 2004 loss=0.137, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=340.8, nsentences=8, sample_size=340.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1001.1, ups=2.94, wpb=340.8, bsz=8, num_updates=56950, lr=4.35997e-05, gnorm=1.921, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=19620
2023-03-15 19:26:46 - progress_bar.py[line:272] - INFO: epoch 029:   1212 / 2004 loss=0.126, loss_v1=0, loss_v2=0, nll_loss=0.126, ntokens=288.3, nsentences=8, sample_size=288.3, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=840.4, ups=2.91, wpb=288.3, bsz=8, num_updates=56960, lr=4.35896e-05, gnorm=1.627, clip=0, loss_scale=2048, train_wall=3, gb_free=14, wall=19624
2023-03-15 19:26:50 - progress_bar.py[line:272] - INFO: epoch 029:   1222 / 2004 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=325.6, nsentences=8, sample_size=325.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=943, ups=2.9, wpb=325.6, bsz=8, num_updates=56970, lr=4.35795e-05, gnorm=1.979, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=19627
2023-03-15 19:26:53 - progress_bar.py[line:272] - INFO: epoch 029:   1232 / 2004 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=308.4, nsentences=8, sample_size=308.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=898.5, ups=2.91, wpb=308.4, bsz=8, num_updates=56980, lr=4.35694e-05, gnorm=1.953, clip=0, loss_scale=2048, train_wall=3, gb_free=13.6, wall=19631
2023-03-15 19:26:57 - progress_bar.py[line:272] - INFO: epoch 029:   1242 / 2004 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=390.3, nsentences=8, sample_size=390.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1093, ups=2.8, wpb=390.3, bsz=8, num_updates=56990, lr=4.35593e-05, gnorm=2.086, clip=0, loss_scale=2048, train_wall=4, gb_free=15.2, wall=19634
2023-03-15 19:27:00 - progress_bar.py[line:272] - INFO: epoch 029:   1252 / 2004 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=345, nsentences=8, sample_size=345, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=995.7, ups=2.89, wpb=345, bsz=8, num_updates=57000, lr=4.35493e-05, gnorm=1.993, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=19638
2023-03-15 19:27:03 - progress_bar.py[line:272] - INFO: epoch 029:   1262 / 2004 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=343.6, nsentences=8, sample_size=343.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=988.8, ups=2.88, wpb=343.6, bsz=8, num_updates=57010, lr=4.35392e-05, gnorm=2.163, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=19641
2023-03-15 19:27:07 - progress_bar.py[line:272] - INFO: epoch 029:   1272 / 2004 loss=0.136, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=348.7, nsentences=8, sample_size=348.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1007.3, ups=2.89, wpb=348.7, bsz=8, num_updates=57020, lr=4.35291e-05, gnorm=1.835, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=19645
2023-03-15 19:27:10 - progress_bar.py[line:272] - INFO: epoch 029:   1282 / 2004 loss=0.124, loss_v1=0, loss_v2=0, nll_loss=0.124, ntokens=327.8, nsentences=8, sample_size=327.8, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=970.5, ups=2.96, wpb=327.8, bsz=8, num_updates=57030, lr=4.3519e-05, gnorm=1.746, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=19648
2023-03-15 19:27:13 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 19:27:14 - progress_bar.py[line:272] - INFO: epoch 029:   1293 / 2004 loss=0.126, loss_v1=0, loss_v2=0, nll_loss=0.126, ntokens=317.6, nsentences=8, sample_size=317.6, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=828.1, ups=2.61, wpb=317.6, bsz=8, num_updates=57040, lr=4.35089e-05, gnorm=1.811, clip=0, loss_scale=2048, train_wall=4, gb_free=15, wall=19652
2023-03-15 19:27:18 - progress_bar.py[line:272] - INFO: epoch 029:   1303 / 2004 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=333.3, nsentences=8, sample_size=333.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=965.9, ups=2.9, wpb=333.3, bsz=8, num_updates=57050, lr=4.34989e-05, gnorm=1.919, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=19655
2023-03-15 19:27:21 - progress_bar.py[line:272] - INFO: epoch 029:   1313 / 2004 loss=0.125, loss_v1=0, loss_v2=0, nll_loss=0.125, ntokens=323.2, nsentences=8, sample_size=323.2, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=943.7, ups=2.92, wpb=323.2, bsz=8, num_updates=57060, lr=4.34888e-05, gnorm=1.808, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=19659
2023-03-15 19:27:25 - progress_bar.py[line:272] - INFO: epoch 029:   1323 / 2004 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=318.3, nsentences=8, sample_size=318.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=914, ups=2.87, wpb=318.3, bsz=8, num_updates=57070, lr=4.34787e-05, gnorm=2.033, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=19662
2023-03-15 19:27:28 - progress_bar.py[line:272] - INFO: epoch 029:   1333 / 2004 loss=0.126, loss_v1=0, loss_v2=0, nll_loss=0.126, ntokens=333.2, nsentences=8, sample_size=333.2, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=973.6, ups=2.92, wpb=333.2, bsz=8, num_updates=57080, lr=4.34686e-05, gnorm=1.905, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=19666
2023-03-15 19:27:31 - progress_bar.py[line:272] - INFO: epoch 029:   1343 / 2004 loss=0.131, loss_v1=0, loss_v2=0, nll_loss=0.131, ntokens=321, nsentences=8, sample_size=321, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=941.5, ups=2.93, wpb=321, bsz=8, num_updates=57090, lr=4.34585e-05, gnorm=1.93, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=19669
2023-03-15 19:27:35 - progress_bar.py[line:272] - INFO: epoch 029:   1353 / 2004 loss=0.135, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=313, nsentences=8, sample_size=313, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=913, ups=2.92, wpb=313, bsz=8, num_updates=57100, lr=4.34485e-05, gnorm=1.928, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=19672
2023-03-15 19:27:38 - progress_bar.py[line:272] - INFO: epoch 029:   1363 / 2004 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=326.8, nsentences=8, sample_size=326.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=951.2, ups=2.91, wpb=326.8, bsz=8, num_updates=57110, lr=4.34384e-05, gnorm=2.349, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=19676
2023-03-15 19:27:42 - progress_bar.py[line:272] - INFO: epoch 029:   1373 / 2004 loss=0.13, loss_v1=0, loss_v2=0, nll_loss=0.13, ntokens=299.6, nsentences=8, sample_size=299.6, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=860.1, ups=2.87, wpb=299.6, bsz=8, num_updates=57120, lr=4.34283e-05, gnorm=1.989, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=19679
2023-03-15 19:27:45 - progress_bar.py[line:272] - INFO: epoch 029:   1383 / 2004 loss=0.128, loss_v1=0, loss_v2=0, nll_loss=0.128, ntokens=384.6, nsentences=8, sample_size=384.6, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1086.3, ups=2.82, wpb=384.6, bsz=8, num_updates=57130, lr=4.34182e-05, gnorm=2.04, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=19683
2023-03-15 19:27:49 - progress_bar.py[line:272] - INFO: epoch 029:   1393 / 2004 loss=0.136, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=362.5, nsentences=8, sample_size=362.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1041.3, ups=2.87, wpb=362.5, bsz=8, num_updates=57140, lr=4.34081e-05, gnorm=2.034, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=19686
2023-03-15 19:27:52 - progress_bar.py[line:272] - INFO: epoch 029:   1403 / 2004 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=337.1, nsentences=8, sample_size=337.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=964.5, ups=2.86, wpb=337.1, bsz=8, num_updates=57150, lr=4.33981e-05, gnorm=1.968, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=19690
2023-03-15 19:27:56 - progress_bar.py[line:272] - INFO: epoch 029:   1413 / 2004 loss=0.133, loss_v1=0, loss_v2=0, nll_loss=0.133, ntokens=378.6, nsentences=8, sample_size=378.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1080.2, ups=2.85, wpb=378.6, bsz=8, num_updates=57160, lr=4.3388e-05, gnorm=2.041, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=19693
2023-03-15 19:27:58 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 19:27:59 - progress_bar.py[line:272] - INFO: epoch 029:   1424 / 2004 loss=0.131, loss_v1=0, loss_v2=0, nll_loss=0.131, ntokens=299, nsentences=8, sample_size=299, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=803.3, ups=2.69, wpb=299, bsz=8, num_updates=57170, lr=4.33779e-05, gnorm=1.956, clip=0, loss_scale=2048, train_wall=4, gb_free=15.4, wall=19697
2023-03-15 19:28:03 - progress_bar.py[line:272] - INFO: epoch 029:   1434 / 2004 loss=0.136, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=368.1, nsentences=8, sample_size=368.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1028.4, ups=2.79, wpb=368.1, bsz=8, num_updates=57180, lr=4.33678e-05, gnorm=2.07, clip=0, loss_scale=2048, train_wall=4, gb_free=13.6, wall=19701
2023-03-15 19:28:06 - progress_bar.py[line:272] - INFO: epoch 029:   1444 / 2004 loss=0.137, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=326.6, nsentences=8, sample_size=326.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=944.2, ups=2.89, wpb=326.6, bsz=8, num_updates=57190, lr=4.33577e-05, gnorm=2.072, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=19704
2023-03-15 19:28:10 - progress_bar.py[line:272] - INFO: epoch 029:   1454 / 2004 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=366.4, nsentences=8, sample_size=366.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1080, ups=2.95, wpb=366.4, bsz=8, num_updates=57200, lr=4.33476e-05, gnorm=2.458, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=19707
2023-03-15 19:28:13 - progress_bar.py[line:272] - INFO: epoch 029:   1464 / 2004 loss=0.136, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=386, nsentences=8, sample_size=386, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1097.2, ups=2.84, wpb=386, bsz=8, num_updates=57210, lr=4.33376e-05, gnorm=1.956, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=19711
2023-03-15 19:28:17 - progress_bar.py[line:272] - INFO: epoch 029:   1474 / 2004 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=398.2, nsentences=8, sample_size=398.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1137.2, ups=2.86, wpb=398.2, bsz=8, num_updates=57220, lr=4.33275e-05, gnorm=2.021, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=19715
2023-03-15 19:28:20 - progress_bar.py[line:272] - INFO: epoch 029:   1484 / 2004 loss=0.127, loss_v1=0, loss_v2=0, nll_loss=0.127, ntokens=372.5, nsentences=8, sample_size=372.5, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1084.2, ups=2.91, wpb=372.5, bsz=8, num_updates=57230, lr=4.33174e-05, gnorm=1.854, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=19718
2023-03-15 19:28:24 - progress_bar.py[line:272] - INFO: epoch 029:   1494 / 2004 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=317.1, nsentences=8, sample_size=317.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=918.9, ups=2.9, wpb=317.1, bsz=8, num_updates=57240, lr=4.33073e-05, gnorm=2.205, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=19721
2023-03-15 19:28:27 - progress_bar.py[line:272] - INFO: epoch 029:   1504 / 2004 loss=0.134, loss_v1=0, loss_v2=0, nll_loss=0.134, ntokens=336.8, nsentences=8, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=964.4, ups=2.86, wpb=336.8, bsz=8, num_updates=57250, lr=4.32972e-05, gnorm=1.877, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=19725
2023-03-15 19:28:31 - progress_bar.py[line:272] - INFO: epoch 029:   1514 / 2004 loss=0.135, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=323.5, nsentences=8, sample_size=323.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=967.8, ups=2.99, wpb=323.5, bsz=8, num_updates=57260, lr=4.32872e-05, gnorm=1.972, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=19728
2023-03-15 19:28:34 - progress_bar.py[line:272] - INFO: epoch 029:   1524 / 2004 loss=0.136, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=321.5, nsentences=8, sample_size=321.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=939.2, ups=2.92, wpb=321.5, bsz=8, num_updates=57270, lr=4.32771e-05, gnorm=1.894, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=19732
2023-03-15 19:28:38 - progress_bar.py[line:272] - INFO: epoch 029:   1534 / 2004 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=354.4, nsentences=8, sample_size=354.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1022, ups=2.88, wpb=354.4, bsz=8, num_updates=57280, lr=4.3267e-05, gnorm=2.149, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=19735
2023-03-15 19:28:41 - progress_bar.py[line:272] - INFO: epoch 029:   1544 / 2004 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=325.5, nsentences=8, sample_size=325.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=953.7, ups=2.93, wpb=325.5, bsz=8, num_updates=57290, lr=4.32569e-05, gnorm=2.188, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=19739
2023-03-15 19:28:43 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 19:28:45 - progress_bar.py[line:272] - INFO: epoch 029:   1555 / 2004 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=339.9, nsentences=8, sample_size=339.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=877.8, ups=2.58, wpb=339.9, bsz=8, num_updates=57300, lr=4.32468e-05, gnorm=2.129, clip=0, loss_scale=2048, train_wall=4, gb_free=13.5, wall=19742
2023-03-15 19:28:48 - progress_bar.py[line:272] - INFO: epoch 029:   1565 / 2004 loss=0.126, loss_v1=0, loss_v2=0, nll_loss=0.126, ntokens=347, nsentences=8, sample_size=347, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=996.2, ups=2.87, wpb=347, bsz=8, num_updates=57310, lr=4.32368e-05, gnorm=1.909, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=19746
2023-03-15 19:28:52 - progress_bar.py[line:272] - INFO: epoch 029:   1575 / 2004 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=336.5, nsentences=8, sample_size=336.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=961.7, ups=2.86, wpb=336.5, bsz=8, num_updates=57320, lr=4.32267e-05, gnorm=2.306, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=19749
2023-03-15 19:28:55 - progress_bar.py[line:272] - INFO: epoch 029:   1585 / 2004 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=321.1, nsentences=8, sample_size=321.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=917.4, ups=2.86, wpb=321.1, bsz=8, num_updates=57330, lr=4.32166e-05, gnorm=2.052, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=19753
2023-03-15 19:28:59 - progress_bar.py[line:272] - INFO: epoch 029:   1595 / 2004 loss=0.133, loss_v1=0, loss_v2=0, nll_loss=0.133, ntokens=362.8, nsentences=8, sample_size=362.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1024, ups=2.82, wpb=362.8, bsz=8, num_updates=57340, lr=4.32065e-05, gnorm=1.767, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=19756
2023-03-15 19:29:02 - progress_bar.py[line:272] - INFO: epoch 029:   1605 / 2004 loss=0.129, loss_v1=0, loss_v2=0, nll_loss=0.129, ntokens=337.9, nsentences=8, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=988.7, ups=2.93, wpb=337.9, bsz=8, num_updates=57350, lr=4.31964e-05, gnorm=1.744, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=19760
2023-03-15 19:29:06 - progress_bar.py[line:272] - INFO: epoch 029:   1615 / 2004 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=341.2, nsentences=8, sample_size=341.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1040.8, ups=3.05, wpb=341.2, bsz=8, num_updates=57360, lr=4.31864e-05, gnorm=2.071, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=19763
2023-03-15 19:29:09 - progress_bar.py[line:272] - INFO: epoch 029:   1625 / 2004 loss=0.137, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=352.5, nsentences=8, sample_size=352.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1099.8, ups=3.12, wpb=352.5, bsz=8, num_updates=57370, lr=4.31763e-05, gnorm=1.962, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=19766
2023-03-15 19:29:12 - progress_bar.py[line:272] - INFO: epoch 029:   1635 / 2004 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=332.2, nsentences=8, sample_size=332.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=1048.8, ups=3.16, wpb=332.2, bsz=8, num_updates=57380, lr=4.31662e-05, gnorm=2.424, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=19770
2023-03-15 19:29:15 - progress_bar.py[line:272] - INFO: epoch 029:   1645 / 2004 loss=0.13, loss_v1=0, loss_v2=0, nll_loss=0.13, ntokens=309.9, nsentences=8, sample_size=309.9, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=902.3, ups=2.91, wpb=309.9, bsz=8, num_updates=57390, lr=4.31561e-05, gnorm=1.75, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=19773
2023-03-15 19:29:19 - progress_bar.py[line:272] - INFO: epoch 029:   1655 / 2004 loss=0.13, loss_v1=0, loss_v2=0, nll_loss=0.13, ntokens=346.4, nsentences=8, sample_size=346.4, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=999.5, ups=2.89, wpb=346.4, bsz=8, num_updates=57400, lr=4.3146e-05, gnorm=1.807, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=19776
2023-03-15 19:29:22 - progress_bar.py[line:272] - INFO: epoch 029:   1665 / 2004 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=352.8, nsentences=8, sample_size=352.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1016, ups=2.88, wpb=352.8, bsz=8, num_updates=57410, lr=4.3136e-05, gnorm=2.148, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=19780
2023-03-15 19:29:26 - progress_bar.py[line:272] - INFO: epoch 029:   1675 / 2004 loss=0.137, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=327.8, nsentences=8, sample_size=327.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=940.6, ups=2.87, wpb=327.8, bsz=8, num_updates=57420, lr=4.31259e-05, gnorm=2.107, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=19783
2023-03-15 19:29:27 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 19:29:30 - progress_bar.py[line:272] - INFO: epoch 029:   1686 / 2004 loss=0.135, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=332.8, nsentences=8, sample_size=332.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=879.8, ups=2.64, wpb=332.8, bsz=8, num_updates=57430, lr=4.31158e-05, gnorm=1.986, clip=0, loss_scale=2048, train_wall=4, gb_free=14.9, wall=19787
2023-03-15 19:29:33 - progress_bar.py[line:272] - INFO: epoch 029:   1696 / 2004 loss=0.129, loss_v1=0, loss_v2=0, nll_loss=0.129, ntokens=337.7, nsentences=8, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=965.3, ups=2.86, wpb=337.7, bsz=8, num_updates=57440, lr=4.31057e-05, gnorm=1.658, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=19791
2023-03-15 19:29:37 - progress_bar.py[line:272] - INFO: epoch 029:   1706 / 2004 loss=0.134, loss_v1=0, loss_v2=0, nll_loss=0.134, ntokens=348.9, nsentences=8, sample_size=348.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1001, ups=2.87, wpb=348.9, bsz=8, num_updates=57450, lr=4.30956e-05, gnorm=1.943, clip=0, loss_scale=2048, train_wall=3, gb_free=13.9, wall=19794
2023-03-15 19:29:40 - progress_bar.py[line:272] - INFO: epoch 029:   1716 / 2004 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=356.2, nsentences=8, sample_size=356.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1009, ups=2.83, wpb=356.2, bsz=8, num_updates=57460, lr=4.30855e-05, gnorm=1.982, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=19798
2023-03-15 19:29:44 - progress_bar.py[line:272] - INFO: epoch 029:   1726 / 2004 loss=0.127, loss_v1=0, loss_v2=0, nll_loss=0.127, ntokens=396.6, nsentences=8, sample_size=396.6, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1132.1, ups=2.85, wpb=396.6, bsz=8, num_updates=57470, lr=4.30755e-05, gnorm=2.066, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=19801
2023-03-15 19:29:47 - progress_bar.py[line:272] - INFO: epoch 029:   1736 / 2004 loss=0.131, loss_v1=0, loss_v2=0, nll_loss=0.131, ntokens=347.5, nsentences=8, sample_size=347.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1019.8, ups=2.93, wpb=347.5, bsz=8, num_updates=57480, lr=4.30654e-05, gnorm=1.858, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=19805
2023-03-15 19:29:50 - progress_bar.py[line:272] - INFO: epoch 029:   1746 / 2004 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=341.3, nsentences=8, sample_size=341.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1046.9, ups=3.07, wpb=341.3, bsz=8, num_updates=57490, lr=4.30553e-05, gnorm=1.869, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=19808
2023-03-15 19:29:54 - progress_bar.py[line:272] - INFO: epoch 029:   1756 / 2004 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=328.1, nsentences=8, sample_size=328.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=966.9, ups=2.95, wpb=328.1, bsz=8, num_updates=57500, lr=4.30452e-05, gnorm=1.983, clip=0, loss_scale=2048, train_wall=3, gb_free=15.9, wall=19811
2023-03-15 19:29:57 - progress_bar.py[line:272] - INFO: epoch 029:   1766 / 2004 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=318.3, nsentences=8, sample_size=318.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=925.6, ups=2.91, wpb=318.3, bsz=8, num_updates=57510, lr=4.30351e-05, gnorm=1.967, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=19815
2023-03-15 19:30:00 - progress_bar.py[line:272] - INFO: epoch 029:   1776 / 2004 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=347.4, nsentences=8, sample_size=347.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1009.9, ups=2.91, wpb=347.4, bsz=8, num_updates=57520, lr=4.30251e-05, gnorm=2.058, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=19818
2023-03-15 19:30:04 - progress_bar.py[line:272] - INFO: epoch 029:   1786 / 2004 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=317, nsentences=8, sample_size=317, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=924.6, ups=2.92, wpb=317, bsz=8, num_updates=57530, lr=4.3015e-05, gnorm=1.926, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=19822
2023-03-15 19:30:07 - progress_bar.py[line:272] - INFO: epoch 029:   1796 / 2004 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=337.2, nsentences=8, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=980.5, ups=2.91, wpb=337.2, bsz=8, num_updates=57540, lr=4.30049e-05, gnorm=2.23, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=19825
2023-03-15 19:30:11 - progress_bar.py[line:272] - INFO: epoch 029:   1806 / 2004 loss=0.128, loss_v1=0, loss_v2=0, nll_loss=0.128, ntokens=345.6, nsentences=8, sample_size=345.6, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1000.3, ups=2.89, wpb=345.6, bsz=8, num_updates=57550, lr=4.29948e-05, gnorm=1.862, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=19828
2023-03-15 19:30:13 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 19:30:15 - progress_bar.py[line:272] - INFO: epoch 029:   1817 / 2004 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=348.1, nsentences=8, sample_size=348.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=921.5, ups=2.65, wpb=348.1, bsz=8, num_updates=57560, lr=4.29847e-05, gnorm=2.04, clip=0, loss_scale=2048, train_wall=4, gb_free=14.9, wall=19832
2023-03-15 19:30:18 - progress_bar.py[line:272] - INFO: epoch 029:   1827 / 2004 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=357.3, nsentences=8, sample_size=357.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1011.3, ups=2.83, wpb=357.3, bsz=8, num_updates=57570, lr=4.29747e-05, gnorm=2.033, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=19836
2023-03-15 19:30:22 - progress_bar.py[line:272] - INFO: epoch 029:   1837 / 2004 loss=0.13, loss_v1=0, loss_v2=0, nll_loss=0.13, ntokens=341.2, nsentences=8, sample_size=341.2, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=983.9, ups=2.88, wpb=341.2, bsz=8, num_updates=57580, lr=4.29646e-05, gnorm=1.83, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=19839
2023-03-15 19:30:25 - progress_bar.py[line:272] - INFO: epoch 029:   1847 / 2004 loss=0.131, loss_v1=0, loss_v2=0, nll_loss=0.131, ntokens=355.5, nsentences=8, sample_size=355.5, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1042, ups=2.93, wpb=355.5, bsz=8, num_updates=57590, lr=4.29545e-05, gnorm=1.878, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=19843
2023-03-15 19:30:28 - progress_bar.py[line:272] - INFO: epoch 029:   1857 / 2004 loss=0.135, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=312.4, nsentences=8, sample_size=312.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=905.1, ups=2.9, wpb=312.4, bsz=8, num_updates=57600, lr=4.29444e-05, gnorm=1.923, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=19846
2023-03-15 19:30:32 - progress_bar.py[line:272] - INFO: epoch 029:   1867 / 2004 loss=0.13, loss_v1=0, loss_v2=0, nll_loss=0.13, ntokens=352.6, nsentences=8, sample_size=352.6, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1012.3, ups=2.87, wpb=352.6, bsz=8, num_updates=57610, lr=4.29343e-05, gnorm=1.827, clip=0, loss_scale=2048, train_wall=3, gb_free=14, wall=19850
2023-03-15 19:30:35 - progress_bar.py[line:272] - INFO: epoch 029:   1877 / 2004 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=331.6, nsentences=8, sample_size=331.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=947.8, ups=2.86, wpb=331.6, bsz=8, num_updates=57620, lr=4.29243e-05, gnorm=2.151, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=19853
2023-03-15 19:30:39 - progress_bar.py[line:272] - INFO: epoch 029:   1887 / 2004 loss=0.131, loss_v1=0, loss_v2=0, nll_loss=0.131, ntokens=314.3, nsentences=8, sample_size=314.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=912.4, ups=2.9, wpb=314.3, bsz=8, num_updates=57630, lr=4.29142e-05, gnorm=1.939, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=19857
2023-03-15 19:30:42 - progress_bar.py[line:272] - INFO: epoch 029:   1897 / 2004 loss=0.124, loss_v1=0, loss_v2=0, nll_loss=0.124, ntokens=352.5, nsentences=8, sample_size=352.5, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1015.7, ups=2.88, wpb=352.5, bsz=8, num_updates=57640, lr=4.29041e-05, gnorm=1.687, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=19860
2023-03-15 19:30:46 - progress_bar.py[line:272] - INFO: epoch 029:   1907 / 2004 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=333.2, nsentences=8, sample_size=333.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=971.8, ups=2.92, wpb=333.2, bsz=8, num_updates=57650, lr=4.2894e-05, gnorm=2.095, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=19863
2023-03-15 19:30:49 - progress_bar.py[line:272] - INFO: epoch 029:   1917 / 2004 loss=0.134, loss_v1=0, loss_v2=0, nll_loss=0.134, ntokens=332, nsentences=8, sample_size=332, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=971.3, ups=2.93, wpb=332, bsz=8, num_updates=57660, lr=4.28839e-05, gnorm=1.968, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=19867
2023-03-15 19:30:52 - progress_bar.py[line:272] - INFO: epoch 029:   1927 / 2004 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=330.9, nsentences=8, sample_size=330.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1012.5, ups=3.06, wpb=330.9, bsz=8, num_updates=57670, lr=4.28738e-05, gnorm=2.174, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=19870
2023-03-15 19:30:56 - progress_bar.py[line:272] - INFO: epoch 029:   1937 / 2004 loss=0.125, loss_v1=0, loss_v2=0, nll_loss=0.125, ntokens=337.9, nsentences=8, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1077.9, ups=3.19, wpb=337.9, bsz=8, num_updates=57680, lr=4.28638e-05, gnorm=1.829, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=19873
2023-03-15 19:30:59 - progress_bar.py[line:272] - INFO: epoch 029:   1947 / 2004 loss=0.13, loss_v1=0, loss_v2=0, nll_loss=0.13, ntokens=344.1, nsentences=8, sample_size=344.1, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1090, ups=3.17, wpb=344.1, bsz=8, num_updates=57690, lr=4.28537e-05, gnorm=1.719, clip=0, loss_scale=4096, train_wall=3, gb_free=15.3, wall=19876
2023-03-15 19:31:00 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 19:31:02 - progress_bar.py[line:272] - INFO: epoch 029:   1958 / 2004 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=346.9, nsentences=8, sample_size=346.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=987.7, ups=2.85, wpb=346.9, bsz=8, num_updates=57700, lr=4.28436e-05, gnorm=2.095, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=19880
2023-03-15 19:31:05 - progress_bar.py[line:272] - INFO: epoch 029:   1968 / 2004 loss=0.136, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=340.2, nsentences=8, sample_size=340.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1101, ups=3.24, wpb=340.2, bsz=8, num_updates=57710, lr=4.28335e-05, gnorm=2.003, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=19883
2023-03-15 19:31:09 - progress_bar.py[line:272] - INFO: epoch 029:   1978 / 2004 loss=0.125, loss_v1=0, loss_v2=0, nll_loss=0.125, ntokens=353.7, nsentences=8, sample_size=353.7, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1106.4, ups=3.13, wpb=353.7, bsz=8, num_updates=57720, lr=4.28234e-05, gnorm=1.886, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=19886
2023-03-15 19:31:12 - progress_bar.py[line:272] - INFO: epoch 029:   1988 / 2004 loss=0.124, loss_v1=0, loss_v2=0, nll_loss=0.124, ntokens=323, nsentences=8, sample_size=323, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1027.1, ups=3.18, wpb=323, bsz=8, num_updates=57730, lr=4.28134e-05, gnorm=1.726, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=19889
2023-03-15 19:31:15 - progress_bar.py[line:272] - INFO: epoch 029:   1998 / 2004 loss=0.128, loss_v1=0, loss_v2=0, nll_loss=0.128, ntokens=398.1, nsentences=8, sample_size=398.1, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1280.9, ups=3.22, wpb=398.1, bsz=8, num_updates=57740, lr=4.28033e-05, gnorm=1.872, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=19892
2023-03-15 19:31:17 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 29 @ 57746 updates
2023-03-15 19:31:17 - trainer.py[line:431] - INFO: Saving checkpoint to ./checkpoints/checkpoint29.pt
2023-03-15 19:31:22 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./checkpoints/checkpoint29.pt
2023-03-15 19:31:26 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./checkpoints/checkpoint29.pt (epoch 29 @ 57746 updates, score None) (writing took 9.06829003058374 seconds)
2023-03-15 19:31:26 - train.py[line:332] - INFO: end of epoch 29 (average epoch stats below)
2023-03-15 19:31:26 - progress_bar.py[line:282] - INFO: epoch 029 | loss 0.14 | loss_v1 0 | loss_v2 0 | nll_loss 0.14 | ntokens 345.493 | nsentences 7.999 | sample_size 345.493 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.1 | wps 984.7 | ups 2.85 | wpb 345.5 | bsz 8 | num_updates 57746 | lr 4.27972e-05 | gnorm 2.01 | clip 0.1 | loss_scale 2048 | train_wall 677 | gb_free 14.4 | wall 19904
2023-03-15 19:31:26 - trainer.py[line:639] - INFO: loading train data for epoch 30
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 row count 8015 total row count 8015
slice_id 0 seek offset 0
2023-03-15 19:31:27 - trainer.py[line:703] - INFO: begin training epoch 30
2023-03-15 19:31:27 - train.py[line:305] - INFO: Start iterating over samples
2023-03-15 19:31:29 - progress_bar.py[line:272] - INFO: epoch 030:      4 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=374.3, nsentences=8, sample_size=374.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=271.8, ups=0.73, wpb=374.3, bsz=8, num_updates=57750, lr=4.27932e-05, gnorm=2.224, clip=0, loss_scale=2048, train_wall=3, gb_free=13.9, wall=19906
2023-03-15 19:31:32 - progress_bar.py[line:272] - INFO: epoch 030:     14 / 2004 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=320.6, nsentences=8, sample_size=320.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=924.1, ups=2.88, wpb=320.6, bsz=8, num_updates=57760, lr=4.27831e-05, gnorm=1.931, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=19910
2023-03-15 19:31:35 - progress_bar.py[line:272] - INFO: epoch 030:     24 / 2004 loss=0.13, loss_v1=0, loss_v2=0, nll_loss=0.13, ntokens=362.6, nsentences=8, sample_size=362.6, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1058.8, ups=2.92, wpb=362.6, bsz=8, num_updates=57770, lr=4.2773e-05, gnorm=2.045, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=19913
2023-03-15 19:31:39 - progress_bar.py[line:272] - INFO: epoch 030:     34 / 2004 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=347.1, nsentences=8, sample_size=347.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1025.9, ups=2.96, wpb=347.1, bsz=8, num_updates=57780, lr=4.2763e-05, gnorm=2.209, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=19916
2023-03-15 19:31:42 - progress_bar.py[line:272] - INFO: epoch 030:     44 / 2004 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=354.6, nsentences=8, sample_size=354.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1023.6, ups=2.89, wpb=354.6, bsz=8, num_updates=57790, lr=4.27529e-05, gnorm=2.373, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=19920
2023-03-15 19:31:46 - progress_bar.py[line:272] - INFO: epoch 030:     54 / 2004 loss=0.137, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=351.6, nsentences=8, sample_size=351.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1003.5, ups=2.85, wpb=351.6, bsz=8, num_updates=57800, lr=4.27428e-05, gnorm=2.046, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=19923
2023-03-15 19:31:49 - progress_bar.py[line:272] - INFO: epoch 030:     64 / 2004 loss=0.123, loss_v1=0, loss_v2=0, nll_loss=0.123, ntokens=320.8, nsentences=8, sample_size=320.8, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=934.1, ups=2.91, wpb=320.8, bsz=8, num_updates=57810, lr=4.27327e-05, gnorm=1.644, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=19927
2023-03-15 19:31:53 - progress_bar.py[line:272] - INFO: epoch 030:     74 / 2004 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=359.2, nsentences=8, sample_size=359.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=1047.3, ups=2.92, wpb=359.2, bsz=8, num_updates=57820, lr=4.27226e-05, gnorm=2.238, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=19930
2023-03-15 19:31:55 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 19:31:57 - progress_bar.py[line:272] - INFO: epoch 030:     85 / 2004 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=339, nsentences=8, sample_size=339, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=890.4, ups=2.63, wpb=339, bsz=8, num_updates=57830, lr=4.27126e-05, gnorm=2.062, clip=0, loss_scale=2048, train_wall=4, gb_free=14.2, wall=19934
2023-03-15 19:32:00 - progress_bar.py[line:272] - INFO: epoch 030:     95 / 2004 loss=0.133, loss_v1=0, loss_v2=0, nll_loss=0.133, ntokens=356.7, nsentences=8, sample_size=356.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1066.7, ups=2.99, wpb=356.7, bsz=8, num_updates=57840, lr=4.27025e-05, gnorm=1.639, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=19937
2023-03-15 19:32:03 - progress_bar.py[line:272] - INFO: epoch 030:    105 / 2004 loss=0.134, loss_v1=0, loss_v2=0, nll_loss=0.134, ntokens=376.9, nsentences=8, sample_size=376.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1090.9, ups=2.89, wpb=376.9, bsz=8, num_updates=57850, lr=4.26924e-05, gnorm=2.074, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=19941
2023-03-15 19:32:08 - progress_bar.py[line:272] - INFO: epoch 030:    115 / 2004 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=340.5, nsentences=8, sample_size=340.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=780.9, ups=2.29, wpb=340.5, bsz=8, num_updates=57860, lr=4.26823e-05, gnorm=2.004, clip=0, loss_scale=2048, train_wall=4, gb_free=13.8, wall=19945
2023-03-15 19:32:11 - progress_bar.py[line:272] - INFO: epoch 030:    125 / 2004 loss=0.132, loss_v1=0, loss_v2=0, nll_loss=0.132, ntokens=326.2, nsentences=8, sample_size=326.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=930.9, ups=2.85, wpb=326.2, bsz=8, num_updates=57870, lr=4.26722e-05, gnorm=2.005, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=19949
2023-03-15 19:32:15 - progress_bar.py[line:272] - INFO: epoch 030:    135 / 2004 loss=0.133, loss_v1=0, loss_v2=0, nll_loss=0.133, ntokens=341.7, nsentences=8, sample_size=341.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=997.1, ups=2.92, wpb=341.7, bsz=8, num_updates=57880, lr=4.26622e-05, gnorm=1.883, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=19952
2023-03-15 19:32:18 - progress_bar.py[line:272] - INFO: epoch 030:    145 / 2004 loss=0.137, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=332.7, nsentences=8, sample_size=332.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=987, ups=2.97, wpb=332.7, bsz=8, num_updates=57890, lr=4.26521e-05, gnorm=1.832, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=19956
2023-03-15 19:32:22 - progress_bar.py[line:272] - INFO: epoch 030:    155 / 2004 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=339.4, nsentences=8, sample_size=339.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=943.1, ups=2.78, wpb=339.4, bsz=8, num_updates=57900, lr=4.2642e-05, gnorm=2.205, clip=0, loss_scale=2048, train_wall=4, gb_free=14.7, wall=19959
2023-03-15 19:32:25 - progress_bar.py[line:272] - INFO: epoch 030:    165 / 2004 loss=0.127, loss_v1=0, loss_v2=0, nll_loss=0.127, ntokens=353.9, nsentences=8, sample_size=353.9, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1002, ups=2.83, wpb=353.9, bsz=8, num_updates=57910, lr=4.26319e-05, gnorm=1.848, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=19963
2023-03-15 19:32:29 - progress_bar.py[line:272] - INFO: epoch 030:    175 / 2004 loss=0.135, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=331.9, nsentences=8, sample_size=331.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=967, ups=2.91, wpb=331.9, bsz=8, num_updates=57920, lr=4.26218e-05, gnorm=2.015, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=19966
2023-03-15 19:32:32 - progress_bar.py[line:272] - INFO: epoch 030:    185 / 2004 loss=0.131, loss_v1=0, loss_v2=0, nll_loss=0.131, ntokens=336.3, nsentences=8, sample_size=336.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=991.2, ups=2.95, wpb=336.3, bsz=8, num_updates=57930, lr=4.26117e-05, gnorm=1.871, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=19970
2023-03-15 19:32:35 - progress_bar.py[line:272] - INFO: epoch 030:    195 / 2004 loss=0.129, loss_v1=0, loss_v2=0, nll_loss=0.129, ntokens=321.6, nsentences=8, sample_size=321.6, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=933.8, ups=2.9, wpb=321.6, bsz=8, num_updates=57940, lr=4.26017e-05, gnorm=1.941, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=19973
2023-03-15 19:32:39 - progress_bar.py[line:272] - INFO: epoch 030:    205 / 2004 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=336.6, nsentences=8, sample_size=336.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=977.6, ups=2.9, wpb=336.6, bsz=8, num_updates=57950, lr=4.25916e-05, gnorm=2.078, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=19976
2023-03-15 19:32:42 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 19:32:43 - progress_bar.py[line:272] - INFO: epoch 030:    216 / 2004 loss=0.13, loss_v1=0, loss_v2=0, nll_loss=0.13, ntokens=319.9, nsentences=8, sample_size=319.9, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=841.6, ups=2.63, wpb=319.9, bsz=8, num_updates=57960, lr=4.25815e-05, gnorm=1.792, clip=0, loss_scale=2048, train_wall=4, gb_free=15.2, wall=19980
2023-03-15 19:32:46 - progress_bar.py[line:272] - INFO: epoch 030:    226 / 2004 loss=0.123, loss_v1=0, loss_v2=0, nll_loss=0.123, ntokens=348.6, nsentences=8, sample_size=348.6, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1008.8, ups=2.89, wpb=348.6, bsz=8, num_updates=57970, lr=4.25714e-05, gnorm=1.691, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=19984
2023-03-15 19:32:50 - progress_bar.py[line:272] - INFO: epoch 030:    236 / 2004 loss=0.129, loss_v1=0, loss_v2=0, nll_loss=0.129, ntokens=378.5, nsentences=8, sample_size=378.5, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1074.6, ups=2.84, wpb=378.5, bsz=8, num_updates=57980, lr=4.25613e-05, gnorm=2.002, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=19987
2023-03-15 19:32:53 - progress_bar.py[line:272] - INFO: epoch 030:    246 / 2004 loss=0.134, loss_v1=0, loss_v2=0, nll_loss=0.134, ntokens=352.2, nsentences=8, sample_size=352.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1023.3, ups=2.91, wpb=352.2, bsz=8, num_updates=57990, lr=4.25513e-05, gnorm=1.975, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=19991
2023-03-15 19:32:57 - progress_bar.py[line:272] - INFO: epoch 030:    256 / 2004 loss=0.127, loss_v1=0, loss_v2=0, nll_loss=0.127, ntokens=329.3, nsentences=8, sample_size=329.3, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=949.4, ups=2.88, wpb=329.3, bsz=8, num_updates=58000, lr=4.25412e-05, gnorm=2.074, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=19994
2023-03-15 19:33:00 - progress_bar.py[line:272] - INFO: epoch 030:    266 / 2004 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=357, nsentences=8, sample_size=357, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1031.7, ups=2.89, wpb=357, bsz=8, num_updates=58010, lr=4.25311e-05, gnorm=1.995, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=19998
2023-03-15 19:33:03 - progress_bar.py[line:272] - INFO: epoch 030:    276 / 2004 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=342.3, nsentences=8, sample_size=342.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=999.8, ups=2.92, wpb=342.3, bsz=8, num_updates=58020, lr=4.2521e-05, gnorm=1.969, clip=0, loss_scale=2048, train_wall=3, gb_free=13.9, wall=20001
2023-03-15 19:33:07 - progress_bar.py[line:272] - INFO: epoch 030:    286 / 2004 loss=0.129, loss_v1=0, loss_v2=0, nll_loss=0.129, ntokens=366.8, nsentences=8, sample_size=366.8, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1039.7, ups=2.83, wpb=366.8, bsz=8, num_updates=58030, lr=4.25109e-05, gnorm=2.117, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=20005
2023-03-15 19:33:10 - progress_bar.py[line:272] - INFO: epoch 030:    296 / 2004 loss=0.13, loss_v1=0, loss_v2=0, nll_loss=0.13, ntokens=352.6, nsentences=8, sample_size=352.6, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1024.9, ups=2.91, wpb=352.6, bsz=8, num_updates=58040, lr=4.25009e-05, gnorm=1.87, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=20008
2023-03-15 19:33:14 - progress_bar.py[line:272] - INFO: epoch 030:    306 / 2004 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=340.2, nsentences=8, sample_size=340.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1013.4, ups=2.98, wpb=340.2, bsz=8, num_updates=58050, lr=4.24908e-05, gnorm=1.973, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=20011
2023-03-15 19:33:17 - progress_bar.py[line:272] - INFO: epoch 030:    316 / 2004 loss=0.125, loss_v1=0, loss_v2=0, nll_loss=0.125, ntokens=362.2, nsentences=8, sample_size=362.2, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1148.4, ups=3.17, wpb=362.2, bsz=8, num_updates=58060, lr=4.24807e-05, gnorm=1.748, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=20015
2023-03-15 19:33:20 - progress_bar.py[line:272] - INFO: epoch 030:    326 / 2004 loss=0.128, loss_v1=0, loss_v2=0, nll_loss=0.128, ntokens=324.5, nsentences=8, sample_size=324.5, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1021.8, ups=3.15, wpb=324.5, bsz=8, num_updates=58070, lr=4.24706e-05, gnorm=1.964, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=20018
2023-03-15 19:33:24 - progress_bar.py[line:272] - INFO: epoch 030:    336 / 2004 loss=0.132, loss_v1=0, loss_v2=0, nll_loss=0.132, ntokens=339, nsentences=8, sample_size=339, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=982.4, ups=2.9, wpb=339, bsz=8, num_updates=58080, lr=4.24605e-05, gnorm=1.837, clip=0, loss_scale=2048, train_wall=3, gb_free=13.9, wall=20021
2023-03-15 19:33:27 - progress_bar.py[line:272] - INFO: epoch 030:    346 / 2004 loss=0.128, loss_v1=0, loss_v2=0, nll_loss=0.128, ntokens=374, nsentences=8, sample_size=374, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1073.8, ups=2.87, wpb=374, bsz=8, num_updates=58090, lr=4.24505e-05, gnorm=1.844, clip=0, loss_scale=4096, train_wall=3, gb_free=14.8, wall=20025
2023-03-15 19:33:28 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 19:33:31 - progress_bar.py[line:272] - INFO: epoch 030:    357 / 2004 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=346.1, nsentences=8, sample_size=346.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=911.9, ups=2.63, wpb=346.1, bsz=8, num_updates=58100, lr=4.24404e-05, gnorm=2.257, clip=0, loss_scale=2048, train_wall=4, gb_free=14.5, wall=20028
2023-03-15 19:33:34 - progress_bar.py[line:272] - INFO: epoch 030:    367 / 2004 loss=0.136, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=351.7, nsentences=8, sample_size=351.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1006.5, ups=2.86, wpb=351.7, bsz=8, num_updates=58110, lr=4.24303e-05, gnorm=2.027, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=20032
2023-03-15 19:33:38 - progress_bar.py[line:272] - INFO: epoch 030:    377 / 2004 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=302.3, nsentences=8, sample_size=302.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=887.6, ups=2.94, wpb=302.3, bsz=8, num_updates=58120, lr=4.24202e-05, gnorm=1.839, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=20035
2023-03-15 19:33:41 - progress_bar.py[line:272] - INFO: epoch 030:    387 / 2004 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=336.1, nsentences=8, sample_size=336.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=977, ups=2.91, wpb=336.1, bsz=8, num_updates=58130, lr=4.24101e-05, gnorm=2.134, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=20039
2023-03-15 19:33:45 - progress_bar.py[line:272] - INFO: epoch 030:    397 / 2004 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=347, nsentences=8, sample_size=347, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=998.4, ups=2.88, wpb=347, bsz=8, num_updates=58140, lr=4.24e-05, gnorm=1.967, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=20042
2023-03-15 19:33:48 - progress_bar.py[line:272] - INFO: epoch 030:    407 / 2004 loss=0.122, loss_v1=0, loss_v2=0, nll_loss=0.122, ntokens=382, nsentences=8, sample_size=382, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1105.2, ups=2.89, wpb=382, bsz=8, num_updates=58150, lr=4.239e-05, gnorm=1.795, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=20046
2023-03-15 19:33:52 - progress_bar.py[line:272] - INFO: epoch 030:    417 / 2004 loss=0.129, loss_v1=0, loss_v2=0, nll_loss=0.129, ntokens=337.8, nsentences=8, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=966.5, ups=2.86, wpb=337.8, bsz=8, num_updates=58160, lr=4.23799e-05, gnorm=1.797, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=20049
2023-03-15 19:33:55 - progress_bar.py[line:272] - INFO: epoch 030:    427 / 2004 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=338.1, nsentences=8, sample_size=338.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=973.8, ups=2.88, wpb=338.1, bsz=8, num_updates=58170, lr=4.23698e-05, gnorm=2.08, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=20053
2023-03-15 19:33:58 - progress_bar.py[line:272] - INFO: epoch 030:    437 / 2004 loss=0.126, loss_v1=0, loss_v2=0, nll_loss=0.126, ntokens=350.6, nsentences=8, sample_size=350.6, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1013.8, ups=2.89, wpb=350.6, bsz=8, num_updates=58180, lr=4.23597e-05, gnorm=1.806, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=20056
2023-03-15 19:34:02 - progress_bar.py[line:272] - INFO: epoch 030:    447 / 2004 loss=0.112, loss_v1=0, loss_v2=0, nll_loss=0.112, ntokens=374.5, nsentences=8, sample_size=374.5, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=1042.4, ups=2.78, wpb=374.5, bsz=8, num_updates=58190, lr=4.23496e-05, gnorm=1.499, clip=0, loss_scale=2048, train_wall=4, gb_free=13.9, wall=20060
2023-03-15 19:34:06 - progress_bar.py[line:272] - INFO: epoch 030:    457 / 2004 loss=0.133, loss_v1=0, loss_v2=0, nll_loss=0.133, ntokens=390, nsentences=8, sample_size=390, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1133.9, ups=2.91, wpb=390, bsz=8, num_updates=58200, lr=4.23396e-05, gnorm=1.837, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=20063
2023-03-15 19:34:09 - progress_bar.py[line:272] - INFO: epoch 030:    467 / 2004 loss=0.135, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=359.1, nsentences=8, sample_size=359.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1023.2, ups=2.85, wpb=359.1, bsz=8, num_updates=58210, lr=4.23295e-05, gnorm=1.908, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=20067
2023-03-15 19:34:12 - progress_bar.py[line:272] - INFO: epoch 030:    477 / 2004 loss=0.132, loss_v1=0, loss_v2=0, nll_loss=0.132, ntokens=334.5, nsentences=8, sample_size=334.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=978.6, ups=2.93, wpb=334.5, bsz=8, num_updates=58220, lr=4.23194e-05, gnorm=1.946, clip=0, loss_scale=4096, train_wall=3, gb_free=15.4, wall=20070
2023-03-15 19:34:13 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 19:34:16 - progress_bar.py[line:272] - INFO: epoch 030:    488 / 2004 loss=0.128, loss_v1=0, loss_v2=0, nll_loss=0.128, ntokens=378.3, nsentences=8, sample_size=378.3, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1000.8, ups=2.65, wpb=378.3, bsz=8, num_updates=58230, lr=4.23093e-05, gnorm=1.993, clip=0, loss_scale=2048, train_wall=4, gb_free=15.4, wall=20074
2023-03-15 19:34:20 - progress_bar.py[line:272] - INFO: epoch 030:    498 / 2004 loss=0.136, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=365.1, nsentences=8, sample_size=365.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1039, ups=2.85, wpb=365.1, bsz=8, num_updates=58240, lr=4.22992e-05, gnorm=1.867, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=20077
2023-03-15 19:34:23 - progress_bar.py[line:272] - INFO: epoch 030:    508 / 2004 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=352.5, nsentences=8, sample_size=352.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1030.5, ups=2.92, wpb=352.5, bsz=8, num_updates=58250, lr=4.22892e-05, gnorm=2.011, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=20081
2023-03-15 19:34:27 - progress_bar.py[line:272] - INFO: epoch 030:    518 / 2004 loss=0.134, loss_v1=0, loss_v2=0, nll_loss=0.134, ntokens=351.6, nsentences=8, sample_size=351.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1021.3, ups=2.9, wpb=351.6, bsz=8, num_updates=58260, lr=4.22791e-05, gnorm=1.98, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=20084
2023-03-15 19:34:30 - progress_bar.py[line:272] - INFO: epoch 030:    528 / 2004 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=402.8, nsentences=8, sample_size=402.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1154.5, ups=2.87, wpb=402.8, bsz=8, num_updates=58270, lr=4.2269e-05, gnorm=2.049, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=20088
2023-03-15 19:34:34 - progress_bar.py[line:272] - INFO: epoch 030:    538 / 2004 loss=0.131, loss_v1=0, loss_v2=0, nll_loss=0.131, ntokens=385.5, nsentences=8, sample_size=385.5, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1108.8, ups=2.88, wpb=385.5, bsz=8, num_updates=58280, lr=4.22589e-05, gnorm=2.048, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=20091
2023-03-15 19:34:37 - progress_bar.py[line:272] - INFO: epoch 030:    548 / 2004 loss=0.136, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=350.6, nsentences=8, sample_size=350.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1096.7, ups=3.13, wpb=350.6, bsz=8, num_updates=58290, lr=4.22488e-05, gnorm=2.061, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=20094
2023-03-15 19:34:40 - progress_bar.py[line:272] - INFO: epoch 030:    558 / 2004 loss=0.133, loss_v1=0, loss_v2=0, nll_loss=0.133, ntokens=378.2, nsentences=8, sample_size=378.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1112.7, ups=2.94, wpb=378.2, bsz=8, num_updates=58300, lr=4.22388e-05, gnorm=1.906, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=20098
2023-03-15 19:34:44 - progress_bar.py[line:272] - INFO: epoch 030:    568 / 2004 loss=0.134, loss_v1=0, loss_v2=0, nll_loss=0.134, ntokens=377.4, nsentences=8, sample_size=377.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1096.3, ups=2.9, wpb=377.4, bsz=8, num_updates=58310, lr=4.22287e-05, gnorm=2.07, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=20101
2023-03-15 19:34:47 - progress_bar.py[line:272] - INFO: epoch 030:    578 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=329.9, nsentences=8, sample_size=329.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=956, ups=2.9, wpb=329.9, bsz=8, num_updates=58320, lr=4.22186e-05, gnorm=2.247, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=20105
2023-03-15 19:34:48 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 19:34:51 - progress_bar.py[line:272] - INFO: epoch 030:    589 / 2004 loss=0.133, loss_v1=0, loss_v2=0, nll_loss=0.133, ntokens=339.2, nsentences=8, sample_size=339.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=864.5, ups=2.55, wpb=339.2, bsz=8, num_updates=58330, lr=4.22085e-05, gnorm=1.939, clip=0, loss_scale=1024, train_wall=4, gb_free=15.5, wall=20109
2023-03-15 19:34:55 - progress_bar.py[line:272] - INFO: epoch 030:    599 / 2004 loss=0.125, loss_v1=0, loss_v2=0, nll_loss=0.125, ntokens=352.5, nsentences=8, sample_size=352.5, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1005.4, ups=2.85, wpb=352.5, bsz=8, num_updates=58340, lr=4.21984e-05, gnorm=1.916, clip=0, loss_scale=1024, train_wall=3, gb_free=13.8, wall=20112
2023-03-15 19:34:58 - progress_bar.py[line:272] - INFO: epoch 030:    609 / 2004 loss=0.135, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=333.9, nsentences=8, sample_size=333.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=958.9, ups=2.87, wpb=333.9, bsz=8, num_updates=58350, lr=4.21884e-05, gnorm=1.984, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=20116
2023-03-15 19:35:02 - progress_bar.py[line:272] - INFO: epoch 030:    619 / 2004 loss=0.127, loss_v1=0, loss_v2=0, nll_loss=0.127, ntokens=367.6, nsentences=8, sample_size=367.6, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1043.8, ups=2.84, wpb=367.6, bsz=8, num_updates=58360, lr=4.21783e-05, gnorm=1.896, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=20119
2023-03-15 19:35:05 - progress_bar.py[line:272] - INFO: epoch 030:    629 / 2004 loss=0.136, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=356.6, nsentences=8, sample_size=356.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1043.1, ups=2.93, wpb=356.6, bsz=8, num_updates=58370, lr=4.21682e-05, gnorm=2.219, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=20123
2023-03-15 19:35:08 - progress_bar.py[line:272] - INFO: epoch 030:    639 / 2004 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=330.3, nsentences=8, sample_size=330.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=980.8, ups=2.97, wpb=330.3, bsz=8, num_updates=58380, lr=4.21581e-05, gnorm=1.967, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=20126
2023-03-15 19:35:12 - progress_bar.py[line:272] - INFO: epoch 030:    649 / 2004 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=335.9, nsentences=8, sample_size=335.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=972.6, ups=2.9, wpb=335.9, bsz=8, num_updates=58390, lr=4.2148e-05, gnorm=2.104, clip=0, loss_scale=1024, train_wall=3, gb_free=15.3, wall=20129
2023-03-15 19:35:15 - progress_bar.py[line:272] - INFO: epoch 030:    659 / 2004 loss=0.124, loss_v1=0, loss_v2=0, nll_loss=0.124, ntokens=339, nsentences=7.8, sample_size=339, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=981.1, ups=2.89, wpb=339, bsz=7.8, num_updates=58400, lr=4.21379e-05, gnorm=1.842, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=20133
2023-03-15 19:35:19 - progress_bar.py[line:272] - INFO: epoch 030:    669 / 2004 loss=0.13, loss_v1=0, loss_v2=0, nll_loss=0.13, ntokens=302.7, nsentences=8, sample_size=302.7, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=876.2, ups=2.89, wpb=302.7, bsz=8, num_updates=58410, lr=4.21279e-05, gnorm=2.009, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=20136
2023-03-15 19:35:22 - progress_bar.py[line:272] - INFO: epoch 030:    679 / 2004 loss=0.123, loss_v1=0, loss_v2=0, nll_loss=0.123, ntokens=347, nsentences=8, sample_size=347, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=995.2, ups=2.87, wpb=347, bsz=8, num_updates=58420, lr=4.21178e-05, gnorm=1.698, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=20140
2023-03-15 19:35:26 - progress_bar.py[line:272] - INFO: epoch 030:    689 / 2004 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=348.2, nsentences=8, sample_size=348.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=994.3, ups=2.86, wpb=348.2, bsz=8, num_updates=58430, lr=4.21077e-05, gnorm=2.102, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=20143
2023-03-15 19:35:29 - progress_bar.py[line:272] - INFO: epoch 030:    699 / 2004 loss=0.13, loss_v1=0, loss_v2=0, nll_loss=0.13, ntokens=351, nsentences=8, sample_size=351, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1020.4, ups=2.91, wpb=351, bsz=8, num_updates=58440, lr=4.20976e-05, gnorm=1.794, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=20147
2023-03-15 19:35:33 - progress_bar.py[line:272] - INFO: epoch 030:    709 / 2004 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=330.8, nsentences=8, sample_size=330.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=963.8, ups=2.91, wpb=330.8, bsz=8, num_updates=58450, lr=4.20875e-05, gnorm=2.256, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=20150
2023-03-15 19:35:36 - progress_bar.py[line:272] - INFO: epoch 030:    719 / 2004 loss=0.123, loss_v1=0, loss_v2=0, nll_loss=0.123, ntokens=345.3, nsentences=8, sample_size=345.3, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=997.8, ups=2.89, wpb=345.3, bsz=8, num_updates=58460, lr=4.20775e-05, gnorm=1.704, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=20154
2023-03-15 19:35:39 - progress_bar.py[line:272] - INFO: epoch 030:    729 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=358.4, nsentences=8, sample_size=358.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1038.2, ups=2.9, wpb=358.4, bsz=8, num_updates=58470, lr=4.20674e-05, gnorm=2.135, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=20157
2023-03-15 19:35:43 - progress_bar.py[line:272] - INFO: epoch 030:    739 / 2004 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=328.2, nsentences=8, sample_size=328.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=962.6, ups=2.93, wpb=328.2, bsz=8, num_updates=58480, lr=4.20573e-05, gnorm=2.359, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=20160
2023-03-15 19:35:46 - progress_bar.py[line:272] - INFO: epoch 030:    749 / 2004 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=371.7, nsentences=8, sample_size=371.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1084.4, ups=2.92, wpb=371.7, bsz=8, num_updates=58490, lr=4.20472e-05, gnorm=2.152, clip=0, loss_scale=2048, train_wall=3, gb_free=13.7, wall=20164
2023-03-15 19:35:50 - progress_bar.py[line:272] - INFO: epoch 030:    759 / 2004 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=301.8, nsentences=8, sample_size=301.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=883, ups=2.93, wpb=301.8, bsz=8, num_updates=58500, lr=4.20371e-05, gnorm=2.193, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=20167
2023-03-15 19:35:53 - progress_bar.py[line:272] - INFO: epoch 030:    769 / 2004 loss=0.131, loss_v1=0, loss_v2=0, nll_loss=0.131, ntokens=410.9, nsentences=8, sample_size=410.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1154.6, ups=2.81, wpb=410.9, bsz=8, num_updates=58510, lr=4.20271e-05, gnorm=2.301, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=20171
2023-03-15 19:35:57 - progress_bar.py[line:272] - INFO: epoch 030:    779 / 2004 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=339.5, nsentences=8, sample_size=339.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=981.1, ups=2.89, wpb=339.5, bsz=8, num_updates=58520, lr=4.2017e-05, gnorm=2.257, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=20174
2023-03-15 19:36:00 - progress_bar.py[line:272] - INFO: epoch 030:    789 / 2004 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=340.1, nsentences=8, sample_size=340.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=977.1, ups=2.87, wpb=340.1, bsz=8, num_updates=58530, lr=4.20069e-05, gnorm=1.836, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=20178
2023-03-15 19:36:04 - progress_bar.py[line:272] - INFO: epoch 030:    799 / 2004 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=329.8, nsentences=8, sample_size=329.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=958.8, ups=2.91, wpb=329.8, bsz=8, num_updates=58540, lr=4.19968e-05, gnorm=1.96, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=20181
2023-03-15 19:36:07 - progress_bar.py[line:272] - INFO: epoch 030:    809 / 2004 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=347.7, nsentences=8, sample_size=347.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1021.1, ups=2.94, wpb=347.7, bsz=8, num_updates=58550, lr=4.19867e-05, gnorm=2.294, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=20185
2023-03-15 19:36:10 - progress_bar.py[line:272] - INFO: epoch 030:    819 / 2004 loss=0.127, loss_v1=0, loss_v2=0, nll_loss=0.127, ntokens=323.4, nsentences=8, sample_size=323.4, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=945, ups=2.92, wpb=323.4, bsz=8, num_updates=58560, lr=4.19767e-05, gnorm=1.722, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=20188
2023-03-15 19:36:14 - progress_bar.py[line:272] - INFO: epoch 030:    829 / 2004 loss=0.127, loss_v1=0, loss_v2=0, nll_loss=0.127, ntokens=368.8, nsentences=8, sample_size=368.8, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1055.7, ups=2.86, wpb=368.8, bsz=8, num_updates=58570, lr=4.19666e-05, gnorm=1.806, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=20192
2023-03-15 19:36:17 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 19:36:18 - progress_bar.py[line:272] - INFO: epoch 030:    840 / 2004 loss=0.131, loss_v1=0, loss_v2=0, nll_loss=0.131, ntokens=328.8, nsentences=8, sample_size=328.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=867.7, ups=2.64, wpb=328.8, bsz=8, num_updates=58580, lr=4.19565e-05, gnorm=1.984, clip=0, loss_scale=2048, train_wall=4, gb_free=14.3, wall=20195
2023-03-15 19:36:21 - progress_bar.py[line:272] - INFO: epoch 030:    850 / 2004 loss=0.13, loss_v1=0, loss_v2=0, nll_loss=0.13, ntokens=356.2, nsentences=8, sample_size=356.2, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1035.7, ups=2.91, wpb=356.2, bsz=8, num_updates=58590, lr=4.19464e-05, gnorm=1.858, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=20199
2023-03-15 19:36:25 - progress_bar.py[line:272] - INFO: epoch 030:    860 / 2004 loss=0.13, loss_v1=0, loss_v2=0, nll_loss=0.13, ntokens=351.3, nsentences=8, sample_size=351.3, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1012, ups=2.88, wpb=351.3, bsz=8, num_updates=58600, lr=4.19363e-05, gnorm=1.865, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=20202
2023-03-15 19:36:28 - progress_bar.py[line:272] - INFO: epoch 030:    870 / 2004 loss=0.131, loss_v1=0, loss_v2=0, nll_loss=0.131, ntokens=365.8, nsentences=8, sample_size=365.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1060.5, ups=2.9, wpb=365.8, bsz=8, num_updates=58610, lr=4.19262e-05, gnorm=1.849, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=20206
2023-03-15 19:36:32 - progress_bar.py[line:272] - INFO: epoch 030:    880 / 2004 loss=0.126, loss_v1=0, loss_v2=0, nll_loss=0.126, ntokens=327.9, nsentences=8, sample_size=327.9, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=962.1, ups=2.93, wpb=327.9, bsz=8, num_updates=58620, lr=4.19162e-05, gnorm=1.755, clip=0, loss_scale=2048, train_wall=3, gb_free=13.8, wall=20209
2023-03-15 19:36:35 - progress_bar.py[line:272] - INFO: epoch 030:    890 / 2004 loss=0.134, loss_v1=0, loss_v2=0, nll_loss=0.134, ntokens=307.5, nsentences=8, sample_size=307.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=883.3, ups=2.87, wpb=307.5, bsz=8, num_updates=58630, lr=4.19061e-05, gnorm=1.857, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=20213
2023-03-15 19:36:38 - progress_bar.py[line:272] - INFO: epoch 030:    900 / 2004 loss=0.129, loss_v1=0, loss_v2=0, nll_loss=0.129, ntokens=365.1, nsentences=8, sample_size=365.1, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1084.6, ups=2.97, wpb=365.1, bsz=8, num_updates=58640, lr=4.1896e-05, gnorm=1.844, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=20216
2023-03-15 19:36:42 - progress_bar.py[line:272] - INFO: epoch 030:    910 / 2004 loss=0.135, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=366.2, nsentences=8, sample_size=366.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1147.8, ups=3.13, wpb=366.2, bsz=8, num_updates=58650, lr=4.18859e-05, gnorm=1.916, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=20219
2023-03-15 19:36:45 - progress_bar.py[line:272] - INFO: epoch 030:    920 / 2004 loss=0.137, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=343.9, nsentences=8, sample_size=343.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1100.6, ups=3.2, wpb=343.9, bsz=8, num_updates=58660, lr=4.18758e-05, gnorm=1.881, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=20222
2023-03-15 19:36:48 - progress_bar.py[line:272] - INFO: epoch 030:    930 / 2004 loss=0.133, loss_v1=0, loss_v2=0, nll_loss=0.133, ntokens=331.7, nsentences=8, sample_size=331.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1051.1, ups=3.17, wpb=331.7, bsz=8, num_updates=58670, lr=4.18658e-05, gnorm=2.095, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=20225
2023-03-15 19:36:51 - progress_bar.py[line:272] - INFO: epoch 030:    940 / 2004 loss=0.134, loss_v1=0, loss_v2=0, nll_loss=0.134, ntokens=359, nsentences=8, sample_size=359, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1086.4, ups=3.03, wpb=359, bsz=8, num_updates=58680, lr=4.18557e-05, gnorm=2.059, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=20229
2023-03-15 19:36:55 - progress_bar.py[line:272] - INFO: epoch 030:    950 / 2004 loss=0.137, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=361.5, nsentences=8, sample_size=361.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1054.1, ups=2.92, wpb=361.5, bsz=8, num_updates=58690, lr=4.18456e-05, gnorm=2.099, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=20232
2023-03-15 19:36:58 - progress_bar.py[line:272] - INFO: epoch 030:    960 / 2004 loss=0.137, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=355.6, nsentences=8, sample_size=355.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1026.2, ups=2.89, wpb=355.6, bsz=8, num_updates=58700, lr=4.18355e-05, gnorm=1.914, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=20236
2023-03-15 19:37:01 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 19:37:02 - progress_bar.py[line:272] - INFO: epoch 030:    971 / 2004 loss=0.126, loss_v1=0, loss_v2=0, nll_loss=0.126, ntokens=343.6, nsentences=8, sample_size=343.6, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=927.4, ups=2.7, wpb=343.6, bsz=8, num_updates=58710, lr=4.18254e-05, gnorm=1.83, clip=0, loss_scale=2048, train_wall=4, gb_free=14.5, wall=20239
2023-03-15 19:37:05 - progress_bar.py[line:272] - INFO: epoch 030:    981 / 2004 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=320.9, nsentences=8, sample_size=320.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=930.6, ups=2.9, wpb=320.9, bsz=8, num_updates=58720, lr=4.18154e-05, gnorm=2.191, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=20243
2023-03-15 19:37:09 - progress_bar.py[line:272] - INFO: epoch 030:    991 / 2004 loss=0.127, loss_v1=0, loss_v2=0, nll_loss=0.127, ntokens=388.1, nsentences=8, sample_size=388.1, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1085.6, ups=2.8, wpb=388.1, bsz=8, num_updates=58730, lr=4.18053e-05, gnorm=1.969, clip=0, loss_scale=2048, train_wall=4, gb_free=15, wall=20246
2023-03-15 19:37:12 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 19:37:13 - progress_bar.py[line:272] - INFO: epoch 030:   1002 / 2004 loss=0.126, loss_v1=0, loss_v2=0, nll_loss=0.126, ntokens=345.1, nsentences=8, sample_size=345.1, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=907.1, ups=2.63, wpb=345.1, bsz=8, num_updates=58740, lr=4.17952e-05, gnorm=1.859, clip=0, loss_scale=1024, train_wall=4, gb_free=14.7, wall=20250
2023-03-15 19:37:16 - progress_bar.py[line:272] - INFO: epoch 030:   1012 / 2004 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=334.7, nsentences=8, sample_size=334.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=985.1, ups=2.94, wpb=334.7, bsz=8, num_updates=58750, lr=4.17851e-05, gnorm=1.982, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=20254
2023-03-15 19:37:19 - progress_bar.py[line:272] - INFO: epoch 030:   1022 / 2004 loss=0.137, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=325.3, nsentences=8, sample_size=325.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=950.7, ups=2.92, wpb=325.3, bsz=8, num_updates=58760, lr=4.1775e-05, gnorm=1.996, clip=0, loss_scale=1024, train_wall=3, gb_free=15.8, wall=20257
2023-03-15 19:37:23 - progress_bar.py[line:272] - INFO: epoch 030:   1032 / 2004 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=324.1, nsentences=8, sample_size=324.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=926.3, ups=2.86, wpb=324.1, bsz=8, num_updates=58770, lr=4.1765e-05, gnorm=2.024, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=20261
2023-03-15 19:37:26 - progress_bar.py[line:272] - INFO: epoch 030:   1042 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=342, nsentences=8, sample_size=342, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=979.9, ups=2.87, wpb=342, bsz=8, num_updates=58780, lr=4.17549e-05, gnorm=2.107, clip=0, loss_scale=1024, train_wall=3, gb_free=14.1, wall=20264
2023-03-15 19:37:30 - progress_bar.py[line:272] - INFO: epoch 030:   1052 / 2004 loss=0.13, loss_v1=0, loss_v2=0, nll_loss=0.13, ntokens=368.4, nsentences=8, sample_size=368.4, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1020.3, ups=2.77, wpb=368.4, bsz=8, num_updates=58790, lr=4.17448e-05, gnorm=1.916, clip=0, loss_scale=1024, train_wall=4, gb_free=15, wall=20268
2023-03-15 19:37:33 - progress_bar.py[line:272] - INFO: epoch 030:   1062 / 2004 loss=0.127, loss_v1=0, loss_v2=0, nll_loss=0.127, ntokens=339.1, nsentences=8, sample_size=339.1, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=981.4, ups=2.89, wpb=339.1, bsz=8, num_updates=58800, lr=4.17347e-05, gnorm=1.926, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=20271
2023-03-15 19:37:37 - progress_bar.py[line:272] - INFO: epoch 030:   1072 / 2004 loss=0.13, loss_v1=0, loss_v2=0, nll_loss=0.13, ntokens=355.3, nsentences=8, sample_size=355.3, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1019.6, ups=2.87, wpb=355.3, bsz=8, num_updates=58810, lr=4.17246e-05, gnorm=1.854, clip=0, loss_scale=1024, train_wall=3, gb_free=14.8, wall=20275
2023-03-15 19:37:40 - progress_bar.py[line:272] - INFO: epoch 030:   1082 / 2004 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=365.5, nsentences=8, sample_size=365.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1040.3, ups=2.85, wpb=365.5, bsz=8, num_updates=58820, lr=4.17146e-05, gnorm=2.237, clip=0, loss_scale=1024, train_wall=3, gb_free=14.4, wall=20278
2023-03-15 19:37:44 - progress_bar.py[line:272] - INFO: epoch 030:   1092 / 2004 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=332.2, nsentences=8, sample_size=332.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=938.7, ups=2.83, wpb=332.2, bsz=8, num_updates=58830, lr=4.17045e-05, gnorm=2.208, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=20282
2023-03-15 19:37:47 - progress_bar.py[line:272] - INFO: epoch 030:   1102 / 2004 loss=0.134, loss_v1=0, loss_v2=0, nll_loss=0.134, ntokens=364.8, nsentences=8, sample_size=364.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1085.5, ups=2.98, wpb=364.8, bsz=8, num_updates=58840, lr=4.16944e-05, gnorm=1.795, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=20285
2023-03-15 19:37:51 - progress_bar.py[line:272] - INFO: epoch 030:   1112 / 2004 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=351.9, nsentences=8, sample_size=351.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1111.5, ups=3.16, wpb=351.9, bsz=8, num_updates=58850, lr=4.16843e-05, gnorm=2.048, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=20288
2023-03-15 19:37:54 - progress_bar.py[line:272] - INFO: epoch 030:   1122 / 2004 loss=0.127, loss_v1=0, loss_v2=0, nll_loss=0.127, ntokens=315.6, nsentences=8, sample_size=315.6, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=962.7, ups=3.05, wpb=315.6, bsz=8, num_updates=58860, lr=4.16742e-05, gnorm=1.85, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=20291
2023-03-15 19:37:57 - progress_bar.py[line:272] - INFO: epoch 030:   1132 / 2004 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=376.8, nsentences=8, sample_size=376.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1098.8, ups=2.92, wpb=376.8, bsz=8, num_updates=58870, lr=4.16641e-05, gnorm=2.051, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=20295
2023-03-15 19:38:01 - progress_bar.py[line:272] - INFO: epoch 030:   1142 / 2004 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=360.1, nsentences=8, sample_size=360.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1046, ups=2.9, wpb=360.1, bsz=8, num_updates=58880, lr=4.16541e-05, gnorm=1.992, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=20298
2023-03-15 19:38:04 - progress_bar.py[line:272] - INFO: epoch 030:   1152 / 2004 loss=0.128, loss_v1=0, loss_v2=0, nll_loss=0.128, ntokens=375.7, nsentences=8, sample_size=375.7, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1050.5, ups=2.8, wpb=375.7, bsz=8, num_updates=58890, lr=4.1644e-05, gnorm=1.834, clip=0, loss_scale=2048, train_wall=4, gb_free=14.3, wall=20302
2023-03-15 19:38:08 - progress_bar.py[line:272] - INFO: epoch 030:   1162 / 2004 loss=0.133, loss_v1=0, loss_v2=0, nll_loss=0.133, ntokens=376.9, nsentences=8, sample_size=376.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1080, ups=2.87, wpb=376.9, bsz=8, num_updates=58900, lr=4.16339e-05, gnorm=2.008, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=20305
2023-03-15 19:38:11 - progress_bar.py[line:272] - INFO: epoch 030:   1172 / 2004 loss=0.137, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=343.5, nsentences=8, sample_size=343.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=982.7, ups=2.86, wpb=343.5, bsz=8, num_updates=58910, lr=4.16238e-05, gnorm=1.922, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=20309
2023-03-15 19:38:15 - progress_bar.py[line:272] - INFO: epoch 030:   1182 / 2004 loss=0.133, loss_v1=0, loss_v2=0, nll_loss=0.133, ntokens=352.3, nsentences=8, sample_size=352.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1022.9, ups=2.9, wpb=352.3, bsz=8, num_updates=58920, lr=4.16137e-05, gnorm=2.149, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=20312
2023-03-15 19:38:18 - progress_bar.py[line:272] - INFO: epoch 030:   1192 / 2004 loss=0.136, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=345.2, nsentences=8, sample_size=345.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=992.2, ups=2.87, wpb=345.2, bsz=8, num_updates=58930, lr=4.16037e-05, gnorm=2.003, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=20316
2023-03-15 19:38:22 - progress_bar.py[line:272] - INFO: epoch 030:   1202 / 2004 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=340.8, nsentences=8, sample_size=340.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=967.9, ups=2.84, wpb=340.8, bsz=8, num_updates=58940, lr=4.15936e-05, gnorm=1.863, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=20319
2023-03-15 19:38:25 - progress_bar.py[line:272] - INFO: epoch 030:   1212 / 2004 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=288.3, nsentences=8, sample_size=288.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=851.9, ups=2.95, wpb=288.3, bsz=8, num_updates=58950, lr=4.15835e-05, gnorm=1.902, clip=0, loss_scale=2048, train_wall=3, gb_free=14, wall=20323
2023-03-15 19:38:29 - progress_bar.py[line:272] - INFO: epoch 030:   1222 / 2004 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=325.6, nsentences=8, sample_size=325.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=928.6, ups=2.85, wpb=325.6, bsz=8, num_updates=58960, lr=4.15734e-05, gnorm=2.062, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=20326
2023-03-15 19:38:32 - progress_bar.py[line:272] - INFO: epoch 030:   1232 / 2004 loss=0.136, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=308.4, nsentences=8, sample_size=308.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=876.2, ups=2.84, wpb=308.4, bsz=8, num_updates=58970, lr=4.15633e-05, gnorm=2.047, clip=0, loss_scale=2048, train_wall=3, gb_free=13.6, wall=20330
2023-03-15 19:38:36 - progress_bar.py[line:272] - INFO: epoch 030:   1242 / 2004 loss=0.115, loss_v1=0, loss_v2=0, nll_loss=0.115, ntokens=390.3, nsentences=8, sample_size=390.3, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=1105.6, ups=2.83, wpb=390.3, bsz=8, num_updates=58980, lr=4.15533e-05, gnorm=1.611, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=20333
2023-03-15 19:38:39 - progress_bar.py[line:272] - INFO: epoch 030:   1252 / 2004 loss=0.13, loss_v1=0, loss_v2=0, nll_loss=0.13, ntokens=345, nsentences=8, sample_size=345, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=996.3, ups=2.89, wpb=345, bsz=8, num_updates=58990, lr=4.15432e-05, gnorm=1.908, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=20337
2023-03-15 19:38:41 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 19:38:43 - progress_bar.py[line:272] - INFO: epoch 030:   1263 / 2004 loss=0.12, loss_v1=0, loss_v2=0, nll_loss=0.12, ntokens=332.8, nsentences=8, sample_size=332.8, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=865.9, ups=2.6, wpb=332.8, bsz=8, num_updates=59000, lr=4.15331e-05, gnorm=1.686, clip=0, loss_scale=2048, train_wall=4, gb_free=15.2, wall=20341
2023-03-15 19:38:46 - progress_bar.py[line:272] - INFO: epoch 030:   1273 / 2004 loss=0.127, loss_v1=0, loss_v2=0, nll_loss=0.127, ntokens=346.4, nsentences=8, sample_size=346.4, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1014.3, ups=2.93, wpb=346.4, bsz=8, num_updates=59010, lr=4.1523e-05, gnorm=1.719, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=20344
2023-03-15 19:38:50 - progress_bar.py[line:272] - INFO: epoch 030:   1283 / 2004 loss=0.129, loss_v1=0, loss_v2=0, nll_loss=0.129, ntokens=343.9, nsentences=8, sample_size=343.9, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=992.4, ups=2.89, wpb=343.9, bsz=8, num_updates=59020, lr=4.15129e-05, gnorm=1.975, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=20347
2023-03-15 19:38:53 - progress_bar.py[line:272] - INFO: epoch 030:   1293 / 2004 loss=0.135, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=300.6, nsentences=8, sample_size=300.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=881.6, ups=2.93, wpb=300.6, bsz=8, num_updates=59030, lr=4.15029e-05, gnorm=2.124, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=20351
2023-03-15 19:38:57 - progress_bar.py[line:272] - INFO: epoch 030:   1303 / 2004 loss=0.127, loss_v1=0, loss_v2=0, nll_loss=0.127, ntokens=333.3, nsentences=8, sample_size=333.3, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=953.5, ups=2.86, wpb=333.3, bsz=8, num_updates=59040, lr=4.14928e-05, gnorm=1.7, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=20354
2023-03-15 19:39:00 - progress_bar.py[line:272] - INFO: epoch 030:   1313 / 2004 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=323.2, nsentences=8, sample_size=323.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=945.9, ups=2.93, wpb=323.2, bsz=8, num_updates=59050, lr=4.14827e-05, gnorm=1.757, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=20358
2023-03-15 19:39:04 - progress_bar.py[line:272] - INFO: epoch 030:   1323 / 2004 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=318.3, nsentences=8, sample_size=318.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=922.6, ups=2.9, wpb=318.3, bsz=8, num_updates=59060, lr=4.14726e-05, gnorm=2.078, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=20361
2023-03-15 19:39:07 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 19:39:07 - progress_bar.py[line:272] - INFO: epoch 030:   1334 / 2004 loss=0.127, loss_v1=0, loss_v2=0, nll_loss=0.127, ntokens=339.9, nsentences=8, sample_size=339.9, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=906.3, ups=2.67, wpb=339.9, bsz=8, num_updates=59070, lr=4.14625e-05, gnorm=1.849, clip=0, loss_scale=1024, train_wall=4, gb_free=14.5, wall=20365
2023-03-15 19:39:11 - progress_bar.py[line:272] - INFO: epoch 030:   1344 / 2004 loss=0.135, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=302.8, nsentences=8, sample_size=302.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=904.9, ups=2.99, wpb=302.8, bsz=8, num_updates=59080, lr=4.14524e-05, gnorm=1.984, clip=0, loss_scale=1024, train_wall=3, gb_free=15.7, wall=20368
2023-03-15 19:39:14 - progress_bar.py[line:272] - INFO: epoch 030:   1354 / 2004 loss=0.126, loss_v1=0, loss_v2=0, nll_loss=0.126, ntokens=324.6, nsentences=8, sample_size=324.6, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=962.3, ups=2.96, wpb=324.6, bsz=8, num_updates=59090, lr=4.14424e-05, gnorm=1.812, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=20372
2023-03-15 19:39:17 - progress_bar.py[line:272] - INFO: epoch 030:   1364 / 2004 loss=0.137, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=315.6, nsentences=8, sample_size=315.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=933.3, ups=2.96, wpb=315.6, bsz=8, num_updates=59100, lr=4.14323e-05, gnorm=1.955, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=20375
2023-03-15 19:39:21 - progress_bar.py[line:272] - INFO: epoch 030:   1374 / 2004 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=314.7, nsentences=8, sample_size=314.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=933.5, ups=2.97, wpb=314.7, bsz=8, num_updates=59110, lr=4.14222e-05, gnorm=2.14, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=20378
2023-03-15 19:39:24 - progress_bar.py[line:272] - INFO: epoch 030:   1384 / 2004 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=389.5, nsentences=8, sample_size=389.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1090.8, ups=2.8, wpb=389.5, bsz=8, num_updates=59120, lr=4.14121e-05, gnorm=2.18, clip=0, loss_scale=1024, train_wall=4, gb_free=14.4, wall=20382
2023-03-15 19:39:28 - progress_bar.py[line:272] - INFO: epoch 030:   1394 / 2004 loss=0.13, loss_v1=0, loss_v2=0, nll_loss=0.13, ntokens=345.8, nsentences=8, sample_size=345.8, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1011.7, ups=2.93, wpb=345.8, bsz=8, num_updates=59130, lr=4.1402e-05, gnorm=1.755, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=20385
2023-03-15 19:39:31 - progress_bar.py[line:272] - INFO: epoch 030:   1404 / 2004 loss=0.129, loss_v1=0, loss_v2=0, nll_loss=0.129, ntokens=343.2, nsentences=8, sample_size=343.2, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=988.4, ups=2.88, wpb=343.2, bsz=8, num_updates=59140, lr=4.1392e-05, gnorm=1.921, clip=0, loss_scale=1024, train_wall=3, gb_free=15, wall=20389
2023-03-15 19:39:35 - progress_bar.py[line:272] - INFO: epoch 030:   1414 / 2004 loss=0.124, loss_v1=0, loss_v2=0, nll_loss=0.124, ntokens=384.8, nsentences=8, sample_size=384.8, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1107.7, ups=2.88, wpb=384.8, bsz=8, num_updates=59150, lr=4.13819e-05, gnorm=1.848, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=20392
2023-03-15 19:39:38 - progress_bar.py[line:272] - INFO: epoch 030:   1424 / 2004 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=297.9, nsentences=8, sample_size=297.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=857.3, ups=2.88, wpb=297.9, bsz=8, num_updates=59160, lr=4.13718e-05, gnorm=1.968, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=20396
2023-03-15 19:39:42 - progress_bar.py[line:272] - INFO: epoch 030:   1434 / 2004 loss=0.132, loss_v1=0, loss_v2=0, nll_loss=0.132, ntokens=368.1, nsentences=8, sample_size=368.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1042.8, ups=2.83, wpb=368.1, bsz=8, num_updates=59170, lr=4.13617e-05, gnorm=1.967, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=20399
2023-03-15 19:39:45 - progress_bar.py[line:272] - INFO: epoch 030:   1444 / 2004 loss=0.136, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=326.6, nsentences=8, sample_size=326.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=954.2, ups=2.92, wpb=326.6, bsz=8, num_updates=59180, lr=4.13516e-05, gnorm=1.83, clip=0, loss_scale=1024, train_wall=3, gb_free=15.6, wall=20403
2023-03-15 19:39:49 - progress_bar.py[line:272] - INFO: epoch 030:   1454 / 2004 loss=0.128, loss_v1=0, loss_v2=0, nll_loss=0.128, ntokens=366.4, nsentences=8, sample_size=366.4, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1063.4, ups=2.9, wpb=366.4, bsz=8, num_updates=59190, lr=4.13416e-05, gnorm=1.839, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=20406
2023-03-15 19:39:52 - progress_bar.py[line:272] - INFO: epoch 030:   1464 / 2004 loss=0.126, loss_v1=0, loss_v2=0, nll_loss=0.126, ntokens=386, nsentences=8, sample_size=386, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1117.8, ups=2.9, wpb=386, bsz=8, num_updates=59200, lr=4.13315e-05, gnorm=1.971, clip=0, loss_scale=2048, train_wall=3, gb_free=14, wall=20410
2023-03-15 19:39:56 - progress_bar.py[line:272] - INFO: epoch 030:   1474 / 2004 loss=0.137, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=398.2, nsentences=8, sample_size=398.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1147.9, ups=2.88, wpb=398.2, bsz=8, num_updates=59210, lr=4.13214e-05, gnorm=2.388, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=20413
2023-03-15 19:39:59 - progress_bar.py[line:272] - INFO: epoch 030:   1484 / 2004 loss=0.136, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=372.5, nsentences=8, sample_size=372.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1044.7, ups=2.8, wpb=372.5, bsz=8, num_updates=59220, lr=4.13113e-05, gnorm=1.997, clip=0, loss_scale=2048, train_wall=4, gb_free=14.7, wall=20417
2023-03-15 19:40:03 - progress_bar.py[line:272] - INFO: epoch 030:   1494 / 2004 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=317.1, nsentences=8, sample_size=317.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=928.2, ups=2.93, wpb=317.1, bsz=8, num_updates=59230, lr=4.13012e-05, gnorm=1.92, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=20420
2023-03-15 19:40:06 - progress_bar.py[line:272] - INFO: epoch 030:   1504 / 2004 loss=0.126, loss_v1=0, loss_v2=0, nll_loss=0.126, ntokens=336.8, nsentences=8, sample_size=336.8, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=999.8, ups=2.97, wpb=336.8, bsz=8, num_updates=59240, lr=4.12912e-05, gnorm=1.779, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=20424
2023-03-15 19:40:09 - progress_bar.py[line:272] - INFO: epoch 030:   1514 / 2004 loss=0.126, loss_v1=0, loss_v2=0, nll_loss=0.126, ntokens=323.5, nsentences=8, sample_size=323.5, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=951.3, ups=2.94, wpb=323.5, bsz=8, num_updates=59250, lr=4.12811e-05, gnorm=1.631, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=20427
2023-03-15 19:40:13 - progress_bar.py[line:272] - INFO: epoch 030:   1524 / 2004 loss=0.127, loss_v1=0, loss_v2=0, nll_loss=0.127, ntokens=321.5, nsentences=8, sample_size=321.5, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=941.4, ups=2.93, wpb=321.5, bsz=8, num_updates=59260, lr=4.1271e-05, gnorm=1.768, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=20430
2023-03-15 19:40:16 - progress_bar.py[line:272] - INFO: epoch 030:   1534 / 2004 loss=0.134, loss_v1=0, loss_v2=0, nll_loss=0.134, ntokens=354.4, nsentences=8, sample_size=354.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1011.6, ups=2.85, wpb=354.4, bsz=8, num_updates=59270, lr=4.12609e-05, gnorm=1.87, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=20434
2023-03-15 19:40:20 - progress_bar.py[line:272] - INFO: epoch 030:   1544 / 2004 loss=0.135, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=325.5, nsentences=8, sample_size=325.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=950.3, ups=2.92, wpb=325.5, bsz=8, num_updates=59280, lr=4.12508e-05, gnorm=1.915, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=20437
2023-03-15 19:40:23 - progress_bar.py[line:272] - INFO: epoch 030:   1554 / 2004 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=330.8, nsentences=8, sample_size=330.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=951.6, ups=2.88, wpb=330.8, bsz=8, num_updates=59290, lr=4.12408e-05, gnorm=2.027, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=20441
2023-03-15 19:40:27 - progress_bar.py[line:272] - INFO: epoch 030:   1564 / 2004 loss=0.131, loss_v1=0, loss_v2=0, nll_loss=0.131, ntokens=361.7, nsentences=8, sample_size=361.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1036.3, ups=2.87, wpb=361.7, bsz=8, num_updates=59300, lr=4.12307e-05, gnorm=2.093, clip=0, loss_scale=2048, train_wall=3, gb_free=13.9, wall=20444
2023-03-15 19:40:30 - progress_bar.py[line:272] - INFO: epoch 030:   1574 / 2004 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=332.8, nsentences=8, sample_size=332.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=954.9, ups=2.87, wpb=332.8, bsz=8, num_updates=59310, lr=4.12206e-05, gnorm=1.922, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=20448
2023-03-15 19:40:34 - progress_bar.py[line:272] - INFO: epoch 030:   1584 / 2004 loss=0.135, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=324.1, nsentences=8, sample_size=324.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=941.4, ups=2.9, wpb=324.1, bsz=8, num_updates=59320, lr=4.12105e-05, gnorm=2.013, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=20451
2023-03-15 19:40:36 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 19:40:37 - progress_bar.py[line:272] - INFO: epoch 030:   1595 / 2004 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=357.9, nsentences=8, sample_size=357.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=939.6, ups=2.63, wpb=357.9, bsz=8, num_updates=59330, lr=4.12004e-05, gnorm=2.417, clip=0, loss_scale=2048, train_wall=4, gb_free=14.8, wall=20455
2023-03-15 19:40:41 - progress_bar.py[line:272] - INFO: epoch 030:   1605 / 2004 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=337.9, nsentences=8, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=975.6, ups=2.89, wpb=337.9, bsz=8, num_updates=59340, lr=4.11903e-05, gnorm=2.025, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=20458
2023-03-15 19:40:43 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 19:40:45 - progress_bar.py[line:272] - INFO: epoch 030:   1616 / 2004 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=331.6, nsentences=8, sample_size=331.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=896.8, ups=2.7, wpb=331.6, bsz=8, num_updates=59350, lr=4.11803e-05, gnorm=1.805, clip=0, loss_scale=1024, train_wall=4, gb_free=15.7, wall=20462
2023-03-15 19:40:48 - progress_bar.py[line:272] - INFO: epoch 030:   1626 / 2004 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=364.7, nsentences=8, sample_size=364.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1052.8, ups=2.89, wpb=364.7, bsz=8, num_updates=59360, lr=4.11702e-05, gnorm=2.016, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=20466
2023-03-15 19:40:51 - progress_bar.py[line:272] - INFO: epoch 030:   1636 / 2004 loss=0.129, loss_v1=0, loss_v2=0, nll_loss=0.129, ntokens=324, nsentences=8, sample_size=324, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=953.7, ups=2.94, wpb=324, bsz=8, num_updates=59370, lr=4.11601e-05, gnorm=1.687, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=20469
2023-03-15 19:40:55 - progress_bar.py[line:272] - INFO: epoch 030:   1646 / 2004 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=318.5, nsentences=8, sample_size=318.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=914.4, ups=2.87, wpb=318.5, bsz=8, num_updates=59380, lr=4.115e-05, gnorm=2.121, clip=0, loss_scale=1024, train_wall=3, gb_free=14.5, wall=20472
2023-03-15 19:40:58 - progress_bar.py[line:272] - INFO: epoch 030:   1656 / 2004 loss=0.125, loss_v1=0, loss_v2=0, nll_loss=0.125, ntokens=358.1, nsentences=8, sample_size=358.1, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1082.3, ups=3.02, wpb=358.1, bsz=8, num_updates=59390, lr=4.11399e-05, gnorm=1.781, clip=0, loss_scale=1024, train_wall=3, gb_free=14.3, wall=20476
2023-03-15 19:41:01 - progress_bar.py[line:272] - INFO: epoch 030:   1666 / 2004 loss=0.125, loss_v1=0, loss_v2=0, nll_loss=0.125, ntokens=345.7, nsentences=8, sample_size=345.7, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1093.8, ups=3.16, wpb=345.7, bsz=8, num_updates=59400, lr=4.11299e-05, gnorm=1.769, clip=0, loss_scale=1024, train_wall=3, gb_free=14.1, wall=20479
2023-03-15 19:41:04 - progress_bar.py[line:272] - INFO: epoch 030:   1676 / 2004 loss=0.13, loss_v1=0, loss_v2=0, nll_loss=0.13, ntokens=320.2, nsentences=8, sample_size=320.2, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1020, ups=3.19, wpb=320.2, bsz=8, num_updates=59410, lr=4.11198e-05, gnorm=1.857, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=20482
2023-03-15 19:41:08 - progress_bar.py[line:272] - INFO: epoch 030:   1686 / 2004 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=334, nsentences=8, sample_size=334, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1057.4, ups=3.17, wpb=334, bsz=8, num_updates=59420, lr=4.11097e-05, gnorm=1.942, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=20485
2023-03-15 19:41:11 - progress_bar.py[line:272] - INFO: epoch 030:   1696 / 2004 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=337.7, nsentences=8, sample_size=337.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1048.1, ups=3.1, wpb=337.7, bsz=8, num_updates=59430, lr=4.10996e-05, gnorm=1.925, clip=0, loss_scale=1024, train_wall=3, gb_free=15.5, wall=20488
2023-03-15 19:41:14 - progress_bar.py[line:272] - INFO: epoch 030:   1706 / 2004 loss=0.127, loss_v1=0, loss_v2=0, nll_loss=0.127, ntokens=348.9, nsentences=8, sample_size=348.9, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1004.4, ups=2.88, wpb=348.9, bsz=8, num_updates=59440, lr=4.10895e-05, gnorm=1.807, clip=0, loss_scale=1024, train_wall=3, gb_free=13.9, wall=20492
2023-03-15 19:41:18 - progress_bar.py[line:272] - INFO: epoch 030:   1716 / 2004 loss=0.124, loss_v1=0, loss_v2=0, nll_loss=0.124, ntokens=356.2, nsentences=8, sample_size=356.2, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1042.8, ups=2.93, wpb=356.2, bsz=8, num_updates=59450, lr=4.10795e-05, gnorm=1.715, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=20495
2023-03-15 19:41:21 - progress_bar.py[line:272] - INFO: epoch 030:   1726 / 2004 loss=0.136, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=396.6, nsentences=8, sample_size=396.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1133.7, ups=2.86, wpb=396.6, bsz=8, num_updates=59460, lr=4.10694e-05, gnorm=1.935, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=20499
2023-03-15 19:41:25 - progress_bar.py[line:272] - INFO: epoch 030:   1736 / 2004 loss=0.124, loss_v1=0, loss_v2=0, nll_loss=0.124, ntokens=347.5, nsentences=8, sample_size=347.5, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=983.1, ups=2.83, wpb=347.5, bsz=8, num_updates=59470, lr=4.10593e-05, gnorm=1.84, clip=0, loss_scale=1024, train_wall=3, gb_free=15.1, wall=20502
2023-03-15 19:41:28 - progress_bar.py[line:272] - INFO: epoch 030:   1746 / 2004 loss=0.133, loss_v1=0, loss_v2=0, nll_loss=0.133, ntokens=341.3, nsentences=8, sample_size=341.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=967.1, ups=2.83, wpb=341.3, bsz=8, num_updates=59480, lr=4.10492e-05, gnorm=1.809, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=20506
2023-03-15 19:41:32 - progress_bar.py[line:272] - INFO: epoch 030:   1756 / 2004 loss=0.124, loss_v1=0, loss_v2=0, nll_loss=0.124, ntokens=328.1, nsentences=8, sample_size=328.1, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=944.9, ups=2.88, wpb=328.1, bsz=8, num_updates=59490, lr=4.10391e-05, gnorm=1.761, clip=0, loss_scale=2048, train_wall=3, gb_free=15.9, wall=20509
2023-03-15 19:41:35 - progress_bar.py[line:272] - INFO: epoch 030:   1766 / 2004 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=318.3, nsentences=8, sample_size=318.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=911.7, ups=2.86, wpb=318.3, bsz=8, num_updates=59500, lr=4.10291e-05, gnorm=2.085, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=20513
2023-03-15 19:41:39 - progress_bar.py[line:272] - INFO: epoch 030:   1776 / 2004 loss=0.136, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=347.4, nsentences=8, sample_size=347.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1010.5, ups=2.91, wpb=347.4, bsz=8, num_updates=59510, lr=4.1019e-05, gnorm=1.961, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=20516
2023-03-15 19:41:42 - progress_bar.py[line:272] - INFO: epoch 030:   1786 / 2004 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=317, nsentences=8, sample_size=317, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=901.1, ups=2.84, wpb=317, bsz=8, num_updates=59520, lr=4.10089e-05, gnorm=1.951, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=20520
2023-03-15 19:41:46 - progress_bar.py[line:272] - INFO: epoch 030:   1796 / 2004 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=337.2, nsentences=8, sample_size=337.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=980.6, ups=2.91, wpb=337.2, bsz=8, num_updates=59530, lr=4.09988e-05, gnorm=2.081, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=20523
2023-03-15 19:41:49 - progress_bar.py[line:272] - INFO: epoch 030:   1806 / 2004 loss=0.122, loss_v1=0, loss_v2=0, nll_loss=0.122, ntokens=345.6, nsentences=8, sample_size=345.6, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=993.8, ups=2.88, wpb=345.6, bsz=8, num_updates=59540, lr=4.09887e-05, gnorm=1.672, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=20527
2023-03-15 19:41:53 - progress_bar.py[line:272] - INFO: epoch 030:   1816 / 2004 loss=0.123, loss_v1=0, loss_v2=0, nll_loss=0.123, ntokens=347.7, nsentences=8, sample_size=347.7, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=983.4, ups=2.83, wpb=347.7, bsz=8, num_updates=59550, lr=4.09786e-05, gnorm=1.744, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=20530
2023-03-15 19:41:56 - progress_bar.py[line:272] - INFO: epoch 030:   1826 / 2004 loss=0.125, loss_v1=0, loss_v2=0, nll_loss=0.125, ntokens=365.7, nsentences=8, sample_size=365.7, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1051.4, ups=2.87, wpb=365.7, bsz=8, num_updates=59560, lr=4.09686e-05, gnorm=1.987, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=20534
2023-03-15 19:42:00 - progress_bar.py[line:272] - INFO: epoch 030:   1836 / 2004 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=327.2, nsentences=8, sample_size=327.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=925.1, ups=2.83, wpb=327.2, bsz=8, num_updates=59570, lr=4.09585e-05, gnorm=2.303, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=20537
2023-03-15 19:42:03 - progress_bar.py[line:272] - INFO: epoch 030:   1846 / 2004 loss=0.136, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=360.5, nsentences=8, sample_size=360.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1028.2, ups=2.85, wpb=360.5, bsz=8, num_updates=59580, lr=4.09484e-05, gnorm=2.242, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=20541
2023-03-15 19:42:07 - progress_bar.py[line:272] - INFO: epoch 030:   1856 / 2004 loss=0.128, loss_v1=0, loss_v2=0, nll_loss=0.128, ntokens=312.9, nsentences=8, sample_size=312.9, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=914.9, ups=2.92, wpb=312.9, bsz=8, num_updates=59590, lr=4.09383e-05, gnorm=1.876, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=20544
2023-03-15 19:42:10 - progress_bar.py[line:272] - INFO: epoch 030:   1866 / 2004 loss=0.127, loss_v1=0, loss_v2=0, nll_loss=0.127, ntokens=343.7, nsentences=8, sample_size=343.7, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1009.9, ups=2.94, wpb=343.7, bsz=8, num_updates=59600, lr=4.09282e-05, gnorm=1.906, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=20548
2023-03-15 19:42:11 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 19:42:14 - progress_bar.py[line:272] - INFO: epoch 030:   1877 / 2004 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=333.9, nsentences=8, sample_size=333.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=873.9, ups=2.62, wpb=333.9, bsz=8, num_updates=59610, lr=4.09182e-05, gnorm=2.088, clip=0, loss_scale=2048, train_wall=4, gb_free=14.6, wall=20551
2023-03-15 19:42:17 - progress_bar.py[line:272] - INFO: epoch 030:   1887 / 2004 loss=0.131, loss_v1=0, loss_v2=0, nll_loss=0.131, ntokens=314.3, nsentences=8, sample_size=314.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=919.3, ups=2.92, wpb=314.3, bsz=8, num_updates=59620, lr=4.09081e-05, gnorm=2.087, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=20555
2023-03-15 19:42:21 - progress_bar.py[line:272] - INFO: epoch 030:   1897 / 2004 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=352.5, nsentences=8, sample_size=352.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1025.3, ups=2.91, wpb=352.5, bsz=8, num_updates=59630, lr=4.0898e-05, gnorm=2.169, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=20558
2023-03-15 19:42:24 - progress_bar.py[line:272] - INFO: epoch 030:   1907 / 2004 loss=0.125, loss_v1=0, loss_v2=0, nll_loss=0.125, ntokens=333.2, nsentences=8, sample_size=333.2, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=971, ups=2.91, wpb=333.2, bsz=8, num_updates=59640, lr=4.08879e-05, gnorm=1.847, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=20562
2023-03-15 19:42:28 - progress_bar.py[line:272] - INFO: epoch 030:   1917 / 2004 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=332, nsentences=8, sample_size=332, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=970.1, ups=2.92, wpb=332, bsz=8, num_updates=59650, lr=4.08778e-05, gnorm=2.224, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=20565
2023-03-15 19:42:31 - progress_bar.py[line:272] - INFO: epoch 030:   1927 / 2004 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=330.9, nsentences=8, sample_size=330.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=961.5, ups=2.91, wpb=330.9, bsz=8, num_updates=59660, lr=4.08678e-05, gnorm=2.249, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=20569
2023-03-15 19:42:34 - progress_bar.py[line:272] - INFO: epoch 030:   1937 / 2004 loss=0.135, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=337.9, nsentences=8, sample_size=337.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=985.9, ups=2.92, wpb=337.9, bsz=8, num_updates=59670, lr=4.08577e-05, gnorm=1.997, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=20572
2023-03-15 19:42:38 - progress_bar.py[line:272] - INFO: epoch 030:   1947 / 2004 loss=0.134, loss_v1=0, loss_v2=0, nll_loss=0.134, ntokens=344.1, nsentences=8, sample_size=344.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1010.4, ups=2.94, wpb=344.1, bsz=8, num_updates=59680, lr=4.08476e-05, gnorm=2.127, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=20575
2023-03-15 19:42:41 - progress_bar.py[line:272] - INFO: epoch 030:   1957 / 2004 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=354.9, nsentences=8, sample_size=354.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1015.8, ups=2.86, wpb=354.9, bsz=8, num_updates=59690, lr=4.08375e-05, gnorm=2.036, clip=0, loss_scale=2048, train_wall=3, gb_free=15.8, wall=20579
2023-03-15 19:42:45 - progress_bar.py[line:272] - INFO: epoch 030:   1967 / 2004 loss=0.134, loss_v1=0, loss_v2=0, nll_loss=0.134, ntokens=352.3, nsentences=8, sample_size=352.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1044.3, ups=2.96, wpb=352.3, bsz=8, num_updates=59700, lr=4.08274e-05, gnorm=2.054, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=20582
2023-03-15 19:42:48 - progress_bar.py[line:272] - INFO: epoch 030:   1977 / 2004 loss=0.129, loss_v1=0, loss_v2=0, nll_loss=0.129, ntokens=346.4, nsentences=8, sample_size=346.4, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=998.9, ups=2.88, wpb=346.4, bsz=8, num_updates=59710, lr=4.08174e-05, gnorm=1.682, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=20586
2023-03-15 19:42:52 - progress_bar.py[line:272] - INFO: epoch 030:   1987 / 2004 loss=0.132, loss_v1=0, loss_v2=0, nll_loss=0.132, ntokens=323.2, nsentences=8, sample_size=323.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=913.5, ups=2.83, wpb=323.2, bsz=8, num_updates=59720, lr=4.08073e-05, gnorm=1.885, clip=0, loss_scale=2048, train_wall=3, gb_free=13.8, wall=20589
2023-03-15 19:42:55 - progress_bar.py[line:272] - INFO: epoch 030:   1997 / 2004 loss=0.123, loss_v1=0, loss_v2=0, nll_loss=0.123, ntokens=398.1, nsentences=8, sample_size=398.1, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1139.4, ups=2.86, wpb=398.1, bsz=8, num_updates=59730, lr=4.07972e-05, gnorm=1.75, clip=0, loss_scale=4096, train_wall=3, gb_free=14.1, wall=20593
2023-03-15 19:42:57 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 19:42:57 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 30 @ 59736 updates
2023-03-15 19:42:57 - trainer.py[line:431] - INFO: Saving checkpoint to ./checkpoints/checkpoint30.pt
2023-03-15 19:43:04 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./checkpoints/checkpoint30.pt
2023-03-15 19:43:07 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./checkpoints/checkpoint30.pt (epoch 30 @ 59736 updates, score None) (writing took 9.83867722377181 seconds)
2023-03-15 19:43:07 - train.py[line:332] - INFO: end of epoch 30 (average epoch stats below)
2023-03-15 19:43:07 - progress_bar.py[line:282] - INFO: epoch 030 | loss 0.135 | loss_v1 0 | loss_v2 0 | nll_loss 0.135 | ntokens 345.318 | nsentences 7.999 | sample_size 345.318 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.1 | wps 979.6 | ups 2.84 | wpb 345.3 | bsz 8 | num_updates 59736 | lr 4.07911e-05 | gnorm 1.959 | clip 0 | loss_scale 2048 | train_wall 678 | gb_free 14.4 | wall 20605
2023-03-15 19:43:07 - trainer.py[line:639] - INFO: loading train data for epoch 31
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/pretrain_data/vision_language_simple.tsv slice_id 0 row count 8015 total row count 8015
slice_id 0 seek offset 0
2023-03-15 19:43:08 - trainer.py[line:703] - INFO: begin training epoch 31
2023-03-15 19:43:08 - train.py[line:305] - INFO: Start iterating over samples
2023-03-15 19:43:10 - progress_bar.py[line:272] - INFO: epoch 031:      4 / 2004 loss=0.125, loss_v1=0, loss_v2=0, nll_loss=0.125, ntokens=364.2, nsentences=8, sample_size=364.2, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=251.7, ups=0.69, wpb=364.2, bsz=8, num_updates=59740, lr=4.07871e-05, gnorm=1.794, clip=0, loss_scale=2048, train_wall=4, gb_free=13.8, wall=20607
2023-03-15 19:43:13 - progress_bar.py[line:272] - INFO: epoch 031:     14 / 2004 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=320.6, nsentences=8, sample_size=320.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=920.2, ups=2.87, wpb=320.6, bsz=8, num_updates=59750, lr=4.0777e-05, gnorm=1.915, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=20611
2023-03-15 19:43:17 - progress_bar.py[line:272] - INFO: epoch 031:     24 / 2004 loss=0.126, loss_v1=0, loss_v2=0, nll_loss=0.126, ntokens=362.6, nsentences=8, sample_size=362.6, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1018.8, ups=2.81, wpb=362.6, bsz=8, num_updates=59760, lr=4.0767e-05, gnorm=1.819, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=20614
2023-03-15 19:43:20 - progress_bar.py[line:272] - INFO: epoch 031:     34 / 2004 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=347.1, nsentences=8, sample_size=347.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=982.4, ups=2.83, wpb=347.1, bsz=8, num_updates=59770, lr=4.07569e-05, gnorm=2.05, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=20618
2023-03-15 19:43:24 - progress_bar.py[line:272] - INFO: epoch 031:     44 / 2004 loss=0.131, loss_v1=0, loss_v2=0, nll_loss=0.131, ntokens=354.6, nsentences=8, sample_size=354.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=994.4, ups=2.8, wpb=354.6, bsz=8, num_updates=59780, lr=4.07468e-05, gnorm=1.869, clip=0, loss_scale=2048, train_wall=4, gb_free=15, wall=20621
2023-03-15 19:43:27 - progress_bar.py[line:272] - INFO: epoch 031:     54 / 2004 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=351.6, nsentences=8, sample_size=351.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1010.9, ups=2.88, wpb=351.6, bsz=8, num_updates=59790, lr=4.07367e-05, gnorm=1.97, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=20625
2023-03-15 19:43:31 - progress_bar.py[line:272] - INFO: epoch 031:     64 / 2004 loss=0.137, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=320.8, nsentences=8, sample_size=320.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=946.8, ups=2.95, wpb=320.8, bsz=8, num_updates=59800, lr=4.07266e-05, gnorm=2.004, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=20628
2023-03-15 19:43:34 - progress_bar.py[line:272] - INFO: epoch 031:     74 / 2004 loss=0.126, loss_v1=0, loss_v2=0, nll_loss=0.126, ntokens=359.2, nsentences=8, sample_size=359.2, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1034.9, ups=2.88, wpb=359.2, bsz=8, num_updates=59810, lr=4.07165e-05, gnorm=1.714, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=20632
2023-03-15 19:43:38 - progress_bar.py[line:272] - INFO: epoch 031:     84 / 2004 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=335.3, nsentences=8, sample_size=335.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=958.8, ups=2.86, wpb=335.3, bsz=8, num_updates=59820, lr=4.07065e-05, gnorm=2.086, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=20635
2023-03-15 19:43:41 - progress_bar.py[line:272] - INFO: epoch 031:     94 / 2004 loss=0.123, loss_v1=0, loss_v2=0, nll_loss=0.123, ntokens=369.4, nsentences=8, sample_size=369.4, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1052, ups=2.85, wpb=369.4, bsz=8, num_updates=59830, lr=4.06964e-05, gnorm=1.677, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=20639
2023-03-15 19:43:45 - progress_bar.py[line:272] - INFO: epoch 031:    104 / 2004 loss=0.133, loss_v1=0, loss_v2=0, nll_loss=0.133, ntokens=374.2, nsentences=8, sample_size=374.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1087.9, ups=2.91, wpb=374.2, bsz=8, num_updates=59840, lr=4.06863e-05, gnorm=2.04, clip=0, loss_scale=2048, train_wall=3, gb_free=13.7, wall=20642
2023-03-15 19:43:48 - progress_bar.py[line:272] - INFO: epoch 031:    114 / 2004 loss=0.136, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=326.5, nsentences=8, sample_size=326.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1063.3, ups=3.26, wpb=326.5, bsz=8, num_updates=59850, lr=4.06762e-05, gnorm=2.057, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=20645
2023-03-15 19:43:51 - progress_bar.py[line:272] - INFO: epoch 031:    124 / 2004 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=351.1, nsentences=8, sample_size=351.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1122.5, ups=3.2, wpb=351.1, bsz=8, num_updates=59860, lr=4.06661e-05, gnorm=1.947, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=20648
2023-03-15 19:43:53 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 19:43:54 - progress_bar.py[line:272] - INFO: epoch 031:    135 / 2004 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=332.3, nsentences=8, sample_size=332.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=959.8, ups=2.89, wpb=332.3, bsz=8, num_updates=59870, lr=4.06561e-05, gnorm=1.992, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=20652
2023-03-15 19:43:57 - progress_bar.py[line:272] - INFO: epoch 031:    145 / 2004 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=332.7, nsentences=8, sample_size=332.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1068.1, ups=3.21, wpb=332.7, bsz=8, num_updates=59880, lr=4.0646e-05, gnorm=1.808, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=20655
2023-03-15 19:44:01 - progress_bar.py[line:272] - INFO: epoch 031:    155 / 2004 loss=0.121, loss_v1=0, loss_v2=0, nll_loss=0.121, ntokens=339.4, nsentences=8, sample_size=339.4, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1019.9, ups=3, wpb=339.4, bsz=8, num_updates=59890, lr=4.06359e-05, gnorm=1.599, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=20658
2023-03-15 19:44:04 - progress_bar.py[line:272] - INFO: epoch 031:    165 / 2004 loss=0.124, loss_v1=0, loss_v2=0, nll_loss=0.124, ntokens=353.9, nsentences=8, sample_size=353.9, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1038, ups=2.93, wpb=353.9, bsz=8, num_updates=59900, lr=4.06258e-05, gnorm=1.711, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=20662
2023-03-15 19:44:08 - progress_bar.py[line:272] - INFO: epoch 031:    175 / 2004 loss=0.133, loss_v1=0, loss_v2=0, nll_loss=0.133, ntokens=331.9, nsentences=8, sample_size=331.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=956.5, ups=2.88, wpb=331.9, bsz=8, num_updates=59910, lr=4.06157e-05, gnorm=1.867, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=20665
2023-03-15 19:44:11 - progress_bar.py[line:272] - INFO: epoch 031:    185 / 2004 loss=0.132, loss_v1=0, loss_v2=0, nll_loss=0.132, ntokens=336.3, nsentences=8, sample_size=336.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=963, ups=2.86, wpb=336.3, bsz=8, num_updates=59920, lr=4.06057e-05, gnorm=2.023, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=20669
2023-03-15 19:44:15 - progress_bar.py[line:272] - INFO: epoch 031:    195 / 2004 loss=0.134, loss_v1=0, loss_v2=0, nll_loss=0.134, ntokens=321.6, nsentences=8, sample_size=321.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=921.8, ups=2.87, wpb=321.6, bsz=8, num_updates=59930, lr=4.05956e-05, gnorm=1.907, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=20672
2023-03-15 19:44:18 - progress_bar.py[line:272] - INFO: epoch 031:    205 / 2004 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=336.6, nsentences=8, sample_size=336.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=965.1, ups=2.87, wpb=336.6, bsz=8, num_updates=59940, lr=4.05855e-05, gnorm=2.014, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=20676
2023-03-15 19:44:22 - progress_bar.py[line:272] - INFO: epoch 031:    215 / 2004 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=334.6, nsentences=8, sample_size=334.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=950.1, ups=2.84, wpb=334.6, bsz=8, num_updates=59950, lr=4.05754e-05, gnorm=2.217, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=20679
2023-03-15 19:44:25 - progress_bar.py[line:272] - INFO: epoch 031:    225 / 2004 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=333.2, nsentences=8, sample_size=333.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=962.4, ups=2.89, wpb=333.2, bsz=8, num_updates=59960, lr=4.05653e-05, gnorm=2.3, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=20683
2023-03-15 19:44:29 - progress_bar.py[line:272] - INFO: epoch 031:    235 / 2004 loss=0.128, loss_v1=0, loss_v2=0, nll_loss=0.128, ntokens=371.3, nsentences=8, sample_size=371.3, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1066.8, ups=2.87, wpb=371.3, bsz=8, num_updates=59970, lr=4.05553e-05, gnorm=1.715, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=20686
2023-03-15 19:44:32 - progress_bar.py[line:272] - INFO: epoch 031:    245 / 2004 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=353.4, nsentences=8, sample_size=353.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1039.5, ups=2.94, wpb=353.4, bsz=8, num_updates=59980, lr=4.05452e-05, gnorm=2.253, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=20690
2023-03-15 19:44:35 - progress_bar.py[line:272] - INFO: epoch 031:    255 / 2004 loss=0.131, loss_v1=0, loss_v2=0, nll_loss=0.131, ntokens=338.4, nsentences=8, sample_size=338.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=985.7, ups=2.91, wpb=338.4, bsz=8, num_updates=59990, lr=4.05351e-05, gnorm=1.94, clip=0, loss_scale=2048, train_wall=3, gb_free=13.8, wall=20693
2023-03-15 19:44:39 - progress_bar.py[line:272] - INFO: epoch 031:    265 / 2004 loss=0.132, loss_v1=0, loss_v2=0, nll_loss=0.132, ntokens=357, nsentences=8, sample_size=357, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1028.5, ups=2.88, wpb=357, bsz=8, num_updates=60000, lr=4.0525e-05, gnorm=1.968, clip=0, loss_scale=4096, train_wall=3, gb_free=14.8, wall=20696
2023-03-15 19:44:39 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 31 @ 60000 updates
2023-03-15 19:44:39 - trainer.py[line:431] - INFO: Saving checkpoint to ./checkpoints/checkpoint_31_60000.pt
2023-03-15 19:44:46 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./checkpoints/checkpoint_31_60000.pt
2023-03-15 19:44:49 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./checkpoints/checkpoint_31_60000.pt (epoch 31 @ 60000 updates, score None) (writing took 10.009007308632135 seconds)
2023-03-15 19:44:50 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 19:44:53 - progress_bar.py[line:272] - INFO: epoch 031:    276 / 2004 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=345.1, nsentences=8, sample_size=345.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=247.4, ups=0.72, wpb=345.1, bsz=8, num_updates=60010, lr=4.05149e-05, gnorm=2.023, clip=0, loss_scale=2048, train_wall=4, gb_free=13.9, wall=20710
2023-03-15 19:44:56 - progress_bar.py[line:272] - INFO: epoch 031:    286 / 2004 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=366.8, nsentences=8, sample_size=366.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1010.3, ups=2.75, wpb=366.8, bsz=8, num_updates=60020, lr=4.05048e-05, gnorm=2.053, clip=0, loss_scale=2048, train_wall=4, gb_free=14.4, wall=20714
2023-03-15 19:45:00 - progress_bar.py[line:272] - INFO: epoch 031:    296 / 2004 loss=0.13, loss_v1=0, loss_v2=0, nll_loss=0.13, ntokens=352.6, nsentences=8, sample_size=352.6, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1010.9, ups=2.87, wpb=352.6, bsz=8, num_updates=60030, lr=4.04948e-05, gnorm=1.855, clip=0, loss_scale=2048, train_wall=3, gb_free=14.5, wall=20718
2023-03-15 19:45:03 - progress_bar.py[line:272] - INFO: epoch 031:    306 / 2004 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=340.2, nsentences=8, sample_size=340.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=977.6, ups=2.87, wpb=340.2, bsz=8, num_updates=60040, lr=4.04847e-05, gnorm=1.91, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=20721
2023-03-15 19:45:07 - progress_bar.py[line:272] - INFO: epoch 031:    316 / 2004 loss=0.125, loss_v1=0, loss_v2=0, nll_loss=0.125, ntokens=362.2, nsentences=8, sample_size=362.2, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1021.8, ups=2.82, wpb=362.2, bsz=8, num_updates=60050, lr=4.04746e-05, gnorm=1.685, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=20725
2023-03-15 19:45:10 - progress_bar.py[line:272] - INFO: epoch 031:    326 / 2004 loss=0.125, loss_v1=0, loss_v2=0, nll_loss=0.125, ntokens=324.5, nsentences=8, sample_size=324.5, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=930.6, ups=2.87, wpb=324.5, bsz=8, num_updates=60060, lr=4.04645e-05, gnorm=1.708, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=20728
2023-03-15 19:45:14 - progress_bar.py[line:272] - INFO: epoch 031:    336 / 2004 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=339, nsentences=8, sample_size=339, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=966.4, ups=2.85, wpb=339, bsz=8, num_updates=60070, lr=4.04544e-05, gnorm=2.204, clip=0, loss_scale=2048, train_wall=3, gb_free=13.9, wall=20732
2023-03-15 19:45:17 - progress_bar.py[line:272] - INFO: epoch 031:    346 / 2004 loss=0.134, loss_v1=0, loss_v2=0, nll_loss=0.134, ntokens=374, nsentences=8, sample_size=374, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1072.7, ups=2.87, wpb=374, bsz=8, num_updates=60080, lr=4.04444e-05, gnorm=1.974, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=20735
2023-03-15 19:45:21 - progress_bar.py[line:272] - INFO: epoch 031:    356 / 2004 loss=0.134, loss_v1=0, loss_v2=0, nll_loss=0.134, ntokens=335.2, nsentences=8, sample_size=335.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=957.4, ups=2.86, wpb=335.2, bsz=8, num_updates=60090, lr=4.04343e-05, gnorm=1.89, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=20739
2023-03-15 19:45:24 - progress_bar.py[line:272] - INFO: epoch 031:    366 / 2004 loss=0.129, loss_v1=0, loss_v2=0, nll_loss=0.129, ntokens=366.6, nsentences=8, sample_size=366.6, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1029.9, ups=2.81, wpb=366.6, bsz=8, num_updates=60100, lr=4.04242e-05, gnorm=2.004, clip=0, loss_scale=2048, train_wall=4, gb_free=14.4, wall=20742
2023-03-15 19:45:28 - progress_bar.py[line:272] - INFO: epoch 031:    376 / 2004 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=307.5, nsentences=8, sample_size=307.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=877.7, ups=2.85, wpb=307.5, bsz=8, num_updates=60110, lr=4.04141e-05, gnorm=2.025, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=20746
2023-03-15 19:45:31 - progress_bar.py[line:272] - INFO: epoch 031:    386 / 2004 loss=0.132, loss_v1=0, loss_v2=0, nll_loss=0.132, ntokens=325.8, nsentences=8, sample_size=325.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=949.3, ups=2.91, wpb=325.8, bsz=8, num_updates=60120, lr=4.0404e-05, gnorm=2.057, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=20749
2023-03-15 19:45:35 - progress_bar.py[line:272] - INFO: epoch 031:    396 / 2004 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=352.3, nsentences=8, sample_size=352.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1021.5, ups=2.9, wpb=352.3, bsz=8, num_updates=60130, lr=4.0394e-05, gnorm=1.984, clip=0, loss_scale=4096, train_wall=3, gb_free=15.5, wall=20752
2023-03-15 19:45:36 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 19:45:39 - progress_bar.py[line:272] - INFO: epoch 031:    407 / 2004 loss=0.132, loss_v1=0, loss_v2=0, nll_loss=0.132, ntokens=373.3, nsentences=8, sample_size=373.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=986.7, ups=2.64, wpb=373.3, bsz=8, num_updates=60140, lr=4.03839e-05, gnorm=1.816, clip=0, loss_scale=2048, train_wall=4, gb_free=14.9, wall=20756
2023-03-15 19:45:42 - progress_bar.py[line:272] - INFO: epoch 031:    417 / 2004 loss=0.127, loss_v1=0, loss_v2=0, nll_loss=0.127, ntokens=337.8, nsentences=8, sample_size=337.8, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=975.4, ups=2.89, wpb=337.8, bsz=8, num_updates=60150, lr=4.03738e-05, gnorm=1.765, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=20760
2023-03-15 19:45:46 - progress_bar.py[line:272] - INFO: epoch 031:    427 / 2004 loss=0.126, loss_v1=0, loss_v2=0, nll_loss=0.126, ntokens=338.1, nsentences=8, sample_size=338.1, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=988.9, ups=2.92, wpb=338.1, bsz=8, num_updates=60160, lr=4.03637e-05, gnorm=1.817, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=20763
2023-03-15 19:45:49 - progress_bar.py[line:272] - INFO: epoch 031:    437 / 2004 loss=0.133, loss_v1=0, loss_v2=0, nll_loss=0.133, ntokens=350.6, nsentences=8, sample_size=350.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1010.6, ups=2.88, wpb=350.6, bsz=8, num_updates=60170, lr=4.03536e-05, gnorm=2.011, clip=0, loss_scale=2048, train_wall=3, gb_free=15.8, wall=20767
2023-03-15 19:45:53 - progress_bar.py[line:272] - INFO: epoch 031:    447 / 2004 loss=0.133, loss_v1=0, loss_v2=0, nll_loss=0.133, ntokens=374.5, nsentences=8, sample_size=374.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1046.7, ups=2.79, wpb=374.5, bsz=8, num_updates=60180, lr=4.03436e-05, gnorm=2, clip=0, loss_scale=2048, train_wall=4, gb_free=14.7, wall=20770
2023-03-15 19:45:56 - progress_bar.py[line:272] - INFO: epoch 031:    457 / 2004 loss=0.113, loss_v1=0, loss_v2=0, nll_loss=0.113, ntokens=390, nsentences=8, sample_size=390, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=1129.3, ups=2.9, wpb=390, bsz=8, num_updates=60190, lr=4.03335e-05, gnorm=1.675, clip=0, loss_scale=2048, train_wall=3, gb_free=14.1, wall=20774
2023-03-15 19:46:00 - progress_bar.py[line:272] - INFO: epoch 031:    467 / 2004 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=359.1, nsentences=8, sample_size=359.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1011, ups=2.82, wpb=359.1, bsz=8, num_updates=60200, lr=4.03234e-05, gnorm=2.091, clip=0, loss_scale=2048, train_wall=3, gb_free=15.2, wall=20777
2023-03-15 19:46:02 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-03-15 19:46:03 - progress_bar.py[line:272] - INFO: epoch 031:    478 / 2004 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=326.6, nsentences=8, sample_size=326.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=851.8, ups=2.61, wpb=326.6, bsz=8, num_updates=60210, lr=4.03133e-05, gnorm=2.118, clip=0, loss_scale=1024, train_wall=4, gb_free=14.3, wall=20781
2023-03-15 19:46:07 - progress_bar.py[line:272] - INFO: epoch 031:    488 / 2004 loss=0.128, loss_v1=0, loss_v2=0, nll_loss=0.128, ntokens=375.5, nsentences=8, sample_size=375.5, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1043.3, ups=2.78, wpb=375.5, bsz=8, num_updates=60220, lr=4.03032e-05, gnorm=1.792, clip=0, loss_scale=1024, train_wall=4, gb_free=15.2, wall=20785
2023-03-15 19:46:11 - progress_bar.py[line:272] - INFO: epoch 031:    498 / 2004 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=365.1, nsentences=8, sample_size=365.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1027, ups=2.81, wpb=365.1, bsz=8, num_updates=60230, lr=4.02932e-05, gnorm=2.14, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=20788
2023-03-15 19:46:14 - progress_bar.py[line:272] - INFO: epoch 031:    508 / 2004 loss=0.123, loss_v1=0, loss_v2=0, nll_loss=0.123, ntokens=352.5, nsentences=8, sample_size=352.5, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1030.7, ups=2.92, wpb=352.5, bsz=8, num_updates=60240, lr=4.02831e-05, gnorm=1.818, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=20792
2023-03-15 19:46:18 - progress_bar.py[line:272] - INFO: epoch 031:    518 / 2004 loss=0.135, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=351.6, nsentences=8, sample_size=351.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=990.2, ups=2.82, wpb=351.6, bsz=8, num_updates=60250, lr=4.0273e-05, gnorm=1.889, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=20795
2023-03-15 19:46:21 - progress_bar.py[line:272] - INFO: epoch 031:    528 / 2004 loss=0.135, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=402.8, nsentences=8, sample_size=402.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1133.9, ups=2.82, wpb=402.8, bsz=8, num_updates=60260, lr=4.02629e-05, gnorm=1.951, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=20799
2023-03-15 19:46:25 - progress_bar.py[line:272] - INFO: epoch 031:    538 / 2004 loss=0.128, loss_v1=0, loss_v2=0, nll_loss=0.128, ntokens=385.5, nsentences=8, sample_size=385.5, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1099.5, ups=2.85, wpb=385.5, bsz=8, num_updates=60270, lr=4.02528e-05, gnorm=1.693, clip=0, loss_scale=1024, train_wall=3, gb_free=15.2, wall=20802
2023-03-15 19:46:28 - progress_bar.py[line:272] - INFO: epoch 031:    548 / 2004 loss=0.125, loss_v1=0, loss_v2=0, nll_loss=0.125, ntokens=350.6, nsentences=8, sample_size=350.6, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1027.1, ups=2.93, wpb=350.6, bsz=8, num_updates=60280, lr=4.02427e-05, gnorm=1.778, clip=0, loss_scale=1024, train_wall=3, gb_free=15.4, wall=20806
2023-03-15 19:46:32 - progress_bar.py[line:272] - INFO: epoch 031:    558 / 2004 loss=0.13, loss_v1=0, loss_v2=0, nll_loss=0.13, ntokens=378.2, nsentences=8, sample_size=378.2, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1070.2, ups=2.83, wpb=378.2, bsz=8, num_updates=60290, lr=4.02327e-05, gnorm=1.944, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=20809
2023-03-15 19:46:35 - progress_bar.py[line:272] - INFO: epoch 031:    568 / 2004 loss=0.125, loss_v1=0, loss_v2=0, nll_loss=0.125, ntokens=377.4, nsentences=8, sample_size=377.4, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1059.9, ups=2.81, wpb=377.4, bsz=8, num_updates=60300, lr=4.02226e-05, gnorm=1.823, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=20813
2023-03-15 19:46:39 - progress_bar.py[line:272] - INFO: epoch 031:    578 / 2004 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=329.9, nsentences=8, sample_size=329.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=965.4, ups=2.93, wpb=329.9, bsz=8, num_updates=60310, lr=4.02125e-05, gnorm=1.927, clip=0, loss_scale=1024, train_wall=3, gb_free=14.9, wall=20816
2023-03-15 19:46:42 - progress_bar.py[line:272] - INFO: epoch 031:    588 / 2004 loss=0.137, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=372.9, nsentences=8, sample_size=372.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1178.6, ups=3.16, wpb=372.9, bsz=8, num_updates=60320, lr=4.02024e-05, gnorm=1.818, clip=0, loss_scale=1024, train_wall=3, gb_free=14.7, wall=20819
2023-03-15 19:46:45 - progress_bar.py[line:272] - INFO: epoch 031:    598 / 2004 loss=0.131, loss_v1=0, loss_v2=0, nll_loss=0.131, ntokens=334.5, nsentences=8, sample_size=334.5, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1063.1, ups=3.18, wpb=334.5, bsz=8, num_updates=60330, lr=4.01923e-05, gnorm=1.817, clip=0, loss_scale=1024, train_wall=3, gb_free=14.6, wall=20822
2023-03-15 19:46:48 - progress_bar.py[line:272] - INFO: epoch 031:    608 / 2004 loss=0.125, loss_v1=0, loss_v2=0, nll_loss=0.125, ntokens=351.9, nsentences=8, sample_size=351.9, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1063.6, ups=3.02, wpb=351.9, bsz=8, num_updates=60340, lr=4.01823e-05, gnorm=1.63, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=20826
2023-03-15 19:46:52 - progress_bar.py[line:272] - INFO: epoch 031:    618 / 2004 loss=0.125, loss_v1=0, loss_v2=0, nll_loss=0.125, ntokens=354, nsentences=8, sample_size=354, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1009.8, ups=2.85, wpb=354, bsz=8, num_updates=60350, lr=4.01722e-05, gnorm=1.772, clip=0, loss_scale=2048, train_wall=3, gb_free=15.5, wall=20829
2023-03-15 19:46:55 - progress_bar.py[line:272] - INFO: epoch 031:    628 / 2004 loss=0.12, loss_v1=0, loss_v2=0, nll_loss=0.12, ntokens=368.7, nsentences=8, sample_size=368.7, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1062, ups=2.88, wpb=368.7, bsz=8, num_updates=60360, lr=4.01621e-05, gnorm=1.813, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=20833
2023-03-15 19:46:59 - progress_bar.py[line:272] - INFO: epoch 031:    638 / 2004 loss=0.131, loss_v1=0, loss_v2=0, nll_loss=0.131, ntokens=331.9, nsentences=8, sample_size=331.9, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=960.6, ups=2.89, wpb=331.9, bsz=8, num_updates=60370, lr=4.0152e-05, gnorm=1.838, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=20836
2023-03-15 19:47:02 - progress_bar.py[line:272] - INFO: epoch 031:    648 / 2004 loss=0.135, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=320.6, nsentences=7.8, sample_size=320.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=924, ups=2.88, wpb=320.6, bsz=7.8, num_updates=60380, lr=4.01419e-05, gnorm=1.82, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=20840
2023-03-15 19:47:06 - progress_bar.py[line:272] - INFO: epoch 031:    658 / 2004 loss=0.126, loss_v1=0, loss_v2=0, nll_loss=0.126, ntokens=360.2, nsentences=8, sample_size=360.2, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1032.2, ups=2.87, wpb=360.2, bsz=8, num_updates=60390, lr=4.01319e-05, gnorm=1.715, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=20843
2023-03-15 19:47:09 - progress_bar.py[line:272] - INFO: epoch 031:    668 / 2004 loss=0.13, loss_v1=0, loss_v2=0, nll_loss=0.13, ntokens=297.6, nsentences=8, sample_size=297.6, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=851, ups=2.86, wpb=297.6, bsz=8, num_updates=60400, lr=4.01218e-05, gnorm=1.688, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=20847
2023-03-15 19:47:13 - progress_bar.py[line:272] - INFO: epoch 031:    678 / 2004 loss=0.128, loss_v1=0, loss_v2=0, nll_loss=0.128, ntokens=336.6, nsentences=8, sample_size=336.6, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=955.8, ups=2.84, wpb=336.6, bsz=8, num_updates=60410, lr=4.01117e-05, gnorm=1.808, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=20850
2023-03-15 19:47:16 - progress_bar.py[line:272] - INFO: epoch 031:    688 / 2004 loss=0.116, loss_v1=0, loss_v2=0, nll_loss=0.116, ntokens=356.5, nsentences=8, sample_size=356.5, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=1018, ups=2.86, wpb=356.5, bsz=8, num_updates=60420, lr=4.01016e-05, gnorm=1.67, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=20854
2023-03-15 19:47:19 - progress_bar.py[line:272] - INFO: epoch 031:    698 / 2004 loss=0.128, loss_v1=0, loss_v2=0, nll_loss=0.128, ntokens=352.9, nsentences=8, sample_size=352.9, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1030, ups=2.92, wpb=352.9, bsz=8, num_updates=60430, lr=4.00915e-05, gnorm=1.915, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=20857
2023-03-15 19:47:23 - progress_bar.py[line:272] - INFO: epoch 031:    708 / 2004 loss=0.136, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=331.3, nsentences=8, sample_size=331.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=952.4, ups=2.87, wpb=331.3, bsz=8, num_updates=60440, lr=4.00815e-05, gnorm=1.784, clip=0, loss_scale=2048, train_wall=3, gb_free=15.9, wall=20861
2023-03-15 19:47:26 - progress_bar.py[line:272] - INFO: epoch 031:    718 / 2004 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=335.1, nsentences=8, sample_size=335.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=967.7, ups=2.89, wpb=335.1, bsz=8, num_updates=60450, lr=4.00714e-05, gnorm=1.868, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=20864
2023-03-15 19:47:30 - progress_bar.py[line:272] - INFO: epoch 031:    728 / 2004 loss=0.131, loss_v1=0, loss_v2=0, nll_loss=0.131, ntokens=361.4, nsentences=8, sample_size=361.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1030.3, ups=2.85, wpb=361.4, bsz=8, num_updates=60460, lr=4.00613e-05, gnorm=1.918, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=20868
2023-03-15 19:47:31 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 19:47:35 - progress_bar.py[line:272] - INFO: epoch 031:    739 / 2004 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=329.3, nsentences=8, sample_size=329.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=691.3, ups=2.1, wpb=329.3, bsz=8, num_updates=60470, lr=4.00512e-05, gnorm=2.074, clip=0, loss_scale=2048, train_wall=5, gb_free=15.4, wall=20872
2023-03-15 19:47:38 - progress_bar.py[line:272] - INFO: epoch 031:    749 / 2004 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=371.7, nsentences=8, sample_size=371.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1050.1, ups=2.83, wpb=371.7, bsz=8, num_updates=60480, lr=4.00411e-05, gnorm=2.122, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=20876
2023-03-15 19:47:42 - progress_bar.py[line:272] - INFO: epoch 031:    759 / 2004 loss=0.128, loss_v1=0, loss_v2=0, nll_loss=0.128, ntokens=301.8, nsentences=8, sample_size=301.8, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=871.9, ups=2.89, wpb=301.8, bsz=8, num_updates=60490, lr=4.0031e-05, gnorm=1.824, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=20879
2023-03-15 19:47:45 - progress_bar.py[line:272] - INFO: epoch 031:    769 / 2004 loss=0.131, loss_v1=0, loss_v2=0, nll_loss=0.131, ntokens=410.9, nsentences=8, sample_size=410.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1132, ups=2.76, wpb=410.9, bsz=8, num_updates=60500, lr=4.0021e-05, gnorm=1.963, clip=0, loss_scale=2048, train_wall=4, gb_free=14.5, wall=20883
2023-03-15 19:47:49 - progress_bar.py[line:272] - INFO: epoch 031:    779 / 2004 loss=0.136, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=339.5, nsentences=8, sample_size=339.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=969.8, ups=2.86, wpb=339.5, bsz=8, num_updates=60510, lr=4.00109e-05, gnorm=2.08, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=20886
2023-03-15 19:47:52 - progress_bar.py[line:272] - INFO: epoch 031:    789 / 2004 loss=0.126, loss_v1=0, loss_v2=0, nll_loss=0.126, ntokens=340.1, nsentences=8, sample_size=340.1, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=978.2, ups=2.88, wpb=340.1, bsz=8, num_updates=60520, lr=4.00008e-05, gnorm=1.667, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=20890
2023-03-15 19:47:56 - progress_bar.py[line:272] - INFO: epoch 031:    799 / 2004 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=329.8, nsentences=8, sample_size=329.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=945.7, ups=2.87, wpb=329.8, bsz=8, num_updates=60530, lr=3.99907e-05, gnorm=2.116, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=20893
2023-03-15 19:47:59 - progress_bar.py[line:272] - INFO: epoch 031:    809 / 2004 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=347.7, nsentences=8, sample_size=347.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1004.1, ups=2.89, wpb=347.7, bsz=8, num_updates=60540, lr=3.99806e-05, gnorm=2.262, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=20897
2023-03-15 19:48:03 - progress_bar.py[line:272] - INFO: epoch 031:    819 / 2004 loss=0.133, loss_v1=0, loss_v2=0, nll_loss=0.133, ntokens=323.4, nsentences=8, sample_size=323.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=935.7, ups=2.89, wpb=323.4, bsz=8, num_updates=60550, lr=3.99706e-05, gnorm=1.877, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=20900
2023-03-15 19:48:06 - progress_bar.py[line:272] - INFO: epoch 031:    829 / 2004 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=368.8, nsentences=8, sample_size=368.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1040.2, ups=2.82, wpb=368.8, bsz=8, num_updates=60560, lr=3.99605e-05, gnorm=2.072, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=20904
2023-03-15 19:48:10 - progress_bar.py[line:272] - INFO: epoch 031:    839 / 2004 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=332.7, nsentences=8, sample_size=332.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=961.1, ups=2.89, wpb=332.7, bsz=8, num_updates=60570, lr=3.99504e-05, gnorm=2.035, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=20907
2023-03-15 19:48:13 - progress_bar.py[line:272] - INFO: epoch 031:    849 / 2004 loss=0.145, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=374.6, nsentences=8, sample_size=374.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1054.3, ups=2.81, wpb=374.6, bsz=8, num_updates=60580, lr=3.99403e-05, gnorm=2.191, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=20911
2023-03-15 19:48:17 - progress_bar.py[line:272] - INFO: epoch 031:    859 / 2004 loss=0.132, loss_v1=0, loss_v2=0, nll_loss=0.132, ntokens=343.3, nsentences=8, sample_size=343.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=979, ups=2.85, wpb=343.3, bsz=8, num_updates=60590, lr=3.99302e-05, gnorm=1.944, clip=0, loss_scale=4096, train_wall=3, gb_free=14.8, wall=20914
2023-03-15 19:48:18 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 19:48:21 - progress_bar.py[line:272] - INFO: epoch 031:    870 / 2004 loss=0.142, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=359.7, nsentences=8, sample_size=359.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=958.1, ups=2.66, wpb=359.7, bsz=8, num_updates=60600, lr=3.99202e-05, gnorm=1.797, clip=0, loss_scale=2048, train_wall=4, gb_free=15.5, wall=20918
2023-03-15 19:48:24 - progress_bar.py[line:272] - INFO: epoch 031:    880 / 2004 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=327.9, nsentences=8, sample_size=327.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=955.8, ups=2.91, wpb=327.9, bsz=8, num_updates=60610, lr=3.99101e-05, gnorm=2.068, clip=0, loss_scale=2048, train_wall=3, gb_free=13.8, wall=20922
2023-03-15 19:48:27 - progress_bar.py[line:272] - INFO: epoch 031:    890 / 2004 loss=0.136, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=307.5, nsentences=8, sample_size=307.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=877.6, ups=2.85, wpb=307.5, bsz=8, num_updates=60620, lr=3.99e-05, gnorm=1.934, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=20925
2023-03-15 19:48:31 - progress_bar.py[line:272] - INFO: epoch 031:    900 / 2004 loss=0.135, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=365.1, nsentences=8, sample_size=365.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1051.2, ups=2.88, wpb=365.1, bsz=8, num_updates=60630, lr=3.98899e-05, gnorm=2.114, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=20929
2023-03-15 19:48:34 - progress_bar.py[line:272] - INFO: epoch 031:    910 / 2004 loss=0.123, loss_v1=0, loss_v2=0, nll_loss=0.123, ntokens=366.2, nsentences=8, sample_size=366.2, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1038.4, ups=2.84, wpb=366.2, bsz=8, num_updates=60640, lr=3.98798e-05, gnorm=1.73, clip=0, loss_scale=2048, train_wall=3, gb_free=15.4, wall=20932
2023-03-15 19:48:38 - progress_bar.py[line:272] - INFO: epoch 031:    920 / 2004 loss=0.136, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=343.9, nsentences=8, sample_size=343.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=982.9, ups=2.86, wpb=343.9, bsz=8, num_updates=60650, lr=3.98698e-05, gnorm=2.019, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=20936
2023-03-15 19:48:41 - progress_bar.py[line:272] - INFO: epoch 031:    930 / 2004 loss=0.125, loss_v1=0, loss_v2=0, nll_loss=0.125, ntokens=331.7, nsentences=8, sample_size=331.7, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=963.1, ups=2.9, wpb=331.7, bsz=8, num_updates=60660, lr=3.98597e-05, gnorm=1.841, clip=0, loss_scale=2048, train_wall=3, gb_free=14.8, wall=20939
2023-03-15 19:48:45 - progress_bar.py[line:272] - INFO: epoch 031:    940 / 2004 loss=0.134, loss_v1=0, loss_v2=0, nll_loss=0.134, ntokens=359, nsentences=8, sample_size=359, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1028.7, ups=2.87, wpb=359, bsz=8, num_updates=60670, lr=3.98496e-05, gnorm=1.79, clip=0, loss_scale=2048, train_wall=3, gb_free=15.6, wall=20943
2023-03-15 19:48:48 - progress_bar.py[line:272] - INFO: epoch 031:    950 / 2004 loss=0.128, loss_v1=0, loss_v2=0, nll_loss=0.128, ntokens=361.5, nsentences=8, sample_size=361.5, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1019.8, ups=2.82, wpb=361.5, bsz=8, num_updates=60680, lr=3.98395e-05, gnorm=1.774, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=20946
2023-03-15 19:48:52 - progress_bar.py[line:272] - INFO: epoch 031:    960 / 2004 loss=0.135, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=355.6, nsentences=8, sample_size=355.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1049.7, ups=2.95, wpb=355.6, bsz=8, num_updates=60690, lr=3.98294e-05, gnorm=2.026, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=20949
2023-03-15 19:48:55 - progress_bar.py[line:272] - INFO: epoch 031:    970 / 2004 loss=0.143, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=341.3, nsentences=8, sample_size=341.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1086.1, ups=3.18, wpb=341.3, bsz=8, num_updates=60700, lr=3.98194e-05, gnorm=1.801, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=20953
2023-03-15 19:48:58 - progress_bar.py[line:272] - INFO: epoch 031:    980 / 2004 loss=0.124, loss_v1=0, loss_v2=0, nll_loss=0.124, ntokens=333.8, nsentences=8, sample_size=333.8, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=984.7, ups=2.95, wpb=333.8, bsz=8, num_updates=60710, lr=3.98093e-05, gnorm=1.84, clip=0, loss_scale=2048, train_wall=3, gb_free=15.7, wall=20956
2023-03-15 19:49:02 - progress_bar.py[line:272] - INFO: epoch 031:    990 / 2004 loss=0.126, loss_v1=0, loss_v2=0, nll_loss=0.126, ntokens=374.7, nsentences=8, sample_size=374.7, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1097.4, ups=2.93, wpb=374.7, bsz=8, num_updates=60720, lr=3.97992e-05, gnorm=1.684, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=20959
2023-03-15 19:49:03 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 19:49:06 - progress_bar.py[line:272] - INFO: epoch 031:   1001 / 2004 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=326.9, nsentences=8, sample_size=326.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=848.4, ups=2.6, wpb=326.9, bsz=8, num_updates=60730, lr=3.97891e-05, gnorm=2.361, clip=0, loss_scale=2048, train_wall=4, gb_free=16, wall=20963
2023-03-15 19:49:09 - progress_bar.py[line:272] - INFO: epoch 031:   1011 / 2004 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=330.4, nsentences=8, sample_size=330.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=951.6, ups=2.88, wpb=330.4, bsz=8, num_updates=60740, lr=3.9779e-05, gnorm=2.356, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=20967
2023-03-15 19:49:13 - progress_bar.py[line:272] - INFO: epoch 031:   1021 / 2004 loss=0.136, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=344.8, nsentences=8, sample_size=344.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=987.4, ups=2.86, wpb=344.8, bsz=8, num_updates=60750, lr=3.97689e-05, gnorm=1.965, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=20970
2023-03-15 19:49:16 - progress_bar.py[line:272] - INFO: epoch 031:   1031 / 2004 loss=0.128, loss_v1=0, loss_v2=0, nll_loss=0.128, ntokens=310.2, nsentences=8, sample_size=310.2, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=919.9, ups=2.97, wpb=310.2, bsz=8, num_updates=60760, lr=3.97589e-05, gnorm=1.827, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=20974
2023-03-15 19:49:19 - progress_bar.py[line:272] - INFO: epoch 031:   1041 / 2004 loss=0.136, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=338, nsentences=8, sample_size=338, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1070.7, ups=3.17, wpb=338, bsz=8, num_updates=60770, lr=3.97488e-05, gnorm=1.819, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=20977
2023-03-15 19:49:23 - progress_bar.py[line:272] - INFO: epoch 031:   1051 / 2004 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=375, nsentences=8, sample_size=375, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1104.1, ups=2.94, wpb=375, bsz=8, num_updates=60780, lr=3.97387e-05, gnorm=2.078, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=20980
2023-03-15 19:49:26 - progress_bar.py[line:272] - INFO: epoch 031:   1061 / 2004 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=334.5, nsentences=8, sample_size=334.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=971.7, ups=2.9, wpb=334.5, bsz=8, num_updates=60790, lr=3.97286e-05, gnorm=2.016, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=20984
2023-03-15 19:49:29 - progress_bar.py[line:272] - INFO: epoch 031:   1071 / 2004 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=362.4, nsentences=8, sample_size=362.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1055.6, ups=2.91, wpb=362.4, bsz=8, num_updates=60800, lr=3.97185e-05, gnorm=2.245, clip=0, loss_scale=2048, train_wall=3, gb_free=14.3, wall=20987
2023-03-15 19:49:33 - progress_bar.py[line:272] - INFO: epoch 031:   1081 / 2004 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=358.9, nsentences=8, sample_size=358.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1024.2, ups=2.85, wpb=358.9, bsz=8, num_updates=60810, lr=3.97085e-05, gnorm=2.081, clip=0, loss_scale=2048, train_wall=3, gb_free=13.7, wall=20991
2023-03-15 19:49:36 - progress_bar.py[line:272] - INFO: epoch 031:   1091 / 2004 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=339.3, nsentences=8, sample_size=339.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=987.9, ups=2.91, wpb=339.3, bsz=8, num_updates=60820, lr=3.96984e-05, gnorm=2.37, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=20994
2023-03-15 19:49:40 - progress_bar.py[line:272] - INFO: epoch 031:   1101 / 2004 loss=0.144, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=349.6, nsentences=8, sample_size=349.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1010.2, ups=2.89, wpb=349.6, bsz=8, num_updates=60830, lr=3.96883e-05, gnorm=2.061, clip=0, loss_scale=2048, train_wall=3, gb_free=15.1, wall=20997
2023-03-15 19:49:43 - progress_bar.py[line:272] - INFO: epoch 031:   1111 / 2004 loss=0.128, loss_v1=0, loss_v2=0, nll_loss=0.128, ntokens=373, nsentences=8, sample_size=373, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1040.3, ups=2.79, wpb=373, bsz=8, num_updates=60840, lr=3.96782e-05, gnorm=1.919, clip=0, loss_scale=2048, train_wall=4, gb_free=14.2, wall=21001
2023-03-15 19:49:47 - progress_bar.py[line:272] - INFO: epoch 031:   1121 / 2004 loss=0.139, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=314, nsentences=8, sample_size=314, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=889.1, ups=2.83, wpb=314, bsz=8, num_updates=60850, lr=3.96681e-05, gnorm=1.808, clip=0, loss_scale=4096, train_wall=3, gb_free=15.1, wall=21005
2023-03-15 19:49:50 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 19:49:51 - progress_bar.py[line:272] - INFO: epoch 031:   1132 / 2004 loss=0.122, loss_v1=0, loss_v2=0, nll_loss=0.122, ntokens=366.2, nsentences=8, sample_size=366.2, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=953.4, ups=2.6, wpb=366.2, bsz=8, num_updates=60860, lr=3.96581e-05, gnorm=1.718, clip=0, loss_scale=2048, train_wall=4, gb_free=15.1, wall=21008
2023-03-15 19:49:54 - progress_bar.py[line:272] - INFO: epoch 031:   1142 / 2004 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=360.1, nsentences=8, sample_size=360.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=1045.2, ups=2.9, wpb=360.1, bsz=8, num_updates=60870, lr=3.9648e-05, gnorm=2.155, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=21012
2023-03-15 19:49:58 - progress_bar.py[line:272] - INFO: epoch 031:   1152 / 2004 loss=0.138, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=375.7, nsentences=8, sample_size=375.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1058.6, ups=2.82, wpb=375.7, bsz=8, num_updates=60880, lr=3.96379e-05, gnorm=2.142, clip=0, loss_scale=2048, train_wall=3, gb_free=14.4, wall=21015
2023-03-15 19:50:01 - progress_bar.py[line:272] - INFO: epoch 031:   1162 / 2004 loss=0.125, loss_v1=0, loss_v2=0, nll_loss=0.125, ntokens=376.9, nsentences=8, sample_size=376.9, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1050.3, ups=2.79, wpb=376.9, bsz=8, num_updates=60890, lr=3.96278e-05, gnorm=1.757, clip=0, loss_scale=2048, train_wall=4, gb_free=15.2, wall=21019
2023-03-15 19:50:05 - progress_bar.py[line:272] - INFO: epoch 031:   1172 / 2004 loss=0.129, loss_v1=0, loss_v2=0, nll_loss=0.129, ntokens=343.5, nsentences=8, sample_size=343.5, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=963.1, ups=2.8, wpb=343.5, bsz=8, num_updates=60900, lr=3.96177e-05, gnorm=1.749, clip=0, loss_scale=2048, train_wall=4, gb_free=15.4, wall=21023
2023-03-15 19:50:08 - progress_bar.py[line:272] - INFO: epoch 031:   1182 / 2004 loss=0.129, loss_v1=0, loss_v2=0, nll_loss=0.129, ntokens=352.3, nsentences=8, sample_size=352.3, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=1006.9, ups=2.86, wpb=352.3, bsz=8, num_updates=60910, lr=3.96077e-05, gnorm=1.874, clip=0, loss_scale=2048, train_wall=3, gb_free=14.9, wall=21026
2023-03-15 19:50:12 - progress_bar.py[line:272] - INFO: epoch 031:   1192 / 2004 loss=0.133, loss_v1=0, loss_v2=0, nll_loss=0.133, ntokens=345.2, nsentences=8, sample_size=345.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=983.7, ups=2.85, wpb=345.2, bsz=8, num_updates=60920, lr=3.95976e-05, gnorm=1.813, clip=0, loss_scale=2048, train_wall=3, gb_free=15, wall=21030
2023-03-15 19:50:15 - progress_bar.py[line:272] - INFO: epoch 031:   1202 / 2004 loss=0.141, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=340.8, nsentences=8, sample_size=340.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=998.3, ups=2.93, wpb=340.8, bsz=8, num_updates=60930, lr=3.95875e-05, gnorm=1.908, clip=0, loss_scale=2048, train_wall=3, gb_free=14.7, wall=21033
2023-03-15 19:50:19 - progress_bar.py[line:272] - INFO: epoch 031:   1212 / 2004 loss=0.136, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=288.3, nsentences=8, sample_size=288.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=835.2, ups=2.9, wpb=288.3, bsz=8, num_updates=60940, lr=3.95774e-05, gnorm=1.645, clip=0, loss_scale=2048, train_wall=3, gb_free=14, wall=21036
2023-03-15 19:50:22 - progress_bar.py[line:272] - INFO: epoch 031:   1222 / 2004 loss=0.137, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=325.6, nsentences=8, sample_size=325.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=935, ups=2.87, wpb=325.6, bsz=8, num_updates=60950, lr=3.95673e-05, gnorm=1.936, clip=0, loss_scale=2048, train_wall=3, gb_free=15.3, wall=21040
2023-03-15 19:50:26 - progress_bar.py[line:272] - INFO: epoch 031:   1232 / 2004 loss=0.131, loss_v1=0, loss_v2=0, nll_loss=0.131, ntokens=308.4, nsentences=8, sample_size=308.4, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=904.8, ups=2.93, wpb=308.4, bsz=8, num_updates=60960, lr=3.95572e-05, gnorm=1.809, clip=0, loss_scale=2048, train_wall=3, gb_free=14.2, wall=21043
2023-03-15 19:50:29 - progress_bar.py[line:272] - INFO: epoch 031:   1242 / 2004 loss=0.14, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=390.3, nsentences=8, sample_size=390.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=1095.5, ups=2.81, wpb=390.3, bsz=8, num_updates=60970, lr=3.95472e-05, gnorm=2.042, clip=0, loss_scale=2048, train_wall=4, gb_free=14.8, wall=21047
2023-03-15 19:50:33 - progress_bar.py[line:272] - INFO: epoch 031:   1252 / 2004 loss=0.131, loss_v1=0, loss_v2=0, nll_loss=0.131, ntokens=345, nsentences=8, sample_size=345, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=977.9, ups=2.83, wpb=345, bsz=8, num_updates=60980, lr=3.95371e-05, gnorm=1.838, clip=0, loss_scale=2048, train_wall=3, gb_free=14.6, wall=21050
2023-03-15 19:50:36 - progress_bar.py[line:272] - INFO: epoch 031:   1262 / 2004 loss=0.125, loss_v1=0, loss_v2=0, nll_loss=0.125, ntokens=343.6, nsentences=8, sample_size=343.6, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=983.9, ups=2.86, wpb=343.6, bsz=8, num_updates=60990, lr=3.9527e-05, gnorm=1.676, clip=0, loss_scale=4096, train_wall=3, gb_free=14.9, wall=21054
2023-03-15 19:50:38 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2048.0
2023-03-15 19:50:40 - progress_bar.py[line:272] - INFO: epoch 031:   1273 / 2004 loss=0.124, loss_v1=0, loss_v2=0, nll_loss=0.124, ntokens=332.4, nsentences=8, sample_size=332.4, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=882.8, ups=2.66, wpb=332.4, bsz=8, num_updates=61000, lr=3.95169e-05, gnorm=1.7, clip=0, loss_scale=2048, train_wall=4, gb_free=15.5, wall=21058
