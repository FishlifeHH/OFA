2023-02-19 15:10:17 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmp9gfnowh3
2023-02-19 15:10:17 - instantiator.py[line:76] - INFO: Writing /tmp/tmp9gfnowh3/_remote_module_non_scriptable.py
2023-02-19 15:10:22 - utils.py[line:255] - INFO: distributed init (rank 0): env://
2023-02-19 15:10:22 - utils.py[line:261] - INFO: Start init
2023-02-19 15:10:22 - distributed_c10d.py[line:228] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2023-02-19 15:10:22 - distributed_c10d.py[line:262] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
2023-02-19 15:10:22 - utils.py[line:271] - INFO: initialized host autodl-container-21fe11863c-c7bb2435 as rank 0
single-machine distributed training is initialized.
2023-02-19 15:10:23 - train.py[line:77] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 8, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 500, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 8, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 2, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [4], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './stage1_checkpoints/2_0.06_2500', 'restore_file': '../../checkpoints/ofa_base.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 500, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': 1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'cider', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=8, batch_size_valid=8, best_checkpoint_metric='cider', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='../../dataset/caption_data/train.tsv,../../dataset/caption_data/val.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=4, distributed_port=-1, distributed_rank=0, distributed_world_size=4, drop_worst_after=2500, drop_worst_ratio=0.2, dropout=0.1, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"max_len_b":16,"no_repeat_ngram_size":3}', eval_bleu=False, eval_cider=True, eval_cider_cached_tokens='../../dataset/caption_data/cider_cached_tokens/coco-valid-words.p', eval_print_samples=False, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=True, freeze_encoder_embedding=True, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[1e-05], lr_scheduler='polynomial_decay', max_epoch=2, max_source_positions=1024, max_src_length=80, max_target_positions=1024, max_tgt_length=20, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=4, num_bins=1000, num_shards=1, num_workers=0, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=480, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='../../checkpoints/ofa_base.pt', sample_patch_num=196, save_dir='./stage1_checkpoints/2_0.06_2500', save_interval=1, save_interval_updates=500, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', scst=False, scst_args='{}', seed=1, selected_cols='0,4,2', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, sync_bn=False, task='caption', tensorboard_logdir=None, threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[4], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=500, wandb_project=None, warmup_ratio=0.06, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'caption', 'data': '../../dataset/caption_data/train.tsv,../../dataset/caption_data/val.tsv', 'selected_cols': '0,4,2', 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 80, 'max_tgt_length': 20, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'eval_bleu': False, 'eval_cider': True, 'eval_args': '{"beam":5,"max_len_b":16,"no_repeat_ngram_size":3}', 'eval_print_samples': False, 'eval_cider_cached_tokens': '../../dataset/caption_data/cider_cached_tokens/coco-valid-words.p', 'scst': False, 'scst_args': '{}'}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.2, 'drop_worst_after': 2500, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.06, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [1e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-02-19 15:10:23 - ofa_task.py[line:109] - INFO: source dictionary: 59457 types
2023-02-19 15:10:23 - ofa_task.py[line:110] - INFO: target dictionary: 59457 types
/root/miniconda3/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
2023-02-19 15:10:27 - train.py[line:110] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=59457, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2023-02-19 15:10:27 - train.py[line:111] - INFO: task: CaptionTask
2023-02-19 15:10:27 - train.py[line:112] - INFO: model: OFAModel
2023-02-19 15:10:27 - train.py[line:113] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2023-02-19 15:10:27 - train.py[line:114] - INFO: num. shared model params: 182,238,536 (num. trained: 136,575,560)
2023-02-19 15:10:27 - train.py[line:121] - INFO: num. expert model params: 0 (num. trained: 0)
local datafile ../../dataset/caption_data/val.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/caption_data/val.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/caption_data/val.tsv slice_id 0 row count 93274 total row count 93274
/root/miniconda3/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2023-02-19 15:10:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2023-02-19 15:10:34 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 1 workers***********************
2023-02-19 15:10:34 - utils.py[line:761] - INFO: rank   0: capabilities =  8.6  ; total memory = 23.688 GB ; name = NVIDIA RTX A5000                        
2023-02-19 15:10:34 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 1 workers***********************
2023-02-19 15:10:34 - train.py[line:152] - INFO: training on 1 devices (GPUs/TPUs)
2023-02-19 15:10:34 - train.py[line:157] - INFO: max tokens per device = None and max sentences per device = 8
2023-02-19 15:10:34 - trainer.py[line:458] - INFO: Preparing to load checkpoint ../../checkpoints/ofa_base.pt
2023-02-19 15:10:34 - trainer.py[line:624] - INFO: No existing checkpoint found ../../checkpoints/ofa_base.pt
2023-02-19 15:10:34 - trainer.py[line:639] - INFO: loading train data for epoch 1
local datafile ../../dataset/caption_data/train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/caption_data/train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/caption_data/train.tsv slice_id 0 row count 699143 total row count 699143
slice_id 0 seek offset 0
Total steps 43698, warmup steps 2621, warmup_factor 0.00038153376573826786
2023-02-19 15:11:23 - trainer.py[line:703] - INFO: begin training epoch 1
2023-02-19 15:11:23 - train.py[line:305] - INFO: Start iterating over samples
2023-02-19 15:11:43 - progress_bar.py[line:272] - INFO: epoch 001:     10 / 21849 loss=11.175, loss_v1=0, loss_v2=0, nll_loss=11.178, ntokens=972, nsentences=32, sample_size=972, sample_size_v1=0, sample_size_v2=0, ppl=2316.34, wps=559.9, ups=0.57, wpb=972, bsz=32, num_updates=10, lr=3.81534e-08, gnorm=13.678, clip=100, loss_scale=128, train_wall=20, gb_free=13.6, wall=69
2023-02-19 15:12:01 - progress_bar.py[line:272] - INFO: epoch 001:     20 / 21849 loss=11.153, loss_v1=0, loss_v2=0, nll_loss=11.154, ntokens=826.4, nsentences=32, sample_size=826.4, sample_size_v1=0, sample_size_v2=0, ppl=2277.97, wps=473, ups=0.57, wpb=826.4, bsz=32, num_updates=20, lr=7.63068e-08, gnorm=14.538, clip=100, loss_scale=128, train_wall=17, gb_free=13.7, wall=86
2023-02-19 15:12:18 - progress_bar.py[line:272] - INFO: epoch 001:     30 / 21849 loss=11.153, loss_v1=0, loss_v2=0, nll_loss=11.153, ntokens=881.9, nsentences=32, sample_size=881.9, sample_size_v1=0, sample_size_v2=0, ppl=2277.46, wps=504.7, ups=0.57, wpb=881.9, bsz=32, num_updates=30, lr=1.1446e-07, gnorm=13.298, clip=100, loss_scale=128, train_wall=17, gb_free=13.7, wall=104
2023-02-19 15:12:36 - progress_bar.py[line:272] - INFO: epoch 001:     40 / 21849 loss=11.15, loss_v1=0, loss_v2=0, nll_loss=11.151, ntokens=924.8, nsentences=32, sample_size=924.8, sample_size_v1=0, sample_size_v2=0, ppl=2273.75, wps=530.5, ups=0.57, wpb=924.8, bsz=32, num_updates=40, lr=1.52614e-07, gnorm=13.547, clip=100, loss_scale=128, train_wall=17, gb_free=13.6, wall=121
2023-02-19 15:12:53 - progress_bar.py[line:272] - INFO: epoch 001:     50 / 21849 loss=11.102, loss_v1=0, loss_v2=0, nll_loss=11.097, ntokens=831.5, nsentences=32, sample_size=831.5, sample_size_v1=0, sample_size_v2=0, ppl=2190.53, wps=477, ups=0.57, wpb=831.5, bsz=32, num_updates=50, lr=1.90767e-07, gnorm=13.824, clip=100, loss_scale=128, train_wall=17, gb_free=13.7, wall=139
2023-02-19 15:13:11 - progress_bar.py[line:272] - INFO: epoch 001:     60 / 21849 loss=11.076, loss_v1=0, loss_v2=0, nll_loss=11.068, ntokens=905.8, nsentences=32, sample_size=905.8, sample_size_v1=0, sample_size_v2=0, ppl=2147.28, wps=518.6, ups=0.57, wpb=905.8, bsz=32, num_updates=60, lr=2.2892e-07, gnorm=13.484, clip=100, loss_scale=128, train_wall=17, gb_free=13.6, wall=156
2023-02-19 15:13:28 - progress_bar.py[line:272] - INFO: epoch 001:     70 / 21849 loss=10.944, loss_v1=0, loss_v2=0, nll_loss=10.921, ntokens=807.1, nsentences=32, sample_size=807.1, sample_size_v1=0, sample_size_v2=0, ppl=1939.33, wps=460, ups=0.57, wpb=807.1, bsz=32, num_updates=70, lr=2.67074e-07, gnorm=15.145, clip=100, loss_scale=128, train_wall=17, gb_free=13.7, wall=174
2023-02-19 15:13:46 - progress_bar.py[line:272] - INFO: epoch 001:     80 / 21849 loss=10.903, loss_v1=0, loss_v2=0, nll_loss=10.875, ntokens=879.3, nsentences=31.9, sample_size=879.3, sample_size_v1=0, sample_size_v2=0, ppl=1878.53, wps=500.2, ups=0.57, wpb=879.3, bsz=31.9, num_updates=80, lr=3.05227e-07, gnorm=14.154, clip=100, loss_scale=128, train_wall=18, gb_free=13.6, wall=191
2023-02-19 15:14:03 - progress_bar.py[line:272] - INFO: epoch 001:     90 / 21849 loss=10.883, loss_v1=0, loss_v2=0, nll_loss=10.854, ntokens=898, nsentences=32, sample_size=898, sample_size_v1=0, sample_size_v2=0, ppl=1850.69, wps=512.6, ups=0.57, wpb=898, bsz=32, num_updates=90, lr=3.4338e-07, gnorm=12.304, clip=100, loss_scale=128, train_wall=17, gb_free=13.6, wall=209
2023-02-19 15:14:21 - progress_bar.py[line:272] - INFO: epoch 001:    100 / 21849 loss=10.873, loss_v1=0, loss_v2=0, nll_loss=10.843, ntokens=824.5, nsentences=32, sample_size=824.5, sample_size_v1=0, sample_size_v2=0, ppl=1836.68, wps=470.2, ups=0.57, wpb=824.5, bsz=32, num_updates=100, lr=3.81534e-07, gnorm=12.872, clip=100, loss_scale=128, train_wall=17, gb_free=13.6, wall=226
2023-02-19 15:14:38 - progress_bar.py[line:272] - INFO: epoch 001:    110 / 21849 loss=10.789, loss_v1=0, loss_v2=0, nll_loss=10.75, ntokens=829.4, nsentences=32, sample_size=829.4, sample_size_v1=0, sample_size_v2=0, ppl=1721.87, wps=471.8, ups=0.57, wpb=829.4, bsz=32, num_updates=110, lr=4.19687e-07, gnorm=12.52, clip=100, loss_scale=128, train_wall=18, gb_free=13.7, wall=244
2023-02-19 15:14:56 - progress_bar.py[line:272] - INFO: epoch 001:    120 / 21849 loss=10.693, loss_v1=0, loss_v2=0, nll_loss=10.642, ntokens=893.1, nsentences=32, sample_size=893.1, sample_size_v1=0, sample_size_v2=0, ppl=1598.14, wps=505.7, ups=0.57, wpb=893.1, bsz=32, num_updates=120, lr=4.57841e-07, gnorm=12.602, clip=100, loss_scale=128, train_wall=18, gb_free=13.6, wall=262
2023-02-19 15:15:14 - progress_bar.py[line:272] - INFO: epoch 001:    130 / 21849 loss=10.654, loss_v1=0, loss_v2=0, nll_loss=10.599, ntokens=918.6, nsentences=32, sample_size=918.6, sample_size_v1=0, sample_size_v2=0, ppl=1551.51, wps=522.5, ups=0.57, wpb=918.6, bsz=32, num_updates=130, lr=4.95994e-07, gnorm=12.132, clip=100, loss_scale=128, train_wall=18, gb_free=13.6, wall=279
2023-02-19 15:15:31 - progress_bar.py[line:272] - INFO: epoch 001:    140 / 21849 loss=10.449, loss_v1=0, loss_v2=0, nll_loss=10.371, ntokens=893.8, nsentences=32, sample_size=893.8, sample_size_v1=0, sample_size_v2=0, ppl=1324.6, wps=508.9, ups=0.57, wpb=893.8, bsz=32, num_updates=140, lr=5.34147e-07, gnorm=10.897, clip=100, loss_scale=128, train_wall=18, gb_free=13.5, wall=297
2023-02-19 15:15:48 - progress_bar.py[line:272] - INFO: epoch 001:    150 / 21849 loss=10.548, loss_v1=0, loss_v2=0, nll_loss=10.482, ntokens=916, nsentences=32, sample_size=916, sample_size_v1=0, sample_size_v2=0, ppl=1429.93, wps=525.8, ups=0.57, wpb=916, bsz=32, num_updates=150, lr=5.72301e-07, gnorm=11.464, clip=100, loss_scale=128, train_wall=17, gb_free=13.6, wall=314
2023-02-19 15:16:06 - progress_bar.py[line:272] - INFO: epoch 001:    160 / 21849 loss=10.542, loss_v1=0, loss_v2=0, nll_loss=10.475, ntokens=899.5, nsentences=32, sample_size=899.5, sample_size_v1=0, sample_size_v2=0, ppl=1422.98, wps=517.3, ups=0.58, wpb=899.5, bsz=32, num_updates=160, lr=6.10454e-07, gnorm=10.717, clip=100, loss_scale=128, train_wall=17, gb_free=13.6, wall=331
2023-02-19 15:16:23 - progress_bar.py[line:272] - INFO: epoch 001:    170 / 21849 loss=10.273, loss_v1=0, loss_v2=0, nll_loss=10.175, ntokens=864, nsentences=32, sample_size=864, sample_size_v1=0, sample_size_v2=0, ppl=1156.26, wps=498.7, ups=0.58, wpb=864, bsz=32, num_updates=170, lr=6.48607e-07, gnorm=13.03, clip=100, loss_scale=128, train_wall=17, gb_free=13.7, wall=349
2023-02-19 15:16:41 - progress_bar.py[line:272] - INFO: epoch 001:    180 / 21849 loss=10.276, loss_v1=0, loss_v2=0, nll_loss=10.179, ntokens=873.8, nsentences=32, sample_size=873.8, sample_size_v1=0, sample_size_v2=0, ppl=1158.9, wps=504.3, ups=0.58, wpb=873.8, bsz=32, num_updates=180, lr=6.86761e-07, gnorm=10.662, clip=100, loss_scale=128, train_wall=17, gb_free=13.6, wall=366
2023-02-19 15:16:58 - progress_bar.py[line:272] - INFO: epoch 001:    190 / 21849 loss=10.252, loss_v1=0, loss_v2=0, nll_loss=10.152, ntokens=947.2, nsentences=32, sample_size=947.2, sample_size_v1=0, sample_size_v2=0, ppl=1137.58, wps=545.6, ups=0.58, wpb=947.2, bsz=32, num_updates=190, lr=7.24914e-07, gnorm=9.841, clip=100, loss_scale=128, train_wall=17, gb_free=13.7, wall=383
2023-02-19 15:17:15 - progress_bar.py[line:272] - INFO: epoch 001:    200 / 21849 loss=10.216, loss_v1=0, loss_v2=0, nll_loss=10.112, ntokens=922.4, nsentences=32, sample_size=922.4, sample_size_v1=0, sample_size_v2=0, ppl=1106.91, wps=530.8, ups=0.58, wpb=922.4, bsz=32, num_updates=200, lr=7.63068e-07, gnorm=9.419, clip=100, loss_scale=128, train_wall=17, gb_free=13.6, wall=401
2023-02-19 15:17:33 - progress_bar.py[line:272] - INFO: epoch 001:    210 / 21849 loss=10.372, loss_v1=0, loss_v2=0, nll_loss=10.286, ntokens=948.9, nsentences=32, sample_size=948.9, sample_size_v1=0, sample_size_v2=0, ppl=1248.39, wps=546, ups=0.58, wpb=948.9, bsz=32, num_updates=210, lr=8.01221e-07, gnorm=9.43, clip=100, loss_scale=128, train_wall=17, gb_free=13.6, wall=418
2023-02-19 15:17:50 - progress_bar.py[line:272] - INFO: epoch 001:    220 / 21849 loss=10.245, loss_v1=0, loss_v2=0, nll_loss=10.144, ntokens=919.7, nsentences=32, sample_size=919.7, sample_size_v1=0, sample_size_v2=0, ppl=1131.78, wps=529.5, ups=0.58, wpb=919.7, bsz=32, num_updates=220, lr=8.39374e-07, gnorm=9.071, clip=100, loss_scale=128, train_wall=17, gb_free=13.7, wall=436
2023-02-19 15:18:07 - progress_bar.py[line:272] - INFO: epoch 001:    230 / 21849 loss=9.934, loss_v1=0, loss_v2=0, nll_loss=9.799, ntokens=776.5, nsentences=32, sample_size=776.5, sample_size_v1=0, sample_size_v2=0, ppl=890.63, wps=446.5, ups=0.57, wpb=776.5, bsz=32, num_updates=230, lr=8.77528e-07, gnorm=10.014, clip=100, loss_scale=128, train_wall=17, gb_free=13.6, wall=453
2023-02-19 15:18:25 - progress_bar.py[line:272] - INFO: epoch 001:    240 / 21849 loss=10.185, loss_v1=0, loss_v2=0, nll_loss=10.077, ntokens=893.7, nsentences=32, sample_size=893.7, sample_size_v1=0, sample_size_v2=0, ppl=1080.35, wps=514.2, ups=0.58, wpb=893.7, bsz=32, num_updates=240, lr=9.15681e-07, gnorm=9.428, clip=100, loss_scale=128, train_wall=17, gb_free=13.7, wall=470
2023-02-19 15:18:42 - progress_bar.py[line:272] - INFO: epoch 001:    250 / 21849 loss=10.324, loss_v1=0, loss_v2=0, nll_loss=10.232, ntokens=1001.9, nsentences=32, sample_size=1001.9, sample_size_v1=0, sample_size_v2=0, ppl=1203, wps=575.9, ups=0.57, wpb=1001.9, bsz=32, num_updates=250, lr=9.53834e-07, gnorm=8.873, clip=100, loss_scale=128, train_wall=17, gb_free=13.6, wall=488
2023-02-19 15:19:00 - progress_bar.py[line:272] - INFO: epoch 001:    260 / 21849 loss=10.107, loss_v1=0, loss_v2=0, nll_loss=9.991, ntokens=915.1, nsentences=32, sample_size=915.1, sample_size_v1=0, sample_size_v2=0, ppl=1017.37, wps=527.6, ups=0.58, wpb=915.1, bsz=32, num_updates=260, lr=9.91988e-07, gnorm=9.01, clip=100, loss_scale=128, train_wall=17, gb_free=13.7, wall=505
2023-02-19 15:19:17 - progress_bar.py[line:272] - INFO: epoch 001:    270 / 21849 loss=10.047, loss_v1=0, loss_v2=0, nll_loss=9.924, ntokens=640.7, nsentences=32, sample_size=640.7, sample_size_v1=0, sample_size_v2=0, ppl=971.26, wps=369.3, ups=0.58, wpb=640.7, bsz=32, num_updates=270, lr=1.03014e-06, gnorm=10.674, clip=100, loss_scale=128, train_wall=17, gb_free=13.7, wall=522
2023-02-19 15:19:34 - progress_bar.py[line:272] - INFO: epoch 001:    280 / 21849 loss=9.9, loss_v1=0, loss_v2=0, nll_loss=9.76, ntokens=661.6, nsentences=32, sample_size=661.6, sample_size_v1=0, sample_size_v2=0, ppl=867.31, wps=382.3, ups=0.58, wpb=661.6, bsz=32, num_updates=280, lr=1.06829e-06, gnorm=9.281, clip=100, loss_scale=128, train_wall=17, gb_free=13.7, wall=540
2023-02-19 15:19:52 - progress_bar.py[line:272] - INFO: epoch 001:    290 / 21849 loss=10.13, loss_v1=0, loss_v2=0, nll_loss=10.017, ntokens=862.8, nsentences=32, sample_size=862.8, sample_size_v1=0, sample_size_v2=0, ppl=1036, wps=497.3, ups=0.58, wpb=862.8, bsz=32, num_updates=290, lr=1.10645e-06, gnorm=8.09, clip=100, loss_scale=128, train_wall=17, gb_free=13.7, wall=557
2023-02-19 15:20:09 - progress_bar.py[line:272] - INFO: epoch 001:    300 / 21849 loss=9.84, loss_v1=0, loss_v2=0, nll_loss=9.694, ntokens=869.7, nsentences=32, sample_size=869.7, sample_size_v1=0, sample_size_v2=0, ppl=828.48, wps=500.4, ups=0.58, wpb=869.7, bsz=32, num_updates=300, lr=1.1446e-06, gnorm=7.656, clip=100, loss_scale=128, train_wall=17, gb_free=13.7, wall=574
2023-02-19 15:20:26 - progress_bar.py[line:272] - INFO: epoch 001:    310 / 21849 loss=10.145, loss_v1=0, loss_v2=0, nll_loss=10.033, ntokens=967, nsentences=32, sample_size=967, sample_size_v1=0, sample_size_v2=0, ppl=1047.76, wps=555.4, ups=0.57, wpb=967, bsz=32, num_updates=310, lr=1.18275e-06, gnorm=7.466, clip=100, loss_scale=128, train_wall=17, gb_free=13.6, wall=592
2023-02-19 15:20:44 - progress_bar.py[line:272] - INFO: epoch 001:    320 / 21849 loss=10.061, loss_v1=0, loss_v2=0, nll_loss=9.94, ntokens=970.6, nsentences=32, sample_size=970.6, sample_size_v1=0, sample_size_v2=0, ppl=981.99, wps=557.7, ups=0.57, wpb=970.6, bsz=32, num_updates=320, lr=1.22091e-06, gnorm=7.354, clip=100, loss_scale=128, train_wall=17, gb_free=13.7, wall=609
2023-02-19 15:21:01 - progress_bar.py[line:272] - INFO: epoch 001:    330 / 21849 loss=9.646, loss_v1=0, loss_v2=0, nll_loss=9.478, ntokens=899.2, nsentences=32, sample_size=899.2, sample_size_v1=0, sample_size_v2=0, ppl=713.35, wps=517.5, ups=0.58, wpb=899.2, bsz=32, num_updates=330, lr=1.25906e-06, gnorm=7.833, clip=100, loss_scale=128, train_wall=17, gb_free=13.7, wall=627
2023-02-19 15:21:18 - progress_bar.py[line:272] - INFO: epoch 001:    340 / 21849 loss=9.232, loss_v1=0, loss_v2=0, nll_loss=9.017, ntokens=792, nsentences=32, sample_size=792, sample_size_v1=0, sample_size_v2=0, ppl=517.96, wps=455.8, ups=0.58, wpb=792, bsz=32, num_updates=340, lr=1.29721e-06, gnorm=7.666, clip=100, loss_scale=128, train_wall=17, gb_free=13.7, wall=644
2023-02-19 15:21:36 - progress_bar.py[line:272] - INFO: epoch 001:    350 / 21849 loss=9.876, loss_v1=0, loss_v2=0, nll_loss=9.733, ntokens=899.2, nsentences=32, sample_size=899.2, sample_size_v1=0, sample_size_v2=0, ppl=851.21, wps=516.1, ups=0.57, wpb=899.2, bsz=32, num_updates=350, lr=1.33537e-06, gnorm=7.278, clip=100, loss_scale=128, train_wall=17, gb_free=13.6, wall=661
2023-02-19 15:21:53 - progress_bar.py[line:272] - INFO: epoch 001:    360 / 21849 loss=9.916, loss_v1=0, loss_v2=0, nll_loss=9.777, ntokens=919.6, nsentences=32, sample_size=919.6, sample_size_v1=0, sample_size_v2=0, ppl=877.65, wps=530.1, ups=0.58, wpb=919.6, bsz=32, num_updates=360, lr=1.37352e-06, gnorm=6.683, clip=100, loss_scale=128, train_wall=17, gb_free=13.7, wall=679
2023-02-19 15:22:11 - progress_bar.py[line:272] - INFO: epoch 001:    370 / 21849 loss=9.598, loss_v1=0, loss_v2=0, nll_loss=9.424, ntokens=746.5, nsentences=32, sample_size=746.5, sample_size_v1=0, sample_size_v2=0, ppl=686.79, wps=431.4, ups=0.58, wpb=746.5, bsz=32, num_updates=370, lr=1.41167e-06, gnorm=7.675, clip=100, loss_scale=128, train_wall=17, gb_free=13.7, wall=696
2023-02-19 15:22:28 - progress_bar.py[line:272] - INFO: epoch 001:    380 / 21849 loss=9.738, loss_v1=0, loss_v2=0, nll_loss=9.58, ntokens=931, nsentences=32, sample_size=931, sample_size_v1=0, sample_size_v2=0, ppl=765.47, wps=537.1, ups=0.58, wpb=931, bsz=32, num_updates=380, lr=1.44983e-06, gnorm=6.328, clip=100, loss_scale=128, train_wall=17, gb_free=13.6, wall=713
2023-02-19 15:22:45 - progress_bar.py[line:272] - INFO: epoch 001:    390 / 21849 loss=9.426, loss_v1=0, loss_v2=0, nll_loss=9.233, ntokens=830.8, nsentences=32, sample_size=830.8, sample_size_v1=0, sample_size_v2=0, ppl=601.93, wps=480, ups=0.58, wpb=830.8, bsz=32, num_updates=390, lr=1.48798e-06, gnorm=6.434, clip=100, loss_scale=128, train_wall=17, gb_free=13.7, wall=731
2023-02-19 15:23:03 - progress_bar.py[line:272] - INFO: epoch 001:    400 / 21849 loss=9.464, loss_v1=0, loss_v2=0, nll_loss=9.275, ntokens=812.2, nsentences=32, sample_size=812.2, sample_size_v1=0, sample_size_v2=0, ppl=619.5, wps=469.7, ups=0.58, wpb=812.2, bsz=32, num_updates=400, lr=1.52614e-06, gnorm=6.357, clip=100, loss_scale=128, train_wall=17, gb_free=13.7, wall=748
2023-02-19 15:23:20 - progress_bar.py[line:272] - INFO: epoch 001:    410 / 21849 loss=9.681, loss_v1=0, loss_v2=0, nll_loss=9.515, ntokens=928.7, nsentences=32, sample_size=928.7, sample_size_v1=0, sample_size_v2=0, ppl=731.89, wps=536.5, ups=0.58, wpb=928.7, bsz=32, num_updates=410, lr=1.56429e-06, gnorm=6.427, clip=100, loss_scale=128, train_wall=17, gb_free=13.6, wall=765
2023-02-19 15:23:37 - progress_bar.py[line:272] - INFO: epoch 001:    420 / 21849 loss=9.095, loss_v1=0, loss_v2=0, nll_loss=8.865, ntokens=856.3, nsentences=32, sample_size=856.3, sample_size_v1=0, sample_size_v2=0, ppl=466.13, wps=493.8, ups=0.58, wpb=856.3, bsz=32, num_updates=420, lr=1.60244e-06, gnorm=5.488, clip=100, loss_scale=128, train_wall=17, gb_free=13.7, wall=783
2023-02-19 15:23:54 - progress_bar.py[line:272] - INFO: epoch 001:    430 / 21849 loss=8.804, loss_v1=0, loss_v2=0, nll_loss=8.54, ntokens=753.2, nsentences=32, sample_size=753.2, sample_size_v1=0, sample_size_v2=0, ppl=372.26, wps=434.6, ups=0.58, wpb=753.2, bsz=32, num_updates=430, lr=1.6406e-06, gnorm=6.176, clip=100, loss_scale=128, train_wall=17, gb_free=13.7, wall=800
2023-02-19 15:24:12 - progress_bar.py[line:272] - INFO: epoch 001:    440 / 21849 loss=9.568, loss_v1=0, loss_v2=0, nll_loss=9.389, ntokens=865.4, nsentences=32, sample_size=865.4, sample_size_v1=0, sample_size_v2=0, ppl=670.41, wps=498.8, ups=0.58, wpb=865.4, bsz=32, num_updates=440, lr=1.67875e-06, gnorm=5.836, clip=100, loss_scale=128, train_wall=17, gb_free=13.7, wall=817
2023-02-19 15:24:29 - progress_bar.py[line:272] - INFO: epoch 001:    450 / 21849 loss=9.588, loss_v1=0, loss_v2=0, nll_loss=9.412, ntokens=862.8, nsentences=32, sample_size=862.8, sample_size_v1=0, sample_size_v2=0, ppl=681.26, wps=496.5, ups=0.58, wpb=862.8, bsz=32, num_updates=450, lr=1.7169e-06, gnorm=5.723, clip=100, loss_scale=128, train_wall=17, gb_free=13.6, wall=835
2023-02-19 15:24:47 - progress_bar.py[line:272] - INFO: epoch 001:    460 / 21849 loss=9.859, loss_v1=0, loss_v2=0, nll_loss=9.713, ntokens=940.4, nsentences=32, sample_size=940.4, sample_size_v1=0, sample_size_v2=0, ppl=839.28, wps=540.8, ups=0.58, wpb=940.4, bsz=32, num_updates=460, lr=1.75506e-06, gnorm=5.779, clip=100, loss_scale=128, train_wall=17, gb_free=13.6, wall=852
2023-02-19 15:25:04 - progress_bar.py[line:272] - INFO: epoch 001:    470 / 21849 loss=9.512, loss_v1=0, loss_v2=0, nll_loss=9.328, ntokens=892.9, nsentences=32, sample_size=892.9, sample_size_v1=0, sample_size_v2=0, ppl=642.64, wps=513.7, ups=0.58, wpb=892.9, bsz=32, num_updates=470, lr=1.79321e-06, gnorm=5.7, clip=100, loss_scale=128, train_wall=17, gb_free=13.6, wall=870
2023-02-19 15:25:21 - progress_bar.py[line:272] - INFO: epoch 001:    480 / 21849 loss=9.498, loss_v1=0, loss_v2=0, nll_loss=9.313, ntokens=892.8, nsentences=32, sample_size=892.8, sample_size_v1=0, sample_size_v2=0, ppl=636.05, wps=513.9, ups=0.58, wpb=892.8, bsz=32, num_updates=480, lr=1.83136e-06, gnorm=5.624, clip=100, loss_scale=128, train_wall=17, gb_free=13.6, wall=887
2023-02-19 15:25:39 - progress_bar.py[line:272] - INFO: epoch 001:    490 / 21849 loss=9.605, loss_v1=0, loss_v2=0, nll_loss=9.432, ntokens=882.2, nsentences=32, sample_size=882.2, sample_size_v1=0, sample_size_v2=0, ppl=690.93, wps=508.3, ups=0.58, wpb=882.2, bsz=32, num_updates=490, lr=1.86952e-06, gnorm=5.614, clip=100, loss_scale=128, train_wall=17, gb_free=13.5, wall=904
2023-02-19 15:25:56 - progress_bar.py[line:272] - INFO: epoch 001:    500 / 21849 loss=9.746, loss_v1=0, loss_v2=0, nll_loss=9.589, ntokens=934.3, nsentences=32, sample_size=934.3, sample_size_v1=0, sample_size_v2=0, ppl=770.07, wps=536.9, ups=0.57, wpb=934.3, bsz=32, num_updates=500, lr=1.90767e-06, gnorm=5.816, clip=100, loss_scale=128, train_wall=17, gb_free=13.7, wall=922
2023-02-19 15:25:56 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
/root/autodl-tmp/OFA/fairseq/fairseq/search.py:140: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  beams_buf = indices_buf // vocab_size
/root/autodl-tmp/OFA/models/sequence_generator.py:705: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  unfin_idx = bbsz_idx // beam_size
2023-02-19 16:35:16 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 9.65 | loss_v1 0 | loss_v2 0 | nll_loss 9.481 | ntokens 600.688 | nsentences 7.999 | sample_size 600.688 | sample_size_v1 0 | sample_size_v2 0 | ppl 714.71 | cider 0 | wps 1683.8 | wpb 600.7 | bsz 8 | num_updates 500
2023-02-19 16:35:16 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 500 updates
2023-02-19 16:35:16 - trainer.py[line:431] - INFO: Saving checkpoint to ./stage1_checkpoints/2_0.06_2500/checkpoint_1_500.pt
2023-02-19 16:35:19 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./stage1_checkpoints/2_0.06_2500/checkpoint_1_500.pt
2023-02-19 16:35:22 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./stage1_checkpoints/2_0.06_2500/checkpoint_1_500.pt (epoch 1 @ 500 updates, score 0.0) (writing took 5.64121700450778 seconds)
2023-02-19 16:35:39 - progress_bar.py[line:272] - INFO: epoch 001:    510 / 21849 loss=9.444, loss_v1=0, loss_v2=0, nll_loss=9.253, ntokens=968.2, nsentences=32, sample_size=968.2, sample_size_v1=0, sample_size_v2=0, ppl=610.17, wps=2.3, ups=0, wpb=968.2, bsz=32, num_updates=510, lr=1.94582e-06, gnorm=5.288, clip=100, loss_scale=128, train_wall=17, gb_free=13.7, wall=5105
2023-02-19 16:35:56 - progress_bar.py[line:272] - INFO: epoch 001:    520 / 21849 loss=9.512, loss_v1=0, loss_v2=0, nll_loss=9.328, ntokens=856.3, nsentences=32, sample_size=856.3, sample_size_v1=0, sample_size_v2=0, ppl=642.71, wps=495.1, ups=0.58, wpb=856.3, bsz=32, num_updates=520, lr=1.98398e-06, gnorm=5.346, clip=100, loss_scale=256, train_wall=17, gb_free=13.7, wall=5122
2023-02-19 16:36:14 - progress_bar.py[line:272] - INFO: epoch 001:    530 / 21849 loss=9.194, loss_v1=0, loss_v2=0, nll_loss=8.974, ntokens=730.9, nsentences=32, sample_size=730.9, sample_size_v1=0, sample_size_v2=0, ppl=502.97, wps=421.7, ups=0.58, wpb=730.9, bsz=32, num_updates=530, lr=2.02213e-06, gnorm=5.782, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=5139
2023-02-19 16:36:31 - progress_bar.py[line:272] - INFO: epoch 001:    540 / 21849 loss=9.275, loss_v1=0, loss_v2=0, nll_loss=9.066, ntokens=835.5, nsentences=32, sample_size=835.5, sample_size_v1=0, sample_size_v2=0, ppl=535.85, wps=480.7, ups=0.58, wpb=835.5, bsz=32, num_updates=540, lr=2.06028e-06, gnorm=5.64, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=5157
2023-02-19 16:36:48 - progress_bar.py[line:272] - INFO: epoch 001:    550 / 21849 loss=9.598, loss_v1=0, loss_v2=0, nll_loss=9.424, ntokens=950.2, nsentences=32, sample_size=950.2, sample_size_v1=0, sample_size_v2=0, ppl=686.9, wps=545.6, ups=0.57, wpb=950.2, bsz=32, num_updates=550, lr=2.09844e-06, gnorm=5.327, clip=100, loss_scale=256, train_wall=17, gb_free=13.7, wall=5174
2023-02-19 16:37:06 - progress_bar.py[line:272] - INFO: epoch 001:    560 / 21849 loss=9.33, loss_v1=0, loss_v2=0, nll_loss=9.125, ntokens=878.5, nsentences=32, sample_size=878.5, sample_size_v1=0, sample_size_v2=0, ppl=558.5, wps=504.8, ups=0.57, wpb=878.5, bsz=32, num_updates=560, lr=2.13659e-06, gnorm=5.434, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=5191
2023-02-19 16:37:23 - progress_bar.py[line:272] - INFO: epoch 001:    570 / 21849 loss=10.061, loss_v1=0, loss_v2=0, nll_loss=9.938, ntokens=904.9, nsentences=32, sample_size=904.9, sample_size_v1=0, sample_size_v2=0, ppl=981.26, wps=522, ups=0.58, wpb=904.9, bsz=32, num_updates=570, lr=2.17474e-06, gnorm=5.917, clip=100, loss_scale=256, train_wall=17, gb_free=13.5, wall=5209
2023-02-19 16:37:41 - progress_bar.py[line:272] - INFO: epoch 001:    580 / 21849 loss=9.621, loss_v1=0, loss_v2=0, nll_loss=9.449, ntokens=972.8, nsentences=32, sample_size=972.8, sample_size_v1=0, sample_size_v2=0, ppl=699.1, wps=559, ups=0.57, wpb=972.8, bsz=32, num_updates=580, lr=2.2129e-06, gnorm=5.792, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=5226
2023-02-19 16:37:58 - progress_bar.py[line:272] - INFO: epoch 001:    590 / 21849 loss=9.619, loss_v1=0, loss_v2=0, nll_loss=9.448, ntokens=1003.9, nsentences=32, sample_size=1003.9, sample_size_v1=0, sample_size_v2=0, ppl=698.36, wps=577.8, ups=0.58, wpb=1003.9, bsz=32, num_updates=590, lr=2.25105e-06, gnorm=5.222, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=5244
2023-02-19 16:38:15 - progress_bar.py[line:272] - INFO: epoch 001:    600 / 21849 loss=9.451, loss_v1=0, loss_v2=0, nll_loss=9.261, ntokens=952.1, nsentences=32, sample_size=952.1, sample_size_v1=0, sample_size_v2=0, ppl=613.42, wps=548.7, ups=0.58, wpb=952.1, bsz=32, num_updates=600, lr=2.2892e-06, gnorm=5.142, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=5261
2023-02-19 16:38:33 - progress_bar.py[line:272] - INFO: epoch 001:    610 / 21849 loss=9.142, loss_v1=0, loss_v2=0, nll_loss=8.918, ntokens=876, nsentences=32, sample_size=876, sample_size_v1=0, sample_size_v2=0, ppl=483.56, wps=503.3, ups=0.57, wpb=876, bsz=32, num_updates=610, lr=2.32736e-06, gnorm=6.167, clip=100, loss_scale=256, train_wall=17, gb_free=13.7, wall=5278
2023-02-19 16:38:50 - progress_bar.py[line:272] - INFO: epoch 001:    620 / 21849 loss=8.872, loss_v1=0, loss_v2=0, nll_loss=8.617, ntokens=855.6, nsentences=32, sample_size=855.6, sample_size_v1=0, sample_size_v2=0, ppl=392.67, wps=492.5, ups=0.58, wpb=855.6, bsz=32, num_updates=620, lr=2.36551e-06, gnorm=5.537, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=5296
2023-02-19 16:39:07 - progress_bar.py[line:272] - INFO: epoch 001:    630 / 21849 loss=9.374, loss_v1=0, loss_v2=0, nll_loss=9.175, ntokens=920.4, nsentences=32, sample_size=920.4, sample_size_v1=0, sample_size_v2=0, ppl=578, wps=530.1, ups=0.58, wpb=920.4, bsz=32, num_updates=630, lr=2.40366e-06, gnorm=5.634, clip=100, loss_scale=256, train_wall=17, gb_free=13.7, wall=5313
2023-02-19 16:39:25 - progress_bar.py[line:272] - INFO: epoch 001:    640 / 21849 loss=9.271, loss_v1=0, loss_v2=0, nll_loss=9.059, ntokens=817.8, nsentences=32, sample_size=817.8, sample_size_v1=0, sample_size_v2=0, ppl=533.51, wps=472.9, ups=0.58, wpb=817.8, bsz=32, num_updates=640, lr=2.44182e-06, gnorm=5.353, clip=100, loss_scale=256, train_wall=17, gb_free=13.7, wall=5330
2023-02-19 16:39:42 - progress_bar.py[line:272] - INFO: epoch 001:    650 / 21849 loss=9.196, loss_v1=0, loss_v2=0, nll_loss=8.976, ntokens=916.7, nsentences=32, sample_size=916.7, sample_size_v1=0, sample_size_v2=0, ppl=503.57, wps=525.7, ups=0.57, wpb=916.7, bsz=32, num_updates=650, lr=2.47997e-06, gnorm=5.387, clip=100, loss_scale=256, train_wall=17, gb_free=13.7, wall=5348
2023-02-19 16:40:00 - progress_bar.py[line:272] - INFO: epoch 001:    660 / 21849 loss=9.13, loss_v1=0, loss_v2=0, nll_loss=8.904, ntokens=764, nsentences=32, sample_size=764, sample_size_v1=0, sample_size_v2=0, ppl=479.07, wps=439.8, ups=0.58, wpb=764, bsz=32, num_updates=660, lr=2.51812e-06, gnorm=6.256, clip=100, loss_scale=256, train_wall=17, gb_free=13.7, wall=5365
2023-02-19 16:40:17 - progress_bar.py[line:272] - INFO: epoch 001:    670 / 21849 loss=9.38, loss_v1=0, loss_v2=0, nll_loss=9.182, ntokens=981.3, nsentences=32, sample_size=981.3, sample_size_v1=0, sample_size_v2=0, ppl=580.95, wps=565.1, ups=0.58, wpb=981.3, bsz=32, num_updates=670, lr=2.55628e-06, gnorm=5.049, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=5383
2023-02-19 16:40:34 - progress_bar.py[line:272] - INFO: epoch 001:    680 / 21849 loss=9.168, loss_v1=0, loss_v2=0, nll_loss=8.947, ntokens=820.1, nsentences=32, sample_size=820.1, sample_size_v1=0, sample_size_v2=0, ppl=493.59, wps=474.3, ups=0.58, wpb=820.1, bsz=32, num_updates=680, lr=2.59443e-06, gnorm=5.648, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=5400
2023-02-19 16:40:52 - progress_bar.py[line:272] - INFO: epoch 001:    690 / 21849 loss=9.381, loss_v1=0, loss_v2=0, nll_loss=9.183, ntokens=869.4, nsentences=32, sample_size=869.4, sample_size_v1=0, sample_size_v2=0, ppl=581.18, wps=502.5, ups=0.58, wpb=869.4, bsz=32, num_updates=690, lr=2.63258e-06, gnorm=5.831, clip=100, loss_scale=256, train_wall=17, gb_free=13.7, wall=5417
2023-02-19 16:41:09 - progress_bar.py[line:272] - INFO: epoch 001:    700 / 21849 loss=8.694, loss_v1=0, loss_v2=0, nll_loss=8.419, ntokens=873.9, nsentences=32, sample_size=873.9, sample_size_v1=0, sample_size_v2=0, ppl=342.33, wps=503.7, ups=0.58, wpb=873.9, bsz=32, num_updates=700, lr=2.67074e-06, gnorm=5.56, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=5434
2023-02-19 16:41:26 - progress_bar.py[line:272] - INFO: epoch 001:    710 / 21849 loss=9.301, loss_v1=0, loss_v2=0, nll_loss=9.094, ntokens=921.4, nsentences=32, sample_size=921.4, sample_size_v1=0, sample_size_v2=0, ppl=546.3, wps=530.3, ups=0.58, wpb=921.4, bsz=32, num_updates=710, lr=2.70889e-06, gnorm=5.416, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=5452
2023-02-19 16:41:44 - progress_bar.py[line:272] - INFO: epoch 001:    720 / 21849 loss=9.251, loss_v1=0, loss_v2=0, nll_loss=9.038, ntokens=842.3, nsentences=32, sample_size=842.3, sample_size_v1=0, sample_size_v2=0, ppl=525.65, wps=483.5, ups=0.57, wpb=842.3, bsz=32, num_updates=720, lr=2.74704e-06, gnorm=5.981, clip=100, loss_scale=256, train_wall=17, gb_free=13.7, wall=5469
2023-02-19 16:42:01 - progress_bar.py[line:272] - INFO: epoch 001:    730 / 21849 loss=8.966, loss_v1=0, loss_v2=0, nll_loss=8.721, ntokens=934.8, nsentences=32, sample_size=934.8, sample_size_v1=0, sample_size_v2=0, ppl=421.99, wps=538.6, ups=0.58, wpb=934.8, bsz=32, num_updates=730, lr=2.7852e-06, gnorm=5.37, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=5487
2023-02-19 16:42:18 - progress_bar.py[line:272] - INFO: epoch 001:    740 / 21849 loss=9.934, loss_v1=0, loss_v2=0, nll_loss=9.798, ntokens=1000, nsentences=32, sample_size=1000, sample_size_v1=0, sample_size_v2=0, ppl=890.25, wps=575.3, ups=0.58, wpb=1000, bsz=32, num_updates=740, lr=2.82335e-06, gnorm=5.987, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=5504
2023-02-19 16:42:36 - progress_bar.py[line:272] - INFO: epoch 001:    750 / 21849 loss=8.595, loss_v1=0, loss_v2=0, nll_loss=8.31, ntokens=794, nsentences=32, sample_size=794, sample_size_v1=0, sample_size_v2=0, ppl=317.29, wps=455.3, ups=0.57, wpb=794, bsz=32, num_updates=750, lr=2.8615e-06, gnorm=6.612, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=5521
2023-02-19 16:42:53 - progress_bar.py[line:272] - INFO: epoch 001:    760 / 21849 loss=9.336, loss_v1=0, loss_v2=0, nll_loss=9.133, ntokens=933.6, nsentences=32, sample_size=933.6, sample_size_v1=0, sample_size_v2=0, ppl=561.55, wps=535.4, ups=0.57, wpb=933.6, bsz=32, num_updates=760, lr=2.89966e-06, gnorm=5.706, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=5539
2023-02-19 16:43:11 - progress_bar.py[line:272] - INFO: epoch 001:    770 / 21849 loss=8.342, loss_v1=0, loss_v2=0, nll_loss=8.029, ntokens=781, nsentences=32, sample_size=781, sample_size_v1=0, sample_size_v2=0, ppl=261.15, wps=450, ups=0.58, wpb=781, bsz=32, num_updates=770, lr=2.93781e-06, gnorm=6.544, clip=100, loss_scale=256, train_wall=17, gb_free=13.7, wall=5556
2023-02-19 16:43:28 - progress_bar.py[line:272] - INFO: epoch 001:    780 / 21849 loss=9.557, loss_v1=0, loss_v2=0, nll_loss=9.378, ntokens=938.1, nsentences=32, sample_size=938.1, sample_size_v1=0, sample_size_v2=0, ppl=665.39, wps=540.1, ups=0.58, wpb=938.1, bsz=32, num_updates=780, lr=2.97596e-06, gnorm=6.197, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=5574
2023-02-19 16:43:45 - progress_bar.py[line:272] - INFO: epoch 001:    790 / 21849 loss=8.962, loss_v1=0, loss_v2=0, nll_loss=8.716, ntokens=946.5, nsentences=32, sample_size=946.5, sample_size_v1=0, sample_size_v2=0, ppl=420.65, wps=545.3, ups=0.58, wpb=946.5, bsz=32, num_updates=790, lr=3.01412e-06, gnorm=5.956, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=5591
2023-02-19 16:44:03 - progress_bar.py[line:272] - INFO: epoch 001:    800 / 21849 loss=8.892, loss_v1=0, loss_v2=0, nll_loss=8.639, ntokens=879.1, nsentences=32, sample_size=879.1, sample_size_v1=0, sample_size_v2=0, ppl=398.71, wps=506.6, ups=0.58, wpb=879.1, bsz=32, num_updates=800, lr=3.05227e-06, gnorm=6.178, clip=100, loss_scale=256, train_wall=17, gb_free=13.7, wall=5608
2023-02-19 16:44:20 - progress_bar.py[line:272] - INFO: epoch 001:    810 / 21849 loss=8.055, loss_v1=0, loss_v2=0, nll_loss=7.708, ntokens=825.6, nsentences=32, sample_size=825.6, sample_size_v1=0, sample_size_v2=0, ppl=209.13, wps=475.5, ups=0.58, wpb=825.6, bsz=32, num_updates=810, lr=3.09042e-06, gnorm=6.379, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=5626
2023-02-19 16:44:37 - progress_bar.py[line:272] - INFO: epoch 001:    820 / 21849 loss=8.57, loss_v1=0, loss_v2=0, nll_loss=8.281, ntokens=896, nsentences=32, sample_size=896, sample_size_v1=0, sample_size_v2=0, ppl=311.14, wps=516, ups=0.58, wpb=896, bsz=32, num_updates=820, lr=3.12858e-06, gnorm=6.378, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=5643
2023-02-19 16:44:55 - progress_bar.py[line:272] - INFO: epoch 001:    830 / 21849 loss=8.468, loss_v1=0, loss_v2=0, nll_loss=8.167, ntokens=882.7, nsentences=32, sample_size=882.7, sample_size_v1=0, sample_size_v2=0, ppl=287.41, wps=508.1, ups=0.58, wpb=882.7, bsz=32, num_updates=830, lr=3.16673e-06, gnorm=6.998, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=5660
2023-02-19 16:45:12 - progress_bar.py[line:272] - INFO: epoch 001:    840 / 21849 loss=8.637, loss_v1=0, loss_v2=0, nll_loss=8.354, ntokens=908.7, nsentences=32, sample_size=908.7, sample_size_v1=0, sample_size_v2=0, ppl=327.23, wps=521.7, ups=0.57, wpb=908.7, bsz=32, num_updates=840, lr=3.20488e-06, gnorm=6.354, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=5678
2023-02-19 16:45:30 - progress_bar.py[line:272] - INFO: epoch 001:    850 / 21849 loss=9.206, loss_v1=0, loss_v2=0, nll_loss=8.987, ntokens=922.7, nsentences=32, sample_size=922.7, sample_size_v1=0, sample_size_v2=0, ppl=507.47, wps=531, ups=0.58, wpb=922.7, bsz=32, num_updates=850, lr=3.24304e-06, gnorm=6.94, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=5695
2023-02-19 16:45:47 - progress_bar.py[line:272] - INFO: epoch 001:    860 / 21849 loss=8.693, loss_v1=0, loss_v2=0, nll_loss=8.416, ntokens=883.8, nsentences=32, sample_size=883.8, sample_size_v1=0, sample_size_v2=0, ppl=341.62, wps=506, ups=0.57, wpb=883.8, bsz=32, num_updates=860, lr=3.28119e-06, gnorm=7.027, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=5713
2023-02-19 16:46:04 - progress_bar.py[line:272] - INFO: epoch 001:    870 / 21849 loss=9.266, loss_v1=0, loss_v2=0, nll_loss=9.054, ntokens=1018.1, nsentences=32, sample_size=1018.1, sample_size_v1=0, sample_size_v2=0, ppl=531.62, wps=586.6, ups=0.58, wpb=1018.1, bsz=32, num_updates=870, lr=3.31934e-06, gnorm=6.12, clip=100, loss_scale=256, train_wall=17, gb_free=13.5, wall=5730
2023-02-19 16:46:22 - progress_bar.py[line:272] - INFO: epoch 001:    880 / 21849 loss=8.537, loss_v1=0, loss_v2=0, nll_loss=8.242, ntokens=864.8, nsentences=32, sample_size=864.8, sample_size_v1=0, sample_size_v2=0, ppl=302.83, wps=501.5, ups=0.58, wpb=864.8, bsz=32, num_updates=880, lr=3.3575e-06, gnorm=7.116, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=5747
2023-02-19 16:46:39 - progress_bar.py[line:272] - INFO: epoch 001:    890 / 21849 loss=9.235, loss_v1=0, loss_v2=0, nll_loss=9.02, ntokens=1038, nsentences=32, sample_size=1038, sample_size_v1=0, sample_size_v2=0, ppl=519.3, wps=597.2, ups=0.58, wpb=1038, bsz=32, num_updates=890, lr=3.39565e-06, gnorm=6.079, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=5765
2023-02-19 16:46:56 - progress_bar.py[line:272] - INFO: epoch 001:    900 / 21849 loss=8.55, loss_v1=0, loss_v2=0, nll_loss=8.257, ntokens=902.6, nsentences=32, sample_size=902.6, sample_size_v1=0, sample_size_v2=0, ppl=305.88, wps=521.6, ups=0.58, wpb=902.6, bsz=32, num_updates=900, lr=3.4338e-06, gnorm=7.704, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=5782
2023-02-19 16:47:14 - progress_bar.py[line:272] - INFO: epoch 001:    910 / 21849 loss=8.995, loss_v1=0, loss_v2=0, nll_loss=8.753, ntokens=937.4, nsentences=32, sample_size=937.4, sample_size_v1=0, sample_size_v2=0, ppl=431.3, wps=540.7, ups=0.58, wpb=937.4, bsz=32, num_updates=910, lr=3.47196e-06, gnorm=6.679, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=5799
2023-02-19 16:47:31 - progress_bar.py[line:272] - INFO: epoch 001:    920 / 21849 loss=8.359, loss_v1=0, loss_v2=0, nll_loss=8.045, ntokens=979.4, nsentences=32, sample_size=979.4, sample_size_v1=0, sample_size_v2=0, ppl=264.14, wps=564, ups=0.58, wpb=979.4, bsz=32, num_updates=920, lr=3.51011e-06, gnorm=6.225, clip=100, loss_scale=256, train_wall=17, gb_free=13.7, wall=5817
2023-02-19 16:47:48 - progress_bar.py[line:272] - INFO: epoch 001:    930 / 21849 loss=8.143, loss_v1=0, loss_v2=0, nll_loss=7.804, ntokens=794.8, nsentences=32, sample_size=794.8, sample_size_v1=0, sample_size_v2=0, ppl=223.41, wps=460.7, ups=0.58, wpb=794.8, bsz=32, num_updates=930, lr=3.54826e-06, gnorm=7.319, clip=100, loss_scale=256, train_wall=17, gb_free=13.7, wall=5834
2023-02-19 16:48:06 - progress_bar.py[line:272] - INFO: epoch 001:    940 / 21849 loss=8.285, loss_v1=0, loss_v2=0, nll_loss=7.962, ntokens=796.4, nsentences=32, sample_size=796.4, sample_size_v1=0, sample_size_v2=0, ppl=249.37, wps=460.4, ups=0.58, wpb=796.4, bsz=32, num_updates=940, lr=3.58642e-06, gnorm=7.315, clip=100, loss_scale=256, train_wall=17, gb_free=13.7, wall=5851
2023-02-19 16:48:23 - progress_bar.py[line:272] - INFO: epoch 001:    950 / 21849 loss=8.133, loss_v1=0, loss_v2=0, nll_loss=7.79, ntokens=884.8, nsentences=32, sample_size=884.8, sample_size_v1=0, sample_size_v2=0, ppl=221.38, wps=511.6, ups=0.58, wpb=884.8, bsz=32, num_updates=950, lr=3.62457e-06, gnorm=7.694, clip=100, loss_scale=256, train_wall=17, gb_free=13.7, wall=5869
2023-02-19 16:48:40 - progress_bar.py[line:272] - INFO: epoch 001:    960 / 21849 loss=8.961, loss_v1=0, loss_v2=0, nll_loss=8.714, ntokens=881.8, nsentences=32, sample_size=881.8, sample_size_v1=0, sample_size_v2=0, ppl=419.86, wps=507.1, ups=0.58, wpb=881.8, bsz=32, num_updates=960, lr=3.66272e-06, gnorm=7.704, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=5886
2023-02-19 16:48:58 - progress_bar.py[line:272] - INFO: epoch 001:    970 / 21849 loss=7.665, loss_v1=0, loss_v2=0, nll_loss=7.268, ntokens=849, nsentences=32, sample_size=849, sample_size_v1=0, sample_size_v2=0, ppl=154.17, wps=490.5, ups=0.58, wpb=849, bsz=32, num_updates=970, lr=3.70088e-06, gnorm=6.471, clip=100, loss_scale=256, train_wall=17, gb_free=13.7, wall=5903
2023-02-19 16:49:15 - progress_bar.py[line:272] - INFO: epoch 001:    980 / 21849 loss=8.13, loss_v1=0, loss_v2=0, nll_loss=7.785, ntokens=879.6, nsentences=32, sample_size=879.6, sample_size_v1=0, sample_size_v2=0, ppl=220.6, wps=507.8, ups=0.58, wpb=879.6, bsz=32, num_updates=980, lr=3.73903e-06, gnorm=6.81, clip=100, loss_scale=256, train_wall=17, gb_free=13.7, wall=5921
2023-02-19 16:49:32 - progress_bar.py[line:272] - INFO: epoch 001:    990 / 21849 loss=8.54, loss_v1=0, loss_v2=0, nll_loss=8.246, ntokens=819.7, nsentences=32, sample_size=819.7, sample_size_v1=0, sample_size_v2=0, ppl=303.51, wps=474, ups=0.58, wpb=819.7, bsz=32, num_updates=990, lr=3.77718e-06, gnorm=7.773, clip=100, loss_scale=256, train_wall=17, gb_free=13.7, wall=5938
2023-02-19 16:49:49 - progress_bar.py[line:272] - INFO: epoch 001:   1000 / 21849 loss=7.93, loss_v1=0, loss_v2=0, nll_loss=7.563, ntokens=744.8, nsentences=32, sample_size=744.8, sample_size_v1=0, sample_size_v2=0, ppl=189.15, wps=432.9, ups=0.58, wpb=744.8, bsz=32, num_updates=1000, lr=3.81534e-06, gnorm=7.472, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=5955
2023-02-19 16:49:49 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-02-19 18:21:34 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 8.834 | loss_v1 0 | loss_v2 0 | nll_loss 8.567 | ntokens 600.688 | nsentences 7.999 | sample_size 600.688 | sample_size_v1 0 | sample_size_v2 0 | ppl 379.29 | cider 0.019 | wps 1272.4 | wpb 600.7 | bsz 8 | num_updates 1000 | best_cider 0.019
2023-02-19 18:21:34 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 1000 updates
2023-02-19 18:21:34 - trainer.py[line:431] - INFO: Saving checkpoint to ./stage1_checkpoints/2_0.06_2500/checkpoint_1_1000.pt
2023-02-19 18:21:37 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./stage1_checkpoints/2_0.06_2500/checkpoint_1_1000.pt
2023-02-19 18:21:41 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./stage1_checkpoints/2_0.06_2500/checkpoint_1_1000.pt (epoch 1 @ 1000 updates, score 0.019) (writing took 7.074474763125181 seconds)
2023-02-19 18:21:59 - progress_bar.py[line:272] - INFO: epoch 001:   1010 / 21849 loss=8.819, loss_v1=0, loss_v2=0, nll_loss=8.556, ntokens=944.1, nsentences=32, sample_size=944.1, sample_size_v1=0, sample_size_v2=0, ppl=376.26, wps=1.7, ups=0, wpb=944.1, bsz=32, num_updates=1010, lr=3.85349e-06, gnorm=6.964, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=11485
2023-02-19 18:22:16 - progress_bar.py[line:272] - INFO: epoch 001:   1020 / 21849 loss=7.97, loss_v1=0, loss_v2=0, nll_loss=7.608, ntokens=820.4, nsentences=32, sample_size=820.4, sample_size_v1=0, sample_size_v2=0, ppl=195.13, wps=475, ups=0.58, wpb=820.4, bsz=32, num_updates=1020, lr=3.89164e-06, gnorm=7.908, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=11502
2023-02-19 18:22:34 - progress_bar.py[line:272] - INFO: epoch 001:   1030 / 21849 loss=8.315, loss_v1=0, loss_v2=0, nll_loss=7.991, ntokens=1014.6, nsentences=32, sample_size=1014.6, sample_size_v1=0, sample_size_v2=0, ppl=254.48, wps=585.4, ups=0.58, wpb=1014.6, bsz=32, num_updates=1030, lr=3.9298e-06, gnorm=6.603, clip=100, loss_scale=512, train_wall=17, gb_free=13.6, wall=11519
2023-02-19 18:22:51 - progress_bar.py[line:272] - INFO: epoch 001:   1040 / 21849 loss=8.764, loss_v1=0, loss_v2=0, nll_loss=8.494, ntokens=1082.2, nsentences=32, sample_size=1082.2, sample_size_v1=0, sample_size_v2=0, ppl=360.43, wps=623.8, ups=0.58, wpb=1082.2, bsz=32, num_updates=1040, lr=3.96795e-06, gnorm=6.387, clip=100, loss_scale=512, train_wall=17, gb_free=13.5, wall=11536
2023-02-19 18:23:08 - progress_bar.py[line:272] - INFO: epoch 001:   1050 / 21849 loss=7.626, loss_v1=0, loss_v2=0, nll_loss=7.224, ntokens=784, nsentences=32, sample_size=784, sample_size_v1=0, sample_size_v2=0, ppl=149.53, wps=453.2, ups=0.58, wpb=784, bsz=32, num_updates=1050, lr=4.0061e-06, gnorm=7.437, clip=100, loss_scale=512, train_wall=17, gb_free=13.7, wall=11554
2023-02-19 18:23:26 - progress_bar.py[line:272] - INFO: epoch 001:   1060 / 21849 loss=8.259, loss_v1=0, loss_v2=0, nll_loss=7.93, ntokens=959.5, nsentences=32, sample_size=959.5, sample_size_v1=0, sample_size_v2=0, ppl=243.87, wps=552, ups=0.58, wpb=959.5, bsz=32, num_updates=1060, lr=4.04426e-06, gnorm=6.989, clip=100, loss_scale=512, train_wall=17, gb_free=13.6, wall=11571
2023-02-19 18:23:43 - progress_bar.py[line:272] - INFO: epoch 001:   1070 / 21849 loss=7.745, loss_v1=0, loss_v2=0, nll_loss=7.356, ntokens=896.3, nsentences=32, sample_size=896.3, sample_size_v1=0, sample_size_v2=0, ppl=163.8, wps=515.7, ups=0.58, wpb=896.3, bsz=32, num_updates=1070, lr=4.08241e-06, gnorm=7.782, clip=100, loss_scale=512, train_wall=17, gb_free=13.7, wall=11589
2023-02-19 18:24:00 - progress_bar.py[line:272] - INFO: epoch 001:   1080 / 21849 loss=7.528, loss_v1=0, loss_v2=0, nll_loss=7.115, ntokens=862.6, nsentences=32, sample_size=862.6, sample_size_v1=0, sample_size_v2=0, ppl=138.58, wps=497.3, ups=0.58, wpb=862.6, bsz=32, num_updates=1080, lr=4.12056e-06, gnorm=6.745, clip=100, loss_scale=512, train_wall=17, gb_free=13.6, wall=11606
2023-02-19 18:24:18 - progress_bar.py[line:272] - INFO: epoch 001:   1090 / 21849 loss=8.209, loss_v1=0, loss_v2=0, nll_loss=7.878, ntokens=1014.7, nsentences=32, sample_size=1014.7, sample_size_v1=0, sample_size_v2=0, ppl=235.23, wps=584.1, ups=0.58, wpb=1014.7, bsz=32, num_updates=1090, lr=4.15872e-06, gnorm=7.368, clip=100, loss_scale=512, train_wall=17, gb_free=13.7, wall=11623
2023-02-19 18:24:35 - progress_bar.py[line:272] - INFO: epoch 001:   1100 / 21849 loss=7.598, loss_v1=0, loss_v2=0, nll_loss=7.191, ntokens=839.6, nsentences=32, sample_size=839.6, sample_size_v1=0, sample_size_v2=0, ppl=146.12, wps=483.9, ups=0.58, wpb=839.6, bsz=32, num_updates=1100, lr=4.19687e-06, gnorm=7.585, clip=100, loss_scale=512, train_wall=17, gb_free=13.6, wall=11641
2023-02-19 18:24:52 - progress_bar.py[line:272] - INFO: epoch 001:   1110 / 21849 loss=8.471, loss_v1=0, loss_v2=0, nll_loss=8.163, ntokens=904.2, nsentences=32, sample_size=904.2, sample_size_v1=0, sample_size_v2=0, ppl=286.58, wps=522.2, ups=0.58, wpb=904.2, bsz=32, num_updates=1110, lr=4.23502e-06, gnorm=6.809, clip=100, loss_scale=512, train_wall=17, gb_free=13.6, wall=11658
2023-02-19 18:25:10 - progress_bar.py[line:272] - INFO: epoch 001:   1120 / 21849 loss=8.259, loss_v1=0, loss_v2=0, nll_loss=7.93, ntokens=940.7, nsentences=32, sample_size=940.7, sample_size_v1=0, sample_size_v2=0, ppl=243.94, wps=542.6, ups=0.58, wpb=940.7, bsz=32, num_updates=1120, lr=4.27318e-06, gnorm=10.049, clip=100, loss_scale=512, train_wall=17, gb_free=13.7, wall=11675
2023-02-19 18:25:13 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-02-19 18:25:29 - progress_bar.py[line:272] - INFO: epoch 001:   1131 / 21849 loss=8.18, loss_v1=0, loss_v2=0, nll_loss=7.842, ntokens=926.2, nsentences=32, sample_size=926.2, sample_size_v1=0, sample_size_v2=0, ppl=229.39, wps=488.3, ups=0.53, wpb=926.2, bsz=32, num_updates=1130, lr=4.31133e-06, gnorm=7.672, clip=100, loss_scale=256, train_wall=19, gb_free=13.7, wall=11694
2023-02-19 18:25:46 - progress_bar.py[line:272] - INFO: epoch 001:   1141 / 21849 loss=7.796, loss_v1=0, loss_v2=0, nll_loss=7.412, ntokens=799.7, nsentences=32, sample_size=799.7, sample_size_v1=0, sample_size_v2=0, ppl=170.35, wps=462.4, ups=0.58, wpb=799.7, bsz=32, num_updates=1140, lr=4.34948e-06, gnorm=8.608, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=11712
2023-02-19 18:26:03 - progress_bar.py[line:272] - INFO: epoch 001:   1151 / 21849 loss=7.829, loss_v1=0, loss_v2=0, nll_loss=7.449, ntokens=965.4, nsentences=32, sample_size=965.4, sample_size_v1=0, sample_size_v2=0, ppl=174.75, wps=557.1, ups=0.58, wpb=965.4, bsz=32, num_updates=1150, lr=4.38764e-06, gnorm=6.629, clip=100, loss_scale=256, train_wall=17, gb_free=13.7, wall=11729
2023-02-19 18:26:21 - progress_bar.py[line:272] - INFO: epoch 001:   1161 / 21849 loss=7.958, loss_v1=0, loss_v2=0, nll_loss=7.589, ntokens=848.8, nsentences=32, sample_size=848.8, sample_size_v1=0, sample_size_v2=0, ppl=192.6, wps=490, ups=0.58, wpb=848.8, bsz=32, num_updates=1160, lr=4.42579e-06, gnorm=8.598, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=11746
2023-02-19 18:26:38 - progress_bar.py[line:272] - INFO: epoch 001:   1171 / 21849 loss=7.945, loss_v1=0, loss_v2=0, nll_loss=7.573, ntokens=876.7, nsentences=32, sample_size=876.7, sample_size_v1=0, sample_size_v2=0, ppl=190.43, wps=506.4, ups=0.58, wpb=876.7, bsz=32, num_updates=1170, lr=4.46395e-06, gnorm=8.824, clip=100, loss_scale=256, train_wall=17, gb_free=13.7, wall=11763
2023-02-19 18:26:55 - progress_bar.py[line:272] - INFO: epoch 001:   1181 / 21849 loss=7.606, loss_v1=0, loss_v2=0, nll_loss=7.194, ntokens=846.2, nsentences=32, sample_size=846.2, sample_size_v1=0, sample_size_v2=0, ppl=146.45, wps=489.1, ups=0.58, wpb=846.2, bsz=32, num_updates=1180, lr=4.5021e-06, gnorm=8.433, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=11781
2023-02-19 18:27:13 - progress_bar.py[line:272] - INFO: epoch 001:   1191 / 21849 loss=8.23, loss_v1=0, loss_v2=0, nll_loss=7.897, ntokens=925.9, nsentences=32, sample_size=925.9, sample_size_v1=0, sample_size_v2=0, ppl=238.4, wps=534.4, ups=0.58, wpb=925.9, bsz=32, num_updates=1190, lr=4.54025e-06, gnorm=6.918, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=11798
2023-02-19 18:27:30 - progress_bar.py[line:272] - INFO: epoch 001:   1201 / 21849 loss=8.825, loss_v1=0, loss_v2=0, nll_loss=8.564, ntokens=896, nsentences=32, sample_size=896, sample_size_v1=0, sample_size_v2=0, ppl=378.46, wps=517.4, ups=0.58, wpb=896, bsz=32, num_updates=1200, lr=4.57841e-06, gnorm=6.871, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=11815
2023-02-19 18:27:47 - progress_bar.py[line:272] - INFO: epoch 001:   1211 / 21849 loss=8.275, loss_v1=0, loss_v2=0, nll_loss=7.944, ntokens=908.6, nsentences=32, sample_size=908.6, sample_size_v1=0, sample_size_v2=0, ppl=246.24, wps=524.9, ups=0.58, wpb=908.6, bsz=32, num_updates=1210, lr=4.61656e-06, gnorm=7.756, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=11833
2023-02-19 18:28:04 - progress_bar.py[line:272] - INFO: epoch 001:   1221 / 21849 loss=8.141, loss_v1=0, loss_v2=0, nll_loss=7.787, ntokens=828.4, nsentences=32, sample_size=828.4, sample_size_v1=0, sample_size_v2=0, ppl=220.89, wps=479, ups=0.58, wpb=828.4, bsz=32, num_updates=1220, lr=4.65471e-06, gnorm=8.074, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=11850
2023-02-19 18:28:22 - progress_bar.py[line:272] - INFO: epoch 001:   1231 / 21849 loss=8.063, loss_v1=0, loss_v2=0, nll_loss=7.71, ntokens=889.9, nsentences=32, sample_size=889.9, sample_size_v1=0, sample_size_v2=0, ppl=209.45, wps=514, ups=0.58, wpb=889.9, bsz=32, num_updates=1230, lr=4.69287e-06, gnorm=6.884, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=11867
2023-02-19 18:28:39 - progress_bar.py[line:272] - INFO: epoch 001:   1241 / 21849 loss=8.01, loss_v1=0, loss_v2=0, nll_loss=7.654, ntokens=1056, nsentences=32, sample_size=1056, sample_size_v1=0, sample_size_v2=0, ppl=201.4, wps=596.3, ups=0.56, wpb=1056, bsz=32, num_updates=1240, lr=4.73102e-06, gnorm=5.609, clip=100, loss_scale=256, train_wall=18, gb_free=13.6, wall=11885
2023-02-19 18:28:57 - progress_bar.py[line:272] - INFO: epoch 001:   1251 / 21849 loss=8.685, loss_v1=0, loss_v2=0, nll_loss=8.405, ntokens=994, nsentences=32, sample_size=994, sample_size_v1=0, sample_size_v2=0, ppl=338.91, wps=569.7, ups=0.57, wpb=994, bsz=32, num_updates=1250, lr=4.76917e-06, gnorm=7.276, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=11903
2023-02-19 18:29:14 - progress_bar.py[line:272] - INFO: epoch 001:   1261 / 21849 loss=8.14, loss_v1=0, loss_v2=0, nll_loss=7.793, ntokens=902.7, nsentences=32, sample_size=902.7, sample_size_v1=0, sample_size_v2=0, ppl=221.81, wps=520.9, ups=0.58, wpb=902.7, bsz=32, num_updates=1260, lr=4.80733e-06, gnorm=7.021, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=11920
2023-02-19 18:29:32 - progress_bar.py[line:272] - INFO: epoch 001:   1271 / 21849 loss=7.998, loss_v1=0, loss_v2=0, nll_loss=7.638, ntokens=902.3, nsentences=32, sample_size=902.3, sample_size_v1=0, sample_size_v2=0, ppl=199.23, wps=521.5, ups=0.58, wpb=902.3, bsz=32, num_updates=1270, lr=4.84548e-06, gnorm=6.797, clip=100, loss_scale=256, train_wall=17, gb_free=13.7, wall=11937
2023-02-19 18:29:49 - progress_bar.py[line:272] - INFO: epoch 001:   1281 / 21849 loss=7.109, loss_v1=0, loss_v2=0, nll_loss=6.641, ntokens=899, nsentences=32, sample_size=899, sample_size_v1=0, sample_size_v2=0, ppl=99.83, wps=520.3, ups=0.58, wpb=899, bsz=32, num_updates=1280, lr=4.88363e-06, gnorm=6.885, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=11954
2023-02-19 18:30:06 - progress_bar.py[line:272] - INFO: epoch 001:   1291 / 21849 loss=7.895, loss_v1=0, loss_v2=0, nll_loss=7.523, ntokens=987.2, nsentences=32, sample_size=987.2, sample_size_v1=0, sample_size_v2=0, ppl=183.98, wps=571, ups=0.58, wpb=987.2, bsz=32, num_updates=1290, lr=4.92179e-06, gnorm=7.483, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=11972
2023-02-19 18:30:23 - progress_bar.py[line:272] - INFO: epoch 001:   1301 / 21849 loss=8.698, loss_v1=0, loss_v2=0, nll_loss=8.414, ntokens=950.6, nsentences=32, sample_size=950.6, sample_size_v1=0, sample_size_v2=0, ppl=341.05, wps=548.4, ups=0.58, wpb=950.6, bsz=32, num_updates=1300, lr=4.95994e-06, gnorm=7.72, clip=100, loss_scale=256, train_wall=17, gb_free=13.7, wall=11989
2023-02-19 18:30:41 - progress_bar.py[line:272] - INFO: epoch 001:   1311 / 21849 loss=7.943, loss_v1=0, loss_v2=0, nll_loss=7.574, ntokens=893.8, nsentences=32, sample_size=893.8, sample_size_v1=0, sample_size_v2=0, ppl=190.58, wps=514.6, ups=0.58, wpb=893.8, bsz=32, num_updates=1310, lr=4.99809e-06, gnorm=7.543, clip=100, loss_scale=256, train_wall=17, gb_free=13.5, wall=12006
2023-02-19 18:30:58 - progress_bar.py[line:272] - INFO: epoch 001:   1321 / 21849 loss=7.877, loss_v1=0, loss_v2=0, nll_loss=7.506, ntokens=956.2, nsentences=32, sample_size=956.2, sample_size_v1=0, sample_size_v2=0, ppl=181.74, wps=550, ups=0.58, wpb=956.2, bsz=32, num_updates=1320, lr=5.03625e-06, gnorm=7.124, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=12024
2023-02-19 18:31:16 - progress_bar.py[line:272] - INFO: epoch 001:   1331 / 21849 loss=7.418, loss_v1=0, loss_v2=0, nll_loss=6.987, ntokens=863.8, nsentences=32, sample_size=863.8, sample_size_v1=0, sample_size_v2=0, ppl=126.86, wps=497.2, ups=0.58, wpb=863.8, bsz=32, num_updates=1330, lr=5.0744e-06, gnorm=7.587, clip=100, loss_scale=256, train_wall=17, gb_free=13.7, wall=12041
2023-02-19 18:31:33 - progress_bar.py[line:272] - INFO: epoch 001:   1341 / 21849 loss=7.452, loss_v1=0, loss_v2=0, nll_loss=7.019, ntokens=789.2, nsentences=32, sample_size=789.2, sample_size_v1=0, sample_size_v2=0, ppl=129.68, wps=454.8, ups=0.58, wpb=789.2, bsz=32, num_updates=1340, lr=5.11255e-06, gnorm=8.251, clip=100, loss_scale=256, train_wall=17, gb_free=13.7, wall=12059
2023-02-19 18:31:50 - progress_bar.py[line:272] - INFO: epoch 001:   1351 / 21849 loss=8.494, loss_v1=0, loss_v2=0, nll_loss=8.184, ntokens=949.4, nsentences=32, sample_size=949.4, sample_size_v1=0, sample_size_v2=0, ppl=290.86, wps=545.8, ups=0.57, wpb=949.4, bsz=32, num_updates=1350, lr=5.15071e-06, gnorm=7.145, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=12076
2023-02-19 18:32:08 - progress_bar.py[line:272] - INFO: epoch 001:   1361 / 21849 loss=7.66, loss_v1=0, loss_v2=0, nll_loss=7.255, ntokens=915.3, nsentences=32, sample_size=915.3, sample_size_v1=0, sample_size_v2=0, ppl=152.77, wps=526.8, ups=0.58, wpb=915.3, bsz=32, num_updates=1360, lr=5.18886e-06, gnorm=6.93, clip=100, loss_scale=256, train_wall=17, gb_free=13.7, wall=12093
2023-02-19 18:32:25 - progress_bar.py[line:272] - INFO: epoch 001:   1371 / 21849 loss=6.751, loss_v1=0, loss_v2=0, nll_loss=6.236, ntokens=647.2, nsentences=32, sample_size=647.2, sample_size_v1=0, sample_size_v2=0, ppl=75.35, wps=374.3, ups=0.58, wpb=647.2, bsz=32, num_updates=1370, lr=5.22701e-06, gnorm=8.219, clip=100, loss_scale=256, train_wall=17, gb_free=13.7, wall=12111
2023-02-19 18:32:42 - progress_bar.py[line:272] - INFO: epoch 001:   1381 / 21849 loss=7.363, loss_v1=0, loss_v2=0, nll_loss=6.92, ntokens=891.9, nsentences=32, sample_size=891.9, sample_size_v1=0, sample_size_v2=0, ppl=121.11, wps=513.7, ups=0.58, wpb=891.9, bsz=32, num_updates=1380, lr=5.26517e-06, gnorm=6.363, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=12128
2023-02-19 18:33:00 - progress_bar.py[line:272] - INFO: epoch 001:   1391 / 21849 loss=7.621, loss_v1=0, loss_v2=0, nll_loss=7.212, ntokens=919.6, nsentences=32, sample_size=919.6, sample_size_v1=0, sample_size_v2=0, ppl=148.27, wps=530.5, ups=0.58, wpb=919.6, bsz=32, num_updates=1390, lr=5.30332e-06, gnorm=6.878, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=12145
2023-02-19 18:33:17 - progress_bar.py[line:272] - INFO: epoch 001:   1401 / 21849 loss=7.939, loss_v1=0, loss_v2=0, nll_loss=7.571, ntokens=936.2, nsentences=32, sample_size=936.2, sample_size_v1=0, sample_size_v2=0, ppl=190.17, wps=538.8, ups=0.58, wpb=936.2, bsz=32, num_updates=1400, lr=5.34147e-06, gnorm=7.019, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=12163
2023-02-19 18:33:34 - progress_bar.py[line:272] - INFO: epoch 001:   1411 / 21849 loss=7.583, loss_v1=0, loss_v2=0, nll_loss=7.172, ntokens=839, nsentences=32, sample_size=839, sample_size_v1=0, sample_size_v2=0, ppl=144.25, wps=486.4, ups=0.58, wpb=839, bsz=32, num_updates=1410, lr=5.37963e-06, gnorm=7.226, clip=100, loss_scale=256, train_wall=17, gb_free=13.7, wall=12180
2023-02-19 18:33:52 - progress_bar.py[line:272] - INFO: epoch 001:   1421 / 21849 loss=7.198, loss_v1=0, loss_v2=0, nll_loss=6.741, ntokens=856.8, nsentences=32, sample_size=856.8, sample_size_v1=0, sample_size_v2=0, ppl=106.96, wps=495.4, ups=0.58, wpb=856.8, bsz=32, num_updates=1420, lr=5.41778e-06, gnorm=6.657, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=12197
2023-02-19 18:34:09 - progress_bar.py[line:272] - INFO: epoch 001:   1431 / 21849 loss=7.186, loss_v1=0, loss_v2=0, nll_loss=6.727, ntokens=954.8, nsentences=32, sample_size=954.8, sample_size_v1=0, sample_size_v2=0, ppl=105.96, wps=551.8, ups=0.58, wpb=954.8, bsz=32, num_updates=1430, lr=5.45593e-06, gnorm=6.941, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=12215
2023-02-19 18:34:26 - progress_bar.py[line:272] - INFO: epoch 001:   1441 / 21849 loss=7.234, loss_v1=0, loss_v2=0, nll_loss=6.771, ntokens=915.2, nsentences=32, sample_size=915.2, sample_size_v1=0, sample_size_v2=0, ppl=109.21, wps=528.7, ups=0.58, wpb=915.2, bsz=32, num_updates=1440, lr=5.49409e-06, gnorm=7.14, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=12232
2023-02-19 18:34:44 - progress_bar.py[line:272] - INFO: epoch 001:   1451 / 21849 loss=7.785, loss_v1=0, loss_v2=0, nll_loss=7.388, ntokens=819.6, nsentences=32, sample_size=819.6, sample_size_v1=0, sample_size_v2=0, ppl=167.47, wps=474.4, ups=0.58, wpb=819.6, bsz=32, num_updates=1450, lr=5.53224e-06, gnorm=7.468, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=12249
2023-02-19 18:35:01 - progress_bar.py[line:272] - INFO: epoch 001:   1461 / 21849 loss=6.635, loss_v1=0, loss_v2=0, nll_loss=6.108, ntokens=666.7, nsentences=32, sample_size=666.7, sample_size_v1=0, sample_size_v2=0, ppl=68.96, wps=386.3, ups=0.58, wpb=666.7, bsz=32, num_updates=1460, lr=5.57039e-06, gnorm=8.739, clip=100, loss_scale=256, train_wall=17, gb_free=13.7, wall=12266
2023-02-19 18:35:18 - progress_bar.py[line:272] - INFO: epoch 001:   1471 / 21849 loss=7.84, loss_v1=0, loss_v2=0, nll_loss=7.451, ntokens=784.6, nsentences=32, sample_size=784.6, sample_size_v1=0, sample_size_v2=0, ppl=174.95, wps=452.6, ups=0.58, wpb=784.6, bsz=32, num_updates=1470, lr=5.60855e-06, gnorm=8.15, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=12284
2023-02-19 18:35:36 - progress_bar.py[line:272] - INFO: epoch 001:   1481 / 21849 loss=8.456, loss_v1=0, loss_v2=0, nll_loss=8.146, ntokens=1035.4, nsentences=32, sample_size=1035.4, sample_size_v1=0, sample_size_v2=0, ppl=283.35, wps=594.7, ups=0.57, wpb=1035.4, bsz=32, num_updates=1480, lr=5.6467e-06, gnorm=7.193, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=12301
2023-02-19 18:35:53 - progress_bar.py[line:272] - INFO: epoch 001:   1491 / 21849 loss=8.058, loss_v1=0, loss_v2=0, nll_loss=7.707, ntokens=981.8, nsentences=32, sample_size=981.8, sample_size_v1=0, sample_size_v2=0, ppl=208.89, wps=566.1, ups=0.58, wpb=981.8, bsz=32, num_updates=1490, lr=5.68485e-06, gnorm=7.743, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=12318
2023-02-19 18:36:10 - progress_bar.py[line:272] - INFO: epoch 001:   1501 / 21849 loss=6.85, loss_v1=0, loss_v2=0, nll_loss=6.353, ntokens=832.9, nsentences=32, sample_size=832.9, sample_size_v1=0, sample_size_v2=0, ppl=81.75, wps=481.7, ups=0.58, wpb=832.9, bsz=32, num_updates=1500, lr=5.72301e-06, gnorm=7.675, clip=100, loss_scale=256, train_wall=17, gb_free=13.7, wall=12336
2023-02-19 18:36:10 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-02-19 20:17:11 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 8.25 | loss_v1 0 | loss_v2 0 | nll_loss 7.898 | ntokens 600.688 | nsentences 7.999 | sample_size 600.688 | sample_size_v1 0 | sample_size_v2 0 | ppl 238.45 | cider 0.023 | wps 1155.7 | wpb 600.7 | bsz 8 | num_updates 1500 | best_cider 0.023
2023-02-19 20:17:11 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 1500 updates
2023-02-19 20:17:11 - trainer.py[line:431] - INFO: Saving checkpoint to ./stage1_checkpoints/2_0.06_2500/checkpoint_1_1500.pt
2023-02-19 20:17:15 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./stage1_checkpoints/2_0.06_2500/checkpoint_1_1500.pt
2023-02-19 20:17:19 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./stage1_checkpoints/2_0.06_2500/checkpoint_1_1500.pt (epoch 1 @ 1500 updates, score 0.023) (writing took 8.213039550930262 seconds)
2023-02-19 20:17:37 - progress_bar.py[line:272] - INFO: epoch 001:   1511 / 21849 loss=8.019, loss_v1=0, loss_v2=0, nll_loss=7.658, ntokens=964.1, nsentences=32, sample_size=964.1, sample_size_v1=0, sample_size_v2=0, ppl=201.91, wps=1.6, ups=0, wpb=964.1, bsz=32, num_updates=1510, lr=5.76116e-06, gnorm=7.22, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=18422
2023-02-19 20:17:54 - progress_bar.py[line:272] - INFO: epoch 001:   1521 / 21849 loss=7.924, loss_v1=0, loss_v2=0, nll_loss=7.556, ntokens=898.1, nsentences=32, sample_size=898.1, sample_size_v1=0, sample_size_v2=0, ppl=188.24, wps=518.4, ups=0.58, wpb=898.1, bsz=32, num_updates=1520, lr=5.79931e-06, gnorm=8.951, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=18440
2023-02-19 20:18:11 - progress_bar.py[line:272] - INFO: epoch 001:   1531 / 21849 loss=6.685, loss_v1=0, loss_v2=0, nll_loss=6.169, ntokens=897.3, nsentences=32, sample_size=897.3, sample_size_v1=0, sample_size_v2=0, ppl=71.94, wps=519.1, ups=0.58, wpb=897.3, bsz=32, num_updates=1530, lr=5.83747e-06, gnorm=7.112, clip=100, loss_scale=256, train_wall=17, gb_free=13.7, wall=18457
2023-02-19 20:18:29 - progress_bar.py[line:272] - INFO: epoch 001:   1541 / 21849 loss=7.966, loss_v1=0, loss_v2=0, nll_loss=7.595, ntokens=794.2, nsentences=32, sample_size=794.2, sample_size_v1=0, sample_size_v2=0, ppl=193.38, wps=458.4, ups=0.58, wpb=794.2, bsz=32, num_updates=1540, lr=5.87562e-06, gnorm=8.192, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=18474
2023-02-19 20:18:46 - progress_bar.py[line:272] - INFO: epoch 001:   1551 / 21849 loss=6.932, loss_v1=0, loss_v2=0, nll_loss=6.436, ntokens=845.4, nsentences=32, sample_size=845.4, sample_size_v1=0, sample_size_v2=0, ppl=86.59, wps=487.2, ups=0.58, wpb=845.4, bsz=32, num_updates=1550, lr=5.91377e-06, gnorm=7.173, clip=100, loss_scale=256, train_wall=17, gb_free=13.7, wall=18492
2023-02-19 20:19:03 - progress_bar.py[line:272] - INFO: epoch 001:   1561 / 21849 loss=6.48, loss_v1=0, loss_v2=0, nll_loss=5.942, ntokens=836.5, nsentences=32, sample_size=836.5, sample_size_v1=0, sample_size_v2=0, ppl=61.47, wps=482.1, ups=0.58, wpb=836.5, bsz=32, num_updates=1560, lr=5.95193e-06, gnorm=7.47, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=18509
2023-02-19 20:19:21 - progress_bar.py[line:272] - INFO: epoch 001:   1571 / 21849 loss=7.503, loss_v1=0, loss_v2=0, nll_loss=7.082, ntokens=943.8, nsentences=32, sample_size=943.8, sample_size_v1=0, sample_size_v2=0, ppl=135.5, wps=542.6, ups=0.57, wpb=943.8, bsz=32, num_updates=1570, lr=5.99008e-06, gnorm=7.262, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=18526
2023-02-19 20:19:38 - progress_bar.py[line:272] - INFO: epoch 001:   1581 / 21849 loss=7.344, loss_v1=0, loss_v2=0, nll_loss=6.895, ntokens=834.6, nsentences=32, sample_size=834.6, sample_size_v1=0, sample_size_v2=0, ppl=118.98, wps=481.2, ups=0.58, wpb=834.6, bsz=32, num_updates=1580, lr=6.02823e-06, gnorm=9.509, clip=100, loss_scale=256, train_wall=17, gb_free=13.7, wall=18544
2023-02-19 20:19:55 - progress_bar.py[line:272] - INFO: epoch 001:   1591 / 21849 loss=6.989, loss_v1=0, loss_v2=0, nll_loss=6.506, ntokens=931, nsentences=32, sample_size=931, sample_size_v1=0, sample_size_v2=0, ppl=90.87, wps=535.4, ups=0.58, wpb=931, bsz=32, num_updates=1590, lr=6.06639e-06, gnorm=7.437, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=18561
2023-02-19 20:20:13 - progress_bar.py[line:272] - INFO: epoch 001:   1601 / 21849 loss=6.453, loss_v1=0, loss_v2=0, nll_loss=5.896, ntokens=899.1, nsentences=32, sample_size=899.1, sample_size_v1=0, sample_size_v2=0, ppl=59.54, wps=516, ups=0.57, wpb=899.1, bsz=32, num_updates=1600, lr=6.10454e-06, gnorm=7.063, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=18578
2023-02-19 20:20:30 - progress_bar.py[line:272] - INFO: epoch 001:   1611 / 21849 loss=6.776, loss_v1=0, loss_v2=0, nll_loss=6.264, ntokens=840.5, nsentences=32, sample_size=840.5, sample_size_v1=0, sample_size_v2=0, ppl=76.86, wps=483.7, ups=0.58, wpb=840.5, bsz=32, num_updates=1610, lr=6.14269e-06, gnorm=8.689, clip=100, loss_scale=256, train_wall=17, gb_free=13.7, wall=18596
2023-02-19 20:20:48 - progress_bar.py[line:272] - INFO: epoch 001:   1621 / 21849 loss=7.035, loss_v1=0, loss_v2=0, nll_loss=6.557, ntokens=688.2, nsentences=32, sample_size=688.2, sample_size_v1=0, sample_size_v2=0, ppl=94.13, wps=397.1, ups=0.58, wpb=688.2, bsz=32, num_updates=1620, lr=6.18085e-06, gnorm=9.376, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=18613
2023-02-19 20:21:05 - progress_bar.py[line:272] - INFO: epoch 001:   1631 / 21849 loss=7.602, loss_v1=0, loss_v2=0, nll_loss=7.188, ntokens=923.1, nsentences=32, sample_size=923.1, sample_size_v1=0, sample_size_v2=0, ppl=145.8, wps=530.6, ups=0.57, wpb=923.1, bsz=32, num_updates=1630, lr=6.219e-06, gnorm=8.248, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=18631
2023-02-19 20:21:22 - progress_bar.py[line:272] - INFO: epoch 001:   1641 / 21849 loss=6.759, loss_v1=0, loss_v2=0, nll_loss=6.244, ntokens=915.9, nsentences=32, sample_size=915.9, sample_size_v1=0, sample_size_v2=0, ppl=75.81, wps=525.7, ups=0.57, wpb=915.9, bsz=32, num_updates=1640, lr=6.25715e-06, gnorm=6.434, clip=100, loss_scale=512, train_wall=17, gb_free=13.6, wall=18648
2023-02-19 20:21:40 - progress_bar.py[line:272] - INFO: epoch 001:   1651 / 21849 loss=6.933, loss_v1=0, loss_v2=0, nll_loss=6.434, ntokens=887.3, nsentences=32, sample_size=887.3, sample_size_v1=0, sample_size_v2=0, ppl=86.46, wps=509.9, ups=0.57, wpb=887.3, bsz=32, num_updates=1650, lr=6.29531e-06, gnorm=8.023, clip=100, loss_scale=512, train_wall=17, gb_free=13.7, wall=18665
2023-02-19 20:21:57 - progress_bar.py[line:272] - INFO: epoch 001:   1661 / 21849 loss=7.917, loss_v1=0, loss_v2=0, nll_loss=7.542, ntokens=760.9, nsentences=32, sample_size=760.9, sample_size_v1=0, sample_size_v2=0, ppl=186.38, wps=433.1, ups=0.57, wpb=760.9, bsz=32, num_updates=1660, lr=6.33346e-06, gnorm=9.958, clip=100, loss_scale=512, train_wall=18, gb_free=13.6, wall=18683
2023-02-19 20:22:15 - progress_bar.py[line:272] - INFO: epoch 001:   1671 / 21849 loss=8.106, loss_v1=0, loss_v2=0, nll_loss=7.752, ntokens=857, nsentences=32, sample_size=857, sample_size_v1=0, sample_size_v2=0, ppl=215.59, wps=488.5, ups=0.57, wpb=857, bsz=32, num_updates=1670, lr=6.37161e-06, gnorm=8.101, clip=100, loss_scale=512, train_wall=17, gb_free=13.6, wall=18701
2023-02-19 20:22:32 - progress_bar.py[line:272] - INFO: epoch 001:   1681 / 21849 loss=7.721, loss_v1=0, loss_v2=0, nll_loss=7.324, ntokens=888, nsentences=32, sample_size=888, sample_size_v1=0, sample_size_v2=0, ppl=160.18, wps=506.1, ups=0.57, wpb=888, bsz=32, num_updates=1680, lr=6.40977e-06, gnorm=6.802, clip=100, loss_scale=512, train_wall=17, gb_free=13.6, wall=18718
2023-02-19 20:22:50 - progress_bar.py[line:272] - INFO: epoch 001:   1691 / 21849 loss=7.647, loss_v1=0, loss_v2=0, nll_loss=7.234, ntokens=901.6, nsentences=32, sample_size=901.6, sample_size_v1=0, sample_size_v2=0, ppl=150.56, wps=514.4, ups=0.57, wpb=901.6, bsz=32, num_updates=1690, lr=6.44792e-06, gnorm=7.145, clip=100, loss_scale=512, train_wall=17, gb_free=13.7, wall=18736
2023-02-19 20:23:08 - progress_bar.py[line:272] - INFO: epoch 001:   1701 / 21849 loss=7.453, loss_v1=0, loss_v2=0, nll_loss=7.03, ntokens=926.4, nsentences=32, sample_size=926.4, sample_size_v1=0, sample_size_v2=0, ppl=130.72, wps=528.5, ups=0.57, wpb=926.4, bsz=32, num_updates=1700, lr=6.48607e-06, gnorm=7.37, clip=100, loss_scale=512, train_wall=17, gb_free=13.6, wall=18753
2023-02-19 20:23:25 - progress_bar.py[line:272] - INFO: epoch 001:   1711 / 21849 loss=6.493, loss_v1=0, loss_v2=0, nll_loss=5.944, ntokens=893.3, nsentences=32, sample_size=893.3, sample_size_v1=0, sample_size_v2=0, ppl=61.56, wps=513.3, ups=0.57, wpb=893.3, bsz=32, num_updates=1710, lr=6.52423e-06, gnorm=7.709, clip=100, loss_scale=512, train_wall=17, gb_free=13.6, wall=18771
2023-02-19 20:23:42 - progress_bar.py[line:272] - INFO: epoch 001:   1721 / 21849 loss=6.644, loss_v1=0, loss_v2=0, nll_loss=6.109, ntokens=852.6, nsentences=32, sample_size=852.6, sample_size_v1=0, sample_size_v2=0, ppl=69.03, wps=491.3, ups=0.58, wpb=852.6, bsz=32, num_updates=1720, lr=6.56238e-06, gnorm=9.56, clip=100, loss_scale=512, train_wall=17, gb_free=13.7, wall=18788
2023-02-19 20:24:00 - progress_bar.py[line:272] - INFO: epoch 001:   1731 / 21849 loss=7.314, loss_v1=0, loss_v2=0, nll_loss=6.869, ntokens=911.5, nsentences=32, sample_size=911.5, sample_size_v1=0, sample_size_v2=0, ppl=116.9, wps=523.9, ups=0.57, wpb=911.5, bsz=32, num_updates=1730, lr=6.60053e-06, gnorm=8.242, clip=100, loss_scale=512, train_wall=17, gb_free=13.7, wall=18805
2023-02-19 20:24:17 - progress_bar.py[line:272] - INFO: epoch 001:   1741 / 21849 loss=6.794, loss_v1=0, loss_v2=0, nll_loss=6.287, ntokens=908.4, nsentences=32, sample_size=908.4, sample_size_v1=0, sample_size_v2=0, ppl=78.06, wps=523, ups=0.58, wpb=908.4, bsz=32, num_updates=1740, lr=6.63869e-06, gnorm=7.729, clip=100, loss_scale=512, train_wall=17, gb_free=13.6, wall=18823
2023-02-19 20:24:34 - progress_bar.py[line:272] - INFO: epoch 001:   1751 / 21849 loss=6.971, loss_v1=0, loss_v2=0, nll_loss=6.486, ntokens=895, nsentences=32, sample_size=895, sample_size_v1=0, sample_size_v2=0, ppl=89.65, wps=515.7, ups=0.58, wpb=895, bsz=32, num_updates=1750, lr=6.67684e-06, gnorm=8.246, clip=100, loss_scale=512, train_wall=17, gb_free=13.6, wall=18840
2023-02-19 20:24:52 - progress_bar.py[line:272] - INFO: epoch 001:   1761 / 21849 loss=6.457, loss_v1=0, loss_v2=0, nll_loss=5.912, ntokens=913.3, nsentences=32, sample_size=913.3, sample_size_v1=0, sample_size_v2=0, ppl=60.2, wps=526.1, ups=0.58, wpb=913.3, bsz=32, num_updates=1760, lr=6.71499e-06, gnorm=7.047, clip=100, loss_scale=512, train_wall=17, gb_free=13.7, wall=18857
2023-02-19 20:25:09 - progress_bar.py[line:272] - INFO: epoch 001:   1771 / 21849 loss=5.794, loss_v1=0, loss_v2=0, nll_loss=5.158, ntokens=845.2, nsentences=32, sample_size=845.2, sample_size_v1=0, sample_size_v2=0, ppl=35.7, wps=484.5, ups=0.57, wpb=845.2, bsz=32, num_updates=1770, lr=6.75315e-06, gnorm=5.966, clip=100, loss_scale=512, train_wall=17, gb_free=13.6, wall=18875
2023-02-19 20:25:27 - progress_bar.py[line:272] - INFO: epoch 001:   1781 / 21849 loss=7.228, loss_v1=0, loss_v2=0, nll_loss=6.76, ntokens=1097, nsentences=32, sample_size=1097, sample_size_v1=0, sample_size_v2=0, ppl=108.39, wps=628.2, ups=0.57, wpb=1097, bsz=32, num_updates=1780, lr=6.7913e-06, gnorm=7.165, clip=100, loss_scale=512, train_wall=17, gb_free=13.5, wall=18892
2023-02-19 20:25:44 - progress_bar.py[line:272] - INFO: epoch 001:   1791 / 21849 loss=7.112, loss_v1=0, loss_v2=0, nll_loss=6.643, ntokens=997.9, nsentences=32, sample_size=997.9, sample_size_v1=0, sample_size_v2=0, ppl=99.92, wps=570, ups=0.57, wpb=997.9, bsz=32, num_updates=1790, lr=6.82945e-06, gnorm=8.115, clip=100, loss_scale=512, train_wall=17, gb_free=13.7, wall=18910
2023-02-19 20:26:02 - progress_bar.py[line:272] - INFO: epoch 001:   1801 / 21849 loss=7.212, loss_v1=0, loss_v2=0, nll_loss=6.757, ntokens=930.4, nsentences=32, sample_size=930.4, sample_size_v1=0, sample_size_v2=0, ppl=108.15, wps=533.1, ups=0.57, wpb=930.4, bsz=32, num_updates=1800, lr=6.86761e-06, gnorm=7.344, clip=100, loss_scale=512, train_wall=17, gb_free=13.6, wall=18927
2023-02-19 20:26:19 - progress_bar.py[line:272] - INFO: epoch 001:   1811 / 21849 loss=6.499, loss_v1=0, loss_v2=0, nll_loss=5.956, ntokens=866.8, nsentences=32, sample_size=866.8, sample_size_v1=0, sample_size_v2=0, ppl=62.09, wps=496.9, ups=0.57, wpb=866.8, bsz=32, num_updates=1810, lr=6.90576e-06, gnorm=7.652, clip=100, loss_scale=512, train_wall=17, gb_free=13.7, wall=18945
2023-02-19 20:26:37 - progress_bar.py[line:272] - INFO: epoch 001:   1821 / 21849 loss=6.929, loss_v1=0, loss_v2=0, nll_loss=6.438, ntokens=976.9, nsentences=32, sample_size=976.9, sample_size_v1=0, sample_size_v2=0, ppl=86.69, wps=559.1, ups=0.57, wpb=976.9, bsz=32, num_updates=1820, lr=6.94391e-06, gnorm=7.33, clip=100, loss_scale=512, train_wall=17, gb_free=13.6, wall=18962
2023-02-19 20:26:54 - progress_bar.py[line:272] - INFO: epoch 001:   1831 / 21849 loss=6.056, loss_v1=0, loss_v2=0, nll_loss=5.455, ntokens=897.2, nsentences=32, sample_size=897.2, sample_size_v1=0, sample_size_v2=0, ppl=43.88, wps=516.3, ups=0.58, wpb=897.2, bsz=32, num_updates=1830, lr=6.98207e-06, gnorm=7.224, clip=100, loss_scale=512, train_wall=17, gb_free=13.6, wall=18980
2023-02-19 20:27:11 - progress_bar.py[line:272] - INFO: epoch 001:   1841 / 21849 loss=6.031, loss_v1=0, loss_v2=0, nll_loss=5.427, ntokens=920, nsentences=32, sample_size=920, sample_size_v1=0, sample_size_v2=0, ppl=43.04, wps=526.6, ups=0.57, wpb=920, bsz=32, num_updates=1840, lr=7.02022e-06, gnorm=7.197, clip=100, loss_scale=512, train_wall=17, gb_free=13.7, wall=18997
2023-02-19 20:27:29 - progress_bar.py[line:272] - INFO: epoch 001:   1851 / 21849 loss=6.977, loss_v1=0, loss_v2=0, nll_loss=6.489, ntokens=903.4, nsentences=32, sample_size=903.4, sample_size_v1=0, sample_size_v2=0, ppl=89.8, wps=519.5, ups=0.58, wpb=903.4, bsz=32, num_updates=1850, lr=7.05837e-06, gnorm=6.897, clip=100, loss_scale=512, train_wall=17, gb_free=13.6, wall=19014
2023-02-19 20:27:46 - progress_bar.py[line:272] - INFO: epoch 001:   1861 / 21849 loss=6.714, loss_v1=0, loss_v2=0, nll_loss=6.195, ntokens=894.4, nsentences=32, sample_size=894.4, sample_size_v1=0, sample_size_v2=0, ppl=73.24, wps=514, ups=0.57, wpb=894.4, bsz=32, num_updates=1860, lr=7.09653e-06, gnorm=7.688, clip=100, loss_scale=512, train_wall=17, gb_free=13.6, wall=19032
2023-02-19 20:28:04 - progress_bar.py[line:272] - INFO: epoch 001:   1871 / 21849 loss=5.656, loss_v1=0, loss_v2=0, nll_loss=5.004, ntokens=839.6, nsentences=32, sample_size=839.6, sample_size_v1=0, sample_size_v2=0, ppl=32.08, wps=481.7, ups=0.57, wpb=839.6, bsz=32, num_updates=1870, lr=7.13468e-06, gnorm=5.853, clip=100, loss_scale=512, train_wall=17, gb_free=13.7, wall=19049
2023-02-19 20:28:21 - progress_bar.py[line:272] - INFO: epoch 001:   1881 / 21849 loss=7.374, loss_v1=0, loss_v2=0, nll_loss=6.936, ntokens=981.8, nsentences=32, sample_size=981.8, sample_size_v1=0, sample_size_v2=0, ppl=122.44, wps=564.8, ups=0.58, wpb=981.8, bsz=32, num_updates=1880, lr=7.17283e-06, gnorm=7.488, clip=100, loss_scale=512, train_wall=17, gb_free=13.5, wall=19067
2023-02-19 20:28:38 - progress_bar.py[line:272] - INFO: epoch 001:   1891 / 21849 loss=7.265, loss_v1=0, loss_v2=0, nll_loss=6.815, ntokens=994.8, nsentences=32, sample_size=994.8, sample_size_v1=0, sample_size_v2=0, ppl=112.61, wps=572.5, ups=0.58, wpb=994.8, bsz=32, num_updates=1890, lr=7.21099e-06, gnorm=7.403, clip=100, loss_scale=512, train_wall=17, gb_free=13.6, wall=19084
2023-02-19 20:28:56 - progress_bar.py[line:272] - INFO: epoch 001:   1901 / 21849 loss=7.282, loss_v1=0, loss_v2=0, nll_loss=6.831, ntokens=950.6, nsentences=32, sample_size=950.6, sample_size_v1=0, sample_size_v2=0, ppl=113.83, wps=546.8, ups=0.58, wpb=950.6, bsz=32, num_updates=1900, lr=7.24914e-06, gnorm=7.292, clip=100, loss_scale=512, train_wall=17, gb_free=13.6, wall=19101
2023-02-19 20:29:13 - progress_bar.py[line:272] - INFO: epoch 001:   1911 / 21849 loss=7.491, loss_v1=0, loss_v2=0, nll_loss=7.068, ntokens=943.6, nsentences=32, sample_size=943.6, sample_size_v1=0, sample_size_v2=0, ppl=134.19, wps=542.9, ups=0.58, wpb=943.6, bsz=32, num_updates=1910, lr=7.28729e-06, gnorm=7.485, clip=100, loss_scale=512, train_wall=17, gb_free=13.6, wall=19119
2023-02-19 20:29:30 - progress_bar.py[line:272] - INFO: epoch 001:   1921 / 21849 loss=6.815, loss_v1=0, loss_v2=0, nll_loss=6.305, ntokens=892.9, nsentences=32, sample_size=892.9, sample_size_v1=0, sample_size_v2=0, ppl=79.09, wps=515.9, ups=0.58, wpb=892.9, bsz=32, num_updates=1920, lr=7.32545e-06, gnorm=8.087, clip=100, loss_scale=512, train_wall=17, gb_free=13.7, wall=19136
2023-02-19 20:29:48 - progress_bar.py[line:272] - INFO: epoch 001:   1931 / 21849 loss=6.085, loss_v1=0, loss_v2=0, nll_loss=5.482, ntokens=925.2, nsentences=32, sample_size=925.2, sample_size_v1=0, sample_size_v2=0, ppl=44.68, wps=533.1, ups=0.58, wpb=925.2, bsz=32, num_updates=1930, lr=7.3636e-06, gnorm=6.461, clip=100, loss_scale=512, train_wall=17, gb_free=13.6, wall=19153
2023-02-19 20:30:05 - progress_bar.py[line:272] - INFO: epoch 001:   1941 / 21849 loss=5.992, loss_v1=0, loss_v2=0, nll_loss=5.375, ntokens=791.3, nsentences=32, sample_size=791.3, sample_size_v1=0, sample_size_v2=0, ppl=41.5, wps=454.3, ups=0.57, wpb=791.3, bsz=32, num_updates=1940, lr=7.40176e-06, gnorm=8.229, clip=100, loss_scale=512, train_wall=17, gb_free=13.6, wall=19171
2023-02-19 20:30:23 - progress_bar.py[line:272] - INFO: epoch 001:   1951 / 21849 loss=5.93, loss_v1=0, loss_v2=0, nll_loss=5.321, ntokens=929.5, nsentences=32, sample_size=929.5, sample_size_v1=0, sample_size_v2=0, ppl=39.98, wps=533.5, ups=0.57, wpb=929.5, bsz=32, num_updates=1950, lr=7.43991e-06, gnorm=8.084, clip=100, loss_scale=512, train_wall=17, gb_free=13.6, wall=19188
2023-02-19 20:30:40 - progress_bar.py[line:272] - INFO: epoch 001:   1961 / 21849 loss=6.451, loss_v1=0, loss_v2=0, nll_loss=5.898, ntokens=935, nsentences=32, sample_size=935, sample_size_v1=0, sample_size_v2=0, ppl=59.62, wps=538.9, ups=0.58, wpb=935, bsz=32, num_updates=1960, lr=7.47806e-06, gnorm=8.491, clip=100, loss_scale=512, train_wall=17, gb_free=13.6, wall=19206
2023-02-19 20:30:57 - progress_bar.py[line:272] - INFO: epoch 001:   1971 / 21849 loss=5.607, loss_v1=0, loss_v2=0, nll_loss=4.964, ntokens=866.5, nsentences=32, sample_size=866.5, sample_size_v1=0, sample_size_v2=0, ppl=31.22, wps=499.3, ups=0.58, wpb=866.5, bsz=32, num_updates=1970, lr=7.51622e-06, gnorm=6.836, clip=100, loss_scale=512, train_wall=17, gb_free=13.6, wall=19223
2023-02-19 20:31:10 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-02-19 20:31:17 - progress_bar.py[line:272] - INFO: epoch 001:   1982 / 21849 loss=6.685, loss_v1=0, loss_v2=0, nll_loss=6.172, ntokens=1074, nsentences=32, sample_size=1074, sample_size_v1=0, sample_size_v2=0, ppl=72.09, wps=560.6, ups=0.52, wpb=1074, bsz=32, num_updates=1980, lr=7.55437e-06, gnorm=7.225, clip=100, loss_scale=256, train_wall=19, gb_free=13.5, wall=19242
2023-02-19 20:31:34 - progress_bar.py[line:272] - INFO: epoch 001:   1992 / 21849 loss=6.735, loss_v1=0, loss_v2=0, nll_loss=6.217, ntokens=910, nsentences=32, sample_size=910, sample_size_v1=0, sample_size_v2=0, ppl=74.38, wps=526.7, ups=0.58, wpb=910, bsz=32, num_updates=1990, lr=7.59252e-06, gnorm=8.687, clip=100, loss_scale=256, train_wall=17, gb_free=13.6, wall=19259
2023-02-19 20:31:51 - progress_bar.py[line:272] - INFO: epoch 001:   2002 / 21849 loss=7.164, loss_v1=0, loss_v2=0, nll_loss=6.697, ntokens=1040, nsentences=32, sample_size=1040, sample_size_v1=0, sample_size_v2=0, ppl=103.76, wps=597.7, ups=0.57, wpb=1040, bsz=32, num_updates=2000, lr=7.63068e-06, gnorm=7.186, clip=100, loss_scale=256, train_wall=17, gb_free=13.5, wall=19277
2023-02-19 20:31:51 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
